# ğŸŒŒ Total Perspective Vortex â€” EEG Brain-Computer Interface (BCI)

<div align="center">

![Python 3.10](https://img.shields.io/badge/python-3.10-blue.svg)
![License](https://img.shields.io/github/license/raveriss/Total_Perspective_Vortex)
[![CI](https://github.com/raveriss/Total_Perspective_Vortex/actions/workflows/ci.yml/badge.svg?branch=main)]()
![lint](https://img.shields.io/badge/lint-ruff%20âœ”-yellow)
![mypy](https://img.shields.io/badge/mypy-checked-purple)
[![Mutation](https://img.shields.io/badge/mutmut-â‰¥90%25-orange.svg)]()
[![codecov](https://codecov.io/github/raveriss/Total_Perspective_Vortex/graph/badge.svg?token=LSR1U908CU)](https://codecov.io/github/raveriss/Total_Perspective_Vortex)
[![Pre-commit](https://img.shields.io/badge/pre--commit-enabled-brightgreen?label=pre--commit)]()
![sklearn](https://img.shields.io/badge/scikit--learn-pipeline-blue)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)]()
[![Security](https://img.shields.io/badge/security-bandit-green.svg)]()
![mne](https://img.shields.io/badge/MNE-EEG%20Analysis-orange)
![numpy](https://img.shields.io/badge/numpy-math%20core-blue)
![pandas](https://img.shields.io/badge/pandas-data%20analysis-green)

</div>

---
## ğŸ“‘ Table des matiÃ¨res

- [ğŸŒŒ Total Perspective Vortex â€” EEG Brain-Computer Interface (BCI)](#total-perspective-vortex--eeg-brain-computer-interface-bci)
- [ğŸ“Œ Overview](#overview)
- [ğŸ“¥ TÃ©lÃ©charger le dÃ©pÃ´t](#-tÃ©lÃ©charger-le-dÃ©pÃ´t)
- [ğŸ§  Objectifs pÃ©dagogiques (42 / IA / ML)](#objectifs-pÃ©dagogiques-42--ia--ml)
- [ğŸ§© Architecture du projet](#architecture-du-projet)
- [ğŸ”¬ 1. PrÃ©processing & parsing EEG (MNE)](#1-prÃ©processing--parsing-eeg-mne)
- [ğŸ“Š Visualiser raw vs filtrÃ©](#-visualiser-raw-vs-filtrÃ©)
- [ğŸ§­ Justification scientifique : canaux & fenÃªtres temporelles](#-justification-scientifique--canaux--fenÃªtres-temporelles)
- [ğŸ›ï¸ 2. Extraction de features](#2-extraction-de-features)
- [ğŸ§® 3. RÃ©duction de dimension (PCA, CSP, ICAâ€¦)](#3-rÃ©duction-de-dimension-pca-csp-ica)
- [ğŸ§  4. Pipeline scikit-learn](#4-pipeline-scikit-learn)
- [ğŸ” 5. EntraÃ®nement](#5-entraÃ®nement)
- [âš¡ 6. PrÃ©diction en pseudo temps rÃ©el](#6-prÃ©diction-en-pseudo-temps-rÃ©el)
- [ğŸ§ª Tests & qualitÃ© logicielle](#tests--qualitÃ©-logicielle)
- [âœ… Contraintes officielles du sujet](#-contraintes-officielles-du-sujet)
- [ğŸ“š Stack technique](#stack-technique)
  - [Traitement du signal / maths](#traitement-du-signal--maths)
  - [Machine Learning](#machine-learning)
  - [QualitÃ© & Murphy Map](#qualitÃ©--murphy-map)
- [ğŸ§­ Vue dâ€™ensemble documentation](#-vue-densemble-documentation)
- [ğŸ” Pourquoi cette stack ?](#pourquoi-cette-stack-)
 [Â© Licence](#licence)
- [ğŸ“– Ressources utilisÃ©es](#ressources-utilisÃ©es)
- [ğŸ‘¤ Auteur](#auteur)

---

# ğŸ“Œ Overview

**Total Perspective Vortex** est un projet de **Brain-Computer Interface (BCI)** utilisant des donnÃ©es **EEG** pour dÃ©terminer, en quasi temps rÃ©el, lâ€™intention motrice dâ€™un individu (mouvement A ou B).

Il implÃ©mente un pipeline complet :

* ğŸ§  **Parsing & preprocessing EEG** (MNE, filtres 8â€“40 Hz)
* ğŸšï¸ **Extraction de features** (spectre, puissance, canaux Ã— temps)
* ğŸ”» **RÃ©duction de dimension** implÃ©mentÃ©e manuellement (CSP, PCA, ICAâ€¦)
* ğŸ”— **Pipeline scikit-learn** (baseEstimator + transformerMixin)
* ğŸ¤– **lassification supervisÃ©e**
* â±ï¸ **Prediction < 2 secondes** (lecture pseudo temps rÃ©el)
* ğŸ“ˆ **Validation croisÃ©e (cross_val_score)**
* ğŸ§ª **Accuracy â‰¥ 75 % sur sujets non vus â€“ mÃ©trique obligatoire**

Le travail final ne contient **que le code Python** ; le dataset EEG Physionet nâ€™est pas versionnÃ©.

---

## ğŸ“¥ TÃ©lÃ©charger le dÃ©pÃ´t

Cloner le projet depuis GitHub :

```bash
git clone https://github.com/raveriss/Total_Perspective_Vortex.git
cd Total_Perspective_Vortex
```
---

# ğŸ§  Objectifs pÃ©dagogiques (42 / IA / ML)

* Concevoir un **pipeline ML complet** sur donnÃ©es EEG
* ImplÃ©menter un **algorithme mathÃ©matique de rÃ©duction de dimension**
* IntÃ©grer ce module dans un **pipeline scikit-learn**
* Traiter un flux **temps rÃ©el**
* Travailler sur un dataset bruitÃ© (EEG rÃ©el)
* Manipuler **MNE**, **NumPy**, **Pandas**, **SciPy**, **scikit-learn**
* Construire des mÃ©triques reproductibles et un score fiable
* PrÃ©parer une dÃ©fense solide (norme 42 + comprÃ©hension algorithmique)

---

# ğŸ§© Architecture du projet

```
Total_Perspective_Vortex/
.
â”œâ”€â”€ AGENTS.md
â”œâ”€â”€ author
â”œâ”€â”€ codecov.yml
â”œâ”€â”€ create_tpv_fields.sh
â”œâ”€â”€ data
â”œâ”€â”€ docs
â”‚Â Â  â”œâ”€â”€ assets
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ image01.png
â”‚Â Â  â”‚Â Â  â””â”€â”€ image02.png
â”‚Â Â  â”œâ”€â”€ index.md
â”‚   â”œâ”€â”€ metrics
â”‚   â”‚   â”œâ”€â”€ eval_payload.json
â”‚   â”‚   â””â”€â”€ eval_payload.npz
â”‚Â Â  â”œâ”€â”€ project
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ benchmark_results.json
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ benchmark_results.md
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ checklist_wbs_matrix.md
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ gantt_tpv.png
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ physionet_dataset.md
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ roadmap.md
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ splits_metrics.md
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ split_strategy.md
â”‚Â Â  â”‚Â Â  â””â”€â”€ wbs_tpv.md
â”‚Â Â  â”œâ”€â”€ risk
â”‚Â Â  â”‚Â Â  â””â”€â”€ tpv_murphy_map.csv
â”‚Â Â  â”œâ”€â”€ total_perspective_vortex.en.checklist.pdf
â”‚Â Â  â””â”€â”€ Total_Perspective_Vortex.en.subject.pdf
â”œâ”€â”€ LICENSE
â”œâ”€â”€ Makefile
â”œâ”€â”€ mybci.py
â”œâ”€â”€ poetry.lock
â”œâ”€â”€ poetry.toml
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ README.md
â”œâ”€â”€ scripts
â”‚   â”œâ”€â”€ aggregate_accuracy.py
â”‚   â”œâ”€â”€ aggregate_experience_scores.py
â”‚   â”œâ”€â”€ aggregate_scores.py
â”‚   â”œâ”€â”€ benchmark.py
â”‚   â”œâ”€â”€ fetch_physionet.py
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ predict.py
â”‚   â”œâ”€â”€ prepare_physionet.py
â”‚   â”œâ”€â”€ sync_dataset.py
â”‚   â”œâ”€â”€ train.py
â”‚   â””â”€â”€ visualize_raw_filtered.py
â”œâ”€â”€ src
â”‚Â Â  â””â”€â”€ tpv
â”‚Â Â      â”œâ”€â”€ classifier.py
â”‚Â Â      â”œâ”€â”€ dimensionality.py
â”‚Â Â      â”œâ”€â”€ features.py
â”‚Â Â      â”œâ”€â”€ __init__.py
â”‚Â Â      â”œâ”€â”€ pipeline.py
â”‚Â Â      â”œâ”€â”€ predict.py
â”‚Â Â      â”œâ”€â”€ preprocessing.py
â”‚       â”œâ”€â”€ __pycache__
â”‚       â”‚   â”œâ”€â”€ classifier.cpython-310.pyc
â”‚       â”‚   â”œâ”€â”€ dimensionality.cpython-310.pyc
â”‚       â”‚   â”œâ”€â”€ features.cpython-310.pyc
â”‚       â”‚   â”œâ”€â”€ __init__.cpython-310.pyc
â”‚       â”‚   â”œâ”€â”€ pipeline.cpython-310.pyc
â”‚       â”‚   â”œâ”€â”€ preprocessing.cpython-310.pyc
â”‚       â”‚   â””â”€â”€ utils.cpython-310.pyc
â”‚Â Â      â”œâ”€â”€ realtime.py
â”‚Â Â      â”œâ”€â”€ train.py
â”‚Â Â      â””â”€â”€ utils.py
â””â”€â”€ tests
    â”œâ”€â”€ test_aggregate_scores_cli.py
    â”œâ”€â”€ test_benchmark.py
    â”œâ”€â”€ test_classifier.py
    â”œâ”€â”€ test_dimensionality.py
    â”œâ”€â”€ test_docs.py
    â”œâ”€â”€ test_experience_scores.py
    â”œâ”€â”€ test_features.py
    â”œâ”€â”€ test_fetch_physionet.py
    â”œâ”€â”€ test_mybci.py
    â”œâ”€â”€ test_pipeline.py
    â”œâ”€â”€ test_predict_cli.py
    â”œâ”€â”€ test_predict_evaluate_run.py
    â”œâ”€â”€ test_predict_load_data.py
    â”œâ”€â”€ test_predict_reports.py
    â”œâ”€â”€ test_prepare_physionet.py
    â”œâ”€â”€ test_preprocessing.py
    â”œâ”€â”€ test_realtime.py
    â”œâ”€â”€ test_scripts_roundtrip.py
    â”œâ”€â”€ test_sync_dataset.py
    â”œâ”€â”€ test_tpv_entrypoints.py
    â”œâ”€â”€ test_train_cli.py
    â”œâ”€â”€ test_train.py
    â”œâ”€â”€ test_utils.py
    â””â”€â”€ test_visualize_raw_filtered.py
```

---

## ğŸš€ Mise en route : donnÃ©es, installation, entraÃ®nement, prÃ©diction (Poetry + Makefile)

Le projet utilise **Poetry exclusivement** (aucun `requirements.txt`).
Le **Makefile** expose des raccourcis vers les commandes `poetry run ...`.

---

| Objectif | Commande recommandÃ©e | Commande Ã©quivalente |
|---|---|---|
| Installer | `make install` | `poetry install --with dev` |
| Linter | `make lint` | `poetry run ruff check .` |
| Formatter | `make format` | `poetry run ruff format . && poetry run ruff check --fix .` |
| Type-check | `make type` | `poetry run mypy src scripts tests` |
| Tests | `make test` | `PYTEST_DISABLE_PLUGIN_AUTOLOAD=1 poetry run pytest -vv` |
| Coverage | `make cov` | `PYTEST_DISABLE_PLUGIN_AUTOLOAD=1 poetry run coverage run -m pytest ...` |
| Mutation | `make mut` | `MUTMUT_USE_COVERAGE=1 ... poetry run mutmut run` |
| EntraÃ®ner | `make train` | `poetry run python mybci.py 109 3 train` *(par dÃ©faut)* |
| PrÃ©dire | `make predict` | `poetry run python mybci.py 109 3 predict` *(par dÃ©faut)* |
| Temps rÃ©el | `make realtime <subject> <run>` | `poetry run python src/tpv/realtime.py <subject> <run>` |
| Visualiser brut/filtrÃ© | `make visualizer <subject> <run>` | `poetry run python scripts/visualize_raw_filtered.py <subject> <run>` |
| Moyenne des moyennes | `make compute-mean-of-means` | `poetry run python scripts/aggregate_experience_scores.py` |
| Benchmark global | `make mybci` | `poetry run python mybci.py` |
| Nettoyer | `make clean` | supprime `./artifacts` + les `*.npy` (hors `.venv`, `.git`, `artifacts`) |

---

### ğŸ“¦ GÃ©nÃ©rer les artefacts manquants avant l'Ã©valuation globale

L'exÃ©cution de `make mybci` sans arguments dÃ©clenche
l'Ã©valuation des 6 expÃ©riences (3 â†’ 14) sur 109 sujets. Pour Ã©viter
les avertissements "aucun modÃ¨le disponible", assurez-vous que
`artifacts/<subject>/<run>/model.joblib` existe pour chaque run visÃ©.

*EntraÃ®ner un modÃ¨le manquant pour un couple sujet/run* :

```bash
make train 1 4
```

*EntraÃ®ner via Makefile avec une stratÃ©gie de features* :

```bash
make train 1 3 wavelet
```

---

# ğŸ”¬ 1. PrÃ©processing & parsing EEG (MNE)

* Lecture des fichiers Physionet
* Visualisation du signal brut
* Filtrage bande-passante 8â€“40 Hz
* DÃ©coupage des epochs (t0â€“tn)
* Extraction des Ã©vÃ©nements motrices (Left Hand / Right Hand / Feet)

**Structure locale attendue** (non versionnÃ©e) : `data/<subject>/<run>.edf`.
VÃ©rifiez lâ€™intÃ©gritÃ© et le nombre de runs avant tout parsing :

---

## ğŸ“Š Visualiser raw vs filtrÃ©

Ce script gÃ©nÃ¨re une figure comparative **signal brut vs signal filtrÃ©**
(bande-passante 8â€“40 Hz), afin de valider visuellement le prÃ©processing
sur un couple **(subject, run)** avant dâ€™enchaÃ®ner sur lâ€™extraction de features.

### Commande

> RecommandÃ© : exÃ©cuter via Poetry pour garantir lâ€™environnement.

```bash
make visualizer 1 3
```
<div align="center">
  <img src="https://github.com/raveriss/Total_Perspective_Vortex/blob/main/docs/assets/image01.png" alt="scripts visualize">
</div>

---

## ğŸ§­ Justification scientifique : canaux & fenÃªtres temporelles

Les canaux EEG retenus se concentrent sur la **rÃ©gion sensorimotrice**
(10-20) car lâ€™imagerie motrice induit des variations dâ€™ERD/ERS surtout
sur les sites **C3/Cz/C4** et leurs voisins fronto-centraux et centro-pariÃ©taux.
Cela aligne la sÃ©lection `DEFAULT_MOTOR_ROI` (ex: FC3/FC1/FCz/FC2/FC4,
C3/C1/Cz/C2/C4, CP3/CP1/CPz/CP2/CP4) du script
`scripts/visualize_raw_filtered.py` et les recommandations classiques en BCI
(Pfurtscheller & Neuper, 2001; Wolpaw et al., 2002).
RÃ©fÃ©rences :
* Pfurtscheller, G. & Neuper, C. (2001). Motor imagery and direct brain-computer communication.
  https://doi.org/10.1109/5.939829
* Wolpaw, J. R. et al. (2002). Brain-computer interfaces for communication.
  https://doi.org/10.1016/S1388-2457(02)00057-3

Les fenÃªtres temporelles dâ€™epoching **0.5â€“2.5 s**, **1.0â€“3.0 s** et **0.0â€“2.0 s**
correspondent aux valeurs par dÃ©faut de `tpv.utils.DEFAULT_EPOCH_WINDOWS`. Elles
Ã©vacuent la phase de rÃ©action immÃ©diate Ã  lâ€™indice visuel tout en couvrant la
rÃ©ponse motrice soutenue, ce qui limite les risques de fenÃªtres trop courtes
ou mal alignÃ©es avec lâ€™ERD/ERS (cf. Murphy TPV-032, TPV-052).

Pour **visualiser lâ€™impact** de ces choix (canaux + filtrage), utiliser le script
de comparaison brut/filtrÃ© :

```bash
make visualizer 1 3 C3 Cz C4
```

Ce graphique permet de vÃ©rifier visuellement que les canaux sensorimoteurs
prÃ©sentent bien une dynamique exploitable dans la bande 8â€“40 Hz avant
dâ€™alimenter la pipeline de features.

---

# ğŸ›ï¸ 2. Extraction de features

* Puissances par frÃ©quence
* Spectrogrammes ou FFT
* Projection channel Ã— time
* AgrÃ©gation temporelle

Tu dÃ©cides des features que tu veux envoyer Ã  ta matrice X âˆˆ R^(d Ã— N).

---

# ğŸ§® 3. RÃ©duction de dimension (PCA, CSP, ICAâ€¦)

ğŸ” **Partie obligatoire du sujet : implÃ©menter lâ€™algorithme soi-mÃªme**

* calcul des matrices de covariance
* dÃ©composition SVD / eigendecomposition
* normalisation
* projection Wáµ€X â†’ X'
* tests de cohÃ©rence dimensionnelle

---

# ğŸ§  4. Pipeline scikit-learn

Le sujet exige :

* hÃ©ritage de `baseEstimator` et `TransformerMixin`
* pipeline â†’ `[Preprocessing â†’ Dimensionality â†’ Classifier]`
* utilisation de `cross_val_score`

---

# ğŸ§ª Tests & qualitÃ© logicielle

* pytest
* ruff
* black
* mypy
* coverage
* mutation testing (mutmut)
  * la configuration Mutmut couvre `mybci.py`, `src/tpv` et `scripts` pour
    Ã©valuer la qualitÃ© sur l'ensemble du pipeline
* CI GitHub Actions + Codecov

### Matrice checklist â†’ WBS â†’ tests

| Item checklist TPV | WBS / livrable | Test ou commande reproductible |
| --- | --- | --- |
| Visualisation raw vs filtrÃ© | 3.3.1â€“3.3.4 | `poetry run python scripts/visualize_raw_filtered.py data/S001` ; `poetry run pytest tests/test_preprocessing.py::test_apply_bandpass_filter_preserves_shape_and_stability` |
| Filtre 8â€“30 Hz + notch 50 Hz | 3.1.1â€“3.1.3 | `poetry run pytest tests/test_preprocessing.py::test_apply_bandpass_filter_preserves_shape_and_stability` |
| RÃ©duction dimension (PCA/CSP) | 5.2.1â€“5.2.4 | `poetry run pytest tests/test_dimensionality.py::test_csp_returns_log_variances_and_orthogonality` |
| Pipeline sklearn (BaseEstimator/TransformerMixin) | 5.3.1â€“5.3.4 | `poetry run pytest tests/test_pipeline.py::test_pipeline_pickling_roundtrip` |
| Train + score via CLI | 6.3.x & 7.1.x | `poetry run pytest tests/test_classifier.py::test_training_cli_main_covers_parser_and_paths` |
| Predict renvoie lâ€™ID de classe | 1.2.x & 6.2.x | `poetry run pytest tests/test_classifier.py::test_predict_cli_main_covers_parser_and_report` |
| Temps rÃ©el < 2 s | 8.2.xâ€“8.3.x | `poetry run pytest tests/test_realtime.py::test_realtime_latency_threshold_enforced` |
| Score â‰¥ 75 % (agrÃ©gation) | 7.2.x | `poetry run pytest tests/test_classifier.py::test_aggregate_scores_exports_files_and_thresholds` |

### DÃ©finition du score global (scripts/aggregate_experience_scores.py)

* **Eligible** = sujet disposant des 4 types dâ€™expÃ©rience (T1..T4).
* **Mean** (par sujet) = moyenne des 4 moyennes dâ€™expÃ©rience.
* **MeetsThreshold_0p75** = `Mean >= 0.75`.
* **GlobalMean** = `(mean(T1) + mean(T2) + mean(T3) + mean(T4)) / 4`.
* Le script affiche les **10 pires sujets** par `Mean` et retourne **exit code 1**
  si `GlobalMean < 0.75`.

La version complÃ¨te et maintenable de cette matrice, incluant les rÃ©fÃ©rences aux risques Murphy, est disponible dans [`docs/project/checklist_wbs_matrix.md`](docs/project/checklist_wbs_matrix.md).

---

# âœ… Contraintes officielles du sujet

Ces exigences doivent Ãªtre **prÃ©sentes et respectÃ©es** dans toute la documentation et le code :

1. **FinalitÃ©** : classer en temps Â« rÃ©el Â» un signal EEG (imagination de mouvement A ou B).
2. **Source des donnÃ©es** : utiliser **exclusivement Physionet (EEG motor imagery)** ; les signaux sont des matrices **channels Ã— time** avec runs dÃ©coupÃ©s et labellisÃ©s proprement.
3. **PrÃ©traitement obligatoire** :
   - visualiser le signal brut dans un script dÃ©diÃ© ;
   - filtrer les bandes utiles (theta, alpha, betaâ€¦ au choix) ;
   - visualiser aprÃ¨s prÃ©traitement ;
   - extraire les features (spectre, PSD, etc.) ;
   - ğŸš« interdiction implicite : ne pas utiliser `mne-realtime`.
4. **Pipeline ML** :
   - utilisation obligatoire de `sklearn.pipeline.Pipeline` ;
   - transformer maison hÃ©ritant de `BaseEstimator` et `TransformerMixin` ;
   - implÃ©menter soi-mÃªme la rÃ©duction **PCA, ICA, CSP ou CSSP** (NumPy/SciPy autorisÃ©s, pas de version prÃªte de sklearn ou MNE).
5. **EntraÃ®nement/validation/test** :
   - `cross_val_score` sur lâ€™ensemble du pipeline ;
   - splits **Train / Validation / Test** distincts pour Ã©viter lâ€™overfit ;
   - moyenne dâ€™**accuracy â‰¥ 60 %** sur **tous les sujets du jeu de test** et les **6 runs** dâ€™expÃ©riences, sur des donnÃ©es **jamais apprises**.
6. **Temps rÃ©el** : le script `predict` lit un flux simulÃ© (lecture progressive dâ€™un fichier) et produit une prÃ©diction en **< 2 secondes** aprÃ¨s chaque chunk.
7. **Architecture** : fournir un script **train** et un script **predict** ; le dÃ©pÃ´t final contient **uniquement le code Python** (pas le dataset).
8. **Bonus facultatifs** : wavelets pour le spectre, classifieur maison ou autres datasets EEG.
9. **Formalisme mathÃ©matique** : pour le transformer, avec X âˆˆ R^{d Ã— N}, produire une matrice W telle que W^T X = X_{CSP}/X_{PCA}/X_{ICA}.

# ğŸ“š Stack technique

### Traitement du signal / maths

* **NumPy** (matrices, opÃ©rations vectorisÃ©es)
* **SciPy** (eigenvalues, SVD)
* **MNE** (EEG parsing)

### Machine Learning

* **scikit-learn** (pipeline, classif, cross-validation)

### QualitÃ© & Murphy Map

* ruff, black, mypy
* pytest, coverage, mutmut
* GitHub Actions, Codecov

Les fichiers de cartographie des risques (Loi de Murphy) se trouvent dans :

- `docs/qa/murphy_map_tpv.csv`

---

## ğŸ§­ Vue dâ€™ensemble documentation

Tous les jalons projet sont rÃ©capitulÃ©s dans [`docs/index.md`](docs/index.md), avec des liens directs vers le WBS, le diagramme de Gantt, la roadmap et la Murphy map.

---

## ğŸ“– Ressources utilisÃ©es

Les contenus suivants ont Ã©tÃ© essentiels pour comprendre lâ€™EEG, les
filtres spatiaux (CSP) et la mise en place dâ€™un pipeline dâ€™analyse
monotrial robuste :

- ğŸ¥ [Playlist YouTube â€” Machine Learning from Scratch](https://www.youtube.com/playlist?list=PLO_fdPEVlfKqUF5BPKjGSh7aV9aBshrpY)
  SÃ©rie pÃ©dagogique pour consolider les bases de lâ€™apprentissage supervisÃ©
  (modÃ¨les linÃ©aires, descente de gradient, rÃ©gularisation) utilisÃ©es pour
  entraÃ®ner le classifieur sur les features EEG.

- ğŸ“„ [WikipÃ©dia â€” Ã‰lectroencÃ©phalographie](https://fr.wikipedia.org/wiki/%C3%89lectroenc%C3%A9phalographie)
  Notions fondamentales sur lâ€™EEG, lâ€™acquisition du signal et le rÃ´le des
  Ã©lectrodes, indispensables pour interprÃ©ter les donnÃ©es brutes.

- ğŸ“„ [WikipÃ©dia â€” Common spatial pattern](https://en.wikipedia.org/wiki/Common_spatial_pattern)
  PrÃ©sentation du principe des filtres spatiaux CSP, de la maximisation de
  la variance entre classes et de leur utilisation en BCI.

- ğŸ“„ [Blankertz et al., *Optimizing Spatial Filters for Robust EEG Single-Trial Analysis*](https://doc.ml.tu-berlin.de/bbci/publications/BlaTomLemKawMue08.pdf)
  Article de rÃ©fÃ©rence dÃ©crivant les stratÃ©gies dâ€™optimisation de filtres
  spatiaux pour amÃ©liorer la robustesse de lâ€™analyse EEG monotrial.

- ğŸ—„ï¸ [PhysioNet â€” EEG Motor Movement/Imagery Dataset v1.0.0](https://physionet.org/content/eegmmidb/1.0.0/)
- ğŸ·ï¸ [ICLabel â€” Tutoriel â€œEEG Independent Component Labelingâ€](https://labeling.ucsd.edu/tutorial/labels)
- ğŸ“š [MNE-Python â€” Tutoriels officiels](https://mne.tools/dev/auto_tutorials/index.html)
- ğŸ“ [Importing EEG data â€” blog / guide pratique](https://cbrnr.github.io/blog/importing-eeg-data/)

---

# Â© Licence

MIT License.

---
# ğŸ‘¤ Auteur

**Rafael Verissimo**
Ã‰tudiant IA/Data â€” Ã‰cole 42 Paris
GitHub : https://github.com/raveriss
LinkedIn : https://www.linkedin.com/in/verissimo-rafael/
