# ğŸŒŒ Total Perspective Vortex â€” EEG Brain-Computer Interface (BCI)

<div align="center">

![Python 3.10](https://img.shields.io/badge/python-3.10-blue.svg)
![License](https://img.shields.io/github/license/raveriss/Total_Perspective_Vortex)
[![CI](https://github.com/raveriss/Total_Perspective_Vortex/actions/workflows/ci.yml/badge.svg?branch=main)]()
![lint](https://img.shields.io/badge/lint-ruff%20âœ”-yellow)
![mypy](https://img.shields.io/badge/mypy-checked-purple)
[![Mutation](https://img.shields.io/badge/mutmut-â‰¥90%25-orange.svg)]()
[![codecov](https://codecov.io/github/raveriss/Total_Perspective_Vortex/graph/badge.svg?token=LSR1U908CU)](https://codecov.io/github/raveriss/Total_Perspective_Vortex)
[![Pre-commit](https://img.shields.io/badge/pre--commit-enabled-brightgreen?label=pre--commit)]()
![sklearn](https://img.shields.io/badge/scikit--learn-pipeline-blue)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)]()
[![Security](https://img.shields.io/badge/security-bandit-green.svg)]()
![mne](https://img.shields.io/badge/MNE-EEG%20Analysis-orange)
![numpy](https://img.shields.io/badge/numpy-math%20core-blue)
![pandas](https://img.shields.io/badge/pandas-data%20analysis-green)

</div>

---
## ğŸ“‘ Table des matiÃ¨res

- [ğŸŒŒ Total Perspective Vortex â€” EEG Brain-Computer Interface (BCI)](#total-perspective-vortex--eeg-brain-computer-interface-bci)
- [ğŸ“Œ Overview](#overview)
- [ğŸ§  Objectifs pÃ©dagogiques (42 / IA / ML)](#objectifs-pÃ©dagogiques-42--ia--ml)
- [ğŸ§© Architecture du projet](#architecture-du-projet)
- [ğŸ”¬ 1. PrÃ©processing & parsing EEG (MNE)](#1-prÃ©processing--parsing-eeg-mne)
- [ğŸ›ï¸ 2. Extraction de features](#2-extraction-de-features)
- [ğŸ§® 3. RÃ©duction de dimension (PCA, CSP, ICAâ€¦)](#3-rÃ©duction-de-dimension-pca-csp-ica)
- [ğŸ§  4. Pipeline scikit-learn](#4-pipeline-scikit-learn)
- [ğŸ” 5. EntraÃ®nement](#5-entraÃ®nement)
- [âš¡ 6. PrÃ©diction en pseudo temps rÃ©el](#6-prÃ©diction-en-pseudo-temps-rÃ©el)
- [ğŸ§ª Tests & qualitÃ© logicielle](#tests--qualitÃ©-logicielle)
- [âœ… Contraintes officielles du sujet](#-contraintes-officielles-du-sujet)
- [ğŸ“š Stack technique](#stack-technique)
  - [Traitement du signal / maths](#traitement-du-signal--maths)
  - [Machine Learning](#machine-learning)
  - [QualitÃ© & Murphy Map](#qualitÃ©--murphy-map)
- [ğŸ” Pourquoi cette stack ?](#pourquoi-cette-stack-)
 [Â© Licence](#licence)
- [ğŸ“– Ressources utilisÃ©es](#ressources-utilisÃ©es)
- [ğŸ‘¤ Auteur](#auteur)

---

# ğŸ“Œ Overview

**Total Perspective Vortex** est un projet de **Brain-Computer Interface (BCI)** utilisant des donnÃ©es **EEG** pour dÃ©terminer, en quasi temps rÃ©el, lâ€™intention motrice dâ€™un individu (mouvement A ou B).

Il implÃ©mente un pipeline complet :

* ğŸ§  **Parsing & preprocessing EEG** (MNE, filtres 8â€“40 Hz)
* ğŸšï¸ **Extraction de features** (spectre, puissance, canaux Ã— temps)
* ğŸ”» **RÃ©duction de dimension** implÃ©mentÃ©e manuellement (CSP, PCA, ICAâ€¦)
* ğŸ”— **Pipeline scikit-learn** (baseEstimator + transformerMixin)
* ğŸ¤– **lassification supervisÃ©e**
* â±ï¸ **Prediction < 2 secondes** (lecture pseudo temps rÃ©el)
* ğŸ“ˆ **Validation croisÃ©e (cross_val_score)**
* ğŸ§ª **Accuracy â‰¥ 60 % sur sujets non vus â€“ mÃ©trique obligatoire**

Le travail final ne contient **que le code Python** ; le dataset EEG Physionet nâ€™est pas versionnÃ©.

---

# ğŸ§  Objectifs pÃ©dagogiques (42 / IA / ML)

* Concevoir un **pipeline ML complet** sur donnÃ©es EEG
* ImplÃ©menter un **algorithme mathÃ©matique de rÃ©duction de dimension**
* IntÃ©grer ce module dans un **pipeline scikit-learn**
* Traiter un flux **temps rÃ©el**
* Travailler sur un dataset bruitÃ© (EEG rÃ©el)
* Manipuler **MNE**, **NumPy**, **Pandas**, **SciPy**, **scikit-learn**
* Construire des mÃ©triques reproductibles et un score fiable
* PrÃ©parer une dÃ©fense solide (norme 42 + comprÃ©hension algorithmique)

---

# ğŸ§© Architecture du projet

```
Total_Perspective_Vortex/
â”œâ”€â”€ docs
â”‚   â”œâ”€â”€ assets
â”‚   â”‚   â”œâ”€â”€ image01.png
â”‚   â”‚   â””â”€â”€ image02.png
â”‚   â”œâ”€â”€ project
â”‚   â”‚   â”œâ”€â”€ gantt_tpv.png
â”‚   â”‚   â”œâ”€â”€ roadmap.md
â”‚   â”‚   â””â”€â”€ wbs_tpv_v1.md
â”‚   â”œâ”€â”€ risk
â”‚   â”‚   â””â”€â”€ tpv_murphy_map_v8.csv
â”‚   â”œâ”€â”€ total_perspective_vortex.en.checklist.pdf
â”‚   â””â”€â”€ Total_Perspective_Vortex.en.subject.pdf
â”œâ”€â”€ LICENSE
â”œâ”€â”€ Makefile
â”œâ”€â”€ poetry.lock
â”œâ”€â”€ poetry.toml
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ README.md
â”œâ”€â”€ scripts
â”‚   â”œâ”€â”€ predict.py
â”‚   â”œâ”€â”€ train.py
â”‚   â””â”€â”€ visualize_raw_filtered.py
â”œâ”€â”€ src
â”‚   â””â”€â”€ tpv
â”‚       â”œâ”€â”€ classifier.py
â”‚       â”œâ”€â”€ dimensionality.py
â”‚       â”œâ”€â”€ features.py
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ pipeline.py
â”‚       â”œâ”€â”€ predict.py
â”‚       â”œâ”€â”€ preprocessing.py
â”‚       â”œâ”€â”€ realtime.py
â”‚       â”œâ”€â”€ train.py
â”‚       â””â”€â”€ utils.py
â””â”€â”€ tests
    â”œâ”€â”€ test_classifier.py
    â”œâ”€â”€ test_dimensionality.py
    â”œâ”€â”€ test_pipeline.py
    â”œâ”€â”€ test_preprocessing.py
    â””â”€â”€ test_realtime.py
```

---

## ğŸš€ Installation et gestion des dÃ©pendances (Poetry uniquement)

Lâ€™environnement est gÃ©rÃ© exclusivement avec **Poetry** (aucun fichier
`requirements.txt` nâ€™est utilisÃ©).

```bash
poetry install --with dev
```

Les commandes CLI existantes restent accessibles via Poetry, par exemple :

```bash
poetry run python mybci.py S01 R01 train
poetry run python mybci.py S01 R01 predict
```

---

# ğŸ”¬ 1. PrÃ©processing & parsing EEG (MNE)

* Lecture des fichiers Physionet
* Visualisation du signal brut
* Filtrage bande-passante 8â€“40 Hz
* DÃ©coupage des epochs (t0â€“tn)
* Extraction des Ã©vÃ©nements motrices (Left Hand / Right Hand / Feet)

Exemple :

```bash
poetry run python scripts/visualize_raw_filtered.py ./path/to/eeg/
```

---

# ğŸ›ï¸ 2. Extraction de features

* Puissances par frÃ©quence
* Spectrogrammes ou FFT
* Projection channel Ã— time
* AgrÃ©gation temporelle

Tu dÃ©cides des features que tu veux envoyer Ã  ta matrice X âˆˆ R^(d Ã— N).

---

# ğŸ§® 3. RÃ©duction de dimension (PCA, CSP, ICAâ€¦)

ğŸ” **Partie obligatoire du sujet : implÃ©menter lâ€™algorithme soi-mÃªme**

* calcul des matrices de covariance
* dÃ©composition SVD / eigendecomposition
* normalisation
* projection Wáµ€X â†’ X'
* tests de cohÃ©rence dimensionnelle

Exemple :

```python
from tpv.dimensionality import CSP
transformer = CSP(n_components=4)
X_reduced = transformer.fit_transform(X, y)
```

---

# ğŸ§  4. Pipeline scikit-learn

Le sujet exige :

* hÃ©ritage de `baseEstimator` et `TransformerMixin`
* pipeline â†’ `[Preprocessing â†’ Dimensionality â†’ Classifier]`
* utilisation de `cross_val_score`

Exemple :

```python
pipeline = Pipeline([
    ("reduce", CSP(n_components=4)),
    ("clf", LinearDiscriminantAnalysis())
])
```

---

# ğŸ” 5. EntraÃ®nement

Lâ€™interface CLI unifiÃ©e `mybci.py` lance les modules `tpv.train` et `tpv.predict` avec
des identifiants explicites :

```bash
python mybci.py S01 R01 train
```

Raccourci Makefile avec des valeurs par dÃ©faut modifiables :

```bash
make train TRAIN_SUBJECT=S01 TRAIN_RUN=R01
```

Affiche :

* scores cross_val_score
* statistiques par run
* moyenne â‰¥ 60 % requise sur sujets jamais vus

---

# âš¡ 6. PrÃ©diction en pseudo temps rÃ©el

RÃ©utilise la mÃªme CLI pour la phase inference :

```bash
python mybci.py S01 R01 predict
```

Ou via le Makefile :

```bash
make predict PREDICT_SUBJECT=S01 PREDICT_RUN=R01
```

Contraintes :

* lecture par chunks simulant un flux
* prÃ©diction < **2 secondes** aprÃ¨s rÃ©ception
* sortie de classe {1, 2}

---

# ğŸ§ª Tests & qualitÃ© logicielle

* pytest
* ruff
* black
* mypy
* coverage
* mutation testing (mutmut)
* CI GitHub Actions + Codecov

---


# âœ… Contraintes officielles du sujet

Ces exigences doivent Ãªtre **prÃ©sentes et respectÃ©es** dans toute la documentation et le code :

1. **FinalitÃ©** : classer en temps Â« rÃ©el Â» un signal EEG (imagination de mouvement A ou B).
2. **Source des donnÃ©es** : utiliser **exclusivement Physionet (EEG motor imagery)** ; les signaux sont des matrices **channels Ã— time** avec runs dÃ©coupÃ©s et labellisÃ©s proprement.
3. **PrÃ©traitement obligatoire** :
   - visualiser le signal brut dans un script dÃ©diÃ© ;
   - filtrer les bandes utiles (theta, alpha, betaâ€¦ au choix) ;
   - visualiser aprÃ¨s prÃ©traitement ;
   - extraire les features (spectre, PSD, etc.) ;
   - ğŸš« interdiction implicite : ne pas utiliser `mne-realtime`.
4. **Pipeline ML** :
   - utilisation obligatoire de `sklearn.pipeline.Pipeline` ;
   - transformer maison hÃ©ritant de `BaseEstimator` et `TransformerMixin` ;
   - implÃ©menter soi-mÃªme la rÃ©duction **PCA, ICA, CSP ou CSSP** (NumPy/SciPy autorisÃ©s, pas de version prÃªte de sklearn ou MNE).
5. **EntraÃ®nement/validation/test** :
   - `cross_val_score` sur lâ€™ensemble du pipeline ;
   - splits **Train / Validation / Test** distincts pour Ã©viter lâ€™overfit ;
   - moyenne dâ€™**accuracy â‰¥ 60 %** sur **tous les sujets du jeu de test** et les **6 runs** dâ€™expÃ©riences, sur des donnÃ©es **jamais apprises**.
6. **Temps rÃ©el** : le script `predict` lit un flux simulÃ© (lecture progressive dâ€™un fichier) et produit une prÃ©diction en **< 2 secondes** aprÃ¨s chaque chunk.
7. **Architecture** : fournir un script **train** et un script **predict** ; le dÃ©pÃ´t final contient **uniquement le code Python** (pas le dataset).
8. **Bonus facultatifs** : wavelets pour le spectre, classifieur maison ou autres datasets EEG.
9. **Formalisme mathÃ©matique** : pour le transformer, avec X âˆˆ R^{d Ã— N}, produire une matrice W telle que W^T X = X_{CSP}/X_{PCA}/X_{ICA}.

# ğŸ“š Stack technique

### Traitement du signal / maths

* **NumPy** (matrices, opÃ©rations vectorisÃ©es)
* **SciPy** (eigenvalues, SVD)
* **MNE** (EEG parsing)

### Machine Learning

* **scikit-learn** (pipeline, classif, cross-validation)

### QualitÃ© & Murphy Map

* ruff, black, mypy
* pytest, coverage, mutmut
* GitHub Actions, Codecov

Les fichiers de cartographie des risques (Loi de Murphy) se trouvent dans :

- `docs/qa/murphy_map_tpv.csv`

---

## ğŸ“– Ressources utilisÃ©es

Les contenus suivants ont Ã©tÃ© essentiels pour comprendre lâ€™EEG, les
filtres spatiaux (CSP) et la mise en place dâ€™un pipeline dâ€™analyse
monotrial robuste :

- ğŸ¥ [Playlist YouTube â€” Machine Learning from Scratch](https://www.youtube.com/playlist?list=PLO_fdPEVlfKqUF5BPKjGSh7aV9aBshrpY)
  SÃ©rie pÃ©dagogique pour consolider les bases de lâ€™apprentissage supervisÃ©
  (modÃ¨les linÃ©aires, descente de gradient, rÃ©gularisation) utilisÃ©es pour
  entraÃ®ner le classifieur sur les features EEG.

- ğŸ“„ [WikipÃ©dia â€” Ã‰lectroencÃ©phalographie](https://fr.wikipedia.org/wiki/%C3%89lectroenc%C3%A9phalographie)
  Notions fondamentales sur lâ€™EEG, lâ€™acquisition du signal et le rÃ´le des
  Ã©lectrodes, indispensables pour interprÃ©ter les donnÃ©es brutes.

- ğŸ“„ [WikipÃ©dia â€” Common spatial pattern](https://en.wikipedia.org/wiki/Common_spatial_pattern)
  PrÃ©sentation du principe des filtres spatiaux CSP, de la maximisation de
  la variance entre classes et de leur utilisation en BCI.

- ğŸ“„ [Blankertz et al., *Optimizing Spatial Filters for Robust EEG Single-Trial Analysis*](https://doc.ml.tu-berlin.de/bbci/publications/BlaTomLemKawMue08.pdf)
  Article de rÃ©fÃ©rence dÃ©crivant les stratÃ©gies dâ€™optimisation de filtres
  spatiaux pour amÃ©liorer la robustesse de lâ€™analyse EEG monotrial.

---

# Â© Licence

MIT License.

---
# ğŸ‘¤ Auteur

**Rafael Verissimo**
Ã‰tudiant IA/Data â€” Ã‰cole 42 Paris
GitHub : https://github.com/raveriss
LinkedIn : https://www.linkedin.com/in/verissimo-rafael/
