# AGENTS.md â€” Blueprint Dev / QualitÃ© / WBS / Loi de Murphy (Total_Perspective_Vortex)

**Contexte cible** : Ubuntu 22.04.5 (Jammy), Python 3.10.18, **pas de sudo**,
**Poetry**, exÃ©cution **uniquement sur Ubuntu**.

Ce document sert de **plan dâ€™action exÃ©cutable** pour les agents (LLM/Codex)
chargÃ©s de modifier le dÃ©pÃ´t **Total_Perspective_Vortex**.

Tous les agents doivent considÃ©rer comme **sources de vÃ©ritÃ©** :

- le **WBS** : `docs/project/wbs_tpv.md`
- le **Gantt / roadmap** : `docs/project/gantt_tpv.png`, `docs/project/roadmap.md`
- la **Murphy Map** : `docs/risk/tpv_murphy_map.csv`
- le **GitHub Project** :
  `Total_Perspective_Vortex â€“ WBS & Murphy Map â€“ v1.0 - 2025/11/28`
- les **issues GitHub** du repo : `raveriss/Total_Perspective_Vortex`

Aucune implÃ©mentation, refactor ou ajout de fichier ne doit Ãªtre rÃ©alisÃ©
hors de ce cadrage (WBS + risques + issues).


---

## ğŸ¯ Contraintes BCI obligatoires

Les contraintes suivantes doivent figurer simultanÃ©ment dans README, AGENTS et Murphy Map et Ãªtre respectÃ©es dans le code :

1. **FinalitÃ©** : classer en temps Â« rÃ©el Â» un signal EEG (imagination de mouvement A ou B).
2. **Source des donnÃ©es** : jeu **Physionet EEG motor imagery** obligatoire ; signaux structurÃ©s en matrice **channels Ã— time** avec runs dÃ©coupÃ©s et labellisÃ©s proprement.
3. **PrÃ©traitement obligatoire** : visualisation du brut (script dÃ©diÃ©), filtrage des bandes utiles (theta/alpha/betaâ€¦), visualisation aprÃ¨s prÃ©traitement, extraction des features (spectre/PSDâ€¦), et interdiction implicite dâ€™utiliser `mne-realtime`.
4. **Pipeline ML** : utilisation de `sklearn.pipeline.Pipeline`, transformer maison hÃ©ritant de `BaseEstimator` et `TransformerMixin`, rÃ©duction de dimension **PCA/ICA/CSP/CSSP implÃ©mentÃ©e Ã  la main** (NumPy/SciPy autorisÃ©s, pas de version prÃªte de sklearn/MNE).
5. **EntraÃ®nement/validation/test** : `cross_val_score` sur le pipeline complet, splits **Train/Validation/Test** distincts (pas dâ€™overfit), accuracy moyenne **â‰¥ 60 %** sur **tous les sujets de test** et les **6 runs** sur donnÃ©es **jamais apprises**.
6. **Temps rÃ©el** : le script `predict` lit un flux simulÃ© (lecture progressive) et fournit chaque prÃ©diction en **moins de 2 secondes** aprÃ¨s rÃ©ception dâ€™un chunk.
7. **Architecture** : prÃ©sence dâ€™un script **train** et dâ€™un script **predict** ; le dÃ©pÃ´t final versionnÃ© contient **uniquement le code Python** (dataset exclu).
8. **Bonus facultatifs** : wavelets pour le spectre, classifieur maison, autres datasets EEG.
9. **Formalisme mathÃ©matique** : pour le transformer, avec X âˆˆ R^{d Ã— N}, produire une matrice W telle que W^T X = X_{CSP}/X_{PCA}/X_{ICA}.
10. **Posture dÃ©fense-proof globale** : pour implÃ©menter `Total_Perspective_Vortex` avec une posture TDD systÃ©matique, couverture 100 %, diff=100 %, contrÃ´le par fichier, CI Ubuntu-only.

---

## ğŸ” RÃ¨gles pour les agents (LLM / Codex)

Avant de gÃ©nÃ©rer du code, **tout agent** doit :

1. **Identifier le WBS ID concernÃ©**
   - Chercher dans `docs/project/wbs_tpv.md` la tÃ¢che correspondante.
   - Si aucune tÃ¢che ne correspond, **ne pas inventer de feature** :
     proposer dâ€™abord une mise Ã  jour du WBS.

2. **Consulter la Murphy Map**
   - Filtrer `docs/risk/tpv_murphy_map.csv` sur ce WBS ID.
   - Lister les `Murphy ID` associÃ©s et leurs risques (cause, effet).
   - Adapter le design / les tests pour couvrir ces risques.

3. **Travailler via une issue GitHub**
   - VÃ©rifier quâ€™une issue existe pour ce WBS ID.
   - Si ce nâ€™est pas le cas, proposer une **issue Ã  crÃ©er** avec :
     - titre = WBS ID + rÃ©sumÃ© court,
     - lien vers les sections WBS + Murphy Map concernÃ©es.

4. **Mettre Ã  jour lâ€™item dans le GitHub Project**
   - Associer lâ€™issue Ã  lâ€™item du Project.
   - Mettre Ã  jour les champs : `Status`, `Phase`, `Type`, `Priority`,
     `Risk score` si pertinent.

5. **Ne jamais livrer de code sans trace WBS**
   - Tout nouveau module / script / test doit pouvoir Ãªtre reliÃ© Ã  un
     `WBS ID` et, si applicable, Ã  un ou plusieurs `Murphy ID`.
   - En cas de doute, lâ€™agent doit **refuser lâ€™implÃ©mentation** et
     demander une clarification WBS / risques.
6. **Respect strict de la structure TPV**
   - Aucun fichier ne doit Ãªtre crÃ©Ã© en dehors de :
     - `src/tpv/` (code ML / EEG)
     - `scripts/` (scripts CLI ou visualisation)
     - `tests/` (tests)
     - `docs/` (documentation)
   - Aucun fichier Python ne doit Ãªtre ajoutÃ© Ã  la racine, sauf `mybci.py`.
   - Toute proposition de nouveau fichier doit pointer vers :
     - un **WBS ID**,
     - une **issue GitHub** existante ou Ã  crÃ©er,
     - un ou plusieurs **Murphy ID** associÃ©s.


## 0) ğŸ—ï¸ Fondations techniques & outillage

### 0.1 Git & hygiÃ¨ne de repo
- [ ] Init repo + `README.md` (usage, sÃ©quence de soutenance, badges CI si voulu)
- [ ] `LICENSE` (MIT) + `author`
- [ ] Convention commits : `feat:`, `fix:`, `refactor:`, `test:`, `docs:`

### 0.2 Environnement & dÃ©pendances (Poetry, noâ€‘sudo)
- [ ] Installer Poetry (utilisateur)Â :
  ```bash
  curl -sSL https://install.python-poetry.org | python3 -
  export PATH="$HOME/.local/bin:$PATH"
  poetry config virtualenvs.in-project true
  poetry env use 3.10
  ```
- [ ] `pyproject.toml`Â â€” **versions Python verrouillÃ©es**Â :
  ```toml
  [tool.poetry]
  name = "total-perspective-vortex"
  version = "0.1.0"
  description = "EEG Brain-Computer Interface pipeline for the Total Perspective Vortex project."
  authors = ["raveriss <you@example.com>"]
  license = "MIT"
  readme = "README.md"
  packages = [{ include = "tpv", from = "src" }]

  [tool.poetry.dependencies]
  python = ">=3.10,<3.11"
  numpy = "^1.26"
  pandas = "^2.2"
  scipy = "^1.11"
  scikit-learn = "^1.3"
  mne = "^1.6"
  matplotlib = "^3.8"
  joblib = "^1.4"

  [tool.poetry.group.dev.dependencies]
  pytest = "^8.3"
  pytest-cov = "^5.0"
  pytest-timeout = "^2.3"
  pytest-randomly = "^3.15"
  hypothesis = "^6.112"
  mypy = "^1.11"
  ruff = "^0.6"
  black = "^24.10"
  isort = "^5.13"
  bandit = "^1.7"
  mutmut = "^3.0"
  radon = "^6.0"
  xenon = "^0.9"
  pre-commit = "^4.0"
  pip-audit = "^2.7"
  coverage = "^7.6"

  [tool.black]
  line-length = 88
  target-version = ["py310"]

  [tool.isort]
  profile = "black"
  line_length = 88
  known_first_party = ["mybci", "tpv"]
  src_paths = ["src", "scripts", "tests"]

  [tool.ruff]
  line-length = 88
  target-version = "py310"

  [tool.ruff.lint]
  select = ["E", "F", "W", "I", "B", "PL", "C4"]
  ignore = []

  [tool.ruff.lint.isort]
  known-first-party = ["mybci", "tpv"]

  [tool.mutmut]
  paths_to_mutate = ["mybci.py", "src/tpv"]
  tests_dir = "tests"
  pytest_add_cli_args = ["-q"]
  mutate_only_covered_lines = true

  [tool.pytest.ini_options]
  pythonpath = ["src", ".", ".."]

  [tool.mypy]
  python_version = "3.10"
  check_untyped_defs = true
  warn_unused_ignores = true
  warn_return_any = true
  warn_redundant_casts = true
  strict_optional = true
  no_implicit_optional = true
  show_error_codes = true
  pretty = true
  ignore_missing_imports = true
  files = "src scripts tests"

  [build-system]
  requires = ["poetry-core"]
  build-backend = "poetry.core.masonry.api"


  ```

### 0.3 Makefile (raccourcis non intrusifs)
```Makefile
# ========================================================================================
# Makefile - Automatisation pour le projet Total_Perspective_Vortex
# Objectifs :
#   - Simplifier lâ€™installation et la gestion de lâ€™environnement (Poetry / venv)
#   - Automatiser les vÃ©rifications (lint, format, type-check, tests, coverage, mutation)
#   - Fournir des commandes pratiques pour lâ€™entraÃ®nement et la prÃ©diction du modÃ¨le
# ========================================================================================

.PHONY: install lint format type test cov mut train predict  activate deactivate

VENV = .venv
VENV_BIN = $(VENV)/bin/activate

# --- Benchmarks ---------------------------------------------------------------
BENCH_DIR   := data/benchmarks
BENCH_CSVS  := $(wildcard $(BENCH_DIR)/*.csv)

# Utilisation raccourcie de Poetry
POETRY = poetry run

# ----------------------------------------------------------------------------------------
# Installation des dÃ©pendances (dev inclus)
# ----------------------------------------------------------------------------------------
install:
	poetry install --with dev

# ----------------------------------------------------------------------------------------
# VÃ©rifications de qualitÃ© du code
# ----------------------------------------------------------------------------------------

# Linting avec Ruff (analyse statique rapide)
lint:
	$(POETRY) ruff check .

# Formatage + correction auto avec Ruff
format:
	$(POETRY) ruff format . && $(POETRY) ruff check --fix .

# VÃ©rification des types avec Mypy
type:
	$(POETRY) mypy src scripts tests


# ----------------------------------------------------------------------------------------
# Tests et couverture
# ----------------------------------------------------------------------------------------

# ExÃ©cution des tests unitaires
test:
	$(POETRY) pytest -vv

# Analyse de la couverture avec rapport JSON, HTML et console (100% requis)
cov:
	$(POETRY) coverage run -m pytest && \
	$(POETRY) coverage json -o coverage.json && \
	$(POETRY) coverage xml -o coverage.xml && \
	$(POETRY) coverage html --skip-empty --show-contexts && \
	$(POETRY) coverage report --fail-under=100


# Mutation testing avec Mutmut (guidÃ© par la couverture)
mut: cov
	$(POETRY) mutmut run --use-coverage --simple-output




# ----------------------------------------------------------------------------------------
# Commandes liÃ©es au modÃ¨le (Poetry)
# ----------------------------------------------------------------------------------------

TRAIN_SUBJECT ?= S01
TRAIN_RUN ?= R01
PREDICT_SUBJECT ?= $(TRAIN_SUBJECT)
PREDICT_RUN ?= $(TRAIN_RUN)

# EntraÃ®nement du modÃ¨le : exemple minimal avec sujet et run de dÃ©monstration
train:
	$(POETRY) python mybci.py $(TRAIN_SUBJECT) $(TRAIN_RUN) train

# PrÃ©diction : exemple minimal rÃ©utilisant les identifiants ci-dessus
predict:
	$(POETRY) python mybci.py $(PREDICT_SUBJECT) $(PREDICT_RUN) predict



# Affiche la commande pour activer le venv
activate:
	@echo "Chemin de l'environnement Poetry :"
	@poetry env info -p
	@echo
	@echo "Pour activer manuellement cet environnement :"
	@echo "  source $$(poetry env info -p)/bin/activate"

# Affiche la commande pour dÃ©sactiver le venv
deactivate:
	@echo "Pour quitter l'environnement :"
	@echo "  deactivate"

# ----------------------------------------------------------------------------------------
# RÃ¨gle gÃ©nÃ©rique pour ignorer les cibles numÃ©riques (ex. make predict-nocheck 23000)
# ----------------------------------------------------------------------------------------
%:
	@:
```

### 0.4 CI/CD (GitHub Actions) â€” **Ubuntuâ€‘only**
`.github/workflows/ci.yml`
```yaml
# .github/workflows/ci.yml
name: CI

on:
  push:
    branches: [ main, develop ]
    tags: [ 'v*' ]
    paths-ignore:
      - '**/*.md'
      - '**/*.txt'
      - '**/*.png'
  pull_request:
    branches: [ main, develop ]
    paths-ignore:
      - '**/*.md'
      - '**/*.txt'
      - '**/*.png'

env:
  # Version Python canonique utilisÃ©e par la CI (alignÃ©e avec pyproject.toml)
  PYTHON_VERSION: "3.10"

jobs:
  pre-commit:
    name: Pre-commit checks
    runs-on: ubuntu-22.04
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install system dependencies
        run: sudo apt-get update && sudo apt-get install -y libasound2-dev

      - name: Install Poetry (retry)
        run: |
          python -m pip install --user --upgrade pip
          for attempt in 1 2 3; do
            python -m pip install --user --retries 3 --timeout 60 poetry==1.8.4 && break
            if [ "$attempt" -eq 3 ]; then
              echo "Poetry installation failed after ${attempt} attempts." >&2
              exit 1
            fi
            echo "Retrying Poetry installation (attempt ${attempt}/3)..." >&2
            sleep 5
          done
          echo "$HOME/.local/bin" >> "$GITHUB_PATH"
          poetry config virtualenvs.create true
          poetry config virtualenvs.in-project true

      - name: Cache virtualenv
        id: cache-poetry
        uses: actions/cache@v3
        with:
          path: .venv
          key: venv-${{ runner.os }}-${{ env.PYTHON_VERSION }}-${{ hashFiles('**/poetry.lock') }}

      - name: Install dependencies (cache miss)
        if: steps.cache-poetry.outputs.cache-hit != 'true'
        run: poetry install --no-interaction --with dev --no-root

      - name: Install project in editable mode
        run: poetry install --no-interaction --with dev

      - name: Run pre-commit
        run: poetry run pre-commit run --all-files

  static-analysis:
    name: Static Analysis
    runs-on: ubuntu-22.04
    needs: pre-commit
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      - run: sudo apt-get update && sudo apt-get install -y libasound2-dev
      - name: Install Poetry (retry)
        run: |
          python -m pip install --user --upgrade pip
          for attempt in 1 2 3; do
            python -m pip install --user --retries 3 --timeout 60 poetry==1.8.4 && break
            if [ "$attempt" -eq 3 ]; then
              echo "Poetry installation failed after ${attempt} attempts." >&2
              exit 1
            fi
            echo "Retrying Poetry installation (attempt ${attempt}/3)..." >&2
            sleep 5
          done
          echo "$HOME/.local/bin" >> "$GITHUB_PATH"
          poetry config virtualenvs.create true
          poetry config virtualenvs.in-project true
      - uses: actions/cache@v3
        id: cache-poetry
        with:
          path: .venv
          key: venv-${{ runner.os }}-${{ env.PYTHON_VERSION }}-${{ hashFiles('**/poetry.lock') }}
      - name: Install dependencies (cache miss)
        if: steps.cache-poetry.outputs.cache-hit != 'true'
        run: poetry install --no-interaction --with dev --no-root
      - name: Install project
        run: poetry install --no-interaction --with dev

      - name: Run Black check
        run: poetry run black --check .

      - name: Run isort check
        run: poetry run isort --check-only .

      - name: Run Ruff
        run: poetry run ruff check .

      - name: Run MyPy
        run: poetry run mypy src scripts tests

      - name: Audit dependencies with pip-audit
        run: poetry run pip-audit --progress-spinner=off


  tests:
    runs-on: ubuntu-22.04
    needs: static-analysis
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install Poetry (retry)
        run: |
          python -m pip install --user --upgrade pip
          for attempt in 1 2 3; do
            python -m pip install --user --retries 3 --timeout 60 poetry==1.8.4 && break
            if [ "$attempt" -eq 3 ]; then
              echo "Poetry installation failed after ${attempt} attempts." >&2
              exit 1
            fi
            echo "Retrying Poetry installation (attempt ${attempt}/3)..." >&2
            sleep 5
          done
          echo "$HOME/.local/bin" >> "$GITHUB_PATH"
          poetry config virtualenvs.create true
          poetry config virtualenvs.in-project true

      - name: Cache virtualenv
        id: cache-poetry
        uses: actions/cache@v3
        with:
          path: .venv
          key: venv-${{ runner.os }}-${{ env.PYTHON_VERSION }}-${{ hashFiles('**/poetry.lock') }}

      - name: Install dependencies (with dev)
        if: steps.cache-poetry.outputs.cache-hit != 'true'
        run: poetry install --no-interaction --with dev

      - name: Ensure project installed
        if: steps.cache-poetry.outputs.cache-hit == 'true'
        run: poetry install --no-interaction --with dev

      - name: Run tests with coverage (Makefile)
        run: make cov

      - name: Generate coverage.xml for Codecov
        run: poetry run coverage xml -o coverage.xml

      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v5
        with:
          files: ./coverage.xml
          disable_search: true
          flags: unittests
          name: ci-ubuntu-py${{ env.PYTHON_VERSION }}
          slug: raveriss/Total_Perspective_Vortex
          token: ${{ secrets.CODECOV_TOKEN }}
          fail_ci_if_error: false

      - name: Run mutation tests (coverage-guided)
        run: |
          poetry run mutmut run --use-coverage --simple-output

      - name: Show mutation results
        run: |
          poetry run mutmut results > mutmut-results.txt
          cat mutmut-results.txt

      - name: Upload mutation report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: mutmut-results
          path: mutmut-results.txt

      - name: Fail if surviving mutants
        run: |
          if grep -Fq "survived" mutmut-results.txt; then
            echo "Surviving mutants detected" && exit 1
          fi

  build:
    name: Build Package
    runs-on: ubuntu-22.04
    needs: [static-analysis, tests]
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      - run: sudo apt-get update && sudo apt-get install -y libasound2-dev
      - name: Install Poetry (retry)
        run: |
          python -m pip install --user --upgrade pip
          for attempt in 1 2 3; do
            python -m pip install --user --retries 3 --timeout 60 poetry==1.8.4 && break
            if [ "$attempt" -eq 3 ]; then
              echo "Poetry installation failed after ${attempt} attempts." >&2
              exit 1
            fi
            echo "Retrying Poetry installation (attempt ${attempt}/3)..." >&2
            sleep 5
          done
          echo "$HOME/.local/bin" >> "$GITHUB_PATH"
          poetry config virtualenvs.create true
          poetry config virtualenvs.in-project true
      - run: poetry install --no-interaction --no-root
      - name: Build package
        run: poetry build
      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        with:
          name: dist
          path: dist/
```

> Exemple minimal de CI ci-dessous. La configuration rÃ©elle utilisÃ©e est
> dÃ©finie dans `.github/workflows/ci.yml` (jobs prÃ©-commit, static-analysis,
> tests, build).


### 0.5 TDD â€” Red â†’ Green â†’ Refactor (rÃ¨gle dâ€™or)
- **Definition of Ready**Â : pas de code sans **au moins un test qui Ã©choue**.
- **Definition of Done**Â : tests verts, **100Â %** couverture (branches), CLI/doc Ã  jour.
- **Hooks (local)** :
  - `pre-commit`Â : `ruff format --check`, `ruff check`, `mypy` (rapide)

---

## 1) ğŸ§© Architecture minimale (agents)
- **`src/tpv/classifier.py`**Â :
- **`src/tpv/dimensionality.py`**Â :
- **`src/tpv/features.py`**Â :
- **`src/tpv/__init__.py`**Â :
- **`src/tpv/pipeline.py`**Â :
- **`src/tpv/predict.py`**Â :
- **`src/tpv/preprocessing.py`**Â :
- **`src/tpv/realtime.py`**Â :
- **`src/tpv/train.py`**Â :
- **`src/tpv/utils.py`**Â :

- **`tests/`**Â : unitaires + E2E + erreurs I/O + contrats.
- **Bonus isolÃ©**Â :

 **Main guard requis** partout : `if __name__ == "__main__": main()`
 et exÃ©cution modulaire via `python -m tpv.train` / `python -m tpv.predict`
 ou via le point d'entrÃ©e `python mybci.py <subject> <run> {train,predict}`.

---

## 2) ğŸ” Pipeline local avant commit (miroir du CI)

Avant **tout `git commit`**, lâ€™agent doit exÃ©cuter **exactement** cette sÃ©quence,
dans cet ordre, et **abandonner le commit** dÃ¨s quâ€™une Ã©tape Ã©choue.

### 2.1 PrÃ©paration (si nouveau clone ou `poetry.lock` modifiÃ©)

Si lâ€™agent ne sait pas si lâ€™environnement est Ã  jour (nouveau clone,
changement de branche, doute sur `poetry.lock`), il doit exÃ©cuter
systÃ©matiquement 2.1.1 et 2.1.2.

1. `poetry install --no-interaction --with dev`
2. VÃ©rifier que la commande `poetry run pytest -q` fonctionne au moins une fois.

### 2.2 Pre-commit + Static analysis (miroir CI)

Ces commandes reflÃ¨tent les jobs `pre-commit` et `static-analysis` de la CI
GitHub. Elles doivent Ãªtre exÃ©cutÃ©es **dans cet ordre**.

> La redondance avec `pre-commit` (qui lance dÃ©jÃ  une partie de ces outils)
> est **volontaire** pour reproduire fidÃ¨lement les jobs de la CI et dÃ©tecter
> toute divergence locale/CI.

1. `poetry run pre-commit run --all-files`
2. `poetry run black --check .`
3. `poetry run isort --check-only .`
4. `poetry run ruff check .`
5. `poetry run mypy src scripts tests`
6. `poetry run pip-audit --progress-spinner=off`

Si une de ces commandes Ã©choue â†’ **corriger le code** puis **rejouer depuis 2.2.1**.

### 2.3 Tests unitaires + couverture (miroir du job `tests`)
1. `make cov`
   - doit produire `coverage.json`, `coverage.xml`, `htmlcov/`
   - doit finir avec `coverage report --fail-under=100` **OK**
2. VÃ©rifier quâ€™aucun fichier nâ€™est sous 100 % via le script de la CI
   (contrÃ´le par fichier avec `coverage.json` si script local existant).

### 2.4 Mutation testing (miroir du job `tests` â€“ step Mutmut)
1. `poetry run mutmut run --use-coverage --simple-output`
2. `poetry run mutmut results > mutmut-results.txt`
3. VÃ©rifier **manuellement** ou via script quâ€™il nâ€™y a **aucune ligne** contenant
   `survived` dans `mutmut-results.txt`.

Si au moins un mutant **survit** â†’ **interdiction de committer** tant que :
- les tests nâ€™ont pas Ã©tÃ© renforcÃ©s, puis
- `poetry run mutmut run` et `poetry run mutmut results` repassent sans `survived`.

### 2.5 RÃ¨gle dâ€™or pour les agents

- Un commit nâ€™est **valide** que si toutes les Ã©tapes 2.2, 2.3 et 2.4 sont **vertes**.
- Tout message â€œModifie ton pre-commit car il y a des fails dans le CIâ€ doit dÃ©clencher :
  1. Relecture de cette section 2),
  2. ExÃ©cution complÃ¨te de la sÃ©quence,
  3. Correction des Ã©checs **avant** de proposer un nouveau commit.

---
cd
## 3) ğŸ§ª Plan de tests (dÃ©fenseâ€‘proof)
**Objectifs**Â : 100Â % couverture (branches + diff), **contrÃ´le par fichier**, tests rapides.

### 3.1 Unitaires
-
...


### 3.5 TolÃ©rances numÃ©riques (si tests internes)
-
...

## 4) âš™ï¸ SpÃ©cifications dâ€™implÃ©mentation

### 4.1 Formules
-
...

### 4.2 CLI (exemples)
```bash

```

### 4.3 Persistance
-
  ```
- **Ne jamais** committer les datasets bruts ou fichiers issus de Physionet.

### 4.4 Structure projet
```
.
â”œâ”€â”€ AGENTS.md
â”œâ”€â”€ author
â”œâ”€â”€ codecov.yml
â”œâ”€â”€ create_tpv_fields.sh
â”œâ”€â”€ docs
â”‚   â”œâ”€â”€ assets
â”‚   â”‚   â”œâ”€â”€ image01.png
â”‚   â”‚   â””â”€â”€ image02.png
â”‚   â”œâ”€â”€ project
â”‚   â”‚   â”œâ”€â”€ gantt_tpv.png
â”‚   â”‚   â”œâ”€â”€ roadmap.md
â”‚   â”‚   â””â”€â”€ wbs_tpv.md
â”‚   â”œâ”€â”€ risk
â”‚   â”‚   â””â”€â”€ tpv_murphy_map.csv
â”‚   â”œâ”€â”€ total_perspective_vortex.en.checklist.pdf
â”‚   â””â”€â”€ Total_Perspective_Vortex.en.subject.pdf
â”œâ”€â”€ LICENSE
â”œâ”€â”€ Makefile
â”œâ”€â”€ mybci.py
â”œâ”€â”€ poetry.lock
â”œâ”€â”€ poetry.toml
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ README.md
â”œâ”€â”€ scripts
â”‚   â”œâ”€â”€ import_murphy_issues.py
â”‚   â”œâ”€â”€ import_murphy_to_project.py
â”‚   â”œâ”€â”€ predict.py
â”‚   â”œâ”€â”€ train.py
â”‚   â””â”€â”€ visualize_raw_filtered.py
â”œâ”€â”€ src
â”‚   â””â”€â”€ tpv
â”‚       â”œâ”€â”€ classifier.py
â”‚       â”œâ”€â”€ dimensionality.py
â”‚       â”œâ”€â”€ features.py
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ pipeline.py
â”‚       â”œâ”€â”€ predict.py
â”‚       â”œâ”€â”€ preprocessing.py
â”‚       â”œâ”€â”€ realtime.py
â”‚       â”œâ”€â”€ train.py
â”‚       â””â”€â”€ utils.py
â””â”€â”€ tests
    â”œâ”€â”€ test_classifier.py
    â”œâ”€â”€ test_dimensionality.py
    â”œâ”€â”€ test_mybci.py
    â”œâ”€â”€ test_pipeline.py
    â”œâ”€â”€ test_preprocessing.py
    â””â”€â”€ test_realtime.py
```

---

## 5) ğŸ›¡ï¸ Loi de Murphy â€” risques & contreâ€‘mesures (condensÃ©)


---

## 6) âœ… ProcÃ©dure de validation finale (soutenance)
1. `pytest -q` â†’ **tout vert**
2. `coverage run -m pytest && coverage json && coverage report --fail-under=100` (branches)
3. **ContrÃ´le par fichier** : script CI sur `coverage.json` â†’ **100 % partout**
3bis. **Upload vers Codecov** (`coverage.xml`) + vÃ©rif diff=100 %
4. **Mutation testing (scope global mandatory) â‰¥ 90 %** + aucun survivant sur les zones critiques.
5. DÃ©mo E2E : `predict(0)=0` â†’ `train` â†’ `predictâ‰ˆcsv` (MAJ simultanÃ©e validÃ©e)
6. VÃ©rif visuelle `htmlcov/` (tout vert)
7. README : commande `predictâ†’trainâ†’predict`, aucune mention de lib â€œmagiqueâ€
8. VÃ©rif environnement : exÃ©cution validÃ©e uniquement sous **Ubuntu 22.04** (soutenance Ã©cole 42)


---

## 7) ğŸ“ Annexes â€” extraits utiles

### 7.1 Bloc dâ€™aide minimal (Ã  snapshot en test)
```
usage: train.py
usage: predict.py
```

### 7.2 ModÃ¨le de messages dâ€™erreurs (tests de rÃ©gression)
- `ERROR:
- `ERROR:
- `ERROR:

---

## 8) ğŸ”­ Bonus CI perso (hors soutenance 42)
- `vulture`, `bandit`, `radon/xenon` (analyse deadâ€‘code/sÃ©curitÃ©/complexitÃ©)
- Job Python 3.11 Ubuntu (smoke) en plus du 3.10

---

## ğŸ“š Documentation du code

Lorsque tu gÃ©nÃ¨res du code pour moi, applique **strictement** les rÃ¨gles
de documentation suivantes.

### RÃ¨gles de commentaires

* **Un commentaire par ligne de code**, placÃ© **juste au-dessus** de la ligne.
* Le commentaire doit expliquer **le â€œpourquoiâ€** de la ligne
  (intention, rÃ´le, effet mÃ©tier, contrainte, robustesse),
  **jamais le â€œcommentâ€** ni une paraphrase du code.
* Longueur maximale : **80 caractÃ¨res par commentaire**.
* Les commentaires doivent **respecter lâ€™indentation du code**
  (un commentaire est dans le mÃªme bloc que la ligne quâ€™il dÃ©crit).
* **Interdit** :

  * Commentaire en fin de ligne (`â€¦  # commentaire`)
  * Commentaire sous la ligne de code

### Docstrings

* Utiliser des **docstrings uniquement** pour les **fonctions/classes/modules** :

  * But global, paramÃ¨tres, valeurs de retour, erreurs levÃ©es.
  * Ne pas rÃ©pÃ©ter ce qui est dÃ©jÃ  expliquÃ© commentaire par commentaire.

---

### Exemple **Ã  ne pas produire** (paraphrase du code, â€œcommentâ€ et non â€œpourquoiâ€)

```py
# Calcule la diffÃ©rence entre max_km et min_km,
# ou 1.0 si la diffÃ©rence vaut 0
km_range = max_km - min_km or 1.0  # pragma: no mutate

# Calcule la diffÃ©rence entre max_price et min_price,
# ou 1.0 si la diffÃ©rence vaut 0
price_range = max_price - min_price or 1.0  # pragma: no mutate
```

### Exemple **attendu** (explication du â€œpourquoiâ€, pas du â€œcommentâ€)

```py
# Garantit un intervalle de distance non nul pour Ã©viter une division par zÃ©ro
km_range = max_km - min_km or 1.0  # pragma: no mutate

# Garantit un intervalle de prix non nul pour stabiliser la normalisation
price_range = max_price - min_price or 1.0  # pragma: no mutate
```
