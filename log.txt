]633;E;make install;d58e6a1e-07fd-4671-8641-df05ecc641ee]633;Cpoetry install --with dev
Installing dependencies from lock file

No dependencies to install or update

Installing the current project: total-perspective-vortex (0.1.0)
/home/raveriss/Desktop/Total_Perspective_Vortex
.
â”œâ”€â”€ AGENTS.md
â”œâ”€â”€ author
â”œâ”€â”€ codecov.yml
â”œâ”€â”€ create_tpv_fields.sh
â”œâ”€â”€ data
â”‚Â Â  â”œâ”€â”€ raw
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ 64_channel_sharbrough-old.png
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ 64_channel_sharbrough.pdf
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ 64_channel_sharbrough.png
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ ANNOTATORS
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ RECORDS
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S001
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S001R01.edf
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S001R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S001R02.edf
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S001R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S001R03.edf
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S001R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S001R04.edf
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S001R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S001R05.edf
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S001R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S001R06.edf
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S001R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S001R07.edf
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S001R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S001R08.edf
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S001R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S001R09.edf
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S001R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S001R10.edf
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S001R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S001R11.edf
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S001R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S001R12.edf
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S001R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S001R13.edf
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S001R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S001R14.edf
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S001R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S002
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S002R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S002R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S002R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S002R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S002R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S002R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S002R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S002R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S002R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S002R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S002R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S002R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S002R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S002R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S003
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S003R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S003R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S003R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S003R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S003R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S003R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S003R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S003R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S003R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S003R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S003R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S003R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S003R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S003R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S004
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S004R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S004R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S004R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S004R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S004R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S004R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S004R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S004R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S004R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S004R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S004R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S004R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S004R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S004R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S005
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S005R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S005R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S005R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S005R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S005R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S005R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S005R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S005R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S005R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S005R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S005R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S005R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S005R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S005R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S006
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S006R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S006R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S006R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S006R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S006R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S006R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S006R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S006R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S006R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S006R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S006R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S006R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S006R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S006R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S007
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S007R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S007R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S007R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S007R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S007R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S007R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S007R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S007R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S007R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S007R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S007R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S007R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S007R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S007R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S008
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S008R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S008R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S008R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S008R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S008R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S008R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S008R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S008R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S008R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S008R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S008R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S008R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S008R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S008R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S009
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S009R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S009R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S009R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S009R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S009R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S009R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S009R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S009R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S009R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S009R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S009R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S009R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S009R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S009R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S010
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S010R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S010R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S010R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S010R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S010R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S010R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S010R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S010R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S010R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S010R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S010R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S010R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S010R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S010R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S011
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S011R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S011R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S011R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S011R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S011R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S011R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S011R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S011R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S011R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S011R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S011R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S011R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S011R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S011R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S012
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S012R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S012R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S012R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S012R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S012R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S012R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S012R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S012R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S012R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S012R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S012R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S012R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S012R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S012R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S013
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S013R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S013R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S013R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S013R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S013R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S013R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S013R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S013R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S013R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S013R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S013R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S013R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S013R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S013R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S014
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S014R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S014R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S014R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S014R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S014R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S014R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S014R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S014R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S014R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S014R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S014R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S014R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S014R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S014R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S015
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S015R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S015R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S015R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S015R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S015R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S015R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S015R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S015R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S015R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S015R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S015R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S015R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S015R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S015R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S016
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S016R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S016R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S016R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S016R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S016R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S016R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S016R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S016R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S016R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S016R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S016R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S016R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S016R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S016R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S017
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S017R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S017R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S017R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S017R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S017R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S017R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S017R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S017R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S017R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S017R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S017R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S017R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S017R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S017R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S018
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S018R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S018R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S018R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S018R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S018R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S018R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S018R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S018R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S018R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S018R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S018R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S018R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S018R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S018R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S019
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S019R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S019R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S019R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S019R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S019R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S019R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S019R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S019R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S019R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S019R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S019R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S019R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S019R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S019R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S020
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S020R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S020R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S020R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S020R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S020R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S020R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S020R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S020R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S020R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S020R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S020R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S020R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S020R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S020R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S021
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S021R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S021R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S021R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S021R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S021R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S021R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S021R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S021R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S021R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S021R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S021R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S021R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S021R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S021R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S022
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S022R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S022R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S022R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S022R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S022R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S022R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S022R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S022R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S022R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S022R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S022R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S022R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S022R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S022R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S023
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S023R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S023R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S023R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S023R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S023R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S023R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S023R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S023R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S023R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S023R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S023R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S023R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S023R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S023R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S024
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S024R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S024R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S024R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S024R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S024R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S024R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S024R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S024R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S024R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S024R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S024R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S024R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S024R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S024R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S025
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S025R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S025R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S025R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S025R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S025R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S025R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S025R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S025R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S025R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S025R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S025R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S025R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S025R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S025R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S026
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S026R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S026R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S026R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S026R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S026R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S026R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S026R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S026R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S026R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S026R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S026R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S026R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S026R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S026R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S027
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S027R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S027R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S027R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S027R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S027R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S027R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S027R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S027R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S027R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S027R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S027R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S027R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S027R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S027R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S028
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S028R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S028R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S028R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S028R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S028R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S028R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S028R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S028R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S028R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S028R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S028R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S028R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S028R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S028R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S029
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S029R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S029R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S029R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S029R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S029R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S029R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S029R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S029R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S029R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S029R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S029R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S029R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S029R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S029R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S030
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S030R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S030R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S030R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S030R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S030R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S030R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S030R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S030R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S030R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S030R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S030R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S030R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S030R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S030R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S031
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S031R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S031R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S031R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S031R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S031R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S031R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S031R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S031R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S031R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S031R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S031R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S031R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S031R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S031R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S032
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S032R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S032R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S032R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S032R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S032R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S032R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S032R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S032R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S032R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S032R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S032R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S032R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S032R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S032R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S033
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S033R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S033R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S033R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S033R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S033R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S033R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S033R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S033R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S033R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S033R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S033R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S033R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S033R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S033R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S034
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S034R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S034R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S034R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S034R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S034R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S034R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S034R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S034R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S034R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S034R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S034R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S034R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S034R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S034R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S035
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S035R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S035R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S035R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S035R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S035R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S035R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S035R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S035R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S035R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S035R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S035R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S035R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S035R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S035R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S036
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S036R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S036R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S036R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S036R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S036R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S036R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S036R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S036R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S036R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S036R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S036R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S036R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S036R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S036R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S037
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S037R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S037R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S037R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S037R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S037R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S037R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S037R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S037R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S037R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S037R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S037R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S037R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S037R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S037R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S038
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S038R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S038R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S038R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S038R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S038R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S038R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S038R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S038R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S038R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S038R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S038R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S038R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S038R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S038R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S039
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S039R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S039R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S039R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S039R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S039R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S039R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S039R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S039R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S039R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S039R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S039R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S039R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S039R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S039R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S040
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S040R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S040R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S040R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S040R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S040R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S040R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S040R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S040R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S040R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S040R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S040R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S040R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S040R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S040R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S041
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S041R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S041R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S041R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S041R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S041R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S041R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S041R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S041R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S041R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S041R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S041R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S041R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S041R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S041R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S042
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S042R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S042R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S042R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S042R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S042R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S042R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S042R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S042R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S042R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S042R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S042R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S042R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S042R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S042R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S043
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S043R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S043R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S043R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S043R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S043R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S043R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S043R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S043R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S043R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S043R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S043R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S043R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S043R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S043R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S044
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S044R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S044R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S044R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S044R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S044R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S044R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S044R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S044R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S044R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S044R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S044R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S044R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S044R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S044R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S045
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S045R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S045R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S045R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S045R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S045R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S045R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S045R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S045R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S045R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S045R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S045R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S045R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S045R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S045R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S046
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S046R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S046R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S046R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S046R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S046R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S046R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S046R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S046R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S046R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S046R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S046R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S046R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S046R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S046R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S047
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S047R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S047R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S047R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S047R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S047R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S047R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S047R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S047R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S047R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S047R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S047R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S047R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S047R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S047R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S048
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S048R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S048R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S048R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S048R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S048R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S048R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S048R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S048R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S048R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S048R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S048R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S048R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S048R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S048R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S049
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S049R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S049R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S049R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S049R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S049R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S049R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S049R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S049R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S049R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S049R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S049R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S049R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S049R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S049R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S050
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S050R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S050R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S050R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S050R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S050R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S050R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S050R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S050R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S050R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S050R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S050R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S050R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S050R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S050R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S051
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S051R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S051R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S051R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S051R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S051R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S051R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S051R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S051R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S051R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S051R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S051R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S051R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S051R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S051R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S052
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S052R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S052R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S052R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S052R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S052R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S052R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S052R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S052R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S052R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S052R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S052R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S052R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S052R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S052R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S053
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S053R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S053R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S053R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S053R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S053R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S053R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S053R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S053R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S053R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S053R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S053R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S053R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S053R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S053R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S054
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S054R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S054R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S054R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S054R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S054R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S054R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S054R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S054R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S054R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S054R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S054R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S054R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S054R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S054R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S055
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S055R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S055R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S055R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S055R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S055R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S055R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S055R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S055R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S055R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S055R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S055R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S055R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S055R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S055R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S056
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S056R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S056R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S056R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S056R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S056R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S056R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S056R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S056R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S056R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S056R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S056R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S056R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S056R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S056R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S057
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S057R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S057R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S057R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S057R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S057R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S057R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S057R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S057R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S057R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S057R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S057R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S057R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S057R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S057R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S058
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S058R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S058R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S058R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S058R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S058R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S058R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S058R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S058R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S058R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S058R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S058R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S058R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S058R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S058R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S059
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S059R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S059R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S059R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S059R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S059R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S059R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S059R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S059R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S059R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S059R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S059R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S059R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S059R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S059R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S060
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S060R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S060R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S060R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S060R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S060R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S060R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S060R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S060R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S060R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S060R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S060R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S060R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S060R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S060R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S061
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S061R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S061R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S061R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S061R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S061R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S061R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S061R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S061R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S061R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S061R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S061R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S061R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S061R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S061R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S062
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S062R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S062R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S062R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S062R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S062R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S062R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S062R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S062R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S062R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S062R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S062R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S062R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S062R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S062R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S063
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S063R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S063R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S063R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S063R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S063R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S063R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S063R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S063R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S063R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S063R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S063R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S063R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S063R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S063R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S064
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S064R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S064R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S064R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S064R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S064R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S064R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S064R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S064R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S064R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S064R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S064R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S064R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S064R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S064R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S065
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S065R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S065R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S065R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S065R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S065R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S065R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S065R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S065R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S065R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S065R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S065R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S065R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S065R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S065R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S066
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S066R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S066R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S066R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S066R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S066R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S066R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S066R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S066R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S066R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S066R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S066R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S066R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S066R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S066R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S067
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S067R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S067R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S067R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S067R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S067R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S067R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S067R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S067R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S067R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S067R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S067R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S067R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S067R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S067R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S068
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S068R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S068R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S068R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S068R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S068R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S068R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S068R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S068R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S068R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S068R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S068R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S068R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S068R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S068R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S069
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S069R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S069R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S069R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S069R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S069R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S069R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S069R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S069R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S069R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S069R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S069R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S069R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S069R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S069R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S070
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S070R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S070R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S070R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S070R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S070R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S070R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S070R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S070R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S070R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S070R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S070R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S070R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S070R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S070R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S071
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S071R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S071R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S071R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S071R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S071R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S071R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S071R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S071R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S071R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S071R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S071R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S071R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S071R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S071R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S072
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S072R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S072R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S072R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S072R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S072R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S072R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S072R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S072R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S072R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S072R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S072R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S072R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S072R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S072R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S073
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S073R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S073R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S073R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S073R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S073R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S073R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S073R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S073R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S073R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S073R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S073R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S073R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S073R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S073R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S074
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S074R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S074R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S074R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S074R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S074R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S074R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S074R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S074R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S074R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S074R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S074R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S074R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S074R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S074R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S075
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S075R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S075R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S075R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S075R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S075R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S075R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S075R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S075R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S075R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S075R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S075R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S075R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S075R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S075R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S076
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S076R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S076R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S076R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S076R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S076R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S076R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S076R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S076R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S076R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S076R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S076R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S076R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S076R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S076R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S077
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S077R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S077R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S077R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S077R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S077R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S077R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S077R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S077R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S077R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S077R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S077R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S077R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S077R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S077R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S078
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S078R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S078R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S078R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S078R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S078R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S078R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S078R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S078R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S078R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S078R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S078R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S078R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S078R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S078R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S079
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S079R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S079R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S079R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S079R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S079R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S079R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S079R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S079R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S079R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S079R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S079R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S079R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S079R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S079R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S080
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S080R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S080R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S080R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S080R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S080R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S080R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S080R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S080R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S080R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S080R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S080R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S080R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S080R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S080R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S081
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S081R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S081R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S081R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S081R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S081R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S081R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S081R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S081R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S081R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S081R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S081R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S081R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S081R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S081R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S082
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S082R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S082R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S082R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S082R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S082R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S082R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S082R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S082R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S082R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S082R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S082R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S082R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S082R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S082R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S083
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S083R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S083R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S083R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S083R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S083R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S083R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S083R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S083R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S083R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S083R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S083R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S083R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S083R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S083R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S084
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S084R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S084R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S084R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S084R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S084R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S084R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S084R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S084R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S084R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S084R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S084R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S084R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S084R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S084R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S085
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S085R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S085R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S085R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S085R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S085R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S085R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S085R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S085R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S085R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S085R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S085R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S085R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S085R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S085R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S086
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S086R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S086R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S086R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S086R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S086R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S086R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S086R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S086R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S086R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S086R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S086R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S086R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S086R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S086R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S087
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S087R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S087R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S087R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S087R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S087R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S087R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S087R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S087R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S087R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S087R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S087R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S087R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S087R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S087R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S088
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S088R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S088R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S088R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S088R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S088R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S088R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S088R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S088R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S088R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S088R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S088R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S088R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S088R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S088R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S089
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S089R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S089R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S089R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S089R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S089R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S089R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S089R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S089R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S089R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S089R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S089R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S089R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S089R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S089R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S090
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S090R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S090R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S090R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S090R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S090R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S090R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S090R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S090R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S090R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S090R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S090R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S090R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S090R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S090R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S091
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S091R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S091R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S091R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S091R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S091R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S091R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S091R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S091R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S091R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S091R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S091R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S091R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S091R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S091R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S092
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S092R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S092R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S092R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S092R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S092R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S092R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S092R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S092R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S092R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S092R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S092R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S092R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S092R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S092R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S093
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S093R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S093R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S093R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S093R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S093R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S093R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S093R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S093R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S093R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S093R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S093R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S093R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S093R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S093R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S094
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S094R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S094R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S094R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S094R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S094R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S094R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S094R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S094R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S094R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S094R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S094R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S094R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S094R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S094R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S095
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S095R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S095R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S095R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S095R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S095R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S095R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S095R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S095R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S095R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S095R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S095R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S095R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S095R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S095R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S096
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S096R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S096R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S096R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S096R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S096R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S096R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S096R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S096R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S096R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S096R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S096R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S096R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S096R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S096R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S097
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S097R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S097R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S097R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S097R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S097R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S097R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S097R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S097R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S097R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S097R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S097R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S097R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S097R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S097R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S098
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S098R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S098R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S098R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S098R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S098R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S098R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S098R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S098R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S098R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S098R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S098R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S098R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S098R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S098R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S099
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S099R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S099R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S099R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S099R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S099R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S099R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S099R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S099R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S099R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S099R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S099R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S099R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S099R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S099R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S100
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S100R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S100R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S100R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S100R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S100R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S100R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S100R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S100R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S100R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S100R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S100R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S100R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S100R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S100R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S101
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S101R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S101R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S101R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S101R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S101R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S101R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S101R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S101R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S101R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S101R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S101R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S101R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S101R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S101R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S102
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S102R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S102R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S102R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S102R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S102R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S102R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S102R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S102R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S102R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S102R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S102R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S102R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S102R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S102R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S103
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S103R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S103R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S103R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S103R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S103R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S103R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S103R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S103R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S103R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S103R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S103R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S103R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S103R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S103R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S104
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S104R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S104R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S104R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S104R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S104R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S104R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S104R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S104R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S104R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S104R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S104R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S104R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S104R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S104R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S105
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S105R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S105R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S105R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S105R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S105R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S105R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S105R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S105R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S105R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S105R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S105R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S105R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S105R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S105R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S106
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S106R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S106R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S106R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S106R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S106R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S106R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S106R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S106R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S106R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S106R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S106R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S106R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S106R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S106R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S107
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S107R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S107R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S107R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S107R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S107R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S107R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S107R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S107R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S107R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S107R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S107R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S107R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S107R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S107R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S108
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S108R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S108R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S108R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S108R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S108R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S108R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S108R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S108R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S108R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S108R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S108R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S108R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S108R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S108R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S109
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S109R01.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S109R02.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S109R03.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S109R04.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S109R05.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S109R06.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S109R07.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S109R08.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S109R09.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S109R10.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S109R11.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S109R12.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ S109R13.edf.event
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ S109R14.edf.event
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ SHA256SUMS.txt
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ Unconfirmed 300755.crdownload
â”‚Â Â  â”‚Â Â  â””â”€â”€ wfdbcal
â”‚Â Â  â””â”€â”€ S001
â”‚Â Â      â”œâ”€â”€ R03_X.npy
â”‚Â Â      â”œâ”€â”€ R03_y.npy
â”‚Â Â      â”œâ”€â”€ S001R01.edf
â”‚Â Â      â”œâ”€â”€ S001R01.edf.event
â”‚Â Â      â”œâ”€â”€ S001R02.edf
â”‚Â Â      â”œâ”€â”€ S001R02.edf.event
â”‚Â Â      â”œâ”€â”€ S001R03.edf
â”‚Â Â      â”œâ”€â”€ S001R03.edf.event
â”‚Â Â      â”œâ”€â”€ S001R04.edf
â”‚Â Â      â”œâ”€â”€ S001R04.edf.event
â”‚Â Â      â”œâ”€â”€ S001R05.edf
â”‚Â Â      â”œâ”€â”€ S001R05.edf.event
â”‚Â Â      â”œâ”€â”€ S001R06.edf
â”‚Â Â      â”œâ”€â”€ S001R06.edf.event
â”‚Â Â      â”œâ”€â”€ S001R07.edf
â”‚Â Â      â”œâ”€â”€ S001R07.edf.event
â”‚Â Â      â”œâ”€â”€ S001R08.edf
â”‚Â Â      â””â”€â”€ S001R08.edf.event
â”œâ”€â”€ docs
â”‚Â Â  â”œâ”€â”€ assets
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ image01.png
â”‚Â Â  â”‚Â Â  â””â”€â”€ image02.png
â”‚Â Â  â”œâ”€â”€ index.md
â”‚Â Â  â”œâ”€â”€ project
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ benchmark_results.json
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ benchmark_results.md
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ checklist_wbs_matrix.md
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ gantt_tpv.png
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ physionet_dataset.md
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ roadmap.md
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ splits_metrics.md
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ split_strategy.md
â”‚Â Â  â”‚Â Â  â””â”€â”€ wbs_tpv.md
â”‚Â Â  â”œâ”€â”€ risk
â”‚Â Â  â”‚Â Â  â””â”€â”€ tpv_murphy_map.csv
â”‚Â Â  â”œâ”€â”€ total_perspective_vortex.en.checklist.pdf
â”‚Â Â  â””â”€â”€ Total_Perspective_Vortex.en.subject.pdf
â”œâ”€â”€ LICENSE
â”œâ”€â”€ log.txt
â”œâ”€â”€ Makefile
â”œâ”€â”€ mybci.py
â”œâ”€â”€ poetry.lock
â”œâ”€â”€ poetry.toml
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ README.md
â”œâ”€â”€ scripts
â”‚Â Â  â”œâ”€â”€ aggregate_accuracy.py
â”‚Â Â  â”œâ”€â”€ aggregate_scores.py
â”‚Â Â  â”œâ”€â”€ benchmark.py
â”‚Â Â  â”œâ”€â”€ fetch_physionet.py
â”‚Â Â  â”œâ”€â”€ import_murphy_issues.py
â”‚Â Â  â”œâ”€â”€ import_murphy_to_project.py
â”‚Â Â  â”œâ”€â”€ __init__.py
â”‚Â Â  â”œâ”€â”€ predict.py
â”‚Â Â  â”œâ”€â”€ prepare_physionet.py
â”‚Â Â  â”œâ”€â”€ __pycache__
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ fetch_physionet.cpython-310.pyc
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ __init__.cpython-310.pyc
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ prepare_physionet.cpython-310.pyc
â”‚Â Â  â”‚Â Â  â””â”€â”€ train.cpython-310.pyc
â”‚Â Â  â”œâ”€â”€ sync_dataset.py
â”‚Â Â  â”œâ”€â”€ train.py
â”‚Â Â  â””â”€â”€ visualize_raw_filtered.py
â”œâ”€â”€ src
â”‚Â Â  â””â”€â”€ tpv
â”‚Â Â      â”œâ”€â”€ classifier.py
â”‚Â Â      â”œâ”€â”€ dimensionality.py
â”‚Â Â      â”œâ”€â”€ features.py
â”‚Â Â      â”œâ”€â”€ __init__.py
â”‚Â Â      â”œâ”€â”€ pipeline.py
â”‚Â Â      â”œâ”€â”€ predict.py
â”‚Â Â      â”œâ”€â”€ preprocessing.py
â”‚Â Â      â”œâ”€â”€ __pycache__
â”‚Â Â      â”‚Â Â  â”œâ”€â”€ classifier.cpython-310.pyc
â”‚Â Â      â”‚Â Â  â”œâ”€â”€ dimensionality.cpython-310.pyc
â”‚Â Â      â”‚Â Â  â”œâ”€â”€ features.cpython-310.pyc
â”‚Â Â      â”‚Â Â  â”œâ”€â”€ __init__.cpython-310.pyc
â”‚Â Â      â”‚Â Â  â”œâ”€â”€ pipeline.cpython-310.pyc
â”‚Â Â      â”‚Â Â  â”œâ”€â”€ preprocessing.cpython-310.pyc
â”‚Â Â      â”‚Â Â  â””â”€â”€ train.cpython-310.pyc
â”‚Â Â      â”œâ”€â”€ realtime.py
â”‚Â Â      â”œâ”€â”€ train.py
â”‚Â Â      â””â”€â”€ utils.py
â””â”€â”€ tests
    â”œâ”€â”€ test_benchmark.py
    â”œâ”€â”€ test_classifier.py
    â”œâ”€â”€ test_dimensionality.py
    â”œâ”€â”€ test_features.py
    â”œâ”€â”€ test_fetch_physionet.py
    â”œâ”€â”€ test_mybci.py
    â”œâ”€â”€ test_pipeline.py
    â”œâ”€â”€ test_prepare_physionet.py
    â”œâ”€â”€ test_preprocessing.py
    â”œâ”€â”€ test_realtime.py
    â”œâ”€â”€ test_scripts_roundtrip.py
    â”œâ”€â”€ test_sync_dataset.py
    â””â”€â”€ test_visualize_raw_filtered.py

122 directories, 1639 files

===== Makefile () =====
# ========================================================================================
# Makefile - Automatisation pour le projet Total_Perspective_Vortex
# Objectifs :
#   - Simplifier lâ€™installation et la gestion de lâ€™environnement (Poetry / venv)
#   - Automatiser les vÃ©rifications (lint, format, type-check, tests, coverage, mutation)
#   - Fournir des commandes pratiques pour lâ€™entraÃ®nement et la prÃ©diction du modÃ¨le
# ========================================================================================

.PHONY: install lint format type test cov mut train predict activate deactivate clean-mutants

VENV = .venv
VENV_BIN = $(VENV)/bin/activate

# --- Benchmarks ---------------------------------------------------------------
BENCH_DIR   := data/benchmarks
BENCH_CSVS  := $(wildcard $(BENCH_DIR)/*.csv)

# Utilisation raccourcie de Poetry
POETRY = poetry run

# DÃ©sactive le chargement automatique des plugins pytest globaux (ROS, etc.)
PYTEST_ENV = PYTEST_DISABLE_PLUGIN_AUTOLOAD=1

# ----------------------------------------------------------------------------------------
# Installation des dÃ©pendances (dev inclus)
# ----------------------------------------------------------------------------------------
install:
	poetry install --with dev

# ----------------------------------------------------------------------------------------
# VÃ©rifications de qualitÃ© du code
# ----------------------------------------------------------------------------------------

# Linting avec Ruff (analyse statique rapide)
lint:
	$(POETRY) ruff check .

# Formatage + correction auto avec Ruff
format:
	$(POETRY) ruff format . && $(POETRY) ruff check --fix .

# VÃ©rification des types avec Mypy
type:
	$(POETRY) mypy src scripts tests

# ----------------------------------------------------------------------------------------
# Tests et couverture
# ----------------------------------------------------------------------------------------

# Nettoyage du dossier de mutants pour Ã©viter les conflits de tests
clean-mutants:
	rm -rf mutants

# ExÃ©cution des tests unitaires (sans plugins pytest externes)
test: clean-mutants
	$(PYTEST_ENV) $(POETRY) pytest -vv

# Analyse de la couverture avec rapport JSON, XML, HTML et console (90% requis)
cov: clean-mutants
	$(PYTEST_ENV) $(POETRY) coverage run -m pytest && \
	$(POETRY) coverage json -o coverage.json && \
	$(POETRY) coverage xml -o coverage.xml && \
	$(POETRY) coverage html --skip-empty --show-contexts && \
	$(POETRY) coverage report --fail-under=90

# Mutation testing avec Mutmut (guidÃ© par la couverture)
mut: clean-mutants cov
	MUTMUT_USE_COVERAGE=1 $(PYTEST_ENV) $(POETRY) mutmut run
	$(POETRY) mutmut results > mutmut-results.txt
	@if grep -E "(survived|timeout)" mutmut-results.txt; then \
		echo "Surviving or timed-out mutants detected" >&2; \
		exit 1; \
	fi

# ----------------------------------------------------------------------------------------
# Commandes liÃ©es au modÃ¨le (Poetry)
# ----------------------------------------------------------------------------------------

TRAIN_SUBJECT ?= S001
TRAIN_RUN ?= R03
PREDICT_SUBJECT ?= $(TRAIN_SUBJECT)
PREDICT_RUN ?= $(TRAIN_RUN)

# EntraÃ®nement du modÃ¨le : exemple minimal avec sujet et run de dÃ©monstration
train:
	$(POETRY) python mybci.py $(TRAIN_SUBJECT) $(TRAIN_RUN) train

# PrÃ©diction : exemple minimal rÃ©utilisant les identifiants ci-dessus
predict:
	$(POETRY) python mybci.py $(PREDICT_SUBJECT) $(PREDICT_RUN) predict

# Affiche la commande pour activer le venv
activate:
	@echo "Chemin de l'environnement Poetry :"
	@poetry env info -p
	@echo
	@echo "Pour activer manuellement cet environnement :"
	@echo "  source $$(poetry env info -p)/bin/activate"

# Affiche la commande pour dÃ©sactiver le venv
deactivate:
	@echo "Pour quitter l'environnement :"
	@echo "  deactivate"

# ----------------------------------------------------------------------------------------
# RÃ¨gle gÃ©nÃ©rique pour ignorer les cibles numÃ©riques (ex. make predict-nocheck 23000)
# ----------------------------------------------------------------------------------------
%:
	@:

===== mybci.py () =====
"""Interface CLI pour piloter les workflows d'entraÃ®nement et de prÃ©diction."""

# PrÃ©serve argparse pour parser les options CLI avec validation
import argparse

# PrÃ©serve subprocess pour lancer les modules en sous-processus isolÃ©s
import subprocess

# PrÃ©serve sys pour identifier l'interprÃ©teur courant
import sys

# PrÃ©serve dataclass pour regrouper les paramÃ¨tres du pipeline
from dataclasses import dataclass

# Garantit l'accÃ¨s aux sÃ©quences typÃ©es pour mypy
from typing import Sequence


# Centralise les options nÃ©cessaires pour invoquer le mode realtime
@dataclass
class RealtimeCallConfig:
    """Conteneur des paramÃ¨tres transmis au module realtime."""

    # Identifie le sujet cible pour cibler les artefacts du modÃ¨le
    subject: str
    # Identifie le run cible pour sÃ©lectionner la session
    run: str
    # Fixe la taille de fenÃªtre glissante en Ã©chantillons
    window_size: int
    # Fixe le pas entre deux fenÃªtres successives
    step_size: int
    # Fixe la taille du buffer utilisÃ© pour lisser les prÃ©dictions
    buffer_size: int
    # Renseigne la frÃ©quence d'Ã©chantillonnage pour calculer les offsets
    sfreq: float
    # SpÃ©cifie la latence maximale autorisÃ©e pour chaque fenÃªtre
    max_latency: float
    # SpÃ©cifie le rÃ©pertoire contenant les fichiers numpy streamÃ©s
    data_dir: str
    # SpÃ©cifie le rÃ©pertoire racine oÃ¹ lire les artefacts entraÃ®nÃ©s
    artifacts_dir: str


# Centralise les options nÃ©cessaires pour invoquer un module TPV
@dataclass
class ModuleCallConfig:
    """Conteneur des paramÃ¨tres transmis aux modules train/predict."""

    # Identifie le sujet cible pour charger les donnÃ©es correspondantes
    subject: str
    # Identifie le run cible pour charger la bonne session
    run: str
    # SÃ©lectionne le classifieur pour harmoniser train et predict
    classifier: str
    # SÃ©lectionne le scaler optionnel pour stabiliser les features
    scaler: str | None
    # Harmonise la stratÃ©gie d'extraction des features
    feature_strategy: str
    # Choisit la mÃ©thode de rÃ©duction de dimension
    dim_method: str
    # SpÃ©cifie le nombre de composantes projetÃ©es
    n_components: int | None
    # Indique si les features doivent Ãªtre normalisÃ©es
    normalize_features: bool


# Construit la ligne de commande pour invoquer un module TPV
def _call_module(module_name: str, config: ModuleCallConfig) -> int:
    """Invoke un module TPV en ajoutant les options du pipeline."""

    # Initialise la commande avec l'interprÃ©teur courant et le module ciblÃ©
    command: list[str] = [
        sys.executable,
        "-m",
        module_name,
        config.subject,
        config.run,
    ]
    # Ajoute le classifieur choisi pour transmettre la prÃ©fÃ©rence utilisateur
    command.extend(["--classifier", config.classifier])
    # Ajoute la stratÃ©gie de scaler uniquement lorsqu'elle est dÃ©finie
    if config.scaler is not None:
        # Propulse le scaler choisi vers le module appelÃ©
        command.extend(["--scaler", config.scaler])
    # Ajoute la stratÃ©gie de features pour harmoniser train et predict
    command.extend(["--feature-strategy", config.feature_strategy])
    # Ajoute la mÃ©thode de rÃ©duction de dimension pour la cohÃ©rence
    command.extend(["--dim-method", config.dim_method])
    # Ajoute le nombre de composantes si fourni pour contrÃ´ler la compression
    if config.n_components is not None:
        # Passe n_components sous forme de chaÃ®ne pour argparse descendant
        command.extend(["--n-components", str(config.n_components)])
    # Ajoute un indicateur pour dÃ©sactiver la normalisation si demandÃ©
    if not config.normalize_features:
        # Utilise un flag boolÃ©en pour inverser la valeur par dÃ©faut
        command.append("--no-normalize-features")
    # ExÃ©cute la commande en capturant le code retour sans lever d'exception
    completed = subprocess.run(command, check=False)
    # Retourne le code retour pour propagation Ã  l'appelant principal
    return completed.returncode


# Construit la ligne de commande pour invoquer le mode realtime
def _call_realtime(config: RealtimeCallConfig) -> int:
    """Invoke le module tpv.realtime avec les paramÃ¨tres streaming."""

    # Initialise la commande avec l'interprÃ©teur courant et le module ciblÃ©
    command: list[str] = [
        sys.executable,
        "-m",
        "tpv.realtime",
        config.subject,
        config.run,
    ]
    # Ajoute la taille de fenÃªtre demandÃ©e pour le streaming
    command.extend(["--window-size", str(config.window_size)])
    # Ajoute le pas de glissement entre fenÃªtres successives
    command.extend(["--step-size", str(config.step_size)])
    # Ajoute la taille du buffer utilisÃ© pour lisser les prÃ©dictions
    command.extend(["--buffer-size", str(config.buffer_size)])
    # Ajoute la latence maximale autorisÃ©e pour surveiller le SLA
    command.extend(["--max-latency", str(config.max_latency)])
    # Ajoute la frÃ©quence d'Ã©chantillonnage pour calculer les offsets
    command.extend(["--sfreq", str(config.sfreq)])
    # Ajoute le rÃ©pertoire des donnÃ©es streamÃ©es
    command.extend(["--data-dir", config.data_dir])
    # Ajoute le rÃ©pertoire d'artefacts contenant le modÃ¨le entraÃ®nÃ©
    command.extend(["--artifacts-dir", config.artifacts_dir])
    # ExÃ©cute la commande en capturant le code retour sans lever d'exception
    completed = subprocess.run(command, check=False)
    # Retourne le code retour pour propagation Ã  l'appelant principal
    return completed.returncode


# Construit le parser CLI avec toutes les options du pipeline
def build_parser() -> argparse.ArgumentParser:
    """Construit l'argument parser pour mybci."""

    # Instancie le parser avec description et usage explicite
    parser = argparse.ArgumentParser(
        description="Pilote un workflow d'entraÃ®nement ou de prÃ©diction TPV",
        usage="python mybci.py <subject> <run> {train,predict,realtime}",
    )
    # Ajoute l'identifiant du sujet pour cibler les donnÃ©es
    parser.add_argument("subject", help="Identifiant du sujet (ex: S001)")
    # Ajoute l'identifiant du run pour cibler la session
    parser.add_argument("run", help="Identifiant du run (ex: R01)")
    # Ajoute le mode pour distinguer entraÃ®nement et prÃ©diction
    parser.add_argument(
        "mode",
        choices=("train", "predict", "realtime"),
        help="Choix du pipeline Ã  lancer",
    )
    # Ajoute le choix du classifieur pour composer le pipeline
    parser.add_argument(
        "--classifier",
        choices=("lda", "logistic", "svm", "centroid"),
        default="lda",
        help="Choix du classifieur final",
    )
    # Ajoute le scaler optionnel pour stabiliser les features
    parser.add_argument(
        "--scaler",
        choices=("standard", "robust", "none"),
        default="none",
        help="Scaler optionnel appliquÃ© aprÃ¨s les features",
    )
    # Ajoute la stratÃ©gie d'extraction de features pour harmoniser train/predict
    parser.add_argument(
        "--feature-strategy",
        choices=("fft", "wavelet"),
        default="fft",
        help="MÃ©thode d'extraction des features",
    )
    # Ajoute la mÃ©thode de rÃ©duction de dimension pour ajuster la compression
    parser.add_argument(
        "--dim-method",
        choices=("pca", "csp"),
        default="pca",
        help="Technique de rÃ©duction de dimension",
    )
    # Ajoute le nombre de composantes pour contrÃ´ler la taille projetÃ©e
    parser.add_argument(
        "--n-components",
        type=int,
        default=argparse.SUPPRESS,
        help="Nombre de composantes Ã  conserver",
    )
    # Ajoute un flag pour dÃ©sactiver la normalisation des features
    parser.add_argument(
        "--no-normalize-features",
        action="store_true",
        help="DÃ©sactive la normalisation des features",
    )
    # Ajoute la taille de fenÃªtre pour la lecture streaming en realtime
    parser.add_argument(
        "--window-size",
        type=int,
        default=50,
        help="Taille de fenÃªtre glissante pour le mode realtime",
    )
    # Ajoute le pas entre deux fenÃªtres successives
    parser.add_argument(
        "--step-size",
        type=int,
        default=25,
        help="Pas entre deux fenÃªtres en streaming realtime",
    )
    # Ajoute la taille du buffer pour lisser les prÃ©dictions instantanÃ©es
    parser.add_argument(
        "--buffer-size",
        type=int,
        default=3,
        help="Taille du buffer de lissage pour le mode realtime",
    )
    # Ajoute la frÃ©quence d'Ã©chantillonnage utilisÃ©e pour les offsets
    parser.add_argument(
        "--sfreq",
        type=float,
        default=50.0,
        help="FrÃ©quence d'Ã©chantillonnage appliquÃ©e au flux realtime",
    )
    # Ajoute la latence maximale tolÃ©rÃ©e pour surveiller la boucle
    parser.add_argument(
        "--max-latency",
        type=float,
        default=2.0,
        help="Latence maximale autorisÃ©e par fenÃªtre realtime",
    )
    # Ajoute le rÃ©pertoire de donnÃ©es nÃ©cessaire au streaming
    parser.add_argument(
        "--data-dir",
        default="data",
        help="RÃ©pertoire racine contenant les fichiers numpy",
    )
    # Ajoute le rÃ©pertoire d'artefacts oÃ¹ lire le modÃ¨le entraÃ®nÃ©
    parser.add_argument(
        "--artifacts-dir",
        default="artifacts",
        help="RÃ©pertoire racine oÃ¹ rÃ©cupÃ©rer le modÃ¨le entraÃ®nÃ©",
    )
    # Retourne le parser configurÃ©
    return parser


# Parse les arguments fournis Ã  la CLI
def parse_args(argv: Sequence[str] | None = None) -> argparse.Namespace:
    """Parse les arguments passÃ©s Ã  mybci."""

    # Construit le parser pour traiter argv
    parser = build_parser()
    # Retourne l'espace de noms aprÃ¨s parsing
    return parser.parse_args(argv)


# Point d'entrÃ©e principal de la CLI
def main(argv: Sequence[str] | None = None) -> int:
    """Point d'entrÃ©e exÃ©cutable de mybci."""

    # Parse les arguments fournis par l'utilisateur
    args = parse_args(argv)
    # InterprÃ¨te le choix du scaler pour convertir "none" en None
    scaler = None if args.scaler == "none" else args.scaler
    # Applique la normalisation en inversant le flag d'opt-out
    normalize_features = not args.no_normalize_features
    # Construit la configuration partagÃ©e entre les modules train et predict
    n_components = getattr(args, "n_components", None)

    config = ModuleCallConfig(
        subject=args.subject,
        run=args.run,
        classifier=args.classifier,
        scaler=scaler,
        feature_strategy=args.feature_strategy,
        dim_method=args.dim_method,
        n_components=n_components,
        normalize_features=normalize_features,
    )
    # Appelle le module train si le mode le demande
    if args.mode == "train":
        # Retourne le code retour du module train avec la configuration
        return _call_module(
            "tpv.train",
            config,
        )
    # Bascule vers le module realtime pour le streaming fenÃªtrÃ©
    if args.mode == "realtime":
        # Construit la configuration spÃ©cifique au lissage et fenÃªtrage
        realtime_config = RealtimeCallConfig(
            subject=args.subject,
            run=args.run,
            window_size=args.window_size,
            step_size=args.step_size,
            buffer_size=args.buffer_size,
            sfreq=args.sfreq,
            max_latency=args.max_latency,
            data_dir=args.data_dir,
            artifacts_dir=args.artifacts_dir,
        )
        # Retourne le code retour du module realtime avec la configuration
        return _call_realtime(realtime_config)
    # Appelle le module predict pour le mode prÃ©diction
    return _call_module(
        "tpv.predict",
        config,
    )


# ProtÃ¨ge l'exÃ©cution directe pour dÃ©lÃ©guer au main
if __name__ == "__main__":  # pragma: no cover - CLI entrypoint
    # Expose le code retour comme exit code du processus
    raise SystemExit(main())

===== pyproject.toml () =====
[tool.poetry]
name = "total-perspective-vortex"
version = "0.1.0"
description = "EEG Brain-Computer Interface pipeline for the Total Perspective Vortex project."
authors = ["raveriss <you@example.com>"]
license = "MIT"
readme = "README.md"
packages = [{ include = "tpv", from = "src" }]

[tool.poetry.dependencies]
python = ">=3.10,<3.11"
numpy = "^1.26"
pandas = "^2.2"
scipy = "^1.11"
scikit-learn = "^1.3"
mne = "^1.6"
matplotlib = "^3.8"
joblib = "^1.4"
urllib3 = "^2.6.0"

[tool.poetry.group.dev.dependencies]
pytest = "^8.3"
pytest-cov = "^5.0"
pytest-timeout = "^2.3"
pytest-randomly = "^3.15"
hypothesis = "^6.112"
mypy = "^1.11"
ruff = "^0.6"
black = "^24.10"
isort = "^5.13"
bandit = "^1.7"
mutmut = "^3.0"
radon = "^6.0"
xenon = "^0.9"
pre-commit = "^4.0"
pip-audit = "^2.7"
coverage = "^7.6"

[tool.black]
line-length = 88
target-version = ["py310"]

[tool.isort]
profile = "black"
line_length = 88
known_first_party = ["mybci", "tpv"]
src_paths = ["src", "scripts", "tests"]

[tool.ruff]
line-length = 88
target-version = "py310"

[tool.ruff.lint]
select = ["E", "F", "W", "I", "B", "PL", "C4"]
ignore = []

[tool.ruff.lint.isort]
known-first-party = ["mybci", "tpv"]

[tool.mutmut]
paths_to_mutate = [
    "src/tpv",
    "mybci.py",
    "scripts",
]
also_copy = ["scripts", "src"]
pytest_add_cli_args = ["-q", "-k", "not latency_benchmark and not benchmark"]
mutate_only_covered_lines = true

[tool.pytest.ini_options]
pythonpath = ["src", ".", ".."]

[tool.mypy]
python_version = "3.10"
check_untyped_defs = true
warn_unused_ignores = true
warn_return_any = true
warn_redundant_casts = true
strict_optional = true
no_implicit_optional = true
show_error_codes = true
pretty = true
ignore_missing_imports = true
files = "src scripts tests"

[build-system]
requires = ["poetry-core"]
build-backend = "poetry.core.masonry.api"

===== src/tpv/train.py () =====
"""Point d'entrÃ©e module pour l'entraÃ®nement via mybci."""

# Centralise le dispatch vers la logique CLI dÃ©finie dans scripts/train
from scripts import train as script_train


# Relaye l'exÃ©cution CLI pour rester compatible avec python -m tpv.train
def main(argv: list[str] | None = None) -> int:
    """Proxy vers scripts.train.main pour lancer l'entraÃ®nement."""

    # DÃ©lÃ¨gue l'ensemble du traitement au module scripts.train
    return script_train.main(argv)


# Expose explicitement la fonction d'entraÃ®nement pour les imports directs
run_training = script_train.run_training


# ProtÃ¨ge l'exÃ©cution directe pour exposer un exit code explicite
if __name__ == "__main__":  # pragma: no cover - exÃ©cution CLI directe
    # Retourne l'issue du main comme code de sortie du processus
    raise SystemExit(main())

===== src/tpv/features.py () =====
"""Feature extraction utilities for EEG signals."""

# Importe les annotations pour clarifier la signature des fonctions
# Importe Any pour typer la configuration dynamique des fonctions
from typing import Any, Dict, Iterable, List, Mapping, Sequence, Tuple

# Importe NumPy pour manipuler les tenseurs spectraux et tabulaires
import numpy as np

# Importe scipy.signal pour accÃ©der Ã  l'estimateur de Welch et Ã  la CWT
from scipy import signal

# Importe BaseEstimator et TransformerMixin pour conserver la compatibilitÃ© scikit-learn
from sklearn.base import BaseEstimator, TransformerMixin


def _resolve_band_ranges(
    config: Mapping[str, Any], default_bands: Mapping[str, Tuple[float, float]]
) -> Dict[str, Tuple[float, float]]:
    """Retourne les bandes explicites en prÃ©servant l'ordre demandÃ©."""

    # Fusionne les bandes personnalisÃ©es pour respecter l'ordre d'entrÃ©e
    return dict(config.get("bands", default_bands))


def _prepare_welch_parameters(
    config: Mapping[str, Any], n_times: int
) -> Tuple[str | Iterable[float], int, int | None, str, str]:
    """Calcule des paramÃ¨tres Welch bornÃ©s pour Ã©viter les avertissements."""

    # Applique une fenÃªtre lisse pour limiter les fuites frÃ©quentielles
    window: str | Iterable[float] = config.get("window", "hann")
    # Permet d'ajuster la taille de segment pour contrÃ´ler la rÃ©solution
    nperseg: int | None = config.get("nperseg")
    # Borne la taille de segment pour Ã©viter les avertissements SciPy
    effective_nperseg: int = min(nperseg or n_times, n_times)
    # Offre un recouvrement configurable pour stabiliser l'estimation
    noverlap: int | None = config.get("noverlap")
    # Borne le recouvrement pour garantir une fenÃªtre strictement positive
    effective_noverlap: int | None = None
    # VÃ©rifie que l'appelant a fourni un recouvrement explicite
    if noverlap is not None:
        # Coupe le recouvrement juste avant la taille de fenÃªtre autorisÃ©e
        effective_noverlap = min(noverlap, effective_nperseg - 1)
    # Permet de choisir la stratÃ©gie d'agrÃ©gation des segments
    average: str = config.get("average", "mean")
    # Permet de choisir la densitÃ© ou la puissance intÃ©grÃ©e
    scaling: str = config.get("scaling", "density")
    # Regroupe les paramÃ¨tres bornÃ©s pour l'appel Welch
    return window, effective_nperseg, effective_noverlap, average, scaling


def _compute_welch_band_powers(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule les puissances de bandes via Welch avec bornes sÃ©curisÃ©es."""

    # Stocke le nombre d'Ã©chantillons pour calibrer les fenÃªtres de Welch
    n_times: int = data.shape[-1]
    # Calcule les paramÃ¨tres Welch pour un appel robuste
    window, effective_nperseg, effective_noverlap, average, scaling = (
        _prepare_welch_parameters(config, n_times)
    )
    # Calcule la densitÃ© spectrale de puissance par canal et par essai
    freqs, psd = signal.welch(
        data,
        sfreq,
        window=window,
        nperseg=effective_nperseg,
        noverlap=effective_noverlap,
        axis=-1,
        average=average,
        scaling=scaling,
    )
    # Accumule les puissances de bande pour chaque intervalle demandÃ©
    band_powers: List[np.ndarray] = []
    # Parcourt les bandes dans l'ordre pour garantir la stabilitÃ© des colonnes
    for _, (low, high) in band_ranges.items():
        # Construit un masque frÃ©quentiel pour isoler l'intervalle cible
        band_mask = (freqs >= low) & (freqs <= high)
        # Renvoie des zÃ©ros si aucune frÃ©quence n'est disponible dans la bande
        if not np.any(band_mask):
            # Fournit un tenseur nul pour prÃ©server la forme de sortie
            band_powers.append(np.zeros(psd.shape[:2]))
        else:
            # Moyenne la PSD sur la bande pour rÃ©duire la dimension temporelle
            band_powers.append(psd[:, :, band_mask].mean(axis=-1))
    # Empile les bandes pour conserver la structure epochs x canaux x bandes
    return np.stack(band_powers, axis=2)


def _compute_wavelet_coefficients(
    channel_values: np.ndarray,
    central_frequencies: Sequence[float],
    sfreq: float,
    wavelet_cycles: float,
) -> np.ndarray:
    """Calcule les coefficients wavelets en convoluant une gaussienne modulÃ©e."""

    # PrÃ©pare un conteneur pour stocker les coefficients par Ã©chelle
    coefficients: List[np.ndarray] = []
    # PrÃ©pare un axe temporel centrÃ© pour construire la gaussienne
    centered_times = np.arange(channel_values.size) - (channel_values.size - 1) / 2
    # Parcourt les frÃ©quences centrales pour projeter le signal
    for central_frequency in central_frequencies:
        # EmpÃªche une frÃ©quence nulle pour Ã©viter des divisions par zÃ©ro
        safe_frequency = max(central_frequency, 1e-9)
        # Calcule l'Ã©cart-type de la gaussienne en fonction du nombre de cycles
        sigma = wavelet_cycles * sfreq / safe_frequency
        # Construit la gaussienne centrÃ©e pour limiter les fuites temporelles
        envelope = np.exp(-(centered_times**2) / (2 * sigma**2))
        # Construit l'oscillation complexe alignÃ©e sur la frÃ©quence centrale
        oscillation = np.exp(2j * np.pi * safe_frequency * centered_times / sfreq)
        # Combine l'enveloppe et l'oscillation pour former la wavelet
        wavelet = envelope * oscillation
        # Convolue le signal avec la wavelet via FFT pour l'efficacitÃ©
        convolved = signal.fftconvolve(channel_values, wavelet, mode="same")
        # Ajoute le rÃ©sultat Ã  la liste pour assembler la matrice finale
        coefficients.append(convolved)
    # Empile les coefficients en matrice (bandes, temps) pour analyse d'Ã©nergie
    return np.stack(coefficients, axis=0)


def _compute_wavelet_band_powers(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule l'Ã©nergie de bandes via une CWT Morlet paramÃ©trable."""

    # Configure la largeur de la wavelet pour ajuster la rÃ©solution temps-frÃ©quence
    wavelet_cycles: float = float(config.get("wavelet_width", 6.0))
    # Calcule la frÃ©quence centrale de chaque bande pour cibler la wavelet
    central_frequencies: List[float] = [
        (low + high) / 2.0 for low, high in band_ranges.values()
    ]
    # PrÃ©pare un tableau pour stocker l'Ã©nergie par essai, canal et bande
    band_powers: np.ndarray = np.zeros((data.shape[0], data.shape[1], len(band_ranges)))
    # Parcourt chaque essai pour Ã©viter des allocations massives inutiles
    for epoch_index, epoch_data in enumerate(data):
        # Parcourt chaque canal pour projeter le signal sur les Ã©chelles ciblÃ©es
        for channel_index, channel_values in enumerate(epoch_data):
            # Calcule les coefficients CWT sur les Ã©chelles demandÃ©es
            coefficients = _compute_wavelet_coefficients(
                channel_values,
                central_frequencies,
                sfreq,
                wavelet_cycles,
            )
            # Calcule la puissance moyenne par bande en intÃ©grant la magnitude
            band_energy = np.abs(coefficients) ** 2
            # Moyenne temporelle pour stabiliser l'Ã©nergie de chaque bande
            band_powers[epoch_index, channel_index, :] = band_energy.mean(axis=1)
    # Retourne le tenseur Ã©nergie pour alignement avec les Ã©tiquettes de bandes
    return band_powers


def _build_labels(
    stacked: np.ndarray,
    band_ranges: Mapping[str, Tuple[float, float]],
    channel_names: Sequence[str],
) -> List[str]:
    """Construit des Ã©tiquettes canal_bande pour interprÃ©ter les features."""

    # PrÃ©pare les Ã©tiquettes par canal et bande pour interprÃ©ter les colonnes
    labels: List[str] = []
    # Parcourt les canaux pour associer les bandes Ã  chaque sÃ©rie temporelle
    for channel_index in range(stacked.shape[1]):
        # SÃ©lectionne un nom explicite ou construit un identifiant gÃ©nÃ©rique
        channel_label = (
            channel_names[channel_index] if channel_names else f"ch{channel_index}"
        )
        # Ajoute une Ã©tiquette pour chaque bande afin de suivre l'ordre des colonnes
        for band_name in band_ranges.keys():
            # ConcatÃ¨ne le canal et la bande pour un suivi lisible
            labels.append(f"{channel_label}_{band_name}")
    # Retourne la liste d'Ã©tiquettes alignÃ©e sur la matrice aplatie
    return labels


class ExtractFeatures(BaseEstimator, TransformerMixin):
    """Extract band power features from EEG recordings."""

    BAND_RANGES = {
        "theta": (4.0, 7.0),
        "alpha": (8.0, 12.0),
        "beta": (13.0, 30.0),
        "gamma": (31.0, 45.0),
    }

    EXPECTED_EEG_NDIM = 3
    NORMALIZATION_EPS = 1e-12

    def __init__(
        self, sfreq: float, feature_strategy: str = "fft", normalize: bool = True
    ):
        self.sfreq = sfreq
        self.feature_strategy = feature_strategy
        self.normalize = normalize

    def fit(self, X, y=None):
        return self

    def transform(self, X):
        if X.ndim != self.EXPECTED_EEG_NDIM:
            raise ValueError("X must have shape (n_samples, n_channels, n_times)")
        # Calcule les features brutes (FFT ou wavelet)
        raw_features = self._compute_features(X)
        # Normalise optionnellement les features bande-par-bande
        if self.normalize:
            mean = raw_features.mean(axis=1, keepdims=True)
            std = raw_features.std(axis=1, keepdims=True) + self.NORMALIZATION_EPS
            features = (raw_features - mean) / std
        else:
            features = raw_features
        # VÃ©rifie qu'aucune valeur non finie ne subsiste
        if not np.all(np.isfinite(features)):
            raise ValueError(
                "ExtractFeatures produced non-finite values (NaN/Inf). "
                "Check band ranges and sampling frequency."
            )
        return features


    @property
    def band_labels(self):
        return list(self.BAND_RANGES.keys())

    def _compute_fft_features(self, X):
        # Calcule les frÃ©quences rÃ©elles Ã  partir de la sfreq configurÃ©e
        freqs = np.fft.rfftfreq(X.shape[2], d=1.0 / self.sfreq)
        # Calcule la puissance spectrale par canal et Ã©chantillon
        power = np.abs(np.fft.rfft(X, axis=2)) ** 2  # pragma: no mutate
        # PrÃ©pare le conteneur pour accumuler les puissances de bandes
        features = []
        # Parcourt chaque bande EEG dÃ©finie dans BAND_RANGES
        for band in self.band_labels:
            # RÃ©cupÃ¨re les bornes frÃ©quentielles de la bande
            low, high = self.BAND_RANGES[band]
            # Construit le masque frÃ©quentiel pour cette bande
            band_mask = (freqs >= low) & (freqs <= high)
            # GÃ¨re le cas oÃ¹ aucune frÃ©quence ne tombe dans la bande
            if not np.any(band_mask):
                # Retourne un bloc de zÃ©ros pour prÃ©server la forme
                band_power = np.zeros(power.shape[:2])
            else:
                # Moyenne la puissance sur les frÃ©quences de la bande
                band_power = power[:, :, band_mask].mean(axis=2)
            # Ajoute la matrice (n_samples, n_channels) Ã  la liste
            features.append(band_power)
        # ConcatÃ¨ne les bandes le long de lâ€™axe des features
        return np.concatenate(features, axis=1)


    def _compute_fft_features(self, X):
        freqs = np.fft.rfftfreq(X.shape[2], d=1.0 / self.sfreq)
        power = np.abs(np.fft.rfft(X, axis=2)) ** 2  # pragma: no mutate
        features = []
        for band in self.band_labels:
            low, high = self.BAND_RANGES[band]
            band_mask = (freqs >= low) & (freqs <= high)
            band_power = power[:, :, band_mask].mean(axis=2)
            features.append(band_power)
        return np.concatenate(features, axis=1)

    def _compute_wavelet_features(self, X):
        # Calcule la frÃ©quence centrale pour chaque bande prÃ©dÃ©finie
        central_frequencies = [
            (low + high) / 2.0 for low, high in self.BAND_RANGES.values()
        ]
        # PrÃ©pare une matrice vide pour accueillir les features wavelets
        features = np.zeros((X.shape[0], X.shape[1] * len(self.BAND_RANGES)))
        # Parcourt chaque essai pour limiter la charge mÃ©moire
        for epoch_index, epoch_data in enumerate(X):
            # Parcourt chaque canal pour calculer les coefficients wavelets
            for channel_index, channel_values in enumerate(epoch_data):
                # Calcule la CWT pour toutes les bandes en une seule fois
                coefficients = _compute_wavelet_coefficients(
                    channel_values,
                    central_frequencies,
                    self.sfreq,
                    wavelet_cycles=6.0,
                )
                # Calcule l'Ã©nergie moyenne par bande Ã  partir des coefficients
                band_energy = np.abs(coefficients) ** 2
                # Aplatit le tenseur pour l'insÃ©rer dans la matrice finale
                start = channel_index * len(self.BAND_RANGES)
                # Termine l'intervalle correspondant au canal courant
                end = start + len(self.BAND_RANGES)
                # Place l'Ã©nergie moyenne dans les colonnes associÃ©es au canal
                features[epoch_index, start:end] = band_energy.mean(axis=1)
        # Retourne la matrice tabulaire prÃªte pour un classifieur scikit-learn
        return features


def extract_features(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = dict(config or {})
    # DÃ©clare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = {
        "theta": (4.0, 7.0),
        "alpha": (8.0, 12.0),
        "beta": (13.0, 30.0),
        "gamma": (31.0, 45.0),
    }
    # Fusionne les bandes personnalisÃ©es en conservant l'ordre demandÃ©
    band_ranges: Dict[str, Tuple[float, float]] = _resolve_band_ranges(
        effective_config, default_bands
    )
    # RÃ©cupÃ¨re la mÃ©thode pour aiguiller la stratÃ©gie d'extraction
    method: str = effective_config.get("method", "welch")
    # Capture les noms de canaux pour aligner les Ã©tiquettes de features
    channel_names: Sequence[str] = getattr(epochs.info, "ch_names", [])
    # Extrait les donnÃ©es temporelles pour calculer les caractÃ©ristiques spectrales
    data: np.ndarray = epochs.get_data()
    # RÃ©cupÃ¨re la frÃ©quence d'Ã©chantillonnage indispensable au calcul frÃ©quentiel
    sfreq: float = float(epochs.info["sfreq"])
    # Oriente vers le calcul Welch lorsque la mÃ©thode par dÃ©faut est demandÃ©e
    if method == "welch":
        # Calcule les PSD de bandes via Welch avec paramÃ¨tres bornÃ©s
        stacked = _compute_welch_band_powers(data, sfreq, band_ranges, effective_config)
    # Oriente vers la transformÃ©e en ondelettes pour une rÃ©solution temporelle
    elif method == "wavelet":
        # Calcule l'Ã©nergie de bandes via une CWT configurÃ©e
        stacked = _compute_wavelet_band_powers(
            data, sfreq, band_ranges, effective_config
        )
    # Rejette explicitement les mÃ©thodes non reconnues pour Ã©viter des surprises
    else:
        # Signale l'erreur avec la mÃ©thode fournie par l'appelant
        raise ValueError(f"Unsupported feature extraction method: {method}")
    # Construit des Ã©tiquettes canal_bande pour interprÃ©ter les features
    labels: List[str] = _build_labels(stacked, band_ranges, channel_names)
    # Aplati les bandes pour fournir une matrice compatible avec scikit-learn
    flattened = stacked.reshape(stacked.shape[0], -1)
    # Retourne les features tabulaires accompagnÃ©s de leurs Ã©tiquettes
    return flattened, labels

===== src/tpv/preprocessing.py () =====
"""Utilities for loading and validating Physionet EEG datasets.

Filtrage EEG 8â€“40 Hz (FIR/IIR) avec padding (FIR auto ~2â€“4*fs, IIR ordre 4).

Le filtre par dÃ©faut suit la contrainte WBS 3.1.1 : bande 8â€“40 Hz avec FIR
zero-phase (longueur auto MNE Ã©quivalente Ã  un ordre ~401 sur des segments
>1s) ou IIR Butterworth (ordre 4) et un padding rÃ©flÃ©chissant de 0.5 seconde
pour limiter les effets de bord sur les segments fenÃªtrÃ©s.
"""

# Garantit la compatibilitÃ© des annotations de type pour lâ€™ensemble du module
from __future__ import annotations

# PrÃ©serve les fonctions de hachage pour valider lâ€™intÃ©gritÃ© des datasets
import hashlib

# Conserve json pour formater les rapports dâ€™erreurs de comptage de runs
import json

# Utilise pathlib pour assurer la portabilitÃ© des interactions fichiers
# Introduit dataclass pour regrouper la configuration de rapport
from dataclasses import dataclass

# Utilise pathlib pour assurer la portabilitÃ© des interactions fichiers
from pathlib import Path

# Centralise les hints pour clarifier les attentes des appels et des tests
from typing import Any, Dict, List, Mapping, Tuple

# MNE est obligatoire pour le parsing EDF/BDF et la gestion des epochs
import mne

# Numpy offre des masques vectorisÃ©s pour filtrer rapidement les Ã©vÃ©nements
import numpy as np

# Pandas gÃ¨re les mÃ©tadonnÃ©es annotÃ©es pour le contrÃ´le qualitÃ©
import pandas as pd

# Typing numpy clarifie les formes et types pour mypy et les tests
from numpy.typing import NDArray

# Provide a default mapping consistent with Physionet motor imagery labels
PHYSIONET_LABEL_MAP: Dict[str, int] = {"T0": 0, "T1": 1, "T2": 2}
# Provide an explicit mapping from Physionet events to motor imagery labels
MOTOR_EVENT_LABELS: Dict[str, str] = {"T1": "A", "T2": "B"}
# DÃ©clare les Ã©tiquettes attendues pour vÃ©rifier la prÃ©sence des classes
EXPECTED_LABELS: Tuple[str, str] = ("A", "B")
# Fixe la mÃ©thode de filtrage par dÃ©faut pour la cohÃ©rence API et tests
DEFAULT_FILTER_METHOD = "fir"
# Fixe la mÃ©thode de normalisation par dÃ©faut pour les canaux EEG
DEFAULT_NORMALIZE_METHOD = "zscore"
# Fixe l'epsilon de stabilisation pour la normalisation par dÃ©faut
DEFAULT_NORMALIZE_EPSILON = 1e-8


def apply_bandpass_filter(
    raw: mne.io.BaseRaw,
    method: str = DEFAULT_FILTER_METHOD,
    freq_band: Tuple[float, float] = (8.0, 40.0),
    order: int | str | None = None,
    pad_duration: float = 0.5,
) -> mne.io.BaseRaw:
    """Apply a padded 8â€“40 Hz band-pass filter using FIR or IIR designs."""

    # Clone the raw object to avoid mutating caller buffers during filtering
    filtered_raw = raw.copy().load_data()
    # Normalize the method string to simplify downstream comparisons
    normalized_method = method.lower()
    # Enforce supported methods to avoid silent fallbacks inside MNE
    if normalized_method not in {"fir", "iir"}:
        # Raise early to force callers to pick an explicit filter family
        raise ValueError("method must be 'fir' or 'iir'")
    # Extract the sampling frequency to derive padding and design parameters
    sampling_rate = float(filtered_raw.info["sfreq"])
    # DÃ©compose la bande en frÃ©quences basse et haute pour le filtrage
    l_freq, h_freq = freq_band
    # Translate the padding duration into sample counts for symmetrical padding
    pad_samples = max(int(round(pad_duration * sampling_rate)), 0)
    # Fetch the data array once to avoid repeated MNE access overhead
    data = filtered_raw.get_data()
    # Build a reflect-padded buffer to minimize edge artifacts during filtering
    if pad_samples > 0:
        # Use symmetric reflection to keep boundary continuity without phase jumps
        padded_data = np.pad(data, ((0, 0), (pad_samples, pad_samples)), mode="reflect")
    else:
        # Skip padding when the caller explicitly disables it via pad_duration=0.0
        padded_data = data
    # Prepare FIR-specific arguments when a linear-phase design is required
    if normalized_method == "fir":
        # SÃ©lectionne lâ€™ordre FIR explicite ou lâ€™auto-calcul par dÃ©faut
        fir_length = order if order is not None else "auto"
        # Configure FIR parameters to balance roll-off and latency for MI bands
        filter_kwargs: Dict[str, Any] = {
            "method": "fir",
            "fir_design": "firwin",
            "fir_window": "hamming",
            "filter_length": fir_length,
            "phase": "zero-double",
        }
    else:
        # DÃ©finit lâ€™ordre IIR Ã  4 par dÃ©faut pour limiter la latence
        iir_order = int(order) if order is not None else 4
        # Configure a Butterworth IIR design to minimize latency during streaming
        filter_kwargs = {
            "method": "iir",
            "iir_params": {"order": iir_order, "ftype": "butter"},
            "phase": "zero-double",
        }
    # Apply the selected filter to the padded buffer to obtain band-limited data
    filtered_data = mne.filter.filter_data(
        padded_data,
        sfreq=sampling_rate,
        l_freq=l_freq,
        h_freq=h_freq,
        verbose=False,
        **filter_kwargs,
    )
    # Remove artificial padding to restore the original signal duration
    if pad_samples > 0:
        # Slice out the central segment corresponding to the unpadded recording
        filtered_data = filtered_data[:, pad_samples:-pad_samples]
    # Assign the filtered samples back into the cloned Raw object for return
    filtered_raw._data = filtered_data
    # Return the filtered recording to feed downstream epoching and features
    return filtered_raw


def _is_bad_description(description: str) -> bool:
    """Return True when an annotation description denotes a BAD marker."""

    # Normalize the description to uppercase for case-insensitive detection
    normalized_description = description.upper()
    # Identify MNE BAD-prefixed annotations regardless of original casing
    return normalized_description.startswith("BAD")


def load_mne_raw_checked(
    file_path: Path,
    expected_montage: str,
    expected_sampling_rate: float,
    expected_channels: List[str],
) -> mne.io.BaseRaw:
    """Load a raw MNE file and validate montage, sampling rate, and channels."""

    # Normalize the file path to avoid surprises from relative inputs
    normalized_path = Path(file_path).expanduser().resolve()
    # Capture the suffix to enforce EDF/BDF compatibility explicitly
    file_suffix = normalized_path.suffix.lower()
    # Reject unsupported formats early to avoid ambiguous MNE errors
    if file_suffix not in {".edf", ".bdf"}:
        # Raise a clear error when the extension does not match EDF/BDF
        raise ValueError(
            json.dumps(
                {
                    "error": "Unsupported file format",
                    "path": str(normalized_path),
                    "suffix": file_suffix,
                }
            )
        )
    # Load the raw file with preload enabled for immediate validation
    raw = mne.io.read_raw_edf(normalized_path, preload=True, verbose=False)
    # Apply the montage to ensure spatial layout matches expectations
    raw.set_montage(expected_montage, on_missing="warn")
    # Retrieve the effective montage to confirm it has been attached
    montage = raw.get_montage()
    # Fail loudly when the montage could not be established on the recording
    if montage is None:
        # Raise a clear error describing the missing montage configuration
        raise ValueError(f"Montage '{expected_montage}' could not be applied")
    # Capture montage channel names to compare against expected layout
    montage_channels = set(montage.ch_names)
    # Capture surplus montage channels to document unexpected electrodes
    extra_montage_channels = sorted(montage_channels - set(expected_channels))
    # Identify montage omissions that would break 10â€“20 assumptions
    missing_montage_channels = sorted(set(expected_channels) - montage_channels)
    # Raise explicit error when the montage lacks required 10â€“20 electrodes
    if missing_montage_channels:
        # Include missing channels in a structured report for debugging
        raise ValueError(
            json.dumps(
                {
                    "error": "Montage missing expected channels",
                    "missing_channels": missing_montage_channels,
                    "extra": extra_montage_channels,
                    "montage": expected_montage,
                }
            )
        )
    # Extract the sampling frequency reported by the recording
    sampling_rate = float(raw.info["sfreq"])
    # Validate the sampling frequency against the expected configuration
    if not np.isclose(sampling_rate, expected_sampling_rate):
        # Raise a descriptive error when the sampling rate deviates
        raise ValueError(
            f"Expected sampling rate {expected_sampling_rate}Hz "
            f"but got {sampling_rate}Hz"
        )
    # Gather channel names from the recording for consistency checks
    channel_names = list(raw.ch_names)
    # Identify unexpected channels that would break downstream spatial filters
    extra_channels = sorted(set(channel_names) - set(expected_channels))
    # Identify missing channels that would prevent feature extraction
    missing_channels = sorted(set(expected_channels) - set(channel_names))
    # Raise an explicit error when the channel layout is inconsistent
    if extra_channels or missing_channels:
        # Compose a readable error describing both types of discrepancies
        raise ValueError(
            json.dumps(
                {
                    "error": "Channel mismatch",
                    "extra": extra_channels,
                    "missing": missing_channels,
                }
            )
        )
    # Return the validated raw object for downstream preprocessing steps
    return raw


def load_mne_motor_run(
    file_path: Path,
    expected_sampling_rate: float,
    expected_channels: List[str],
    expected_montage: str = "standard_1020",
) -> Tuple[mne.io.BaseRaw, np.ndarray, Dict[str, int], List[str]]:
    """Load an EDF/BDF run and expose motor labels A/B."""

    # VÃ©rifie et charge le fichier en imposant montage et frÃ©quence attendus
    raw = load_mne_raw_checked(
        file_path,
        expected_montage=expected_montage,
        expected_sampling_rate=expected_sampling_rate,
        expected_channels=expected_channels,
    )
    # Mappe les Ã©vÃ©nements vers des Ã©tiquettes motrices compatibles A/B
    events, event_id, motor_labels = map_events_to_motor_labels(raw)
    # Retourne l'enregistrement et les structures nÃ©cessaires au dÃ©coupage
    return raw, events, event_id, motor_labels


def load_physionet_raw(
    file_path: Path, montage: str = "standard_1020"
) -> Tuple[mne.io.BaseRaw, Dict[str, object]]:
    """Load an EDF/BDF Physionet file with metadata."""

    # Resolve the input path to avoid surprises with relative locations
    normalized_path = Path(file_path).expanduser().resolve()
    # Load the recording with preload to enable immediate validation steps
    raw = mne.io.read_raw_edf(normalized_path, preload=True, verbose=False)
    # Attach the montage so downstream spatial filters assume 10-20 layout
    raw.set_montage(montage, on_missing="warn")
    # Extract sampling rate to guide later filtering and epoch durations
    sampling_rate = float(raw.info["sfreq"])
    # Capture channel names to expose them to downstream feature builders
    channel_names = list(raw.ch_names)
    # Record the montage name for traceability in integrity reports
    montage_name = montage
    # Bundle metadata for callers that need reproducible preprocessing config
    metadata = {
        "sampling_rate": sampling_rate,
        "channel_names": channel_names,
        "montage": montage_name,
        "path": str(normalized_path),
    }
    # Return both signal and metadata to keep the loader side-effect free
    return raw, metadata


def _extract_bad_intervals(raw: mne.io.BaseRaw) -> List[Tuple[float, float]]:
    """Return BAD annotation windows as (start, end) times in seconds."""

    # Start with an empty list to accumulate invalid windows
    bad_intervals: List[Tuple[float, float]] = []
    # Iterate annotations to translate BAD markers into explicit intervals
    for onset, duration, desc in zip(
        raw.annotations.onset,
        raw.annotations.duration,
        raw.annotations.description,
        strict=True,
    ):
        # Skip annotations not flagged BAD to avoid overzealous filtering
        if not _is_bad_description(desc):
            # Continue looping when the annotation is not an invalid segment
            continue
        # Append the interval boundaries to help later event rejection
        bad_intervals.append((float(onset), float(onset + duration)))
    # Return all invalid windows for consumers that exclude unsafe events
    return bad_intervals


def map_events_and_validate(
    raw: mne.io.BaseRaw,
    label_map: Mapping[str, int] | None = None,
    motor_label_map: Mapping[str, str] | None = None,
) -> Tuple[np.ndarray, Dict[str, int]]:
    """Map annotations to events while checking label consistency."""

    # Use caller-provided label map or default Physionet mapping for labels
    effective_label_map = (
        dict(label_map) if label_map is not None else dict(PHYSIONET_LABEL_MAP)
    )
    # Confirm annotations contain only labels that the mapping can handle
    _validate_annotation_labels(raw, effective_label_map)
    # Detect whether motor mapping validation should be applied
    motor_labels_present = any(
        desc in MOTOR_EVENT_LABELS
        for desc in raw.annotations.description
        if not _is_bad_description(desc)
    )
    # Build a motor mapping to make motor imagery labels explicit when needed
    if motor_labels_present or motor_label_map is not None:
        # Validate the mapping either provided by the caller or defaulted
        _validate_motor_mapping(
            raw,
            effective_label_map,
            motor_label_map if motor_label_map is not None else MOTOR_EVENT_LABELS,
        )
    # Extract invalid windows to support removal of corrupted epochs
    bad_intervals = _extract_bad_intervals(raw)
    # Convert annotations into events that MNE Epochs can consume
    events, _ = mne.events_from_annotations(
        raw, event_id=effective_label_map, verbose=False
    )
    # Preserve the full label map even if some labels are absent in a run
    event_id = dict(effective_label_map)
    # Build a boolean mask describing which events survive BAD intervals
    keep_mask = _build_keep_mask(events, raw.info["sfreq"], bad_intervals)
    # Gather events whose mask entries remain explicitly True
    filtered_events_list = [
        event for flag, event in zip(keep_mask, events, strict=True) if flag is True
    ]
    # Convert the preserved events back to a NumPy array for downstream consumers
    filtered_events = np.array(filtered_events_list)
    # Return clean events and the mapping for downstream epoch creation
    return filtered_events, event_id


def map_events_to_motor_labels(raw):
    """
    Map EEGMMI (PhysioNet) annotations (T0, T1, T2, ...) to motor labels.

    Returns
    -------
    events : np.ndarray
        Tableau d'Ã©vÃ©nements MNE (n_events, 3), filtrÃ© pour ne garder
        que les essais moteurs (T1, T2, T3, T4 si prÃ©sents).
    event_id : dict[str, int]
        Dictionnaire MNE ne contenant que les codes moteurs prÃ©sents.
    motor_labels : list[str]
        Liste triÃ©e des codes moteurs rÃ©ellement prÃ©sents (ex: ['T1', 'T2']).
    """
    # RÃ©cupÃ¨re les Ã©vÃ©nements et le mapping brut depuis les annotations MNE
    events, event_id = mne.events_from_annotations(raw)

    # Inverse le mapping pour passer du code entier -> label texte (T0, T1, T2, ...)
    inv_event_id = {v: k for k, v in event_id.items()}

    # RÃ©cupÃ¨re le label texte pour chaque Ã©vÃ©nement
    labels = [inv_event_id[e[2]] for e in events]

    # Toutes les Ã©tiquettes prÃ©sentes dans les annotations
    all_labels = sorted(set(labels))

    # Codes moteurs possibles dans EEGMMI
    motor_codes = ("T1", "T2", "T3", "T4")

    # Codes moteurs effectivement prÃ©sents dans ce run
    present_motor_codes = [code for code in motor_codes if code in all_labels]

    # Si vraiment aucun essai moteur dans ce run, alors seulement on lÃ¨ve l'erreur
    if not present_motor_codes:
        raise ValueError(
            {
                "error": "No motor events present",
                "available_labels": all_labels,
            }
        )

    # Masque pour ne garder que les Ã©vÃ©nements dont le label est moteur (T1/T2/T3/T4 prÃ©sents)
    mask = np.isin(labels, present_motor_codes)

    # Filtre le tableau d'Ã©vÃ©nements
    events = events[mask]

    # Restreint event_id aux codes moteurs prÃ©sents seulement
    motor_event_id = {code: event_id[code] for code in present_motor_codes}

    # Retourne les Ã©vÃ©nements filtrÃ©s, le mapping et la liste des labels moteurs
    return events, motor_event_id, present_motor_codes


def _validate_annotation_labels(
    raw: mne.io.BaseRaw, effective_label_map: Mapping[str, int]
) -> None:
    """Ensure annotations only include labels present in the mapping."""

    # Inspect annotations to ensure only expected labels remain
    present_labels = set(raw.annotations.description)
    # Identify labels that would break the supervised mapping stage
    unknown_labels = {
        lab
        for lab in present_labels
        if lab not in effective_label_map and not _is_bad_description(lab)
    }
    # Stop early when unknown labels are detected to prevent silent errors
    if unknown_labels:
        # Raise a descriptive error to support dataset hygiene during setup
        raise ValueError(
            json.dumps(
                {
                    "error": "Unknown annotation labels",
                    "unknown_labels": sorted(unknown_labels),
                }
            )
        )


def _validate_motor_mapping(
    raw: mne.io.BaseRaw,
    effective_label_map: Mapping[str, int],
    motor_label_map: Mapping[str, str],
) -> Dict[str, str]:
    """Validate motor mapping covers all events with A/B labels."""

    # Copy the mapping to avoid mutating caller dictionaries during validation
    effective_motor_map = dict(motor_label_map)
    # Restrict allowed motor labels to the binary A/B tasks defined by the project
    allowed_motor_labels = {"A", "B"}
    # Detect invalid motor labels that would break downstream training splits
    invalid_motor_labels = set(effective_motor_map.values()) - allowed_motor_labels
    # Raise a clear error when unsupported motor labels are provided
    if invalid_motor_labels:
        # Surface which labels are invalid to guide mapping corrections
        raise ValueError(
            f"Motor labels must be within {sorted(allowed_motor_labels)}: "
            f"found {sorted(invalid_motor_labels)}"
        )
    # Collect all annotation labels excluding BAD markers for completeness checks
    observed_labels = {
        desc for desc in raw.annotations.description if not _is_bad_description(desc)
    }
    # Restrict completeness checks to motor-related annotation labels
    motor_label_candidates = {
        desc for desc in observed_labels if desc in MOTOR_EVENT_LABELS
    }
    # Identify observed motor labels not covered by the motor mapping
    missing_motor_keys = motor_label_candidates - set(effective_motor_map.keys())
    # Raise a descriptive error when observed labels lack motor interpretations
    if missing_motor_keys:
        # Include unknown label names to speed up dataset adjustments
        raise ValueError(
            f"Motor mapping missing labels for events: {sorted(missing_motor_keys)}"
        )
    # Identify motor labels that are expected but absent from the mapping outputs
    missing_targets = allowed_motor_labels - set(effective_motor_map.values())
    # Raise when A or B is not reachable from the mapping configuration
    if missing_targets:
        # Provide actionable feedback by listing missing motor targets explicitly
        raise ValueError(
            f"Motor mapping must include targets {sorted(allowed_motor_labels)}: "
            f"missing {sorted(missing_targets)}"
        )
    # Identify motor keys that are not part of the annotation label map
    unknown_keys = set(effective_motor_map.keys()) - set(effective_label_map.keys())
    # Stop when the motor mapping references labels outside the event ID map
    if unknown_keys:
        # Include stray keys in the error to steer label alignment quickly
        raise ValueError(
            f"Motor mapping references unknown events: {sorted(unknown_keys)}"
        )
    # Return the validated motor mapping for optional downstream logging
    return effective_motor_map


def _build_keep_mask(
    events: np.ndarray,
    sampling_rate: float,
    bad_intervals: List[Tuple[float, float]],
    forced_mask: List[Any] | None = None,
) -> List[bool]:
    """Return a boolean mask that excludes events overlapping BAD spans."""

    # Declare the mask variable once to maintain consistent typing across branches
    keep_mask: List[Any]
    # Accept an externally supplied mask to validate defensive branches explicitly
    if forced_mask is not None:
        # Copy the forced mask to avoid caller-side mutations affecting validation
        keep_mask = list(forced_mask)
    else:
        # Initialize a boolean mask list to track valid events explicitly
        keep_mask = [True] * len(events)
        # Iterate over events to check whether they overlap a BAD interval
        for idx, (sample, _, _) in enumerate(events):
            # Convert sample index to seconds to compare against annotation times
            event_time = sample / sampling_rate
            # Mark the event for removal when it lies within a BAD interval
            if any(start <= event_time <= end for start, end in bad_intervals):
                # Update the mask to drop contaminated events from the dataset
                keep_mask[idx] = False
    # Enforce boolean typing on the mask to avoid silent drops from bad values
    if not all(isinstance(flag, bool) for flag in keep_mask):
        # Raise when the mask contains non-boolean entries to surface errors early
        raise TypeError("Event mask contained non-boolean values")
    # Return the vetted mask for downstream event filtering
    return keep_mask


def create_epochs_from_raw(
    raw: mne.io.BaseRaw,
    events: np.ndarray,
    event_id: Mapping[str, int],
    tmin: float = -0.2,
    tmax: float = 0.8,
) -> mne.Epochs:
    """Construct epochs with annotation-aware rejection."""

    # Convert the events array to enforce integer sample indices
    safe_events = np.asarray(events)
    # Validate that all event indices are integers to satisfy MNE expectations
    if not np.issubdtype(safe_events.dtype, np.integer):
        # Raise an explicit error when indices are not numeric to avoid MNE crashes
        raise ValueError("events must contain integer-coded sample indices")
    # Reuse the typed array without copying when already integer
    typed_events = safe_events.astype(int, copy=False)
    # Build epochs while honoring BAD annotations to avoid contaminating data
    epochs = mne.Epochs(
        raw,
        events=typed_events,
        event_id=event_id,
        tmin=tmin,
        tmax=tmax,
        preload=True,
        reject_by_annotation=True,
        baseline=None,
        # Ignore labels missing from specific runs to keep epoching robust
        on_missing="ignore",
        verbose=False,
    )
    # Return epochs ready for feature extraction and model training
    return epochs


def _expected_epoch_samples(epochs: mne.Epochs) -> int:
    """Compute the expected number of samples per epoch."""

    # Derive duration-based sample count to catch truncated segments
    return int(round((epochs.tmax - epochs.tmin) * epochs.info["sfreq"])) + 1


def _flag_epoch_quality(
    epoch: np.ndarray, max_peak_to_peak: float, expected_samples: int
) -> List[str]:
    """Identify quality issues for a single epoch."""

    # Track reasons to support later reporting or masking
    reasons: List[str] = []
    # Measure peak-to-peak amplitude to reveal sharp artifacts
    ptp_value = float(np.ptp(epoch))
    # Record amplitude excursions beyond the threshold to protect models
    if ptp_value > max_peak_to_peak:
        reasons.append("artifact")
    # Detect incomplete epochs via shape or NaN inspection
    if epoch.shape[1] < expected_samples or np.isnan(epoch).any():
        reasons.append("incomplete")
    # Return accumulated flags for the caller to aggregate
    return reasons


def _apply_marking(
    safe_epochs: mne.Epochs, flagged: Dict[str, List[int]]
) -> Tuple[mne.Epochs, Dict[str, List[int]]]:
    """Mark flagged epochs in metadata and return the updated set."""

    # Initialize metadata so downstream code can track quality per epoch
    if safe_epochs.metadata is None:
        # Build a DataFrame with a single column matching epoch count
        safe_epochs.metadata = pd.DataFrame({"quality_flag": ["ok"] * len(safe_epochs)})
    # Iterate to update quality flags for each identified issue
    for reason, indices in flagged.items():
        # Apply the reason to all recorded indices for transparency
        for idx in indices:
            # Overwrite the quality flag to reflect the detected issue
            safe_epochs.metadata.at[idx, "quality_flag"] = reason
    # Return the annotated epochs along with the indexed reasons
    return safe_epochs, flagged


def _apply_rejection(
    safe_epochs: mne.Epochs, flagged: Dict[str, List[int]]
) -> Tuple[mne.Epochs, Dict[str, List[int]]]:
    """Drop flagged epochs and return the pruned set."""

    # Build a set of indices to remove for efficient membership tests
    removed_indices = set(flagged["artifact"]) | set(flagged["incomplete"])
    # Construct a boolean mask that preserves only unflagged epochs
    keep_mask = [idx not in removed_indices for idx in range(len(safe_epochs))]
    # Apply the mask to drop contaminated epochs before returning
    return safe_epochs[keep_mask], flagged


def quality_control_epochs(
    epochs: mne.Epochs,
    max_peak_to_peak: float,
    mode: str = "reject",
) -> Tuple[mne.Epochs, Dict[str, List[int]]]:
    """Screen epochs for artifacts or incompleteness and flag or drop them."""

    # Copy the epochs to avoid mutating caller data during quality enforcement
    safe_epochs = epochs.copy()
    # Retrieve the data to inspect amplitude and completeness metrics
    data = safe_epochs.get_data(copy=True)
    # Compute expected sample count to detect truncated epoch shapes
    expected_samples = _expected_epoch_samples(safe_epochs)
    # Prepare buckets to track artifact and incomplete epoch indices
    flagged: Dict[str, List[int]] = {"artifact": [], "incomplete": []}
    # Iterate over epochs to check amplitude and completeness constraints
    for idx, epoch in enumerate(data):
        # Aggregate all reasons identified for the current epoch
        for reason in _flag_epoch_quality(epoch, max_peak_to_peak, expected_samples):
            # Record the reason to enable downstream removal or marking
            flagged[reason].append(idx)
    # When the mode is reject, remove flagged epochs to stabilize training
    if mode == "reject":
        # Delegate rejection to simplify complexity for linting and tests
        return _apply_rejection(safe_epochs, flagged)
    # When the mode is mark, annotate metadata instead of dropping epochs
    if mode == "mark":
        # Delegate marking to reuse the metadata update logic
        return _apply_marking(safe_epochs, flagged)
    # Raise when the mode is unsupported to avoid silent misuse
    raise ValueError("mode must be either 'reject' or 'mark'")


def summarize_epoch_quality(
    epochs: mne.Epochs,
    motor_labels: List[str],
    session: Tuple[str, str],
    max_peak_to_peak: float,
    expected_labels: Tuple[str, str] = ("A", "B"),
) -> Tuple[mne.Epochs, Dict[str, Any], List[str]]:
    """Drop incomplete epochs then count valid labels per subject/run."""

    # VÃ©rifie l'alignement entre Ã©vÃ©nements et Ã©tiquettes transmises
    if len(motor_labels) != len(epochs):
        # GÃ©nÃ¨re un rapport clair pour identifier le dÃ©calage dÃ©tectÃ©
        raise ValueError(
            json.dumps(
                {
                    "error": "Label/event mismatch",
                    "expected_events": len(epochs),
                    "labels": len(motor_labels),
                }
            )
        )
    # Applique le contrÃ´le qualitÃ© pour supprimer les segments incomplets
    cleaned_epochs, flagged = quality_control_epochs(
        epochs, max_peak_to_peak=max_peak_to_peak, mode="reject"
    )
    # Calcule les indices supprimÃ©s afin de filtrer les Ã©tiquettes associÃ©es
    removed_indices = set(flagged["artifact"]) | set(flagged["incomplete"])
    # Construit la liste des labels conservÃ©s aprÃ¨s suppression des segments
    cleaned_labels = [
        label for idx, label in enumerate(motor_labels) if idx not in removed_indices
    ]
    # DÃ©compte les occurrences pour chaque Ã©tiquette attendue
    counts = {label: cleaned_labels.count(label) for label in expected_labels}
    # PrÃ©pare un rapport synthÃ©tique pour la surveillance par sujet et run
    report = {
        "subject": session[0],
        "run": session[1],
        "dropped": {key: len(value) for key, value in flagged.items()},
        "counts": counts,
    }
    # Identifie les classes absentes aprÃ¨s nettoyage pour remonter une erreur
    missing_labels = [label for label, count in counts.items() if count == 0]
    # GÃ©nÃ¨re une erreur explicite lorsque des classes attendues manquent
    if missing_labels:
        # InsÃ¨re le rapport de comptage pour faciliter le diagnostic utilisateur
        raise ValueError(
            json.dumps(
                {**report, "error": "Missing labels", "missing_labels": missing_labels}
            )
        )
    # Retourne les epochs nettoyÃ©es, le rapport et les labels filtrÃ©s
    return cleaned_epochs, report, cleaned_labels


@dataclass
class ReportConfig:
    """Regroupe les paramÃ¨tres nÃ©cessaires Ã  la sÃ©rialisation du rapport."""

    # Stocke le chemin cible pour centraliser la sortie des rapports
    path: Path
    # SpÃ©cifie le format attendu pour contrÃ´ler la normalisation amont
    fmt: str = "json"


def _ensure_label_alignment(epochs: mne.Epochs, motor_labels: List[str]) -> None:
    """Valide la correspondance entre Ã©vÃ©nements MNE et labels utilisateur."""

    # DÃ©tecte immÃ©diatement les dÃ©calages pour Ã©viter des rapports incohÃ©rents
    if len(motor_labels) != len(epochs):
        # Fournit un rapport JSON pour aider Ã  diagnostiquer le dÃ©salignement
        raise ValueError(
            json.dumps(
                {
                    "error": "Label/event mismatch",
                    "expected_events": len(epochs),
                    "labels": len(motor_labels),
                }
            )
        )


def _apply_quality_control(
    epochs: mne.Epochs,
    motor_labels: List[str],
    max_peak_to_peak: float,
) -> Tuple[mne.Epochs, Dict[str, List[int]], List[str]]:
    """Applique le rejet automatique et conserve les labels alignÃ©s."""

    # Filtre les artefacts et segments incomplets selon le seuil fourni
    cleaned_epochs, flagged = quality_control_epochs(
        epochs, max_peak_to_peak=max_peak_to_peak, mode="reject"
    )
    # Liste les indices rejetÃ©s pour synchroniser le filtrage des labels
    removed_indices = set(flagged["artifact"]) | set(flagged["incomplete"])
    # Retient les labels qui restent alignÃ©s avec les epochs conservÃ©es
    cleaned_labels = [
        label for idx, label in enumerate(motor_labels) if idx not in removed_indices
    ]
    # Retourne les donnÃ©es nettoyÃ©es et les labels synchronisÃ©s
    return cleaned_epochs, flagged, cleaned_labels


def _count_remaining_labels(cleaned_labels: List[str]) -> Dict[str, int]:
    """Calcule le nombre d'occurrences par classe attendue."""

    # Utilise les labels attendus pour assurer la cohÃ©rence des rapports
    return {label: cleaned_labels.count(label) for label in EXPECTED_LABELS}


def _assert_expected_labels_present(
    report: Dict[str, Any], counts: Dict[str, int]
) -> None:
    """LÃ¨ve une erreur claire lorsque des classes manquent aprÃ¨s nettoyage."""

    # RepÃ¨re les classes dont le comptage tombe Ã  zÃ©ro aprÃ¨s filtrage
    missing_labels = [label for label, count in counts.items() if count == 0]
    # Remonte une erreur structurÃ©e pour faciliter le diagnostic utilisateur
    if missing_labels:
        # Injecte les labels manquants dans le rapport pour guider l'enquÃªte
        raise ValueError(
            json.dumps(
                {**report, "error": "Missing labels", "missing_labels": missing_labels}
            )
        )


def _build_epoch_report(
    run_metadata: Mapping[str, str],
    total_epochs: int,
    kept_epochs: int,
    counts: Dict[str, int],
    flagged: Dict[str, List[int]],
) -> Dict[str, Any]:
    """Assemble les informations nÃ©cessaires au rapport qualitÃ©."""

    # Centralise les informations utiles pour le suivi par sujet et par run
    return {
        "subject": run_metadata["subject"],
        "run": run_metadata["run"],
        "total_epochs_before": total_epochs,
        "kept_epochs": kept_epochs,
        "counts": counts,
        "anomalies": {
            "artifact": flagged["artifact"],
            "incomplete": flagged["incomplete"],
        },
    }


def _normalize_report_config(report_config: ReportConfig) -> ReportConfig:
    """Normalise la configuration pour sÃ©curiser la sÃ©rialisation."""

    # Harmonise la casse pour Ã©viter des variations inattendues dans les noms
    fmt_normalized = report_config.fmt.lower()
    # VÃ©rifie que la casse initiale respecte la normalisation imposÃ©e
    if report_config.fmt != fmt_normalized:
        # Refuse une casse incohÃ©rente pour prÃ©venir des collisions de fichiers
        raise ValueError("fmt must be lowercase")
    # Valide la liste des formats acceptÃ©s pour verrouiller l'API
    if fmt_normalized not in {"json", "csv"}:
        # Signale explicitement la liste des formats supportÃ©s par la pipeline
        raise ValueError("fmt must be either 'json' or 'csv'")
    # Retourne la configuration avec un format uniformisÃ©
    return ReportConfig(path=report_config.path, fmt=fmt_normalized)


def _write_json_report(report: Dict[str, Any], target: Path) -> None:
    """Ã‰crit le rapport qualitÃ© au format JSON."""

    # CrÃ©e les dossiers parents pour Ã©viter une erreur d'Ã©criture
    target.parent.mkdir(parents=True, exist_ok=True)
    # SÃ©rialise le rapport avec indentation pour faciliter la lecture humaine
    target.write_text(json.dumps(report, indent=2), encoding="utf-8")


def _write_csv_report(
    report: Dict[str, Any],
    flagged: Dict[str, List[int]],
    counts: Dict[str, int],
    total_epochs: int,
    target: Path,
) -> None:
    """Ã‰crit le rapport qualitÃ© au format CSV."""

    # CrÃ©e les dossiers parents pour Ã©viter une erreur d'Ã©criture
    target.parent.mkdir(parents=True, exist_ok=True)
    # Construit l'en-tÃªte en exposant les colonnes critiques pour la QA
    lines = [
        "subject,run,total_epochs_before,kept_epochs,dropped_artifact,dropped_incomplete,label,count"
    ]
    # GÃ©nÃ¨re une ligne par classe pour dÃ©tailler les indices supprimÃ©s
    for label, count in counts.items():
        # ConcatÃ¨ne les indices artefacts pour conserver la traÃ§abilitÃ©
        artifact_indices = ";".join(str(idx) for idx in flagged["artifact"])
        # ConcatÃ¨ne les indices incomplets pour un niveau de dÃ©tail Ã©quivalent
        incomplete_indices = ";".join(str(idx) for idx in flagged["incomplete"])
        # AgrÃ¨ge la ligne finale pour la classe courante
        lines.append(
            ",".join(
                [
                    report["subject"],
                    report["run"],
                    str(total_epochs),
                    str(report["kept_epochs"]),
                    artifact_indices,
                    incomplete_indices,
                    label,
                    str(count),
                ]
            )
        )
    # Ã‰crit le contenu complet pour permettre une inspection rapide
    target.write_text("\n".join(lines), encoding="utf-8")


def report_epoch_anomalies(
    epochs: mne.Epochs,
    motor_labels: List[str],
    run_metadata: Mapping[str, str],
    max_peak_to_peak: float,
    report_config: ReportConfig,
) -> Tuple[mne.Epochs, Dict[str, Any], Path]:
    """Reject corrupted epochs then persist a detailed quality report."""

    # VÃ©rifie l'alignement entre Ã©vÃ©nements et labels pour fiabiliser le rapport
    _ensure_label_alignment(epochs, motor_labels)
    # Applique le contrÃ´le qualitÃ© afin de mesurer l'impact des anomalies
    cleaned_epochs, flagged, cleaned_labels = _apply_quality_control(
        epochs, motor_labels, max_peak_to_peak
    )
    # Calcule le dÃ©compte par classe aprÃ¨s filtrage
    counts = _count_remaining_labels(cleaned_labels)
    # Assemble le rapport avec les mÃ©tadonnÃ©es de run
    report = _build_epoch_report(
        run_metadata, len(epochs), len(cleaned_epochs), counts, flagged
    )
    # Valide la prÃ©sence de toutes les classes attendues
    _assert_expected_labels_present(report, counts)
    # Normalise la configuration pour sÃ©curiser le format
    normalized_config = _normalize_report_config(report_config)
    # SÃ©rialise en JSON lorsque demandÃ©
    if normalized_config.fmt == "json":
        # Ã‰crit le rapport JSON prÃªt Ã  l'usage
        _write_json_report(report, normalized_config.path)
        # Retourne les rÃ©sultats accompagnÃ©s du chemin gÃ©nÃ©rÃ©
        return cleaned_epochs, report, normalized_config.path
    # SÃ©rialise en CSV lorsque demandÃ©
    _write_csv_report(report, flagged, counts, len(epochs), normalized_config.path)
    # Retourne les rÃ©sultats accompagnÃ©s du chemin gÃ©nÃ©rÃ©
    return cleaned_epochs, report, normalized_config.path


def detect_artifacts(
    signal: np.ndarray,
    amplitude_threshold: float,
    variance_threshold: float,
    mode: str = "reject",
) -> Tuple[np.ndarray, np.ndarray]:
    """Detect amplitude or variance artifacts and reject or interpolate."""

    # Copie le signal en flottants pour uniformiser la suite du traitement
    safe_signal: NDArray[np.floating[Any]] = np.asarray(signal, dtype=float)
    # Calcule l'amplitude absolue pour repÃ©rer les excursions extrÃªmes
    amplitude_mask = np.abs(safe_signal) > amplitude_threshold
    # Calcule la variance par Ã©chantillon pour capturer les dÃ©viations croisÃ©es
    variance_per_sample = np.var(safe_signal, axis=0)
    # Ã‰tend le masque de variance Ã  toutes les voies pour uniformiser le traitement
    variance_mask = variance_per_sample > variance_threshold
    # Combine les critÃ¨res pour identifier chaque Ã©chantillon contaminÃ©
    combined_mask = amplitude_mask | variance_mask
    # DÃ©duit un masque global indiquant les colonnes Ã  exclure ou corriger
    sample_mask = combined_mask.any(axis=0)
    # Traite la branche de rejet pour supprimer les Ã©chantillons fautifs
    if mode == "reject":
        # Construit un masque de conservation pour filtrer les colonnes sÃ»res
        keep_mask = ~sample_mask
        # Supprime les colonnes contaminÃ©es afin de stabiliser l'apprentissage
        return safe_signal[:, keep_mask], sample_mask
    # Traite la branche d'interpolation pour conserver la structure temporelle
    if mode == "interpolate":
        # Localise les indices sÃ»rs pour guider l'interpolation linÃ©aire
        valid_indices = np.flatnonzero(~sample_mask)
        # Traite l'absence totale de points fiables en conservant le signal brut
        if len(valid_indices) == 0:
            # Retourne le signal initial lorsque l'interpolation est impossible
            return safe_signal, sample_mask
        # PrÃ©pare un vecteur d'indices cible pour reconstituer chaque colonne
        target_indices = np.arange(safe_signal.shape[1])
        # ItÃ¨re sur chaque canal pour appliquer une interpolation indÃ©pendante
        for channel in range(safe_signal.shape[0]):
            # Extrait les valeurs sÃ»res du canal courant pour alimenter l'interpolation
            valid_values = safe_signal[channel, valid_indices]
            # Remplace les Ã©chantillons fautifs par l'interpolation linÃ©aire
            safe_signal[channel] = np.interp(
                target_indices, valid_indices, valid_values
            )
        # Retourne le signal interpolÃ© pour prÃ©server la longueur temporelle
        return safe_signal, sample_mask
    # LÃ¨ve une erreur explicite pour les modes non supportÃ©s
    raise ValueError("mode must be either 'reject' or 'interpolate'")


def normalize_channels(
    signal: NDArray[np.floating[Any]],
    method: str = DEFAULT_NORMALIZE_METHOD,
    epsilon: float = DEFAULT_NORMALIZE_EPSILON,
) -> NDArray[np.floating[Any]]:
    """Normalize each channel using z-score or robust statistics."""

    # Copie le signal en flottants pour garantir des sorties typÃ©es
    safe_signal: NDArray[np.floating[Any]] = np.asarray(signal, dtype=float)
    # Uniformise le nom de mÃ©thode pour Ã©viter les confusions de casse
    normalized_method = method.lower()
    # Applique une normalisation z-score basÃ©e sur moyenne et Ã©cart-type
    if normalized_method == "zscore":
        # Calcule la moyenne par canal pour centrer la distribution
        mean_per_channel = np.mean(safe_signal, axis=1, keepdims=True)
        # Calcule l'Ã©cart-type par canal et ajoute epsilon pour la stabilitÃ©
        std_per_channel = np.std(safe_signal, axis=1, keepdims=True) + epsilon
        # Centre et rÃ©duit chaque canal pour homogÃ©nÃ©iser les amplitudes
        result: NDArray[np.floating[Any]] = np.asarray(
            (safe_signal - mean_per_channel) / std_per_channel, dtype=float
        )
        # Retourne l'Ã©talonnage z-score avec un type numpy explicite
        return result
    # Applique une normalisation robuste basÃ©e sur mÃ©diane et IQR
    if normalized_method == "robust":
        # Calcule la mÃ©diane par canal pour neutraliser les valeurs extrÃªmes
        median_per_channel = np.median(safe_signal, axis=1, keepdims=True)
        # Calcule l'IQR par canal et ajoute epsilon pour Ã©viter les divisions nulles
        iqr_per_channel = (
            np.percentile(safe_signal, 75, axis=1, keepdims=True)
            - np.percentile(safe_signal, 25, axis=1, keepdims=True)
            + epsilon
        )
        # Centre et met Ã  l'Ã©chelle chaque canal selon les statistiques robustes
        robust_result: NDArray[np.floating[Any]] = np.asarray(
            (safe_signal - median_per_channel) / iqr_per_channel, dtype=float
        )
        # Retourne la version robuste typÃ©e pour mypy et les tests
        return robust_result
    # LÃ¨ve une erreur explicite pour les mÃ©thodes non supportÃ©es
    raise ValueError("method must be either 'zscore' or 'robust'")


def _build_file_entry(
    data_root: Path,
    file_path: Path,
    expected_hashes: Mapping[str, str] | None,
) -> Dict[str, object]:
    """Compose a report entry for a single EDF file."""

    # Record the file size to detect incomplete downloads
    size_bytes = file_path.stat().st_size
    # Compute SHA256 only when reference hashes are provided for comparison
    file_hash = (
        hashlib.sha256(file_path.read_bytes()).hexdigest() if expected_hashes else None
    )
    # Build a stable relative key to align with expected hashes mapping
    rel_key = str(file_path.relative_to(data_root))
    # Evaluate hash parity when expectations exist to surface corruption
    hash_match = expected_hashes is None or expected_hashes.get(rel_key) == file_hash
    # Return a structured entry consumable by integrity reports
    return {
        "path": rel_key,
        "size": size_bytes,
        "sha256": file_hash,
        "hash_ok": hash_match,
    }


def _collect_run_counts(data_root: Path) -> Dict[str, int]:
    """Count EDF runs per subject directory."""

    # Initialize dictionary to aggregate run totals by subject
    subject_counts: Dict[str, int] = {}
    # Iterate over immediate child directories representing subjects
    for subject_dir in data_root.iterdir():
        # Ignore non-directories to focus exclusively on subject folders
        if not subject_dir.is_dir():
            # Continue scanning when encountering stray files at the root
            continue
        # Count EDF files within the subject directory to quantify runs
        run_count = len(list(subject_dir.glob("*.edf")))
        # Persist the count for downstream comparison against expectations
        subject_counts[subject_dir.name] = run_count
    # Return all computed run counts for further validation steps
    return subject_counts


def verify_dataset_integrity(
    base_path: Path,
    expected_hashes: Mapping[str, str] | None = None,
    expected_runs_per_subject: Mapping[str, int] | None = None,
) -> Dict[str, Any]:
    """Verify presence, size, and optional hashes for Physionet data."""

    # Resolve dataset root to ensure comparisons use absolute locations
    data_root = Path(base_path).expanduser().resolve()
    # Prepare a container for per-file reports to keep typing explicit
    file_entries: List[Dict[str, object]] = []
    # Prepare a report structure to feed monitoring or logging systems
    report: Dict[str, Any] = {"root": str(data_root), "files": file_entries}
    # Fail fast if the dataset directory is missing to avoid silent skips
    if not data_root.exists():
        # Raise an explicit error when the dataset root cannot be found
        raise FileNotFoundError(f"Dataset directory not found: {data_root}")
    # Walk through EDF files to build a detailed integrity report
    for file_path in data_root.rglob("*.edf"):
        # Append structured entry for each discovered EDF recording
        file_entries.append(_build_file_entry(data_root, file_path, expected_hashes))
    # Validate expected run counts when provided by the caller
    if expected_runs_per_subject:
        # Collect run totals per subject to compare against expectations
        subject_counts = _collect_run_counts(data_root)
        # Attach run counts to the report for external visibility
        report["subject_run_counts"] = subject_counts
        # Identify subjects whose run counts deviate from expectations
        missing_runs = {
            subject: count
            for subject, count in subject_counts.items()
            if expected_runs_per_subject.get(subject) not in (None, count)
        }
        # Raise when any subject is incomplete to protect model validity
        if missing_runs:
            # Raise a clear error so dataset preparation can be fixed early
            raise ValueError(f"Run count mismatch: {json.dumps(missing_runs)}")
    # Return the report to enable higher-level monitoring or logging
    return report


def generate_epoch_report(
    epochs: mne.Epochs,
    event_id: Mapping[str, int],
    run_metadata: Mapping[str, str],
    output_path: Path,
    fmt: str = "json",
) -> Path:
    """Persist epoch counts per class, subject, and run in JSON or CSV."""

    # Convertit le format en minuscules pour uniformiser les comparaisons
    fmt_normalized = fmt.lower()
    # Refuse les formats non minuscules pour Ã©viter les ambiguÃ¯tÃ©s silencieuses
    if fmt != fmt_normalized:
        # ArrÃªte l'exÃ©cution pour imposer une convention de nommage explicite
        raise ValueError("fmt must be lowercase")
    # VÃ©rifie que le format fourni est limitÃ© aux options minuscules supportÃ©es
    if fmt_normalized not in {"json", "csv"}:
        # Interrompt tÃ´t pour Ã©viter d'Ã©crire un rapport avec un format ambigu
        raise ValueError("fmt must be either 'json' or 'csv'")
    # Normalise le chemin pour garantir des Ã©critures cohÃ©rentes sur disque
    # Ensure the parent directory exists to make the report path valid
    output_path = Path(output_path)
    # Create parent directories so the report can be written without errors
    output_path.parent.mkdir(parents=True, exist_ok=True)
    # Build a reverse lookup to translate event codes into label names
    reverse_map = {code: label for label, code in event_id.items()}
    # Count epochs for every label present in the event mapping
    label_counts = {
        label: int(np.sum(epochs.events[:, 2] == code))
        for code, label in reverse_map.items()
    }
    # Compose a structured payload describing the run content
    payload: Dict[str, Any] = {
        "subject": run_metadata["subject"],
        "run": run_metadata["run"],
        "total_epochs": int(len(epochs)),
        "counts": label_counts,
    }
    # Serialize the payload to JSON when requested by the caller
    if fmt_normalized == "json":
        # Write the JSON content with indentation for human readability
        output_path.write_text(json.dumps(payload, indent=2), encoding="utf-8")
        # Return the path so callers can locate the generated report
        return output_path
    # Serialize the payload to CSV rows when CSV is requested
    else:
        # Build header and rows capturing each class count explicitly
        lines = ["subject,run,label,count"]
        # Iterate over label counts to materialize per-class entries
        for label, count in label_counts.items():
            # Append a CSV line detailing subject, run, label, and count
            lines.append(
                f"{run_metadata['subject']},{run_metadata['run']},{label},{count}"
            )
        # Write all lines with newline separation to the output path
        output_path.write_text("\n".join(lines), encoding="utf-8")
        # Return the path so downstream processes can load the CSV
        return output_path

===== scripts/train.py () =====
"""CLI d'entraÃ®nement pour le pipeline TPV."""

# PrÃ©serve argparse pour exposer une interface CLI homogÃ¨ne avec mybci
# Expose les primitives d'analyse des arguments CLI
# Fournit le parsing CLI pour aligner la signature mybci
import argparse

# Fournit l'Ã©criture CSV pour exposer un manifeste tabulaire
import csv

# Fournit la sÃ©rialisation JSON pour exposer un manifeste exploitable
import json

# Rassemble la construction de structures immuables orientÃ©es donnÃ©es
from dataclasses import asdict, dataclass

# Garantit l'accÃ¨s aux chemins portables pour donnÃ©es et artefacts
from pathlib import Path

# Offre la persistance dÃ©diÃ©e aux objets scikit-learn pour inspection sÃ©parÃ©e
import joblib

# Centralise l'accÃ¨s aux tableaux manipulÃ©s par scikit-learn
import numpy as np

# Fournit la validation croisÃ©e pour Ã©valuer la pipeline complÃ¨te
from sklearn.model_selection import StratifiedKFold, cross_val_score

# Centralise le parsing et le contrÃ´le qualitÃ© des fichiers EDF
# Extrait les features frÃ©quentielles depuis des epochs EEG
from tpv import preprocessing

# Permet de persister sÃ©parÃ©ment la matrice W apprise
from tpv.dimensionality import TPVDimReducer

# Assemble la pipeline cohÃ©rente pour l'entraÃ®nement
from tpv.pipeline import PipelineConfig, build_pipeline, save_pipeline

# DÃ©finit le rÃ©pertoire par dÃ©faut oÃ¹ chercher les enregistrements
DEFAULT_DATA_DIR = Path("data")

# DÃ©finit le rÃ©pertoire par dÃ©faut pour dÃ©poser les artefacts d'entraÃ®nement
DEFAULT_ARTIFACTS_DIR = Path("artifacts")

# DÃ©finit le rÃ©pertoire par dÃ©faut oÃ¹ rÃ©sident les fichiers EDF bruts
DEFAULT_RAW_DIR = Path("data/raw")

# Fige la frÃ©quence d'Ã©chantillonnage par dÃ©faut utilisÃ©e pour les features
DEFAULT_SAMPLING_RATE = 50.0

# DÃ©clare le seuil minimal de splits exigÃ© pour la validation croisÃ©e
MIN_CV_SPLITS = 3


# Regroupe toutes les informations nÃ©cessaires Ã  un run d'entraÃ®nement
@dataclass
class TrainingRequest:
    """DÃ©crit les paramÃ¨tres nÃ©cessaires pour entraÃ®ner un run."""

    # Identifie le sujet cible pour l'entraÃ®nement
    subject: str
    # Identifie le run ciblÃ© pour le sujet sÃ©lectionnÃ©
    run: str
    # Transporte la configuration complÃ¨te de pipeline
    pipeline_config: PipelineConfig
    # SpÃ©cifie le rÃ©pertoire contenant les donnÃ©es numpy
    data_dir: Path
    # SpÃ©cifie le rÃ©pertoire racine pour dÃ©poser les artefacts
    artifacts_dir: Path
    # SpÃ©cifie le rÃ©pertoire des enregistrements EDF bruts
    raw_dir: Path = DEFAULT_RAW_DIR


# Construit un argument parser alignÃ© sur la CLI mybci
def build_parser() -> argparse.ArgumentParser:
    """Construit le parser CLI pour l'entraÃ®nement TPV."""

    # CrÃ©e le parser avec description lisible pour l'utilisateur
    parser = argparse.ArgumentParser(
        description="EntraÃ®ne une pipeline TPV et sauvegarde ses artefacts",
    )
    # Ajoute l'argument positionnel du sujet pour identifier les fichiers
    parser.add_argument("subject", help="Identifiant du sujet (ex: S001)")
    # Ajoute l'argument positionnel du run pour sÃ©lectionner la session
    parser.add_argument("run", help="Identifiant du run (ex: R01)")
    # Ajoute l'option classifieur pour synchroniser avec mybci
    parser.add_argument(
        "--classifier",
        choices=("lda", "logistic", "svm", "centroid"),
        default="lda",
        help="Classifieur final utilisÃ© pour l'entraÃ®nement",
    )
    # Ajoute le choix du scaler optionnel pour stabiliser les features
    parser.add_argument(
        "--scaler",
        choices=("standard", "robust", "none"),
        default="none",
        help="Scaler optionnel appliquÃ© aprÃ¨s l'extraction de features",
    )
    # Ajoute la stratÃ©gie d'extraction de features pour garder la cohÃ©rence
    parser.add_argument(
        "--feature-strategy",
        choices=("fft", "wavelet"),
        default="fft",
        help="MÃ©thode d'extraction de features spectrales",
    )
    # Ajoute la mÃ©thode de rÃ©duction de dimension pour contrÃ´ler la compression
    parser.add_argument(
        "--dim-method",
        choices=("pca", "csp"),
        default="pca",
        help="MÃ©thode de rÃ©duction de dimension pour la pipeline",
    )
    # Ajoute le nombre de composantes cible pour la rÃ©duction
    parser.add_argument(
        "--n-components",
        type=int,
        default=argparse.SUPPRESS,
        help="Nombre de composantes conservÃ©es par le rÃ©ducteur",
    )
    # Ajoute un flag pour dÃ©sactiver la normalisation des features
    parser.add_argument(
        "--no-normalize-features",
        action="store_true",
        help="DÃ©sactive la normalisation des features extraites",
    )
    # Ajoute une option pour cibler un rÃ©pertoire de donnÃ©es spÃ©cifique
    parser.add_argument(
        "--data-dir",
        type=Path,
        default=DEFAULT_DATA_DIR,
        help="RÃ©pertoire racine contenant les fichiers numpy",
    )
    # Ajoute une option pour configurer le rÃ©pertoire d'artefacts
    parser.add_argument(
        "--artifacts-dir",
        type=Path,
        default=DEFAULT_ARTIFACTS_DIR,
        help="RÃ©pertoire racine oÃ¹ enregistrer le modÃ¨le",
    )
    # Ajoute une option pour pointer vers les fichiers EDF bruts
    parser.add_argument(
        "--raw-dir",
        type=Path,
        default=DEFAULT_RAW_DIR,
        help="RÃ©pertoire racine contenant les fichiers EDF bruts",
    )
    # Ajoute une option pour spÃ©cifier la frÃ©quence d'Ã©chantillonnage
    parser.add_argument(
        "--sfreq",
        type=float,
        default=DEFAULT_SAMPLING_RATE,
        help="FrÃ©quence d'Ã©chantillonnage utilisÃ©e pour les features",
    )
    # Retourne le parser configurÃ©
    return parser


# Construit les chemins des donnÃ©es pour un sujet et un run donnÃ©s
def _resolve_data_paths(subject: str, run: str, data_dir: Path) -> tuple[Path, Path]:
    """Retourne les chemins des matrices X et y pour un sujet/run."""

    # Localise le sous-dossier spÃ©cifique au sujet
    base_dir = data_dir / subject
    # Compose le chemin du fichier de donnÃ©es numpy
    features_path = base_dir / f"{run}_X.npy"
    # Compose le chemin du fichier d'Ã©tiquettes numpy
    labels_path = base_dir / f"{run}_y.npy"
    # Retourne les deux chemins pour chargement ultÃ©rieur
    return features_path, labels_path


# Construit des matrices numpy Ã  partir d'un EDF lorsqu'elles manquent
def _build_npy_from_edf(
    subject: str,
    run: str,
    data_dir: Path,
    raw_dir: Path,
) -> tuple[Path, Path]:
    """GÃ©nÃ¨re X (epochs brutes) et y depuis un fichier EDF Physionet.

    - X est sauvegardÃ© sous forme (n_trials, n_channels, n_times)
      pour Ãªtre compatible avec la pipeline (tpv.features).
    - Les features frÃ©quentielles sont ensuite calculÃ©es *dans* la
      pipeline, pas au moment de la gÃ©nÃ©ration des .npy.
    """

    # Calcule les chemins cibles pour les fichiers numpy
    features_path, labels_path = _resolve_data_paths(subject, run, data_dir)
    # Calcule le chemin attendu du fichier EDF brut
    raw_path = raw_dir / subject / f"{subject}{run}.edf"

    # Interrompt tÃ´t si l'EDF est absent
    if not raw_path.exists():
        raise FileNotFoundError(
            "EDF introuvable pour "
            f"{subject} {run}: {raw_path}. "
            "TÃ©lÃ©chargez les enregistrements Physionet dans data/raw ou "
            "pointez --raw-dir vers un dossier dÃ©jÃ  synchronisÃ©."
        )

    # CrÃ©e l'arborescence cible pour dÃ©poser les .npy
    features_path.parent.mkdir(parents=True, exist_ok=True)

    # Charge l'EDF en conservant les mÃ©tadonnÃ©es essentielles
    raw, _ = preprocessing.load_physionet_raw(raw_path)

    # Mappe les annotations en Ã©vÃ©nements moteurs
    events, event_id, motor_labels = preprocessing.map_events_to_motor_labels(raw)

    # DÃ©coupe le signal en epochs exploitables
    epochs = preprocessing.create_epochs_from_raw(raw, events, event_id)

    # RÃ©cupÃ¨re les donnÃ©es brutes des epochs (n_trials, n_channels, n_times)
    epochs_data = epochs.get_data(copy=True)

    # DÃ©finit un mapping stable label â†’ entier
    label_mapping = {label: idx for idx, label in enumerate(sorted(set(motor_labels)))}

    # Convertit les labels symboliques en entiers
    numeric_labels = np.array([label_mapping[label] for label in motor_labels])

    # Persiste les epochs brutes
    np.save(features_path, epochs_data)
    # Persiste les labels alignÃ©s
    np.save(labels_path, numeric_labels)

    # Retourne les chemins nouvellement gÃ©nÃ©rÃ©s
    return features_path, labels_path




# Charge ou gÃ©nÃ¨re les matrices numpy attendues pour l'entraÃ®nement
def _load_data(
    subject: str,
    run: str,
    data_dir: Path,
    raw_dir: Path,
) -> tuple[np.ndarray, np.ndarray]:
    """Charge ou construit les donnÃ©es et Ã©tiquettes pour un run.

    - Si les .npy n'existent pas, on les gÃ©nÃ¨re depuis l'EDF.
    - Si X existe mais n'est pas 3D, on *reconstruit* Ã  partir de l'EDF
      pour garantir X.shape == (n_samples, n_channels, n_times).
    """

    # DÃ©termine les chemins attendus pour les features et labels
    features_path, labels_path = _resolve_data_paths(subject, run, data_dir)

    # Indique si nous devons rÃ©gÃ©nÃ©rer les .npy
    needs_rebuild = False

    # Cas 1 : fichiers manquants â†’ on reconstruira
    if not features_path.exists() or not labels_path.exists():
        needs_rebuild = True
    else:
        # Cas 2 : fichiers prÃ©sents mais X n'a pas la bonne dimension
        candidate_X = np.load(features_path)
        if candidate_X.ndim != 3:
            print(
                f"INFO: X chargÃ© depuis '{features_path}' a ndim={candidate_X.ndim} "
                "au lieu de 3, rÃ©gÃ©nÃ©ration depuis l'EDF..."
            )
            needs_rebuild = True

    # Reconstruit les fichiers lorsque nÃ©cessaire
    if needs_rebuild:
        features_path, labels_path = _build_npy_from_edf(
            subject,
            run,
            data_dir,
            raw_dir,
        )

    # Charge les donnÃ©es validÃ©es (3D) et labels
    X = np.load(features_path)
    y = np.load(labels_path)

    return X, y




# RÃ©cupÃ¨re le hash git courant pour tracer la reproductibilitÃ©
def _get_git_commit() -> str:
    """Retourne le hash du commit courant ou "unknown" en secours."""

    # Localise le fichier HEAD pour extraire la rÃ©fÃ©rence courante
    head_path = Path(".git") / "HEAD"
    # Retourne unknown lorsque le dÃ©pÃ´t git n'est pas disponible
    if not head_path.exists():
        # Fournit une valeur de repli pour conserver un manifeste valide
        return "unknown"
    # Lit le contenu du HEAD pour dÃ©terminer la rÃ©fÃ©rence active
    head_content = head_path.read_text().strip()
    # DÃ©tecte les rÃ©fÃ©rences symboliques du style "ref: ..."
    if head_content.startswith("ref:"):
        # Isole le chemin relatif vers le fichier de rÃ©fÃ©rence
        ref_path = Path(".git") / head_content.split(" ", 1)[1]
        # Retourne unknown si la rÃ©fÃ©rence est introuvable
        if not ref_path.exists():
            # Fournit une valeur de repli pour prÃ©server la validation
            return "unknown"
        # Lit le hash contenu dans le fichier de rÃ©fÃ©rence
        return ref_path.read_text().strip()
    # Retourne le contenu brut lorsque HEAD contient dÃ©jÃ  un hash
    return head_content or "unknown"


# SÃ©rialise un manifeste complet Ã  cÃ´tÃ© du modÃ¨le entraÃ®nÃ©
def _flatten_hyperparams(hyperparams: dict) -> dict[str, str]:
    """Aplati les hyperparamÃ¨tres pour une exportation CSV lisible."""

    # PrÃ©pare un dictionnaire de sortie initialement vide
    flattened: dict[str, str] = {}
    # Parcourt chaque entrÃ©e pour extraire les valeurs simples
    for key, value in hyperparams.items():
        # SÃ©rialise chaque valeur pour conserver la lisibilitÃ© CSV
        flattened[key] = json.dumps(value, ensure_ascii=False)
    # Retourne le dictionnaire aplati prÃªt pour l'Ã©criture CSV
    return flattened


def _write_manifest(
    request: TrainingRequest,
    target_dir: Path,
    cv_scores: np.ndarray,
    artifacts: dict[str, Path | None],
) -> dict[str, Path]:
    """Ã‰crit des manifestes JSON et CSV dÃ©crivant le run d'entraÃ®nement."""

    # PrÃ©pare la section dataset pour identifier les entrÃ©es de donnÃ©es
    dataset = {
        "subject": request.subject,
        "run": request.run,
        "data_dir": str(request.data_dir),
    }
    # Convertit la configuration de pipeline en dictionnaire sÃ©rialisable
    hyperparams = asdict(request.pipeline_config)
    # Calcule la moyenne des scores si la validation croisÃ©e a tournÃ©
    cv_mean = float(np.mean(cv_scores)) if cv_scores.size else None
    # PrÃ©pare la section des scores en sÃ©rialisant les arrays numpy
    scores = {
        "cv_scores": cv_scores.tolist(),
        "cv_mean": cv_mean,
    }
    # RÃ©sout l'identifiant du commit git pour tracer les artefacts
    git_commit = _get_git_commit()
    # PrÃ©pare la section chemins pour retrouver rapidement les fichiers
    artifacts_section = {
        "model": str(artifacts["model"]),
        "scaler": str(artifacts["scaler"]) if artifacts["scaler"] else None,
        "w_matrix": str(artifacts["w_matrix"]),
    }
    # Assemble toutes les sections dans un objet manifeste unique
    manifest = {
        "dataset": dataset,
        "hyperparams": hyperparams,
        "scores": scores,
        "git_commit": git_commit,
        "artifacts": artifacts_section,
    }
    # DÃ©finit le chemin de sortie du manifeste JSON Ã  cÃ´tÃ© des artefacts
    manifest_json_path = target_dir / "manifest.json"
    # Ã‰crit le manifeste JSON sur disque en UTF-8 pour la portabilitÃ©
    manifest_json_path.write_text(json.dumps(manifest, ensure_ascii=False, indent=2))
    # Aplati les hyperparamÃ¨tres pour faciliter la lecture dans un tableur
    flattened_hyperparams = _flatten_hyperparams(hyperparams)
    # Construit une ligne CSV unique regroupant toutes les informations
    csv_line = {
        "subject": request.subject,
        "run": request.run,
        "data_dir": str(request.data_dir),
        "git_commit": git_commit,
        "cv_scores": ";".join(str(score) for score in cv_scores.tolist()),
        "cv_mean": "" if cv_mean is None else str(cv_mean),
        **flattened_hyperparams,
    }
    # DÃ©finit le chemin du manifeste CSV Ã  cÃ´tÃ© du JSON
    manifest_csv_path = target_dir / "manifest.csv"
    # Ouvre le fichier CSV en Ã©criture sans lignes superflues
    with manifest_csv_path.open("w", newline="") as handle:
        # Initialise l'Ã©criture CSV avec les clÃ©s dÃ©tectÃ©es
        writer = csv.DictWriter(handle, fieldnames=list(csv_line.keys()))
        # Inscrit les en-tÃªtes pour faciliter l'import dans un tableur
        writer.writeheader()
        # Inscrit la ligne unique dÃ©crivant le run en cours
        writer.writerow(csv_line)
    # Retourne les chemins des manifestes pour les appels appelants
    return {"json": manifest_json_path, "csv": manifest_csv_path}


# ExÃ©cute la validation croisÃ©e et l'entraÃ®nement final
def run_training(request: TrainingRequest) -> dict:
    """EntraÃ®ne la pipeline et sauvegarde ses artefacts."""

    # Charge ou gÃ©nÃ¨re les tableaux numpy nÃ©cessaires Ã  l'entraÃ®nement
    X, y = _load_data(request.subject, request.run, request.data_dir, request.raw_dir)
    # Construit la pipeline complÃ¨te sans prÃ©processeur amont
    pipeline = build_pipeline(request.pipeline_config)
    # Calcule le nombre minimal d'Ã©chantillons par classe pour calibrer la CV
    min_class_count = int(np.bincount(y).min())
    # Choisit le nombre de splits en restant compatible avec la taille des classes
    n_splits = min(MIN_CV_SPLITS, min_class_count) if min_class_count > 0 else 0
    # Initialise un tableau vide lorsque la validation croisÃ©e est impossible
    cv_scores = np.array([])
    # Lance la validation croisÃ©e seulement si chaque classe en dispose de trois
    if n_splits >= MIN_CV_SPLITS:
        # Configure une StratifiedKFold stable sur le nombre de splits calculÃ©
        cv = StratifiedKFold(n_splits=n_splits)
        # Calcule les scores de validation croisÃ©e sur l'ensemble du pipeline
        cv_scores = cross_val_score(pipeline, X, y, cv=cv)
    # Ajuste la pipeline sur toutes les donnÃ©es aprÃ¨s Ã©valuation
    pipeline.fit(X, y)
    # PrÃ©pare le dossier d'artefacts spÃ©cifique au sujet et au run
    target_dir = request.artifacts_dir / request.subject / request.run
    # CrÃ©e les rÃ©pertoires au besoin pour Ã©viter les erreurs de sauvegarde
    target_dir.mkdir(parents=True, exist_ok=True)
    # Calcule le chemin du fichier modÃ¨le pour joblib
    model_path = target_dir / "model.joblib"
    # Sauvegarde la pipeline complÃ¨te pour les prÃ©dictions futures
    save_pipeline(pipeline, str(model_path))
    # RÃ©cupÃ¨re l'Ã©ventuel scaler pour une sauvegarde dÃ©diÃ©e
    scaler_step = pipeline.named_steps.get("scaler")
    # Sauvegarde le scaler uniquement s'il est prÃ©sent dans la pipeline
    if scaler_step is not None:
        # DÃ©pose le scaler dans un fichier distinct pour inspection
        joblib.dump(scaler_step, target_dir / "scaler.joblib")
    # RÃ©cupÃ¨re le rÃ©ducteur de dimension pour exposer la matrice W
    dim_reducer: TPVDimReducer = pipeline.named_steps["dimensionality"]
    # Sauvegarde la matrice de projection pour les usages temps-rÃ©el
    dim_reducer.save(target_dir / "w_matrix.joblib")
    # Calcule le chemin du scaler pour l'ajouter au manifeste
    scaler_path = None
    # Renseigne le chemin du scaler uniquement lorsqu'il existe
    if scaler_step is not None:
        # Stocke le chemin vers le scaler sauvegardÃ© pour le manifeste
        scaler_path = target_dir / "scaler.joblib"
    # Calcule le chemin du fichier W pour le rÃ©fÃ©rencer dans le manifeste
    w_matrix_path = target_dir / "w_matrix.joblib"
    # Ã‰crit un manifeste dÃ©crivant l'entraÃ®nement et ses artefacts
    manifest_paths = _write_manifest(
        request,
        target_dir,
        cv_scores,
        {
            "model": model_path,
            "scaler": scaler_path,
            "w_matrix": w_matrix_path,
        },
    )
    # Retourne un rapport synthÃ©tique pour les tests et la CLI
    return {
        "cv_scores": cv_scores,
        "model_path": model_path,
        "scaler_path": scaler_path,
        "w_matrix_path": w_matrix_path,
        "manifest_path": manifest_paths["json"],
        "manifest_csv_path": manifest_paths["csv"],
    }


# Point d'entrÃ©e principal pour l'exÃ©cution en ligne de commande
def main(argv: list[str] | None = None) -> int:
    """Parse les arguments et lance l'entraÃ®nement."""

    # Construit le parser pour interprÃ©ter les arguments
    parser = build_parser()
    # Parse les arguments fournis par l'utilisateur
    args = parser.parse_args(argv)
    # Convertit l'option scaler "none" en None pour la pipeline
    scaler = None if args.scaler == "none" else args.scaler
    # Calcule la valeur de normalisation en inversant le flag d'opt-out
    normalize = not args.no_normalize_features
    # RÃ©cupÃ¨re le paramÃ¨tre n_components s'il est fourni
    n_components = getattr(args, "n_components", None)
    # Construit la configuration de pipeline alignÃ©e sur mybci
    config = PipelineConfig(
        sfreq=args.sfreq,
        feature_strategy=args.feature_strategy,
        normalize_features=normalize,
        dim_method=args.dim_method,
        n_components=n_components,
        classifier=args.classifier,
        scaler=scaler,
    )
    # Regroupe les paramÃ¨tres d'entraÃ®nement dans une structure dÃ©diÃ©e
    request = TrainingRequest(
        subject=args.subject,
        run=args.run,
        pipeline_config=config,
        data_dir=args.data_dir,
        artifacts_dir=args.artifacts_dir,
        raw_dir=args.raw_dir,
    )
    # ExÃ©cute l'entraÃ®nement et la sauvegarde des artefacts
    # SÃ©curise l'exÃ©cution pour afficher une erreur lisible sans trace
    try:
        # Lance l'entraÃ®nement et laisse remonter les succÃ¨s
        run_training(request)
    except FileNotFoundError as error:
        # Remonte l'erreur utilisateur de maniÃ¨re concise pour la CLI
        print(f"ERREUR: {error}")
        # Expose un code de sortie explicite pour signaler l'Ã©chec
        return 1
    # Retourne 0 pour signaler un succÃ¨s CLI Ã  mybci
    return 0


# ProtÃ¨ge l'exÃ©cution directe pour exposer un exit code explicite
if __name__ == "__main__":  # pragma: no cover - exÃ©cution CLI directe
    # Retourne l'issue du main comme code de sortie du processus
    raise SystemExit(main())

===== scripts/prepare_physionet.py () =====
# Centralise la prÃ©paration locale du dataset Physionet
import argparse

# Normalise les chemins d'entrÃ©e / sortie
from pathlib import Path

# Copie les fichiers en prÃ©servant les mÃ©tadonnÃ©es
import shutil


# Regroupe la logique de copie des fichiers EDF / events
def prepare_physionet(
    source_root: str,
    subject: str,
    runs: list[str],
    output_dir: str,
) -> None:
    """Copie les fichiers EDF/.event d'un sujet vers un dossier de travail.

    Exemple attendu de layout :

        source_root/
          S001/
            S001R01.edf
            S001R01.edf.event
            ...
        output_dir/
          S001R01.edf
          S001R01.edf.event
          ...

    Ce script NE tÃ©lÃ©charge PAS les donnÃ©es : il suppose que les EDF
    existent dÃ©jÃ  dans source_root.
    """
    # Normalise la racine source (ex: data/raw)
    source_root_path = Path(source_root)
    # Construit le dossier du sujet (ex: data/raw/S001)
    subject_dir = source_root_path / subject
    # Normalise le dossier de sortie (ex: data/S001)
    output_path = Path(output_dir)

    # CrÃ©e le dossier cible si nÃ©cessaire
    output_path.mkdir(parents=True, exist_ok=True)

    # Log dâ€™info sur la configuration utilisÃ©e
    print(
        f"INFO: prÃ©paration locale de Physionet pour sujet '{subject}' "
        f"depuis '{subject_dir}' vers '{output_path}'",
    )

    # VÃ©rifie que le dossier du sujet existe
    if not subject_dir.is_dir():
        msg = f"ERREUR: dossier sujet introuvable: '{subject_dir}'"
        raise SystemExit(msg)

    # Parcourt chaque run demandÃ© (R01, R02, ...)
    for run in runs:
        # Construit le prÃ©fixe de fichier (ex: S001R01)
        stem = f"{subject}{run}"

        # Pour chaque extension attendue (*.edf, *.edf.event)
        for ext in (".edf", ".edf.event"):
            # Chemin source attendu (ex: data/raw/S001/S001R01.edf)
            src = subject_dir / f"{stem}{ext}"
            # Chemin cible correspondant (ex: data/S001/S001R01.edf)
            dst = output_path / f"{stem}{ext}"

            # VÃ©rifie l'existence du fichier source
            if not src.is_file():
                print(f"ERREUR: fichier manquant: '{src}'")
                raise SystemExit(1)

            # Copie le fichier en conservant les mÃ©tadonnÃ©es
            shutil.copy2(src, dst)
            # Log de confirmation par fichier
            print(f"INFO: copiÃ© '{src}' â†’ '{dst}'")

    # RÃ©sumÃ© final une fois tous les fichiers copiÃ©s
    print("INFO: prÃ©paration Physionet terminÃ©e avec succÃ¨s.")


# Construit l'interface CLI compatible avec tes commandes actuelles
def parse_args() -> argparse.Namespace:
    """Construit les paramÃ¨tres CLI pour prepare_physionet."""
    # Initialise un parseur avec une description claire
    parser = argparse.ArgumentParser(
        description=(
            "PrÃ©pare localement le dataset Physionet en copiant les "
            "fichiers EDF et .event d'un sujet vers un dossier de travail."
        ),
    )

    # Racine des donnÃ©es brutes (ex: data/raw)
    parser.add_argument(
        "--source",
        required=True,
        help="Racine des donnÃ©es brutes (ex: data/raw)",
    )

    # Sujet (ex: S001)
    parser.add_argument(
        "--subject",
        required=True,
        help="Identifiant du sujet (ex: S001)",
    )

    # Liste des runs Ã  copier (ex: R01 R02 ... R08)
    parser.add_argument(
        "--runs",
        nargs="+",
        required=True,
        help="Liste des runs Ã  copier (ex: R01 R02 R03 ...)",
    )

    # Dossier de sortie (ex: data/S001)
    parser.add_argument(
        "--output",
        required=True,
        help="Dossier de sortie oÃ¹ copier les fichiers du sujet",
    )

    # Retourne les arguments parsÃ©s
    return parser.parse_args()


# Point d'entrÃ©e du script en mode CLI
def main() -> None:
    """Point d'entrÃ©e principal pour la prÃ©paration Physionet."""
    # RÃ©cupÃ¨re les paramÃ¨tres fournis en CLI
    args = parse_args()
    # DÃ©lÃ¨gue la logique mÃ©tier Ã  la fonction dÃ©diÃ©e
    prepare_physionet(args.source, args.subject, args.runs, args.output)


# Active l'exÃ©cution lorsqu'on lance le module en script
if __name__ == "__main__":
    main()

===== RUN: poetry run python mybci.py S001 R01 train =====

poetry run python mybci.py S001 R03 train
Traceback (most recent call last):
  File "/usr/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/home/raveriss/Desktop/Total_Perspective_Vortex/src/tpv/train.py", line 22, in <module>
    raise SystemExit(main())
  File "/home/raveriss/Desktop/Total_Perspective_Vortex/src/tpv/train.py", line 12, in main
    return script_train.main(argv)
  File "/home/raveriss/Desktop/Total_Perspective_Vortex/scripts/train.py", line 501, in main
    run_training(request)
  File "/home/raveriss/Desktop/Total_Perspective_Vortex/scripts/train.py", line 415, in run_training
    pipeline.fit(X, y)
  File "/home/raveriss/Desktop/Total_Perspective_Vortex/.venv/lib/python3.10/site-packages/sklearn/base.py", line 1365, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/home/raveriss/Desktop/Total_Perspective_Vortex/.venv/lib/python3.10/site-packages/sklearn/pipeline.py", line 655, in fit
    Xt = self._fit(X, y, routed_params, raw_params=params)
  File "/home/raveriss/Desktop/Total_Perspective_Vortex/.venv/lib/python3.10/site-packages/sklearn/pipeline.py", line 589, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File "/home/raveriss/Desktop/Total_Perspective_Vortex/.venv/lib/python3.10/site-packages/joblib/memory.py", line 326, in __call__
    return self.func(*args, **kwargs)
  File "/home/raveriss/Desktop/Total_Perspective_Vortex/.venv/lib/python3.10/site-packages/sklearn/pipeline.py", line 1540, in _fit_transform_one
    res = transformer.fit_transform(X, y, **params.get("fit_transform", {}))
  File "/home/raveriss/Desktop/Total_Perspective_Vortex/.venv/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 316, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/raveriss/Desktop/Total_Perspective_Vortex/.venv/lib/python3.10/site-packages/sklearn/base.py", line 897, in fit_transform
    return self.fit(X, y, **fit_params).transform(X)
  File "/home/raveriss/Desktop/Total_Perspective_Vortex/.venv/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 316, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/raveriss/Desktop/Total_Perspective_Vortex/src/tpv/features.py", line 212, in transform
    raw_features = self._compute_features(X)
AttributeError: 'ExtractFeatures' object has no attribute '_compute_features'. Did you mean: '_compute_fft_features'?
make: *** [Makefile:86: train] Error 1
