ID,Phase,Sous-étape,Failure mode,Cause racine,Symptômes observables,Impact,Détection,Prévention,Test reproductible,Gravité,Probabilité,Priorité,Statut
TPV-001,Source & Repo,Structure repo,mybci.py absent à la racine du repo,Mauvaise organisation des fichiers au démarrage du projet,Impossible d’exécuter python mybci.py 4 14 train/predict,Blocage complet de la défense (0 ou -42 si cheat),ls -R du repo ; recherche mybci.py à la racine,Imposer le chemin et le nom de script selon le subject §V.1.2,Cloner le repo vierge et lancer python mybci.py 4 14 train : attendre usage,5,3,Must,à faire
TPV-002,Source & Repo,Structure repo,Scripts dispersés dans plusieurs sous-dossiers non documentés,Ajouts successifs sans refactor de l’arborescence,Évaluateur incapable de trouver train/predict sans lire tout le code,"Perte de temps, incompréhension, suspicion de hors-sujet",tree ; repérage manuel des scripts ; absence de README clair,"Figer une arborescence simple: src/, scripts/, tests/, mybci.py",Demander à un pair de lancer le projet uniquement via README,3,4,Must,à faire
TPV-003,Source & Repo,Imports,Import absolu cassé dès qu’on lance depuis un autre cwd,Utilisation de chemins relatifs fragiles dans sys.path/ imports,python mybci.py échoue avec ModuleNotFoundError,Impossible de lancer les scripts dans un autre environnement,"Lancer mybci.py depuis différentes positions (., scripts/)",Utiliser des imports relatifs de package et un setup clair,python -m scripts.mybci 4 14 train depuis la racine,4,4,Must,à faire
TPV-004,Source & Repo,.gitignore,Datasets Physionet EEG inclus en dur dans le repo,Téléchargement manuel puis commit sans .gitignore,"Repo très lourd, clone lent, suspicion non-respect subject §VII",Problèmes pratiques + potentielle violation des consignes,du -sh . ; vérifier présence de fichiers EDF/FIF bruts,Mettre les données dans data/ et ignorer dans .gitignore,Cloner sur une machine vierge et mesurer le temps de clone,3,3,Should,à faire
TPV-005,Source & Repo,.gitignore,Fichiers temporaires MNE/sklearn (cache) committés,Lancement en debug sans nettoyage avant git add,"Repo rempli de .npy, .fif~, pipelines picklés inutiles","Manque de propreté, risques de confusion à la défense","git status ; recherche *.npy, *.fif, *.pkl dans le repo","Ajouter patterns dans .gitignore (cache/, *.npy, *.fif)",Exécuter find . -name '*.npy' avant chaque commit,2,4,Should,à surveiller
TPV-006,Source & Repo,Dépendances,poetry.lock obsolète ou incomplet,Installation Poetry non synchronisée avec pyproject.toml,poetry install échoue ou installe des versions divergentes,Projet non reproductible sur machine 42 ou pair évaluateur,Créer un environnement Poetry propre,Verrouiller toutes les libs dans pyproject.toml et poetry.lock,poetry env remove --all puis poetry install sur machine vierge,5,3,Must,à faire
TPV-007,Source & Repo,Dépendances,"Utilisation de libs interdites (mne-realtime, autoML, etc.)",Recherche de raccourcis pour le temps réel/ML,"Présence d’imports non autorisés, ou d’appels suspects",Risque de flag 'Forbidden function' ou 'Cheat' (§Checklist),grep -R 'mne.realtime' 'auto-sklearn' 'autosklearn',"Limiter aux libs autorisées: MNE, numpy/scipy, sklearn",Débrancher Internet et vérifier que tout tourne en local,5,2,Must,à faire
TPV-008,Source & Repo,Makefile/CI,Aucune règle pour lancer train/predict et les tests,"Makefile minimaliste ou absent, CI inexistante",Évaluateur obligé de chercher à la main les commandes,"Perte de temps, risque d’oublier des cas importants",Afficher make help ; lire la CI si elle existe,"Créer des cibles claires: make train, make predict, make eval",Exécuter make all sur une machine vierge 42 sans IDE,3,3,Should,à faire
TPV-009,Source & Repo,Scripts utilitaires,Scripts perso d’évaluation non testés et non documentés,Écriture rapide de scripts de bench en 'one-shot',Résultats présentés en défense impossible à reproduire,Crédibilité des scores remise en question,Inspecter scripts/ ; vérifier docstrings et README,"Documenter chaque script avec usage, entrées/sorties",Demander à un pair de reproduire les scores à partir du README,3,3,Should,à surveiller
TPV-010,Source & Repo,Compatibilité machines 42,Utilisation de fonctionnalités Python/OS non disponibles 42,Tests uniquement sur laptop perso avec sudo et libs globales,"Crashs sur machines 42 (lib introuvable, version incompatible)",Projet inexploitable au moment de la défense,Tester strictement sur machine 42 sans sudo,Figer version Python et libs dans pyproject.toml/poetry.lock,Lancer l’ensemble du pipeline sur une machine 42 neuve,5,3,Must,à faire
TPV-011,Parsing EEG,Chargement Physionet,Chemin Physionet codé en dur dépendant du home local,Utilisation de chemins absolus utilisateur dans le code,FileNotFoundError dès qu’un autre utilisateur lance le script,Impossibilité de lancer sur machine 42 ou autre login,"Rechercher '/' + login dans le code, ex: '/home/user/'",Utiliser des chemins relatifs à data/ + variables d’env,Changer d’utilisateur (autre login 42) et lancer train,4,4,Must,à faire
TPV-012,Parsing EEG,Chargement Physionet,Utilisation d’un format de fichier différent de celui du subject,Téléchargement manuel d’une autre version des data,MNE lève une erreur ou les events ne correspondent pas,Pipeline entrainé sur un dataset non conforme à la défense,Comparer checksum data avec celui recommandé Physionet,Documenter la version et le téléchargement dans README,"Supprimer data/, re-télécharger via script documenté",4,2,Should,à surveiller
TPV-013,Parsing EEG,MNE Raw,Mauvais montage (montage EEG standard non appliqué),Ignorance de la notion de montage dans MNE,"Topographies incohérentes, canaux mal positionnés",Features spatiales non pertinentes pour CSP et co.,Inspecter raw.get_montage() et info['chs'],Appliquer un montage standard adapté (ex: standard_1020),Tracer les capteurs sur scalp et vérifier la cohérence,3,3,Should,à faire
TPV-014,Parsing EEG,Canaux,Channels EOG/EMG non retirés avant traitement,Parsing naïf de tous les channels disponibles,Artefacts oculaires/musculaires dominent la variance,Dimensionalité réduction/apprentissage biaisés,Vérifier les channel types via raw.get_channel_types(),Sélectionner uniquement les canaux EEG utiles,Refaire l’entraînement avec et sans canaux EOG/EMG,4,3,Must,à faire
TPV-015,Parsing EEG,Fréquence d’échantillonnage,Supposition d’un fs fixe sans le lire dans MNE,Hardcoding d’une fréquence d’échantillonnage,Filtres et fenêtrage incohérents avec le vrai fs,"Risque de filtrage aberrant, aliasing, features invalides",Afficher raw.info['sfreq'] avant tout prétraitement,Toujours paramétrer les filtres à partir de fs réel,Changer de dataset Physionet et vérifier robustesse du code,5,3,Must,à faire
TPV-016,Parsing EEG,Bad segments,Segments marqués 'bad' dans MNE non exclus,Utilisation directe de raw sans tenir compte des annotations,"Epochs contenant des artéfacts extrêmes, saturations","Apprentissage sur signaux pollués, scores instables",Inspecter raw.annotations et epochs.drop_log,Dropper les epochs marqués bad avant features,Comparer accuracy avec et sans exclusion des bad epochs,4,3,Must,à surveiller
TPV-017,Parsing EEG,Types d’événements,Mauvais mapping entre codes d’événements et labels,Interprétation erronée de la doc Physionet,Classe 'pied' traitée comme 'main' ou inversement,Classification sur labels incohérents avec la tâche réelle,Afficher la correspondance event_id et vérifier avec la doc,Créer un mapping explicite event_id -> label,Comparer la distribution des labels à celle attendue Physionet,5,3,Must,à faire
TPV-018,Parsing EEG,Reproductibilité,Téléchargement manuel des fichiers sans script dédié,Procédure non documentée pour récupérer les données,Impossible pour un tiers de recréer exactement le dataset,"Non-reproductibilité forte, difficulté de debug",Chercher un script download_data.py ou section README dédiée,Écrire un script ou section 'Data acquisition' complète,"Supprimer data/, tout recréer via la procédure documentée",4,3,Should,à faire
TPV-019,Parsing EEG,Normalisation unités,Confusion entre microvolts et volts dans les signaux,Absence de conversion ou doc sur les unités,Valeurs extrêmes (1e-5 vs 100) selon dataset,Thresholds/features non comparables entre sujets,Inspecter min/max du signal brut par channel,Documenter les unités et normaliser si nécessaire,Comparer histos d’amplitude avant/après normalisation,3,3,Should,à surveiller
TPV-020,Parsing EEG,Robustesse parsing,Aucun try/except autour du parsing MNE,Assumption que tous les fichiers sont valides,Un fichier corrompu crash tout le pipeline,Runtime cassé au milieu d’un batch d’évaluation,Simuler un fichier manquant/corrompu dans data/,Ajouter gestion d’erreurs claire et message explicite,Lancer le script avec un sujet volontairement incomplet,4,2,Must,à faire
TPV-021,Filtrage,Bandpass 8–40 Hz,Oubli complet de filtrage bande-passante,Focalisation sur ML sans prétraitement fréquentiel,Raw et filtered plots quasi identiques,"Scores instables, surapprentissage, bruit large bande",Comparer raw.plot() et filtered.plot(),Appliquer un bandpass ~8–40 Hz comme en checklist,Mesurer accuracy avant/après bandpass standard,5,3,Must,à faire
TPV-022,Filtrage,Bandpass 8–40 Hz,Bande-passante incorrecte (ex: 0.5–60 Hz),Copier un exemple générique sans l’adapter à la tâche motrice,Spectrum montre forte énergie hors 8–40 Hz,"Pertinence réduite pour MI, difficulté à généraliser","Tracer PSD par channel, vérifier concentration énergétique",Régler la bande-passante selon MI (8–40 Hz),Comparer cross_val_score entre config générique et MI,4,3,Must,à faire
TPV-023,Filtrage,Notch,Absence de notch 50/60 Hz sur environnement bruité,Méconnaissance du bruit secteur sur EEG,Pics nets à 50/60 Hz dans PSD post-filtrage,"Réduction du SNR, erreurs de classification",Inspecter PSD autour de 50/60 Hz,Ajouter un notch filter si nécessaire,Comparer résultats avec/ sans notch sur même sujet,3,3,Should,à surveiller
TPV-024,Filtrage,Edge effects,Fenêtre filtrée trop courte par rapport au filtre,Utilisation naïve de filtres FIR/IIR,"Artefacts aux bords d’epochs, oscillations artificielles",Features dépendantes de bord erronées,Visualiser un epoch filtré avec padding visible,Utiliser padding approprié ou filtres adaptés (MNE defaults),Zoomer sur le début/fin des epochs filtrés,3,3,Should,à surveiller
TPV-025,Filtrage,Application ordre,Filtrage appliqué avant re-référencement inapproprié,Ordre des opérations non réfléchi,Différences importantes si on inverse re-ref et filtrage,Incohérences entre sujets selon montage initial,Comparer deux pipelines: ref->filter vs filter->ref,Documenter l’ordre dans le code/README,Reproduire un même sujet avec 2 ordres et comparer scores,2,3,Could,à surveiller
TPV-026,Filtrage,Écrasement données,Filtrage appliqué en écrasant le Raw original sans copie,Optimisation naïve de mémoire,Impossible de revenir au signal brut pour debug/viz,Perte d’information pour analyse d’erreurs,Vérifier si raw est modifié in-place (MNE defaults),Toujours conserver une version raw initiale pour debug,Ajouter un test unitaire qui compare copies avant/après,2,3,Should,à surveiller
TPV-027,Filtrage,Paramètres dynamiques,Hyperparamètres de filtrage codés en dur partout,Pas de configuration centralisée ou CLI,Changer la bande-passante nécessite modifier plusieurs fichiers,Risque d’incohérence entre modes train/predict,Rechercher '8-40' ou fréquences en dur dans le code,Centraliser config dans un module ou fichier YAML,Changer la bande-passante et vérifier que tout suit,3,4,Should,à faire
TPV-028,Filtrage,Temporal leakage,Utilisation de filtres non causaux simulant un futur inaccessible,Choix d’options MNE sans considérer temps réel,"Prévisions irréalistes en temps réel, latence mal modélisée",Risque de triche 'involontaire' sur contrainte <2s,Comparer filtrage causal vs non causal sur un clin d’œil,Adapter la config de filtrage pour réalisme temps réel,Simuler une chaîne temps réel avec streaming MNE,4,2,Should,à surveiller
TPV-029,Filtrage,Stabilité numérique,Paramètres de filtre provoquant instabilité numérique,Choix de très haut ordre de filtre ou IIR mal conçu,"NaNs ou infs après filtrage, warnings MNE ignorés",Données inutilisables pour features,Activer warnings MNE et vérifier NaN/inf après filtres,Utiliser les recommandations MNE par défaut,Test unitaire: assert not np.isnan(filtered)._any(),4,2,Must,à faire
TPV-030,Filtrage,Différences train/predict,Filtres configurés différemment entre train et predict,Code dupliqué avec paramètres divergents,Distribution des features différente en production,Chute d’accuracy en mode predict vs cross_val_score,Comparer les pipelines serialisés entre train/predict,Factoriser le pipeline dans un seul objet sklearn,Sauvegarder/charger le pipeline complet via joblib,5,3,Must,à faire
TPV-031,Events & labels,Alignement temporel,Décalage constant entre events et signal (offset mal géré),Confusion entre temps absolu et index d’échantillon,Epochs centrés avant ou après le vrai mouvement,"Apprentissage sur mauvaises fenêtres, accuracy plafonne",Comparer courbes stimulus vs epochs (MNE.plot_events),Toujours convertir events en samples via sfreq,Simuler un offset +10 samples et mesurer chute d’accuracy,5,3,Must,à faire
TPV-032,Events & labels,Fenêtrage epochs,Fenêtre trop courte pour couvrir la réponse motrice,Choix arbitraire d’une durée trop faible,Perte d’information dans les bandes mu/bêta post-stimulus,Modèle ne capte pas le pattern MI complet,Visualiser moyenne temporelle par classe sur plusieurs epochs,Ajuster tmin/tmax en fonction de la littérature MI,Tester plusieurs durées d’epoch et comparer cross_val_score,4,3,Should,à faire
TPV-033,Events & labels,Labels bruités,Non prise en compte de trials où le sujet n’a pas respecté la consigne,Considération naïve de tous les essais comme corrects,Certains epochs sont impossibles à classer même pour un humain,Plafond théorique d’accuracy plus bas que 100%,Comparer courbes individuelles et repérer trials aberrants,Mettre en place un filtrage basique des trials extrêmes,Retirer 5% des trials à amplitude extrême et re-mesurer score,3,2,Could,à surveiller
TPV-034,Feature engineering,PSD,Erreur de reshape ch×freq dans les features PSD,Manipulation manuelle de np.reshape sans vérifier dimensions,Features mélangent canaux et fréquences,CSP/Classifier reçoivent des patterns incohérents,"Afficher shape avant/après reshape, vérifier ordre axes",Utiliser des fonctions helpers claires pour construire X,"Test unitaire: vérifier que chaque feature mappe un (ch,freq) unique",5,3,Must,à faire
TPV-035,Feature engineering,Fenêtres temps-fréquence,Fenêtres glissantes chevauchantes non cohérentes entre sujets,Hardcoding d’offsets dépendant de la durée brute,Certaines epochs produisent plus de fenêtres que d’autres,"X hétérogène, errors de shape ou padding ad hoc",Vérifier nombre de fenêtres par epoch sur plusieurs sujets,Définir une règle générale en secondes puis convertir avec sfreq,Comparer distributions de features entre sujets après normalisation,4,3,Should,à faire
TPV-036,Feature engineering,Normalisation features,Standardisation faite globalement sur train+test,Utilisation de StandardScaler.fit sur tout le dataset,"Leakage massif, scores cross_val_score surévalués",Performance réelle en test sujet non vu catastrophique,Inspecter où est appelé fit() du scaler dans le pipeline,Mettre scaler dans sklearn.Pipeline avant réduction/CLF,"Utiliser cross_val_score sur pipeline complet, pas sur X transformé",5,4,Must,à faire
TPV-037,Réduction dimension,Covariance singulière,Covariance estimée sur trop peu d’epochs par classe,Découpage abusif en petits sous-ensembles,np.linalg.LinAlgError lors de l’inversion/diag,Algorithme CSP/CCA casse en plein entraînement,Logger nombre d’epochs/classe avant estimation covariance,Imposer un minimum de trials par classe ou régulariser,Réduire nombre de filtres CSP et vérifier stabilité,5,3,Must,à faire
TPV-038,Réduction dimension,W non sauvegardée,Matrice de projection W recalculée différemment en predict,Séparation des chemins train/predict sans persistance,Distribution des features différente entre train et prod,Accuracy correcte en cross_val_score mais mauvaise en predict,Vérifier que W est sérialisée avec le pipeline complet,Stocker réduction+clf dans un seul objet sklearn Pipeline,Sauvegarder/charger joblib du pipeline et comparer sorties,5,4,Must,à faire
TPV-039,Réduction dimension,Implémentation PCA/CSP,Confusion entre vecteurs propres colonne/ligne,Transposition oubliée dans la projection,"Variance expliquée incohérente, patterns non interprétables",Perte d’information ou projections absurdes,Comparer eigenvalues/variance expliquée à sklearn.PCA,Écrire tests qui comparent avec une implémentation de référence,Appliquer PCA maison vs sklearn sur un toy dataset connu,4,3,Must,à faire
TPV-040,Pipeline sklearn,Non utilisation de Pipeline,Appels manuels successifs fit_transform/fit,Subject §V.1.2 demande un sklearn.Pipeline,Risque d’incohérence entre ordre train/predict,"Rechercher 'Pipeline(' dans le code, vérifier présence",Refactoriser en un pipeline unique : scaler->réduction->clf,Utiliser cross_val_score directement sur le pipeline,Appliquer la détection décrite et vérifier la disparition du symptôme,4,3,Must,à faire
TPV-041,Pipeline sklearn,TransformerMixin non respecté,Classe de réduction ne respecte pas fit/transform standard,Méthodes avec signatures custom et side effects,Impossible d’utiliser la classe dans un Pipeline sklearn,"Feature clé du subject manquante, debug compliqué",Vérifier héritage baseEstimator/TransformerMixin,"Suivre la contract sklearn (fit, transform, fit_transform)",Écrire un test sklearn.check_estimator sur la classe,4,3,Must,à faire
TPV-042,Pipeline sklearn,Shapes,Transform renvoie une shape différente entre fit et predict,Conditions if/else différentes selon mode,"ValueError 'X has n_features, expected m' en predict",Pipeline inutilisable en prod temps réel,Comparer X.shape à chaque étape train et predict,Interdire toute logique conditionnelle dépendant du mode,Test unitaire: appliquer pipeline.fit puis pipeline.predict sur X,5,3,Must,à faire
TPV-043,Train/Val/Test,Leakage sujets,Mélange des epochs de tous les sujets dans un même split,split sklearn train_test_split sur toutes les lignes,Subjects présents à la fois en train et test,"Accuracy surévaluée, non conforme au subject §V.1.4",Vérifier répartition unique des subject_id par split,Faire split par sujet (GroupKFold/LeaveOneGroupOut),Comparer accuracy avant/après split par sujet,5,4,Must,à faire
TPV-044,Train/Val/Test,Cross_val_score mal utilisé,Usage sur X pré-transformé sans pipeline complet,Score évalué sans filtrage ni CSP dans la boucle CV,Résultat ne reflète pas la chaîne réelle de traitement,Écart fort entre cross_val_score et accuracy finale,Vérifier objet passé à cross_val_score (Pipeline vs clf),Toujours donner pipeline complet à cross_val_score,Imprimer les scores pour chaque fold et les comparer à test final,4,3,Must,à faire
TPV-045,Score global,Moyenne des six expériences,Mauvais calcul de la moyenne demandée §V.1.4,Somme des accuracy non divisée par le bon nombre,Mean accuracy affichée diffère des logs par expérience,Critère 60% non vérifié correctement,Reproduire l’exemple du subject et comparer formule,Écrire une fonction compute_global_score testée,Tester compute_global_score sur les valeurs de l’exemple,4,3,Must,à faire
TPV-046,Classification,Surapprentissage extrême,Choix d’un classifier très complexe sur peu de données,"Accuracy quasi 100% en train, <50% en sujet non vu","Modèle inutilisable en pratique, biaisé par bruit",Comparer learning curves train/validation,Commencer par un classifier simple (LDA/LogReg),Tracer courbes de validation selon C/régularisation,Appliquer la détection décrite et vérifier la disparition du symptôme,4,3,Should,à faire
TPV-047,Classification,Classes déséquilibrées,Ignorer le ratio classe 1/2 dans les epochs,Random baseline déjà >50%,Interpretation naïve d’un 60% comme excellent,Biais en faveur de la classe majoritaire,Afficher distribution des labels dans chaque split,Utiliser metrics balanced_accuracy_score,Comparer accuracy et balanced_accuracy sur même modèle,3,3,Should,à surveiller
TPV-048,Temps réel,Latence >2s,"Pipeline trop lourd (FFT dense, CSP coûteux, classifier lent)",Optimisation jamais testée en chronométrant,Temps entre event et prédiction >2s,Non-respect checklist 'Realtime',Mesurer temps d’inférence avec time.perf_counter par epoch,"Optimiser pipeline (réduire dims, classifier plus simple)",Tester sur 1 minute de stream simulé et logguer les latences,5,3,Must,à faire
TPV-050,CLI,Arguments incohérents,Syntaxe mybci.py <subj> <task> non respectée,Ajout d’options sans doc ni valeurs par défaut,Évaluateur n’arrive pas à reproduire exemple du subject,"Perte de temps, suspicion de non-conformité",Tester python mybci.py 4 14 train/predict comme dans §V.1.4,Aligner interface CLI sur l’exemple officiel,Écrire tests CLI avec argparse et subprocess,4,3,Must,à faire
TPV-051,Robustesse,NaN dans X,Aucune vérification de NaN/inf après chaque étape,"Divisions par zéro, log sur 0, erreurs num.",Classifier sklearn lève des erreurs aléatoires,Training/predict interrompus avec stacktrace compliqué,Utiliser np.isnan/np.isinf sur X à chaque étape clé,Nettoyer ou dropper les epochs problématiques,Test unitaire qui échoue si NaN/inf détectés,5,3,Must,à faire
TPV-052,Viz,Plots non représentatifs,Choix de canaux/fenêtres non expliqués dans la défense,Étudiant montre des figures 'belles' mais peu informatives,Évaluateur ne voit pas l’apport du filtrage/MI,Bonus viz non crédible,Comparer raw vs filtered sur mêmes canaux/temps que la vidéo,Préparer 2–3 figures directement liées au checklist,Revérifier que les figures reproduisent l’exemple du sujet,2,3,Could,à surveiller
TPV-053,Documentation & défense,Écart subject/code,Code ne suit plus la description orale en défense,Refactors tardifs non mis à jour dans le README,Évaluateur trouve des divergences sur pipeline réel,"Perte de confiance, risques de questions de cheat",Relire subject §V.1.* et vérifier alignment avec README,Maintenir README à jour à chaque refactor clé,Dry-run de défense avec un pair en suivant le subject,4,3,Must,à faire
TPV-200,Events & labels,Alignement,Offset event-signal,Décalage seconds/samples,Epoch mal centrée,Baisse accuracy,Comparer event times,Convertir via sfreq,Tester sur 3 sujets,5,3,Must,à faire
TPV-201,Events & labels,Alignement,Offset event-signal,Décalage seconds/samples,Epoch mal centrée,Baisse accuracy,Comparer event times,Convertir via sfreq,Tester sur 3 sujets,5,3,Must,à faire
TPV-202,Events & labels,Alignement,Offset event-signal,Décalage seconds/samples,Epoch mal centrée,Baisse accuracy,Comparer event times,Convertir via sfreq,Tester sur 3 sujets,5,3,Must,à faire
TPV-203,Events & labels,Alignement,Offset event-signal,Décalage seconds/samples,Epoch mal centrée,Baisse accuracy,Comparer event times,Convertir via sfreq,Tester sur 3 sujets,5,3,Must,à faire
TPV-204,Events & labels,Alignement,Offset event-signal,Décalage seconds/samples,Epoch mal centrée,Baisse accuracy,Comparer event times,Convertir via sfreq,Tester sur 3 sujets,5,3,Must,à faire
TPV-205,Events & labels,Alignement,Offset event-signal,Décalage seconds/samples,Epoch mal centrée,Baisse accuracy,Comparer event times,Convertir via sfreq,Tester sur 3 sujets,5,3,Must,à faire
TPV-206,Events & labels,Alignement,Offset event-signal,Décalage seconds/samples,Epoch mal centrée,Baisse accuracy,Comparer event times,Convertir via sfreq,Tester sur 3 sujets,5,3,Must,à faire
TPV-207,Events & labels,Alignement,Offset event-signal,Décalage seconds/samples,Epoch mal centrée,Baisse accuracy,Comparer event times,Convertir via sfreq,Tester sur 3 sujets,5,3,Must,à faire
TPV-208,Events & labels,Alignement,Offset event-signal,Décalage seconds/samples,Epoch mal centrée,Baisse accuracy,Comparer event times,Convertir via sfreq,Tester sur 3 sujets,5,3,Must,à faire
TPV-209,Events & labels,Alignement,Offset event-signal,Décalage seconds/samples,Epoch mal centrée,Baisse accuracy,Comparer event times,Convertir via sfreq,Tester sur 3 sujets,5,3,Must,à faire
TPV-210,Feature engineering,PSD,Erreur reshape PSD,Axes inversés,Features incohérentes,CSP instable,Vérif shape,Utiliser helper,Test unitaire reshape,5,3,Must,à faire
TPV-211,Feature engineering,PSD,Erreur reshape PSD,Axes inversés,Features incohérentes,CSP instable,Vérif shape,Utiliser helper,Test unitaire reshape,5,3,Must,à faire
TPV-212,Feature engineering,PSD,Erreur reshape PSD,Axes inversés,Features incohérentes,CSP instable,Vérif shape,Utiliser helper,Test unitaire reshape,5,3,Must,à faire
TPV-213,Feature engineering,PSD,Erreur reshape PSD,Axes inversés,Features incohérentes,CSP instable,Vérif shape,Utiliser helper,Test unitaire reshape,5,3,Must,à faire
TPV-214,Feature engineering,PSD,Erreur reshape PSD,Axes inversés,Features incohérentes,CSP instable,Vérif shape,Utiliser helper,Test unitaire reshape,5,3,Must,à faire
TPV-215,Feature engineering,PSD,Erreur reshape PSD,Axes inversés,Features incohérentes,CSP instable,Vérif shape,Utiliser helper,Test unitaire reshape,5,3,Must,à faire
TPV-216,Feature engineering,PSD,Erreur reshape PSD,Axes inversés,Features incohérentes,CSP instable,Vérif shape,Utiliser helper,Test unitaire reshape,5,3,Must,à faire
TPV-217,Feature engineering,PSD,Erreur reshape PSD,Axes inversés,Features incohérentes,CSP instable,Vérif shape,Utiliser helper,Test unitaire reshape,5,3,Must,à faire
TPV-218,Feature engineering,PSD,Erreur reshape PSD,Axes inversés,Features incohérentes,CSP instable,Vérif shape,Utiliser helper,Test unitaire reshape,5,3,Must,à faire
TPV-219,Feature engineering,PSD,Erreur reshape PSD,Axes inversés,Features incohérentes,CSP instable,Vérif shape,Utiliser helper,Test unitaire reshape,5,3,Must,à faire
TPV-220,Réduction dimension,Covariance,Covariance singulière,Peu d’epochs,np.linalg error,Training cassé,Logger n_epochs,Régulariser,Tester petites tailles,5,3,Must,à faire
TPV-221,Réduction dimension,Covariance,Covariance singulière,Peu d’epochs,np.linalg error,Training cassé,Logger n_epochs,Régulariser,Tester petites tailles,5,3,Must,à faire
TPV-222,Réduction dimension,Covariance,Covariance singulière,Peu d’epochs,np.linalg error,Training cassé,Logger n_epochs,Régulariser,Tester petites tailles,5,3,Must,à faire
TPV-223,Réduction dimension,Covariance,Covariance singulière,Peu d’epochs,np.linalg error,Training cassé,Logger n_epochs,Régulariser,Tester petites tailles,5,3,Must,à faire
TPV-224,Réduction dimension,Covariance,Covariance singulière,Peu d’epochs,np.linalg error,Training cassé,Logger n_epochs,Régulariser,Tester petites tailles,5,3,Must,à faire
TPV-225,Réduction dimension,Covariance,Covariance singulière,Peu d’epochs,np.linalg error,Training cassé,Logger n_epochs,Régulariser,Tester petites tailles,5,3,Must,à faire
TPV-226,Réduction dimension,Covariance,Covariance singulière,Peu d’epochs,np.linalg error,Training cassé,Logger n_epochs,Régulariser,Tester petites tailles,5,3,Must,à faire
TPV-227,Réduction dimension,Covariance,Covariance singulière,Peu d’epochs,np.linalg error,Training cassé,Logger n_epochs,Régulariser,Tester petites tailles,5,3,Must,à faire
TPV-228,Réduction dimension,Covariance,Covariance singulière,Peu d’epochs,np.linalg error,Training cassé,Logger n_epochs,Régulariser,Tester petites tailles,5,3,Must,à faire
TPV-229,Réduction dimension,Covariance,Covariance singulière,Peu d’epochs,np.linalg error,Training cassé,Logger n_epochs,Régulariser,Tester petites tailles,5,3,Must,à faire
TPV-680,Events & labels,Alignement temporel,"Events alignés sur début du cue, pas sur période d’imagerie",Lecture incomplète du protocole moteur,Epochs centrés trop tôt par rapport à la vraie activité MI,"Le modèle ne voit que la préparation visuelle, pas le MI","Tracer moyenne par classe autour de l’event sur [-2s, +4s]",Recentrer les fenêtres sur la période d’imagerie (cf. doc Physionet),Appliquer la détection décrite et vérifier la disparition du symptôme,5,3,Must,à faire
TPV-681,Events & labels,Alignement temporel,tmin/tmax exprimés en samples alors que MNE attend des secondes,Confusion unités secondes/samples dans l’API MNE,"Epochs beaucoup trop longs ou trop courts, voire vides","Découpage aberrant, shapes inattendues, training instable",Inspecter epochs.get_data().shape vs tmin/tmax choisis,"Toujours exprimer tmin/tmax en secondes, vérifier cohérence avec sfreq",Appliquer la détection décrite et vérifier la disparition du symptôme,5,3,Must,à faire
TPV-682,Events & labels,Sélection des events,"Inclusion de codes d’events non MI (rest, artefacts, breaks)",Mapping event_id trop large sans filtrage des tâches,Dataset mélangé avec des états de repos ou de pause,Classifier apprend à distinguer repos/bruit plutôt que MI,Lister les event_id uniques et les confronter à la doc Physionet,Limiter explicitement aux event_id MI décrits par le subject,Appliquer la détection décrite et vérifier la disparition du symptôme,5,3,Must,à faire
TPV-683,Events & labels,Sélection des events,Exclusion involontaire d’une classe (ex: feet) lors du filtrage,Filtre sur event_id mal paramétré/typo,Une classe disparait du jeu d’apprentissage,Classifier se comporte comme un modèle mono-classe,Vérifier distribution des labels après filtrage (np.bincount),Ajouter une assertion sur la présence de toutes les classes attendues,Appliquer la détection décrite et vérifier la disparition du symptôme,5,3,Must,à faire
TPV-684,Events & labels,Structure des runs,Mélange d’events de runs différents dans la même séquence temporelle,Concaténation brute de fichiers sans garder l’info de run,"Indices de temps non remis à zéro, time gaps énormes",Epochs chevauchent des transitions de run artificielles,Inspecter chronologie des events par fichier/run,Garder un identifiant run dans les métadonnées des epochs,Appliquer la détection décrite et vérifier la disparition du symptôme,5,3,Must,à faire
TPV-685,Events & labels,Qualité des trials,Conservation de trials avec amplitude saturée persistante,Aucun critère de rejet sur amplitude ou variance,Certaines epochs contiennent uniquement du signal saturé,Scores très sensibles à quelques trials extrêmes,Tracer la distribution des amplitudes par epoch,"Définir des règles de rejet (z-score amplitude, variance)",Appliquer la détection décrite et vérifier la disparition du symptôme,5,3,Must,à faire
TPV-686,Events & labels,Jitter intra-epoch,"Fenêtres MI trop longues, couvrant plusieurs événements",Durée fixée sans vérifier la densité d’événements,Epochs contiennent potentiellement deux cues successifs,"Confusion de labels, features moyennées sur plusieurs tâches",Comparer histogramme des inter-event intervals,Adapter tmax pour ne pas chevaucher le cue suivant,Appliquer la détection décrite et vérifier la disparition du symptôme,5,3,Must,à faire
TPV-687,Events & labels,Leak temporel,Utilisation de fenêtres centrées après le feedback visuel,Décision entraînée sur une information postérieure à la consigne,"Accuracy anormalement haute en test, chute sur sujet non vu",Triche involontaire sur la tâche MI,Comparer tmin/tmax à la timeline réelle du protocole,"Contraindre fenêtres à rester dans [cue, fin MI]",Appliquer la détection décrite et vérifier la disparition du symptôme,5,3,Must,à faire
TPV-688,Events & labels,Alignement labels / epochs,Décalage de 1 event entre y et les epochs (off-by-one),Indexation des labels après un shuffle/tri des events,Courbes de vérité/prediction déphasées de 1,Accuracy proche d’une permutation circulaire,Comparer y et y_shuffled pour détecter un motif de décalage,Toujours attacher les labels aux epochs via structures MNE (metadata),Appliquer la détection décrite et vérifier la disparition du symptôme,5,3,Must,à faire
TPV-689,Events & labels,Gestion des trials rejetés,Rejet d’epochs sans ajuster la taille correspondante de y,Manipulation séparée de X et y sans index commun,"ValueError ou, pire, mauvaise association X/y silencieuse",Apprentissage sur des labels décalés,Comparer len(X) et len(y) à chaque opération de drop,"Centraliser drop dans une structure qui manipule X,y ensemble",Appliquer la détection décrite et vérifier la disparition du symptôme,5,3,Must,à faire
TPV-690,Events & labels,Stratification,Split train/test ignorent complètement l’équilibre des labels,Random split sans stratification sur la classe,Une classe dominante en train et absente en test ou inversement,"Scores instables, interprétation des métriques difficile","Afficher np.bincount(y_train), np.bincount(y_test)",Utiliser StratifiedKFold/StratifiedShuffleSplit pour MI binaire,Appliquer la détection décrite et vérifier la disparition du symptôme,5,3,Must,à faire
TPV-691,Events & labels,Cross-subject consistency,Labels inversés (1/2) pour certains sujets par erreur de mapping,Mapping event_id->label défini par sujet sans harmonisation,Le modèle voit des patterns contradictoires entre sujets,Accuracy moyenne faible malgré performance correcte par sujet,Vérifier la table de mapping par sujet et la rendre globale,Fixer un mapping unique au niveau projet et tester par sujet,Appliquer la détection décrite et vérifier la disparition du symptôme,5,3,Must,à faire
TPV-692,Events & labels,Balance runs/classes,Certains runs/sujets contribuent beaucoup plus de trials,Aucune pondération ni équilibrage par run/sujet,Le modèle se spécialise sur quelques sujets,Scores biaisés vers les patterns de quelques personnes,"Analyser n_trials par (sujet, run, classe)",Échantillonner ou pondérer les trials pour équilibrer,Appliquer la détection décrite et vérifier la disparition du symptôme,5,3,Must,à faire
TPV-693,Events & labels,Mélange train/test par run,Runs d’un même sujet partagés entre train et test,"Split fait au niveau epoch, pas au niveau run/sujet",Leak massif de distribution temporelle,"Accuracy test irréaliste, subject §V.1.4 non respecté","Tagger chaque epoch avec (sujet, run) et vérifier la séparation","Utiliser GroupKFold par sujet ou (sujet, run)",Appliquer la détection décrite et vérifier la disparition du symptôme,5,3,Must,à faire
TPV-694,Events & labels,Labels manquants,Certaines epochs créées sans label associé (NaN ou placeholder),Mauvaise jointure entre events et structure de labels,Exceptions intermittentes ou drop silencieux de données,Distribution des labels ne correspond plus au dataset brut,Chercher NaN dans y et dans la metadata associée aux epochs,"Interdire NaN dans y, imposer un mapping exhaustif",Appliquer la détection décrite et vérifier la disparition du symptôme,5,3,Must,à faire
TPV-695,Feature engineering,PSD / spectre,Utilisation d’une fenêtre de Hann inadaptée à la longueur d’epoch,Copie de paramètres par défaut sans vérifier durée d’epoch,Résolution fréquentielle trop grossière pour 8–40 Hz,"Perte de finesse sur bandes mu/beta, patterns lissés",Comparer résolution en Hz = fs / n_fft,Adapter n_fft pour obtenir une résolution suffisante dans 8–40 Hz,Appliquer la détection décrite et vérifier la disparition du symptôme,5,3,Must,à faire
TPV-696,Feature engineering,PSD / spectre,"Mélange des axes (freq, channel) dans le flatten final",np.reshape(-1) sans convention explicite,Impossible de retrouver quelles features appartiennent à quelles bandes,Difficile de diagnostiquer quelles bandes sont réellement utiles,"Logguer shape avant/ après reshape, documenter l’ordre",Encapsuler reshape dans une fonction dédiée testée,Appliquer la détection décrite et vérifier la disparition du symptôme,5,3,Must,à faire
TPV-697,Feature engineering,Normalisation features,StandardScaler fit sur train+test au lieu de train uniquement,Pipeline monté manuellement hors sklearn.Pipeline,"Leak massif, scores CV trop optimistes",Chute brutale de l’accuracy sur sujet vraiment unseen,"Tracer où est appelé fit du scaler, vérifier sur quels indices",Mettre le scaler dans sklearn.Pipeline complet,Appliquer la détection décrite et vérifier la disparition du symptôme,5,3,Must,à faire
TPV-698,Feature engineering,Sélection de bandes,Choix arbitraire de bandes autres que 8–40 Hz sans justification,Portage d’un autre projet EEG non MI,Suppression de bandes mu/beta critiques,Non-respect checklist 'significative frequencies ~8–40Hz',Comparer PSD moyenne par classe sur [0–80Hz],Restreindre features principales à 8–40 Hz pour MI,Appliquer la détection décrite et vérifier la disparition du symptôme,5,3,Must,à faire
TPV-699,Feature engineering,Réduction trop forte,Agglomération de features par moyennes grossières,Volonté de réduire la dimension avant CSP/PCA,Perte d’information discriminante finement spatiale/fréquentielle,"Modèle sous-paramétré, plateau bas d’accuracy",Analyser variance expliquée par composantes pré-CSP/PCA,Conserver un nombre minimal de features par channel/bande,Appliquer la détection décrite et vérifier la disparition du symptôme,5,3,Must,à faire
TPV-700,Feature engineering,Features inconsistentes train/predict,Logique de construction de X différente entre scripts train et predict,Duplication de code de feature engineering,Shapes identiques mais sémantique différente des features,Comportement différent entre cross_val_score et prédiction temps réel,Comparer numériquement X_train[0] et X_predict sur un même epoch,Factoriser la construction de features dans un module unique,Appliquer la détection décrite et vérifier la disparition du symptôme,5,3,Must,à faire
TPV-701,Feature engineering,Fenêtres glissantes,Pas de contrôle sur le stride des fenêtres glissantes,Choix d’un stride trop petit par rapport à la corrélation temporelle,Nombre massif de fenêtres très redondantes,Leakage temporel et gonflement artificiel des données,Afficher n_windows par epoch et le ratio overlap,Fixer un stride minimal (ex: 50% de la fenêtre),Appliquer la détection décrite et vérifier la disparition du symptôme,5,3,Must,à faire
TPV-702,Feature engineering,Combinaison temps-fréquence,Concaténation brute features temps + fréquence sans normalisation commune,Mélange d’échelles très différentes dans le même vecteur,Classifier dominé par les composantes de plus grande amplitude,Réduction de dimension se focalise sur les mauvaises parties du vecteur,Analyser échelles des deux blocs de features séparément,"Normaliser chaque bloc (temps, freq) avant concaténation",Appliquer la détection décrite et vérifier la disparition du symptôme,5,3,Must,à faire
TPV-703,Feature engineering,Encodage des labels dans les features,Ajout involontaire d’indices de trial ou d’ID subject dans X,Debug feature ajoutée puis oubliée pour le modèle final,"Accuracy proche de 1.0 en cross_val_score, chute sur vrai sujet unseen",Cheat involontaire par fuite d’ID,Vérifier que X ne contient que des transformations du signal EEG brut,Supprimer toute meta non dérivée du signal dans X,Appliquer la détection décrite et vérifier la disparition du symptôme,5,3,Must,à faire
TPV-704,Feature engineering,Augmentation artificielle,Augmentations incohérentes (ex: time-reversal) pour MI,Copie de techniques d’augmentation non adaptées à EEG,Patterns MI inversés physiquement impossibles,Modèle sur-apprend des invariances inexistantes,Analyser sémantique physiologique des augmentations appliquées,Limiter aux augmentations EEG physiquement plausibles,Appliquer la détection décrite et vérifier la disparition du symptôme,5,3,Must,à faire
TPV-705,Feature engineering,Static features,Features identiques pour tous les trials d’un sujet,Erreur d’indexation qui prend toujours la même fenêtre,Accuracy proche d’un random constant,Absence totale de variance dans X pour un sujet,"Vérifier variance par feature et par trial (np.var, axis=0)",Ajouter des assertions sur la variance minimale de X,Appliquer la détection décrite et vérifier la disparition du symptôme,5,3,Must,à faire
TPV-706,Feature engineering,Skew features,Features très fortement asymétriques (longues queues) non transformées,Paramètres ML sensibles à la distribution (LogReg sans regularisation adaptée),Décision boundary dominée par quelques outliers,Instabilité des poids appris d’un run à l’autre,Inspecter histogrammes/log-hist de chaque feature,"Appliquer transformations (log, sqrt) aux features très skewed",Appliquer la détection décrite et vérifier la disparition du symptôme,5,3,Must,à faire
TPV-707,Feature engineering,Mauvaise gestion des NaN dans features,NaN introduits par divisions ou logs sans filtre,Filtrage ou normalisation opérant sur des données vides,Sklearn rejette des samples ou lève des exceptions en fit/predict,Déséquilibre difficile à diagnostiquer dans X,Scanner X pour NaN/inf après chaque étape majeure,Remplacer ou dropper les samples fautifs de manière contrôlée,Appliquer la détection décrite et vérifier la disparition du symptôme,5,3,Must,à faire
TPV-708,Feature engineering,Non reproductibilité des features,Usage de générateurs aléatoires sans seed fixé pour certaines transformations,Initialisation aléatoire dans une étape de features non contrôlée,Différences de X d’un run à l’autre à données identiques,Impossible de reproduire un score donné en défense,Comparer X généré sur deux runs avec les mêmes données,Fixer un random_state global dans toutes les étapes stochastiques,Appliquer la détection décrite et vérifier la disparition du symptôme,5,3,Must,à faire
TPV-709,Feature engineering,Dimension trop élevée pour CPU 42,Explosion du nombre de features (ch×freq×time×windows),Pas de réflexion sur la complexité O(N*d),"Temps de fit prohibitif, voire OOM sur machines 42",Incapacité à terminer cross_val_score dans le temps de la défense,Mesurer temps de fit pour différentes tailles de feature set,Appliquer une pré-sélection de features ou réduction raisonnable,Appliquer la détection décrite et vérifier la disparition du symptôme,5,3,Must,à faire
TPV-710,Réduction dimension,CSP,Whitening ignoré avant calcul des patterns spatiaux,Implémentation CSP incomplète par rapport à la littérature,"Filtres apprennent surtout la covariance globale, peu discriminante","Gains de variance inter-classes faibles, patterns peu interprétables",Comparer implémentation avec une librairie CSP de référence,Ajouter étape de whitening explicite dans le pipeline CSP,Appliquer la détection décrite et vérifier la disparition du symptôme,5,3,Must,à faire
TPV-711,Réduction dimension,CSP,Nombre de filtres CSP fixé trop élevé vs nombre d’epochs,Envie de capturer 'tous les patterns' sans contrainte statistique,"Covariance mal estimée, filtres bruités",Modèle hautement instable d’un split à l’autre,Comparer stability des filtres CSP entre folds de CV,Limiter n_filters à un ratio raisonnable du nombre d’epochs,Appliquer la détection décrite et vérifier la disparition du symptôme,5,3,Must,à faire
TPV-712,Réduction dimension,PCA,"Choix d’un nombre de composantes PCA arbitraire (ex: 2, 3)",Absence de vérification de la variance expliquée,Perte de la majorité de l’information discriminante,CSP/Classifier en aval opère sur un sous-espace trop réduit,Afficher cumulative explained variance ratio,Choisir n_components pour couvrir ex: 95% de la variance,Appliquer la détection décrite et vérifier la disparition du symptôme,5,3,Must,à faire
TPV-713,Réduction dimension,PCA,PCA fit sur train+test au lieu de train uniquement,Mauvaise intégration de PCA hors sklearn.Pipeline,Leak d’information structurelle du test dans le training,Cross_val_score surestime les performances réelles,Vérifier sur quel X est appelé PCA.fit,Mettre PCA dans le Pipeline complet avant le classifier,Appliquer la détection décrite et vérifier la disparition du symptôme,5,3,Must,à faire
TPV-714,Réduction dimension,ICA,Usage d’ICA sans contrôler convergence ni initialisation,Paramètres par défaut inadéquats pour EEG bruité,"Composantes instables, très différentes d’un run à l’autre",Difficile d’interpréter/fiabiliser les features ICA,Comparer les ICs sur plusieurs runs avec le même seed,Fixer random_state et critères de convergence explicites,Appliquer la détection décrite et vérifier la disparition du symptôme,5,3,Must,à faire
TPV-715,Réduction dimension,Réduction custom,Algorithme de réduction maison non testé sur un dataset jouet,Implémentation ad hoc complexe sans baseline de référence,Difficile de repérer les bugs logiques ou mathématiques,Performance erratique par rapport à CSP/PCA standard,Tester l’algo sur un dataset synthétique bien compris,"Comparer aux résultats d’un algo standard (CSP, PCA)",Appliquer la détection décrite et vérifier la disparition du symptôme,5,3,Must,à faire
TPV-716,Réduction dimension,Régularisation covariance,Pas de shrinkage ou régularisation pour matrices mal conditionnées,"Covariance estimée sur peu d’epochs, bruitée","Inversion numérique instable, valeurs propres négatives",Runtime errors ou filtres extrêmement sensibles au bruit,Inspecter condition number des matrices de covariance,Ajouter une régularisation de type shrinkage (ex: alpha*I),Appliquer la détection décrite et vérifier la disparition du symptôme,5,3,Must,à faire
TPV-717,Réduction dimension,Compatibilité avec sklearn,Classe de réduction ne passe pas check_estimator,Interface fit/transform partiellement respectée,Comportement différent selon qu’on utilise ou non Pipeline,Usage dans sklearn.grid_search ou CV difficile,Lancer sklearn.utils.estimator_checks.check_estimator,"Corriger la signature et les attributs (fit, transform, n_features_in_)",Appliquer la détection décrite et vérifier la disparition du symptôme,5,3,Must,à faire
TPV-718,Réduction dimension,Stockage W,W recalculée à chaque prédiction au lieu d’être fixée après entraînement,Confusion entre fit et predict dans l’implémentation,"Pipeline imprévisible, temps réel plus lent que nécessaire",Décisions divergentes entre deux runs sur la même donnée,Tracer un hash de W après fit et le vérifier en predict,Sauvegarder W comme attribut figé après fit,Appliquer la détection décrite et vérifier la disparition du symptôme,5,3,Must,à faire
TPV-719,Réduction dimension,Interprétabilité,Aucune vérification de la topographie des filtres spatiaux,CSP/PCA vus comme 'boîte noire' sans contrôle humain,Filtres incohérents avec la physiologie attendue (ex: canaux frontaux),Doute sur la validité scientifique des patterns appris,Projeter les filtres sur le scalp avec les outils MNE,"Comparer patterns obtenus à la littérature MI (mu/beta, zones motrices)",Appliquer la détection décrite et vérifier la disparition du symptôme,5,3,Must,à faire
TPV-720,Réduction dimension,Empilement de réductions,Combinaison PCA→CSP→PCA sans justification,Empilement successif pour 'améliorer le score',Difficile de comprendre quel bloc fait quoi,Risque de surcompression et de surapprentissage,Analyser l’effet de chaque bloc séparément,Réduire à une chaîne simple (ex: CSP→Classifier) pour baseline,Appliquer la détection décrite et vérifier la disparition du symptôme,5,3,Must,à faire
TPV-721,Réduction dimension,Complexité temporelle,Choix d’un algo de réduction O(d^3) sur des features très hautes dim.,Ignorance du coût des décompositions SVD/eigen,Temps de fit prohibitif dans cross_val_score,Cross_val_score impraticable sur machines 42,Profiler temps de calcul par étape de réduction,Choisir un algo plus léger ou réduire d avant réduction,Appliquer la détection décrite et vérifier la disparition du symptôme,5,3,Must,à faire
TPV-722,Réduction dimension,Dépendance à l’échelle,Réduction sensible à la mise à l’échelle des features (ex: PCA non centrée),Oubli du centrage/mise à l’échelle avant la réduction,Composantes dominées par features au plus grand écart-type,Loss de directions réellement informatives,Vérifier si les données sont centrées avant réduction,Ajouter un scaler approprié avant l’étape de réduction,Appliquer la détection décrite et vérifier la disparition du symptôme,5,3,Must,à faire
TPV-723,Réduction dimension,Validation partielle,Réduction validée uniquement sur un sujet ou un run,Supposition que le comportement sera identique sur tous,Collapse de performance sur d’autres sujets/runs,Surajustement de la réduction à un seul ensemble,Évaluer la même réduction sur plusieurs sujets et runs,Concevoir une validation croisée multi-sujets,Appliquer la détection décrite et vérifier la disparition du symptôme,5,3,Must,à faire
TPV-724,Réduction dimension,Non reproductibilité W,Résultats de réduction différents selon la machine/BLAS,Appui sur des décompositions non déterministes sans seed,"Mêmes données, même code, W différente",Difficile de reproduire un comportement en défense,Comparer W entre plusieurs exécutions sur la même machine,"Fixer autant que possible la chaîne numérique (seed, lib)",Appliquer la détection décrite et vérifier la disparition du symptôme,5,3,Must,à faire
TPV-725,Temps réel,Latence cumulée,Latence totale >2s,Accumulation FFT + PCA + classifier,Prédiction dépasse le temps réel,Non-respect checklist realtime,Profiler chaque étape (time.perf_counter),Pipeline warm-up + optimisation n_fft,"Script mesure: fit puis 100 predicts, latence <2s",5,3,Must,à faire
TPV-726,Temps réel,Warm-up absent,Pas d'appel dummy avant prédiction,JIT numpy/BLAS non initialisé,Premier predict très lent,Spike de latence,Comparer predict#1 vs predict#2,Effectuer warm-up sur un epoch factice,Test: delta predict1/2 <20%,5,3,Must,à faire
TPV-729,Temps réel,No async,Blocage sur I/O EEG,Predict synchrone,Jitter visible,Événements retardés,Tracer timestamps predict,Thread dédié ou pré-buffer,Test: jitter<100ms,5,3,Must,à faire
TPV-730,Temps réel,FFT trop fine,n_fft énorme (4096),Copié d’un autre projet,Temps FFT irrealisable 42,Predict >3s,Profiler FFT seule,Adapter n_fft=fs*1s,Test: FFT<0.5s,5,3,Must,à faire
TPV-731,Temps réel,Scaling absent,Données non normalisées,Valeurs trop grandes,Temps PCA/Classifier élevé,Latence augmente,Inspecter max/min Xstream,Scaler dans pipeline,Test: scaler actif=True,5,3,Must,à faire
TPV-732,Temps réel,PCA hors pipeline,PCA calculée hors Pipeline,Deux étapes séparées,Deux passes compute,Latence doublée,Comparer temps avec pipeline unique,Remettre PCA dans pipeline,Test: predict_time dropped 40%,5,3,Must,à faire
TPV-733,Temps réel,CSP coûteux,n_filters trop haut,20–30 filtres CSP,CSP transform lent,Predict lent,Analyser temps transform CSP,Limiter n_filters 2–6,Test: CSP time<0.3s,5,3,Must,à faire
TPV-734,Temps réel,Pas de cache W,W recalculée,Implémentation incorrecte,Recalcul lourd,Predict oscillant,Logger hash W,Geler W après fit,Test: hash W stable,5,3,Must,à faire
TPV-735,Temps réel,Dérive CPU,Charge fluctuante,Pas de contrôle,Latency variance,Predict instable,Mesurer variance latence,Fixer threads BLAS/OMP,Test: var(predict)<20%,5,3,Must,à faire
TPV-736,Temps réel,Fonction non vectorisée,Boucles Python,Implémentation naïve,Compute lent,Predict>2s,Profiler ligne/ligne,Vectoriser via numpy,"Test: same result, 5× faster",5,3,Must,à faire
TPV-737,Train/Validation/Test,Split sujets,CrossVal leakage,Split epoch-level,Leak inter-runs,Accuracy déraisonnable,Tag subject/run,GroupKFold,Test: run unique/acc drop,5,3,Must,à faire
TPV-738,Train/Validation/Test,Seed fix,Seed non fixé,Variabilité entre runs,Score instable,Impossible reproduire,Comparer deux runs,Fix random_state,Test: diff<5pts,5,3,Must,à faire
TPV-739,Train/Validation/Test,Répartition runs,Runs déséquilibrés,dataset hetero,Train bias sujet riche,Slump sur unseen,Analyser n_runs/class,Équilibrer,Test: acc per-run stable,5,3,Must,à faire
TPV-740,Train/Validation/Test,Normalisation leak,Scaler fit global,Fit Xtrain+Xtest,Leak massif,CV surestimé,Inspecter fit,Scaler in Pipeline,Test: CV baisse attendu,5,3,Must,à faire
TPV-741,Train/Validation/Test,Test multi-exp,1 seule exp testée,Ignorer 5 autres,Mauvaise mean accuracy,Note 42 incorrecte,Boucle sur 6 exp,Moyenne pondérée,Test: avg 6 exp ok,5,3,Must,à faire
TPV-742,Train/Validation/Test,Temporal leak,Trames consécutives,Fenêtres overlap excessif,Leak temporel,CV gonflé,Afficher seq index,No overlap train/test,Test: shuffle gap,5,3,Must,à faire
TPV-743,Train/Validation/Test,Synchronisation y,Décalage X/y,Drop epochs sans y,Label mismatch,Accuracy erratique,"Checker len X,y",Drop synchronisé,Test: asserts,5,3,Must,à faire
TPV-744,Train/Validation/Test,Statistiques invalides,Variance test<train,Split biaisé,Répartition mauvaise,Écart énorme,Montrer stats,Stratified split,Test: var acceptable,5,3,Must,à faire
TPV-745,Robustesse,Pipeline,Double fit,fit appelé 2×,Poids incohérents,CV bruité,Logger appels fit,Remove duplicate fit,Test: fit counter==1,5,3,Must,à faire
TPV-746,Robustesse,Classifier,Hyperparams,Valeurs absurdes,Surcharge compute,Predict lent,Afficher params,Grid sensé,Test: warn if C>1000,5,3,Must,à faire
TPV-747,Robustesse,Preprocessing,Bad montage,Ref manquante,EEG bruité,CSP foire,Inspecter montage,Set montage standard,Test: SNR ↑,5,3,Must,à faire
TPV-748,Robustesse,CLI,Args invalides,subject not int,Crash,Pas de predict,parser strict,Sanity check,Test: bad args fail,5,3,Must,à faire
TPV-749,Robustesse,Datasets,Fichier manquant,Chemin dur,Erreur silencieuse,Training incomplet,Assert file exists,Paths relatifs,Test: missing→fail,5,3,Must,à faire
TPV-750,Temps réel,Fenêtrage glissant,Stride/fenêtrage/overlap mal configurés en streaming temps réel,"Choix d’une fenêtre trop longue ou d’un stride trop faible, sans contrôle du nombre de fenêtres générées","Nombre de fenêtres par seconde très élevé, latence cumulée qui dépasse le temps réel, décisions retardées","Non-respect de la contrainte realtime <2s de la checklist, pipeline inutilisable en conditions réelles","Logguer pour chaque flux le nombre de fenêtres générées par seconde, mesurer le temps de traitement moyen par fenêtre","Fixer une durée de fenêtre cohérente (≈1s) et un stride >=50% de la fenêtre, avec une borne maximale sur le nombre de fenêtres traitées par seconde","Sur une minute de stream simulé, vérifier que le temps total de traitement reste <60s et que la latence par décision reste <2s",5,3,Must,à faire
TPV-751,Réduction dimension,ICA convergence,Convergence ICA non atteinte mais ignorée,Critères de convergence par défaut inadaptés au bruit EEG,Warnings de non-convergence affichés mais non traités,"Composantes ICA aléatoires, instables d’un run à l’autre",Activer les warnings et logger l’état de convergence de l’ICA,"Adapter les paramètres de convergence (max_iter, tol) et vérifier l’état","Test: forcer un max_iter bas, vérifier qu’un test échoue si non-convergence",5,3,Must,à faire
TPV-752,Réduction dimension,ICA convergence,ICA exécutée sur trop peu d’epochs,Peu de données pour estimer correctement les composantes indépendantes,Composantes dominées par le bruit ou un seul trial,Difficulté à séparer artefacts EOG/EMG du signal MI,Vérifier n_epochs utilisés pour l’ICA et le rapport n_channels/n_epochs,Imposer un minimum d’epochs ou augmenter la fenêtre de données,Test: échouer si n_epochs < seuil (ex: 20×n_channels),5,3,Must,à faire
TPV-753,Réduction dimension,ICA convergence,Initialisation ICA non contrôlée (seed aléatoire),Résultats fortement dépendants de l’initialisation,Différences marquées de performance entre deux runs identiques,Difficile de reproduire exactement un score en défense,Fixer random_state pour l’estimateur ICA,Documenter l’impact de l’initialisation sur les ICs et l’accuracy,Test: comparer l’accuracy sur 5 runs avec et sans seed fixé,5,3,Must,à faire
TPV-754,Réduction dimension,ICA convergence,Suppression trop agressive de composantes ICA,Rejet de nombreuses ICs sans vérification de leur nature,Perte de composantes réellement informatives pour MI,Dégradation des scores de classification post-ICA,"Inspecter les ICs marquées pour rejet (topos, time-courses)",Limiter le rejet aux ICs clairement artefactuelles (EOG/EMG),Test: comparer accuracy avec rejet conservateur vs agressif,5,3,Must,à faire
TPV-755,Réduction dimension,ICA convergence,Application d’ICA sur des données déjà filtrées très étroitement,Bande-passante trop réduite avant identification des ICs,"Difficulté à séparer certaines sources, ICs corrélées","Peu de gain en SNR malgré ICA, complexité inutile",Comparer ICA sur données filtrées large vs étroit,Appliquer ICA sur une bande plus large avant resserrage fréquentiel,Test: mesurer le gain de SNR ou d’accuracy avec les deux stratégies,5,3,Must,à faire
TPV-756,Filtrage,Edge effects,Ignorance totale des effets de bord des filtres FIR/IIR,Application du filtrage sans padding ni trim des bords,Oscillations artificielles visibles au début/fin des epochs,Features temps/fréquence biaisées sur les premières/dernières centaines de ms,Comparer signaux bruts vs filtrés en zoomant sur les bords d’epoch,Utiliser les options de padding MNE appropriées et tronquer les bords,Test: vérifier par script que la zone d’analyse exclut les n premiers/derniers samples filtrés,5,3,Must,à faire
TPV-757,Filtrage,Edge effects,Incohérence des effets de bord entre train et prédiction temps réel,Filtrage offline avec padding différent du filtrage online,Différences systématiques de phase ou d’amplitude au début des fenêtres,Modèle entraîné sur des signaux filtrés différemment de ceux du stream,Comparer réponse impulsionnelle du filtre offline vs online,Aligner la configuration de filtrage entre mode batch et mode streaming,Test: appliquer filtre sur un même signal en offline/online et comparer l’erreur max,5,3,Must,à faire
TPV-758,Temps réel,Latence prédiction,Latence moyenne de prédiction >= 2.0 s sur stream simulé,Accumulation de coûts FFT/réduction/classif sans contrôle de borne temporelle,Temps entre event et décision observé comme > 2.0 s sur plusieurs essais,"Non-respect explicite de la contrainte realtime de la checklist, système inutilisable",Instrumenter le pipeline et mesurer le temps de N prédictions consécutives,"Optimiser n_fft, nombre de features et complexité du classif pour tenir < 2.0 s","Script benchmark: sur 100 fenêtres consécutives, vérifier latence moyenne < 2.0 s et max < 2.2 s",5,3,Must,à faire
TPV-759,Train/Validation/Test,Stabilité cross_val_score,Variance de cross_val_score > 0.10 entre folds,Pipeline hyper-sensible au split (data trop petite ou sur-apprentissage),"Scores par fold très dispersés, écart type élevé",Difficile d’estimer une performance moyenne fiable sur les 6 expériences,Logguer les scores individuels de cross_val_score sur K folds,Ajuster complexité du modèle et taille des features pour réduire la variance,Test: assert np.var(scores) <= 0.10 pour un Kfold typique sur le dataset MI,5,3,Must,à faire
TPV-760,Réduction dimension,Variance expliquée PCA,PCA conserve moins de 95% de la variance globale,Choix arbitraire de n_components sans inspection de explained_variance_ratio_,"Perte de directions informatives, baisse d’accuracy non comprise",Modèle sous-performant malgré prétraitement avancé,Afficher cumulative explained_variance_ratio_ du PCA,Choisir n_components tel que la variance expliquée cumulative >= 0.95,Test: vérifier par script que la somme des premières composantes retenues >= 0.95,5,3,Must,à faire
TPV-761,Feature engineering,SNR des features spectrales,SNR moyen des bandes mu/bêta < 3 dB,Filtrage ou fenêtrage qui laisse trop de bruit large bande,PSD par classe quasi confondue avec le bruit de fond,Difficile pour CSP/classif de distinguer les états MI,Estimer SNR (signal vs baseline) sur bandes 8–13 Hz et 13–30 Hz,"Adapter filtrage, ICA et rejet de trials pour obtenir un SNR >= 3 dB",Test: calculer SNR moyen sur un sous-ensemble et vérifier qu’il dépasse 3 dB,5,3,Must,à faire
TPV-762,Filtrage,Amplitude effets de bord,Amplitude des oscillations de bord > 10% de l’amplitude moyenne de l’epoch,Filtres FIR/IIR utilisés sans trim suffisant des n premiers/derniers samples,Pics artificiels visibles au début/fin des signaux filtrés,Features temporelles/fréquentielles biaisées aux bords d’epoch,Mesurer l’amplitude max des 100 premiers/derniers samples vs zone centrale,Tronquer systématiquement les n premiers/derniers samples des epochs analysés,Test: ratio amplitude_bords / amplitude_centre <= 0.10 sur un panel d’epochs,5,3,Must,à faire
TPV-763,Réduction dimension,Critère numérique ICA,Norme du résidu de reconstruction ICA > seuil toléré,ICA conservée même si la reconstruction du signal est médiocre,Différence importante entre signal brut et recomposé par ICA,Artefacts résiduels forts malgré passage par ICA,Calculer la norme de l’erreur entre signal original et signal reconstruit par ICA,Régler tol/max_iter jusqu’à obtenir un résidu sous un seuil acceptable,Test: imposer un seuil (ex: ||x - x_recon||_2 / ||x||_2 < 0.05) et échouer si dépassé,5,3,Must,à faire
TPV-764,Temps réel,Jitter de latence,Écart type de la latence de prédiction > 0.5 s,Charge CPU variable ou gestion non déterministe de la file de fenêtres,Latence très fluctuante d’un appel predict à l’autre,"Expérience utilisateur incohérente, difficile à calibrer en temps réel",Mesurer la latence de N prédictions et calculer moyenne et écart type,"Stabiliser les ressources (threads BLAS, taille des batchs) pour réduire le jitter","Test: sur 100 prédictions, vérifier que std(latences) <= 0.5 s",5,3,Must,à faire
