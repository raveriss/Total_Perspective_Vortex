"""Feature extraction utilities for EEG signals."""

# Importe les annotations pour clarifier la signature des fonctions
# Importe Any pour typer la configuration dynamique des fonctions
from typing import Any, Dict, Iterable, List, Mapping, Sequence, Tuple, cast

# Importe NumPy pour manipuler les tenseurs spectraux et tabulaires
import numpy as np

# Importe scipy.signal pour accéder à l'estimateur de Welch et à la CWT
from scipy import signal

# Importe BaseEstimator et TransformerMixin pour conserver la compatibilité scikit-learn
from sklearn.base import BaseEstimator, TransformerMixin
from inspect import signature as _mutmut_signature
from typing import Annotated
from typing import Callable
from typing import ClassVar


MutantDict = Annotated[dict[str, Callable], "Mutant"]


def _mutmut_trampoline(orig, mutants, call_args, call_kwargs, self_arg = None):
    """Forward call to original or mutated function, depending on the environment"""
    import os
    mutant_under_test = os.environ['MUTANT_UNDER_TEST']
    if mutant_under_test == 'fail':
        from mutmut.__main__ import MutmutProgrammaticFailException
        raise MutmutProgrammaticFailException('Failed programmatically')      
    elif mutant_under_test == 'stats':
        from mutmut.__main__ import record_trampoline_hit
        record_trampoline_hit(orig.__module__ + '.' + orig.__name__)
        result = orig(*call_args, **call_kwargs)
        return result
    prefix = orig.__module__ + '.' + orig.__name__ + '__mutmut_'
    if not mutant_under_test.startswith(prefix):
        result = orig(*call_args, **call_kwargs)
        return result
    mutant_name = mutant_under_test.rpartition('.')[-1]
    if self_arg is not None:
        # call to a class method where self is not bound
        result = mutants[mutant_name](self_arg, *call_args, **call_kwargs)
    else:
        result = mutants[mutant_name](*call_args, **call_kwargs)
    return result


def x__resolve_band_ranges__mutmut_orig(
    config: Mapping[str, Any], default_bands: Mapping[str, Tuple[float, float]]
) -> Dict[str, Tuple[float, float]]:
    """Retourne les bandes explicites en préservant l'ordre demandé."""

    # Fusionne les bandes personnalisées pour respecter l'ordre d'entrée
    return dict(config.get("bands", default_bands))


def x__resolve_band_ranges__mutmut_1(
    config: Mapping[str, Any], default_bands: Mapping[str, Tuple[float, float]]
) -> Dict[str, Tuple[float, float]]:
    """Retourne les bandes explicites en préservant l'ordre demandé."""

    # Fusionne les bandes personnalisées pour respecter l'ordre d'entrée
    return dict(None)


def x__resolve_band_ranges__mutmut_2(
    config: Mapping[str, Any], default_bands: Mapping[str, Tuple[float, float]]
) -> Dict[str, Tuple[float, float]]:
    """Retourne les bandes explicites en préservant l'ordre demandé."""

    # Fusionne les bandes personnalisées pour respecter l'ordre d'entrée
    return dict(config.get(None, default_bands))


def x__resolve_band_ranges__mutmut_3(
    config: Mapping[str, Any], default_bands: Mapping[str, Tuple[float, float]]
) -> Dict[str, Tuple[float, float]]:
    """Retourne les bandes explicites en préservant l'ordre demandé."""

    # Fusionne les bandes personnalisées pour respecter l'ordre d'entrée
    return dict(config.get("bands", None))


def x__resolve_band_ranges__mutmut_4(
    config: Mapping[str, Any], default_bands: Mapping[str, Tuple[float, float]]
) -> Dict[str, Tuple[float, float]]:
    """Retourne les bandes explicites en préservant l'ordre demandé."""

    # Fusionne les bandes personnalisées pour respecter l'ordre d'entrée
    return dict(config.get(default_bands))


def x__resolve_band_ranges__mutmut_5(
    config: Mapping[str, Any], default_bands: Mapping[str, Tuple[float, float]]
) -> Dict[str, Tuple[float, float]]:
    """Retourne les bandes explicites en préservant l'ordre demandé."""

    # Fusionne les bandes personnalisées pour respecter l'ordre d'entrée
    return dict(config.get("bands", ))


def x__resolve_band_ranges__mutmut_6(
    config: Mapping[str, Any], default_bands: Mapping[str, Tuple[float, float]]
) -> Dict[str, Tuple[float, float]]:
    """Retourne les bandes explicites en préservant l'ordre demandé."""

    # Fusionne les bandes personnalisées pour respecter l'ordre d'entrée
    return dict(config.get("XXbandsXX", default_bands))


def x__resolve_band_ranges__mutmut_7(
    config: Mapping[str, Any], default_bands: Mapping[str, Tuple[float, float]]
) -> Dict[str, Tuple[float, float]]:
    """Retourne les bandes explicites en préservant l'ordre demandé."""

    # Fusionne les bandes personnalisées pour respecter l'ordre d'entrée
    return dict(config.get("BANDS", default_bands))

x__resolve_band_ranges__mutmut_mutants : ClassVar[MutantDict] = {
'x__resolve_band_ranges__mutmut_1': x__resolve_band_ranges__mutmut_1, 
    'x__resolve_band_ranges__mutmut_2': x__resolve_band_ranges__mutmut_2, 
    'x__resolve_band_ranges__mutmut_3': x__resolve_band_ranges__mutmut_3, 
    'x__resolve_band_ranges__mutmut_4': x__resolve_band_ranges__mutmut_4, 
    'x__resolve_band_ranges__mutmut_5': x__resolve_band_ranges__mutmut_5, 
    'x__resolve_band_ranges__mutmut_6': x__resolve_band_ranges__mutmut_6, 
    'x__resolve_band_ranges__mutmut_7': x__resolve_band_ranges__mutmut_7
}

def _resolve_band_ranges(*args, **kwargs):
    result = _mutmut_trampoline(x__resolve_band_ranges__mutmut_orig, x__resolve_band_ranges__mutmut_mutants, args, kwargs)
    return result 

_resolve_band_ranges.__signature__ = _mutmut_signature(x__resolve_band_ranges__mutmut_orig)
x__resolve_band_ranges__mutmut_orig.__name__ = 'x__resolve_band_ranges'


def x__prepare_welch_parameters__mutmut_orig(
    config: Mapping[str, Any], n_times: int
) -> Tuple[str | Iterable[float], int, int | None, str, str]:
    """Calcule des paramètres Welch bornés pour éviter les avertissements."""

    # Applique une fenêtre lisse pour limiter les fuites fréquentielles
    window: str | Iterable[float] = _validate_welch_window(config.get("window", "hann"))
    # Permet d'ajuster la taille de segment pour contrôler la résolution
    effective_nperseg = _sanitize_nperseg(config.get("nperseg"), n_times)
    # Offre un recouvrement configurable pour stabiliser l'estimation
    effective_noverlap = _sanitize_noverlap(
        config.get("noverlap"), effective_nperseg=effective_nperseg
    )
    # Permet de choisir la stratégie d'agrégation des segments
    average: str = config.get("average", "mean")
    # Permet de choisir la densité ou la puissance intégrée
    scaling: str = config.get("scaling", "density")
    # Regroupe les paramètres bornés pour l'appel Welch
    return window, effective_nperseg, effective_noverlap, average, scaling


def x__prepare_welch_parameters__mutmut_1(
    config: Mapping[str, Any], n_times: int
) -> Tuple[str | Iterable[float], int, int | None, str, str]:
    """Calcule des paramètres Welch bornés pour éviter les avertissements."""

    # Applique une fenêtre lisse pour limiter les fuites fréquentielles
    window: str | Iterable[float] = None
    # Permet d'ajuster la taille de segment pour contrôler la résolution
    effective_nperseg = _sanitize_nperseg(config.get("nperseg"), n_times)
    # Offre un recouvrement configurable pour stabiliser l'estimation
    effective_noverlap = _sanitize_noverlap(
        config.get("noverlap"), effective_nperseg=effective_nperseg
    )
    # Permet de choisir la stratégie d'agrégation des segments
    average: str = config.get("average", "mean")
    # Permet de choisir la densité ou la puissance intégrée
    scaling: str = config.get("scaling", "density")
    # Regroupe les paramètres bornés pour l'appel Welch
    return window, effective_nperseg, effective_noverlap, average, scaling


def x__prepare_welch_parameters__mutmut_2(
    config: Mapping[str, Any], n_times: int
) -> Tuple[str | Iterable[float], int, int | None, str, str]:
    """Calcule des paramètres Welch bornés pour éviter les avertissements."""

    # Applique une fenêtre lisse pour limiter les fuites fréquentielles
    window: str | Iterable[float] = _validate_welch_window(None)
    # Permet d'ajuster la taille de segment pour contrôler la résolution
    effective_nperseg = _sanitize_nperseg(config.get("nperseg"), n_times)
    # Offre un recouvrement configurable pour stabiliser l'estimation
    effective_noverlap = _sanitize_noverlap(
        config.get("noverlap"), effective_nperseg=effective_nperseg
    )
    # Permet de choisir la stratégie d'agrégation des segments
    average: str = config.get("average", "mean")
    # Permet de choisir la densité ou la puissance intégrée
    scaling: str = config.get("scaling", "density")
    # Regroupe les paramètres bornés pour l'appel Welch
    return window, effective_nperseg, effective_noverlap, average, scaling


def x__prepare_welch_parameters__mutmut_3(
    config: Mapping[str, Any], n_times: int
) -> Tuple[str | Iterable[float], int, int | None, str, str]:
    """Calcule des paramètres Welch bornés pour éviter les avertissements."""

    # Applique une fenêtre lisse pour limiter les fuites fréquentielles
    window: str | Iterable[float] = _validate_welch_window(config.get(None, "hann"))
    # Permet d'ajuster la taille de segment pour contrôler la résolution
    effective_nperseg = _sanitize_nperseg(config.get("nperseg"), n_times)
    # Offre un recouvrement configurable pour stabiliser l'estimation
    effective_noverlap = _sanitize_noverlap(
        config.get("noverlap"), effective_nperseg=effective_nperseg
    )
    # Permet de choisir la stratégie d'agrégation des segments
    average: str = config.get("average", "mean")
    # Permet de choisir la densité ou la puissance intégrée
    scaling: str = config.get("scaling", "density")
    # Regroupe les paramètres bornés pour l'appel Welch
    return window, effective_nperseg, effective_noverlap, average, scaling


def x__prepare_welch_parameters__mutmut_4(
    config: Mapping[str, Any], n_times: int
) -> Tuple[str | Iterable[float], int, int | None, str, str]:
    """Calcule des paramètres Welch bornés pour éviter les avertissements."""

    # Applique une fenêtre lisse pour limiter les fuites fréquentielles
    window: str | Iterable[float] = _validate_welch_window(config.get("window", None))
    # Permet d'ajuster la taille de segment pour contrôler la résolution
    effective_nperseg = _sanitize_nperseg(config.get("nperseg"), n_times)
    # Offre un recouvrement configurable pour stabiliser l'estimation
    effective_noverlap = _sanitize_noverlap(
        config.get("noverlap"), effective_nperseg=effective_nperseg
    )
    # Permet de choisir la stratégie d'agrégation des segments
    average: str = config.get("average", "mean")
    # Permet de choisir la densité ou la puissance intégrée
    scaling: str = config.get("scaling", "density")
    # Regroupe les paramètres bornés pour l'appel Welch
    return window, effective_nperseg, effective_noverlap, average, scaling


def x__prepare_welch_parameters__mutmut_5(
    config: Mapping[str, Any], n_times: int
) -> Tuple[str | Iterable[float], int, int | None, str, str]:
    """Calcule des paramètres Welch bornés pour éviter les avertissements."""

    # Applique une fenêtre lisse pour limiter les fuites fréquentielles
    window: str | Iterable[float] = _validate_welch_window(config.get("hann"))
    # Permet d'ajuster la taille de segment pour contrôler la résolution
    effective_nperseg = _sanitize_nperseg(config.get("nperseg"), n_times)
    # Offre un recouvrement configurable pour stabiliser l'estimation
    effective_noverlap = _sanitize_noverlap(
        config.get("noverlap"), effective_nperseg=effective_nperseg
    )
    # Permet de choisir la stratégie d'agrégation des segments
    average: str = config.get("average", "mean")
    # Permet de choisir la densité ou la puissance intégrée
    scaling: str = config.get("scaling", "density")
    # Regroupe les paramètres bornés pour l'appel Welch
    return window, effective_nperseg, effective_noverlap, average, scaling


def x__prepare_welch_parameters__mutmut_6(
    config: Mapping[str, Any], n_times: int
) -> Tuple[str | Iterable[float], int, int | None, str, str]:
    """Calcule des paramètres Welch bornés pour éviter les avertissements."""

    # Applique une fenêtre lisse pour limiter les fuites fréquentielles
    window: str | Iterable[float] = _validate_welch_window(config.get("window", ))
    # Permet d'ajuster la taille de segment pour contrôler la résolution
    effective_nperseg = _sanitize_nperseg(config.get("nperseg"), n_times)
    # Offre un recouvrement configurable pour stabiliser l'estimation
    effective_noverlap = _sanitize_noverlap(
        config.get("noverlap"), effective_nperseg=effective_nperseg
    )
    # Permet de choisir la stratégie d'agrégation des segments
    average: str = config.get("average", "mean")
    # Permet de choisir la densité ou la puissance intégrée
    scaling: str = config.get("scaling", "density")
    # Regroupe les paramètres bornés pour l'appel Welch
    return window, effective_nperseg, effective_noverlap, average, scaling


def x__prepare_welch_parameters__mutmut_7(
    config: Mapping[str, Any], n_times: int
) -> Tuple[str | Iterable[float], int, int | None, str, str]:
    """Calcule des paramètres Welch bornés pour éviter les avertissements."""

    # Applique une fenêtre lisse pour limiter les fuites fréquentielles
    window: str | Iterable[float] = _validate_welch_window(config.get("XXwindowXX", "hann"))
    # Permet d'ajuster la taille de segment pour contrôler la résolution
    effective_nperseg = _sanitize_nperseg(config.get("nperseg"), n_times)
    # Offre un recouvrement configurable pour stabiliser l'estimation
    effective_noverlap = _sanitize_noverlap(
        config.get("noverlap"), effective_nperseg=effective_nperseg
    )
    # Permet de choisir la stratégie d'agrégation des segments
    average: str = config.get("average", "mean")
    # Permet de choisir la densité ou la puissance intégrée
    scaling: str = config.get("scaling", "density")
    # Regroupe les paramètres bornés pour l'appel Welch
    return window, effective_nperseg, effective_noverlap, average, scaling


def x__prepare_welch_parameters__mutmut_8(
    config: Mapping[str, Any], n_times: int
) -> Tuple[str | Iterable[float], int, int | None, str, str]:
    """Calcule des paramètres Welch bornés pour éviter les avertissements."""

    # Applique une fenêtre lisse pour limiter les fuites fréquentielles
    window: str | Iterable[float] = _validate_welch_window(config.get("WINDOW", "hann"))
    # Permet d'ajuster la taille de segment pour contrôler la résolution
    effective_nperseg = _sanitize_nperseg(config.get("nperseg"), n_times)
    # Offre un recouvrement configurable pour stabiliser l'estimation
    effective_noverlap = _sanitize_noverlap(
        config.get("noverlap"), effective_nperseg=effective_nperseg
    )
    # Permet de choisir la stratégie d'agrégation des segments
    average: str = config.get("average", "mean")
    # Permet de choisir la densité ou la puissance intégrée
    scaling: str = config.get("scaling", "density")
    # Regroupe les paramètres bornés pour l'appel Welch
    return window, effective_nperseg, effective_noverlap, average, scaling


def x__prepare_welch_parameters__mutmut_9(
    config: Mapping[str, Any], n_times: int
) -> Tuple[str | Iterable[float], int, int | None, str, str]:
    """Calcule des paramètres Welch bornés pour éviter les avertissements."""

    # Applique une fenêtre lisse pour limiter les fuites fréquentielles
    window: str | Iterable[float] = _validate_welch_window(config.get("window", "XXhannXX"))
    # Permet d'ajuster la taille de segment pour contrôler la résolution
    effective_nperseg = _sanitize_nperseg(config.get("nperseg"), n_times)
    # Offre un recouvrement configurable pour stabiliser l'estimation
    effective_noverlap = _sanitize_noverlap(
        config.get("noverlap"), effective_nperseg=effective_nperseg
    )
    # Permet de choisir la stratégie d'agrégation des segments
    average: str = config.get("average", "mean")
    # Permet de choisir la densité ou la puissance intégrée
    scaling: str = config.get("scaling", "density")
    # Regroupe les paramètres bornés pour l'appel Welch
    return window, effective_nperseg, effective_noverlap, average, scaling


def x__prepare_welch_parameters__mutmut_10(
    config: Mapping[str, Any], n_times: int
) -> Tuple[str | Iterable[float], int, int | None, str, str]:
    """Calcule des paramètres Welch bornés pour éviter les avertissements."""

    # Applique une fenêtre lisse pour limiter les fuites fréquentielles
    window: str | Iterable[float] = _validate_welch_window(config.get("window", "HANN"))
    # Permet d'ajuster la taille de segment pour contrôler la résolution
    effective_nperseg = _sanitize_nperseg(config.get("nperseg"), n_times)
    # Offre un recouvrement configurable pour stabiliser l'estimation
    effective_noverlap = _sanitize_noverlap(
        config.get("noverlap"), effective_nperseg=effective_nperseg
    )
    # Permet de choisir la stratégie d'agrégation des segments
    average: str = config.get("average", "mean")
    # Permet de choisir la densité ou la puissance intégrée
    scaling: str = config.get("scaling", "density")
    # Regroupe les paramètres bornés pour l'appel Welch
    return window, effective_nperseg, effective_noverlap, average, scaling


def x__prepare_welch_parameters__mutmut_11(
    config: Mapping[str, Any], n_times: int
) -> Tuple[str | Iterable[float], int, int | None, str, str]:
    """Calcule des paramètres Welch bornés pour éviter les avertissements."""

    # Applique une fenêtre lisse pour limiter les fuites fréquentielles
    window: str | Iterable[float] = _validate_welch_window(config.get("window", "hann"))
    # Permet d'ajuster la taille de segment pour contrôler la résolution
    effective_nperseg = None
    # Offre un recouvrement configurable pour stabiliser l'estimation
    effective_noverlap = _sanitize_noverlap(
        config.get("noverlap"), effective_nperseg=effective_nperseg
    )
    # Permet de choisir la stratégie d'agrégation des segments
    average: str = config.get("average", "mean")
    # Permet de choisir la densité ou la puissance intégrée
    scaling: str = config.get("scaling", "density")
    # Regroupe les paramètres bornés pour l'appel Welch
    return window, effective_nperseg, effective_noverlap, average, scaling


def x__prepare_welch_parameters__mutmut_12(
    config: Mapping[str, Any], n_times: int
) -> Tuple[str | Iterable[float], int, int | None, str, str]:
    """Calcule des paramètres Welch bornés pour éviter les avertissements."""

    # Applique une fenêtre lisse pour limiter les fuites fréquentielles
    window: str | Iterable[float] = _validate_welch_window(config.get("window", "hann"))
    # Permet d'ajuster la taille de segment pour contrôler la résolution
    effective_nperseg = _sanitize_nperseg(None, n_times)
    # Offre un recouvrement configurable pour stabiliser l'estimation
    effective_noverlap = _sanitize_noverlap(
        config.get("noverlap"), effective_nperseg=effective_nperseg
    )
    # Permet de choisir la stratégie d'agrégation des segments
    average: str = config.get("average", "mean")
    # Permet de choisir la densité ou la puissance intégrée
    scaling: str = config.get("scaling", "density")
    # Regroupe les paramètres bornés pour l'appel Welch
    return window, effective_nperseg, effective_noverlap, average, scaling


def x__prepare_welch_parameters__mutmut_13(
    config: Mapping[str, Any], n_times: int
) -> Tuple[str | Iterable[float], int, int | None, str, str]:
    """Calcule des paramètres Welch bornés pour éviter les avertissements."""

    # Applique une fenêtre lisse pour limiter les fuites fréquentielles
    window: str | Iterable[float] = _validate_welch_window(config.get("window", "hann"))
    # Permet d'ajuster la taille de segment pour contrôler la résolution
    effective_nperseg = _sanitize_nperseg(config.get("nperseg"), None)
    # Offre un recouvrement configurable pour stabiliser l'estimation
    effective_noverlap = _sanitize_noverlap(
        config.get("noverlap"), effective_nperseg=effective_nperseg
    )
    # Permet de choisir la stratégie d'agrégation des segments
    average: str = config.get("average", "mean")
    # Permet de choisir la densité ou la puissance intégrée
    scaling: str = config.get("scaling", "density")
    # Regroupe les paramètres bornés pour l'appel Welch
    return window, effective_nperseg, effective_noverlap, average, scaling


def x__prepare_welch_parameters__mutmut_14(
    config: Mapping[str, Any], n_times: int
) -> Tuple[str | Iterable[float], int, int | None, str, str]:
    """Calcule des paramètres Welch bornés pour éviter les avertissements."""

    # Applique une fenêtre lisse pour limiter les fuites fréquentielles
    window: str | Iterable[float] = _validate_welch_window(config.get("window", "hann"))
    # Permet d'ajuster la taille de segment pour contrôler la résolution
    effective_nperseg = _sanitize_nperseg(n_times)
    # Offre un recouvrement configurable pour stabiliser l'estimation
    effective_noverlap = _sanitize_noverlap(
        config.get("noverlap"), effective_nperseg=effective_nperseg
    )
    # Permet de choisir la stratégie d'agrégation des segments
    average: str = config.get("average", "mean")
    # Permet de choisir la densité ou la puissance intégrée
    scaling: str = config.get("scaling", "density")
    # Regroupe les paramètres bornés pour l'appel Welch
    return window, effective_nperseg, effective_noverlap, average, scaling


def x__prepare_welch_parameters__mutmut_15(
    config: Mapping[str, Any], n_times: int
) -> Tuple[str | Iterable[float], int, int | None, str, str]:
    """Calcule des paramètres Welch bornés pour éviter les avertissements."""

    # Applique une fenêtre lisse pour limiter les fuites fréquentielles
    window: str | Iterable[float] = _validate_welch_window(config.get("window", "hann"))
    # Permet d'ajuster la taille de segment pour contrôler la résolution
    effective_nperseg = _sanitize_nperseg(config.get("nperseg"), )
    # Offre un recouvrement configurable pour stabiliser l'estimation
    effective_noverlap = _sanitize_noverlap(
        config.get("noverlap"), effective_nperseg=effective_nperseg
    )
    # Permet de choisir la stratégie d'agrégation des segments
    average: str = config.get("average", "mean")
    # Permet de choisir la densité ou la puissance intégrée
    scaling: str = config.get("scaling", "density")
    # Regroupe les paramètres bornés pour l'appel Welch
    return window, effective_nperseg, effective_noverlap, average, scaling


def x__prepare_welch_parameters__mutmut_16(
    config: Mapping[str, Any], n_times: int
) -> Tuple[str | Iterable[float], int, int | None, str, str]:
    """Calcule des paramètres Welch bornés pour éviter les avertissements."""

    # Applique une fenêtre lisse pour limiter les fuites fréquentielles
    window: str | Iterable[float] = _validate_welch_window(config.get("window", "hann"))
    # Permet d'ajuster la taille de segment pour contrôler la résolution
    effective_nperseg = _sanitize_nperseg(config.get(None), n_times)
    # Offre un recouvrement configurable pour stabiliser l'estimation
    effective_noverlap = _sanitize_noverlap(
        config.get("noverlap"), effective_nperseg=effective_nperseg
    )
    # Permet de choisir la stratégie d'agrégation des segments
    average: str = config.get("average", "mean")
    # Permet de choisir la densité ou la puissance intégrée
    scaling: str = config.get("scaling", "density")
    # Regroupe les paramètres bornés pour l'appel Welch
    return window, effective_nperseg, effective_noverlap, average, scaling


def x__prepare_welch_parameters__mutmut_17(
    config: Mapping[str, Any], n_times: int
) -> Tuple[str | Iterable[float], int, int | None, str, str]:
    """Calcule des paramètres Welch bornés pour éviter les avertissements."""

    # Applique une fenêtre lisse pour limiter les fuites fréquentielles
    window: str | Iterable[float] = _validate_welch_window(config.get("window", "hann"))
    # Permet d'ajuster la taille de segment pour contrôler la résolution
    effective_nperseg = _sanitize_nperseg(config.get("XXnpersegXX"), n_times)
    # Offre un recouvrement configurable pour stabiliser l'estimation
    effective_noverlap = _sanitize_noverlap(
        config.get("noverlap"), effective_nperseg=effective_nperseg
    )
    # Permet de choisir la stratégie d'agrégation des segments
    average: str = config.get("average", "mean")
    # Permet de choisir la densité ou la puissance intégrée
    scaling: str = config.get("scaling", "density")
    # Regroupe les paramètres bornés pour l'appel Welch
    return window, effective_nperseg, effective_noverlap, average, scaling


def x__prepare_welch_parameters__mutmut_18(
    config: Mapping[str, Any], n_times: int
) -> Tuple[str | Iterable[float], int, int | None, str, str]:
    """Calcule des paramètres Welch bornés pour éviter les avertissements."""

    # Applique une fenêtre lisse pour limiter les fuites fréquentielles
    window: str | Iterable[float] = _validate_welch_window(config.get("window", "hann"))
    # Permet d'ajuster la taille de segment pour contrôler la résolution
    effective_nperseg = _sanitize_nperseg(config.get("NPERSEG"), n_times)
    # Offre un recouvrement configurable pour stabiliser l'estimation
    effective_noverlap = _sanitize_noverlap(
        config.get("noverlap"), effective_nperseg=effective_nperseg
    )
    # Permet de choisir la stratégie d'agrégation des segments
    average: str = config.get("average", "mean")
    # Permet de choisir la densité ou la puissance intégrée
    scaling: str = config.get("scaling", "density")
    # Regroupe les paramètres bornés pour l'appel Welch
    return window, effective_nperseg, effective_noverlap, average, scaling


def x__prepare_welch_parameters__mutmut_19(
    config: Mapping[str, Any], n_times: int
) -> Tuple[str | Iterable[float], int, int | None, str, str]:
    """Calcule des paramètres Welch bornés pour éviter les avertissements."""

    # Applique une fenêtre lisse pour limiter les fuites fréquentielles
    window: str | Iterable[float] = _validate_welch_window(config.get("window", "hann"))
    # Permet d'ajuster la taille de segment pour contrôler la résolution
    effective_nperseg = _sanitize_nperseg(config.get("nperseg"), n_times)
    # Offre un recouvrement configurable pour stabiliser l'estimation
    effective_noverlap = None
    # Permet de choisir la stratégie d'agrégation des segments
    average: str = config.get("average", "mean")
    # Permet de choisir la densité ou la puissance intégrée
    scaling: str = config.get("scaling", "density")
    # Regroupe les paramètres bornés pour l'appel Welch
    return window, effective_nperseg, effective_noverlap, average, scaling


def x__prepare_welch_parameters__mutmut_20(
    config: Mapping[str, Any], n_times: int
) -> Tuple[str | Iterable[float], int, int | None, str, str]:
    """Calcule des paramètres Welch bornés pour éviter les avertissements."""

    # Applique une fenêtre lisse pour limiter les fuites fréquentielles
    window: str | Iterable[float] = _validate_welch_window(config.get("window", "hann"))
    # Permet d'ajuster la taille de segment pour contrôler la résolution
    effective_nperseg = _sanitize_nperseg(config.get("nperseg"), n_times)
    # Offre un recouvrement configurable pour stabiliser l'estimation
    effective_noverlap = _sanitize_noverlap(
        None, effective_nperseg=effective_nperseg
    )
    # Permet de choisir la stratégie d'agrégation des segments
    average: str = config.get("average", "mean")
    # Permet de choisir la densité ou la puissance intégrée
    scaling: str = config.get("scaling", "density")
    # Regroupe les paramètres bornés pour l'appel Welch
    return window, effective_nperseg, effective_noverlap, average, scaling


def x__prepare_welch_parameters__mutmut_21(
    config: Mapping[str, Any], n_times: int
) -> Tuple[str | Iterable[float], int, int | None, str, str]:
    """Calcule des paramètres Welch bornés pour éviter les avertissements."""

    # Applique une fenêtre lisse pour limiter les fuites fréquentielles
    window: str | Iterable[float] = _validate_welch_window(config.get("window", "hann"))
    # Permet d'ajuster la taille de segment pour contrôler la résolution
    effective_nperseg = _sanitize_nperseg(config.get("nperseg"), n_times)
    # Offre un recouvrement configurable pour stabiliser l'estimation
    effective_noverlap = _sanitize_noverlap(
        config.get("noverlap"), effective_nperseg=None
    )
    # Permet de choisir la stratégie d'agrégation des segments
    average: str = config.get("average", "mean")
    # Permet de choisir la densité ou la puissance intégrée
    scaling: str = config.get("scaling", "density")
    # Regroupe les paramètres bornés pour l'appel Welch
    return window, effective_nperseg, effective_noverlap, average, scaling


def x__prepare_welch_parameters__mutmut_22(
    config: Mapping[str, Any], n_times: int
) -> Tuple[str | Iterable[float], int, int | None, str, str]:
    """Calcule des paramètres Welch bornés pour éviter les avertissements."""

    # Applique une fenêtre lisse pour limiter les fuites fréquentielles
    window: str | Iterable[float] = _validate_welch_window(config.get("window", "hann"))
    # Permet d'ajuster la taille de segment pour contrôler la résolution
    effective_nperseg = _sanitize_nperseg(config.get("nperseg"), n_times)
    # Offre un recouvrement configurable pour stabiliser l'estimation
    effective_noverlap = _sanitize_noverlap(
        effective_nperseg=effective_nperseg
    )
    # Permet de choisir la stratégie d'agrégation des segments
    average: str = config.get("average", "mean")
    # Permet de choisir la densité ou la puissance intégrée
    scaling: str = config.get("scaling", "density")
    # Regroupe les paramètres bornés pour l'appel Welch
    return window, effective_nperseg, effective_noverlap, average, scaling


def x__prepare_welch_parameters__mutmut_23(
    config: Mapping[str, Any], n_times: int
) -> Tuple[str | Iterable[float], int, int | None, str, str]:
    """Calcule des paramètres Welch bornés pour éviter les avertissements."""

    # Applique une fenêtre lisse pour limiter les fuites fréquentielles
    window: str | Iterable[float] = _validate_welch_window(config.get("window", "hann"))
    # Permet d'ajuster la taille de segment pour contrôler la résolution
    effective_nperseg = _sanitize_nperseg(config.get("nperseg"), n_times)
    # Offre un recouvrement configurable pour stabiliser l'estimation
    effective_noverlap = _sanitize_noverlap(
        config.get("noverlap"), )
    # Permet de choisir la stratégie d'agrégation des segments
    average: str = config.get("average", "mean")
    # Permet de choisir la densité ou la puissance intégrée
    scaling: str = config.get("scaling", "density")
    # Regroupe les paramètres bornés pour l'appel Welch
    return window, effective_nperseg, effective_noverlap, average, scaling


def x__prepare_welch_parameters__mutmut_24(
    config: Mapping[str, Any], n_times: int
) -> Tuple[str | Iterable[float], int, int | None, str, str]:
    """Calcule des paramètres Welch bornés pour éviter les avertissements."""

    # Applique une fenêtre lisse pour limiter les fuites fréquentielles
    window: str | Iterable[float] = _validate_welch_window(config.get("window", "hann"))
    # Permet d'ajuster la taille de segment pour contrôler la résolution
    effective_nperseg = _sanitize_nperseg(config.get("nperseg"), n_times)
    # Offre un recouvrement configurable pour stabiliser l'estimation
    effective_noverlap = _sanitize_noverlap(
        config.get(None), effective_nperseg=effective_nperseg
    )
    # Permet de choisir la stratégie d'agrégation des segments
    average: str = config.get("average", "mean")
    # Permet de choisir la densité ou la puissance intégrée
    scaling: str = config.get("scaling", "density")
    # Regroupe les paramètres bornés pour l'appel Welch
    return window, effective_nperseg, effective_noverlap, average, scaling


def x__prepare_welch_parameters__mutmut_25(
    config: Mapping[str, Any], n_times: int
) -> Tuple[str | Iterable[float], int, int | None, str, str]:
    """Calcule des paramètres Welch bornés pour éviter les avertissements."""

    # Applique une fenêtre lisse pour limiter les fuites fréquentielles
    window: str | Iterable[float] = _validate_welch_window(config.get("window", "hann"))
    # Permet d'ajuster la taille de segment pour contrôler la résolution
    effective_nperseg = _sanitize_nperseg(config.get("nperseg"), n_times)
    # Offre un recouvrement configurable pour stabiliser l'estimation
    effective_noverlap = _sanitize_noverlap(
        config.get("XXnoverlapXX"), effective_nperseg=effective_nperseg
    )
    # Permet de choisir la stratégie d'agrégation des segments
    average: str = config.get("average", "mean")
    # Permet de choisir la densité ou la puissance intégrée
    scaling: str = config.get("scaling", "density")
    # Regroupe les paramètres bornés pour l'appel Welch
    return window, effective_nperseg, effective_noverlap, average, scaling


def x__prepare_welch_parameters__mutmut_26(
    config: Mapping[str, Any], n_times: int
) -> Tuple[str | Iterable[float], int, int | None, str, str]:
    """Calcule des paramètres Welch bornés pour éviter les avertissements."""

    # Applique une fenêtre lisse pour limiter les fuites fréquentielles
    window: str | Iterable[float] = _validate_welch_window(config.get("window", "hann"))
    # Permet d'ajuster la taille de segment pour contrôler la résolution
    effective_nperseg = _sanitize_nperseg(config.get("nperseg"), n_times)
    # Offre un recouvrement configurable pour stabiliser l'estimation
    effective_noverlap = _sanitize_noverlap(
        config.get("NOVERLAP"), effective_nperseg=effective_nperseg
    )
    # Permet de choisir la stratégie d'agrégation des segments
    average: str = config.get("average", "mean")
    # Permet de choisir la densité ou la puissance intégrée
    scaling: str = config.get("scaling", "density")
    # Regroupe les paramètres bornés pour l'appel Welch
    return window, effective_nperseg, effective_noverlap, average, scaling


def x__prepare_welch_parameters__mutmut_27(
    config: Mapping[str, Any], n_times: int
) -> Tuple[str | Iterable[float], int, int | None, str, str]:
    """Calcule des paramètres Welch bornés pour éviter les avertissements."""

    # Applique une fenêtre lisse pour limiter les fuites fréquentielles
    window: str | Iterable[float] = _validate_welch_window(config.get("window", "hann"))
    # Permet d'ajuster la taille de segment pour contrôler la résolution
    effective_nperseg = _sanitize_nperseg(config.get("nperseg"), n_times)
    # Offre un recouvrement configurable pour stabiliser l'estimation
    effective_noverlap = _sanitize_noverlap(
        config.get("noverlap"), effective_nperseg=effective_nperseg
    )
    # Permet de choisir la stratégie d'agrégation des segments
    average: str = None
    # Permet de choisir la densité ou la puissance intégrée
    scaling: str = config.get("scaling", "density")
    # Regroupe les paramètres bornés pour l'appel Welch
    return window, effective_nperseg, effective_noverlap, average, scaling


def x__prepare_welch_parameters__mutmut_28(
    config: Mapping[str, Any], n_times: int
) -> Tuple[str | Iterable[float], int, int | None, str, str]:
    """Calcule des paramètres Welch bornés pour éviter les avertissements."""

    # Applique une fenêtre lisse pour limiter les fuites fréquentielles
    window: str | Iterable[float] = _validate_welch_window(config.get("window", "hann"))
    # Permet d'ajuster la taille de segment pour contrôler la résolution
    effective_nperseg = _sanitize_nperseg(config.get("nperseg"), n_times)
    # Offre un recouvrement configurable pour stabiliser l'estimation
    effective_noverlap = _sanitize_noverlap(
        config.get("noverlap"), effective_nperseg=effective_nperseg
    )
    # Permet de choisir la stratégie d'agrégation des segments
    average: str = config.get(None, "mean")
    # Permet de choisir la densité ou la puissance intégrée
    scaling: str = config.get("scaling", "density")
    # Regroupe les paramètres bornés pour l'appel Welch
    return window, effective_nperseg, effective_noverlap, average, scaling


def x__prepare_welch_parameters__mutmut_29(
    config: Mapping[str, Any], n_times: int
) -> Tuple[str | Iterable[float], int, int | None, str, str]:
    """Calcule des paramètres Welch bornés pour éviter les avertissements."""

    # Applique une fenêtre lisse pour limiter les fuites fréquentielles
    window: str | Iterable[float] = _validate_welch_window(config.get("window", "hann"))
    # Permet d'ajuster la taille de segment pour contrôler la résolution
    effective_nperseg = _sanitize_nperseg(config.get("nperseg"), n_times)
    # Offre un recouvrement configurable pour stabiliser l'estimation
    effective_noverlap = _sanitize_noverlap(
        config.get("noverlap"), effective_nperseg=effective_nperseg
    )
    # Permet de choisir la stratégie d'agrégation des segments
    average: str = config.get("average", None)
    # Permet de choisir la densité ou la puissance intégrée
    scaling: str = config.get("scaling", "density")
    # Regroupe les paramètres bornés pour l'appel Welch
    return window, effective_nperseg, effective_noverlap, average, scaling


def x__prepare_welch_parameters__mutmut_30(
    config: Mapping[str, Any], n_times: int
) -> Tuple[str | Iterable[float], int, int | None, str, str]:
    """Calcule des paramètres Welch bornés pour éviter les avertissements."""

    # Applique une fenêtre lisse pour limiter les fuites fréquentielles
    window: str | Iterable[float] = _validate_welch_window(config.get("window", "hann"))
    # Permet d'ajuster la taille de segment pour contrôler la résolution
    effective_nperseg = _sanitize_nperseg(config.get("nperseg"), n_times)
    # Offre un recouvrement configurable pour stabiliser l'estimation
    effective_noverlap = _sanitize_noverlap(
        config.get("noverlap"), effective_nperseg=effective_nperseg
    )
    # Permet de choisir la stratégie d'agrégation des segments
    average: str = config.get("mean")
    # Permet de choisir la densité ou la puissance intégrée
    scaling: str = config.get("scaling", "density")
    # Regroupe les paramètres bornés pour l'appel Welch
    return window, effective_nperseg, effective_noverlap, average, scaling


def x__prepare_welch_parameters__mutmut_31(
    config: Mapping[str, Any], n_times: int
) -> Tuple[str | Iterable[float], int, int | None, str, str]:
    """Calcule des paramètres Welch bornés pour éviter les avertissements."""

    # Applique une fenêtre lisse pour limiter les fuites fréquentielles
    window: str | Iterable[float] = _validate_welch_window(config.get("window", "hann"))
    # Permet d'ajuster la taille de segment pour contrôler la résolution
    effective_nperseg = _sanitize_nperseg(config.get("nperseg"), n_times)
    # Offre un recouvrement configurable pour stabiliser l'estimation
    effective_noverlap = _sanitize_noverlap(
        config.get("noverlap"), effective_nperseg=effective_nperseg
    )
    # Permet de choisir la stratégie d'agrégation des segments
    average: str = config.get("average", )
    # Permet de choisir la densité ou la puissance intégrée
    scaling: str = config.get("scaling", "density")
    # Regroupe les paramètres bornés pour l'appel Welch
    return window, effective_nperseg, effective_noverlap, average, scaling


def x__prepare_welch_parameters__mutmut_32(
    config: Mapping[str, Any], n_times: int
) -> Tuple[str | Iterable[float], int, int | None, str, str]:
    """Calcule des paramètres Welch bornés pour éviter les avertissements."""

    # Applique une fenêtre lisse pour limiter les fuites fréquentielles
    window: str | Iterable[float] = _validate_welch_window(config.get("window", "hann"))
    # Permet d'ajuster la taille de segment pour contrôler la résolution
    effective_nperseg = _sanitize_nperseg(config.get("nperseg"), n_times)
    # Offre un recouvrement configurable pour stabiliser l'estimation
    effective_noverlap = _sanitize_noverlap(
        config.get("noverlap"), effective_nperseg=effective_nperseg
    )
    # Permet de choisir la stratégie d'agrégation des segments
    average: str = config.get("XXaverageXX", "mean")
    # Permet de choisir la densité ou la puissance intégrée
    scaling: str = config.get("scaling", "density")
    # Regroupe les paramètres bornés pour l'appel Welch
    return window, effective_nperseg, effective_noverlap, average, scaling


def x__prepare_welch_parameters__mutmut_33(
    config: Mapping[str, Any], n_times: int
) -> Tuple[str | Iterable[float], int, int | None, str, str]:
    """Calcule des paramètres Welch bornés pour éviter les avertissements."""

    # Applique une fenêtre lisse pour limiter les fuites fréquentielles
    window: str | Iterable[float] = _validate_welch_window(config.get("window", "hann"))
    # Permet d'ajuster la taille de segment pour contrôler la résolution
    effective_nperseg = _sanitize_nperseg(config.get("nperseg"), n_times)
    # Offre un recouvrement configurable pour stabiliser l'estimation
    effective_noverlap = _sanitize_noverlap(
        config.get("noverlap"), effective_nperseg=effective_nperseg
    )
    # Permet de choisir la stratégie d'agrégation des segments
    average: str = config.get("AVERAGE", "mean")
    # Permet de choisir la densité ou la puissance intégrée
    scaling: str = config.get("scaling", "density")
    # Regroupe les paramètres bornés pour l'appel Welch
    return window, effective_nperseg, effective_noverlap, average, scaling


def x__prepare_welch_parameters__mutmut_34(
    config: Mapping[str, Any], n_times: int
) -> Tuple[str | Iterable[float], int, int | None, str, str]:
    """Calcule des paramètres Welch bornés pour éviter les avertissements."""

    # Applique une fenêtre lisse pour limiter les fuites fréquentielles
    window: str | Iterable[float] = _validate_welch_window(config.get("window", "hann"))
    # Permet d'ajuster la taille de segment pour contrôler la résolution
    effective_nperseg = _sanitize_nperseg(config.get("nperseg"), n_times)
    # Offre un recouvrement configurable pour stabiliser l'estimation
    effective_noverlap = _sanitize_noverlap(
        config.get("noverlap"), effective_nperseg=effective_nperseg
    )
    # Permet de choisir la stratégie d'agrégation des segments
    average: str = config.get("average", "XXmeanXX")
    # Permet de choisir la densité ou la puissance intégrée
    scaling: str = config.get("scaling", "density")
    # Regroupe les paramètres bornés pour l'appel Welch
    return window, effective_nperseg, effective_noverlap, average, scaling


def x__prepare_welch_parameters__mutmut_35(
    config: Mapping[str, Any], n_times: int
) -> Tuple[str | Iterable[float], int, int | None, str, str]:
    """Calcule des paramètres Welch bornés pour éviter les avertissements."""

    # Applique une fenêtre lisse pour limiter les fuites fréquentielles
    window: str | Iterable[float] = _validate_welch_window(config.get("window", "hann"))
    # Permet d'ajuster la taille de segment pour contrôler la résolution
    effective_nperseg = _sanitize_nperseg(config.get("nperseg"), n_times)
    # Offre un recouvrement configurable pour stabiliser l'estimation
    effective_noverlap = _sanitize_noverlap(
        config.get("noverlap"), effective_nperseg=effective_nperseg
    )
    # Permet de choisir la stratégie d'agrégation des segments
    average: str = config.get("average", "MEAN")
    # Permet de choisir la densité ou la puissance intégrée
    scaling: str = config.get("scaling", "density")
    # Regroupe les paramètres bornés pour l'appel Welch
    return window, effective_nperseg, effective_noverlap, average, scaling


def x__prepare_welch_parameters__mutmut_36(
    config: Mapping[str, Any], n_times: int
) -> Tuple[str | Iterable[float], int, int | None, str, str]:
    """Calcule des paramètres Welch bornés pour éviter les avertissements."""

    # Applique une fenêtre lisse pour limiter les fuites fréquentielles
    window: str | Iterable[float] = _validate_welch_window(config.get("window", "hann"))
    # Permet d'ajuster la taille de segment pour contrôler la résolution
    effective_nperseg = _sanitize_nperseg(config.get("nperseg"), n_times)
    # Offre un recouvrement configurable pour stabiliser l'estimation
    effective_noverlap = _sanitize_noverlap(
        config.get("noverlap"), effective_nperseg=effective_nperseg
    )
    # Permet de choisir la stratégie d'agrégation des segments
    average: str = config.get("average", "mean")
    # Permet de choisir la densité ou la puissance intégrée
    scaling: str = None
    # Regroupe les paramètres bornés pour l'appel Welch
    return window, effective_nperseg, effective_noverlap, average, scaling


def x__prepare_welch_parameters__mutmut_37(
    config: Mapping[str, Any], n_times: int
) -> Tuple[str | Iterable[float], int, int | None, str, str]:
    """Calcule des paramètres Welch bornés pour éviter les avertissements."""

    # Applique une fenêtre lisse pour limiter les fuites fréquentielles
    window: str | Iterable[float] = _validate_welch_window(config.get("window", "hann"))
    # Permet d'ajuster la taille de segment pour contrôler la résolution
    effective_nperseg = _sanitize_nperseg(config.get("nperseg"), n_times)
    # Offre un recouvrement configurable pour stabiliser l'estimation
    effective_noverlap = _sanitize_noverlap(
        config.get("noverlap"), effective_nperseg=effective_nperseg
    )
    # Permet de choisir la stratégie d'agrégation des segments
    average: str = config.get("average", "mean")
    # Permet de choisir la densité ou la puissance intégrée
    scaling: str = config.get(None, "density")
    # Regroupe les paramètres bornés pour l'appel Welch
    return window, effective_nperseg, effective_noverlap, average, scaling


def x__prepare_welch_parameters__mutmut_38(
    config: Mapping[str, Any], n_times: int
) -> Tuple[str | Iterable[float], int, int | None, str, str]:
    """Calcule des paramètres Welch bornés pour éviter les avertissements."""

    # Applique une fenêtre lisse pour limiter les fuites fréquentielles
    window: str | Iterable[float] = _validate_welch_window(config.get("window", "hann"))
    # Permet d'ajuster la taille de segment pour contrôler la résolution
    effective_nperseg = _sanitize_nperseg(config.get("nperseg"), n_times)
    # Offre un recouvrement configurable pour stabiliser l'estimation
    effective_noverlap = _sanitize_noverlap(
        config.get("noverlap"), effective_nperseg=effective_nperseg
    )
    # Permet de choisir la stratégie d'agrégation des segments
    average: str = config.get("average", "mean")
    # Permet de choisir la densité ou la puissance intégrée
    scaling: str = config.get("scaling", None)
    # Regroupe les paramètres bornés pour l'appel Welch
    return window, effective_nperseg, effective_noverlap, average, scaling


def x__prepare_welch_parameters__mutmut_39(
    config: Mapping[str, Any], n_times: int
) -> Tuple[str | Iterable[float], int, int | None, str, str]:
    """Calcule des paramètres Welch bornés pour éviter les avertissements."""

    # Applique une fenêtre lisse pour limiter les fuites fréquentielles
    window: str | Iterable[float] = _validate_welch_window(config.get("window", "hann"))
    # Permet d'ajuster la taille de segment pour contrôler la résolution
    effective_nperseg = _sanitize_nperseg(config.get("nperseg"), n_times)
    # Offre un recouvrement configurable pour stabiliser l'estimation
    effective_noverlap = _sanitize_noverlap(
        config.get("noverlap"), effective_nperseg=effective_nperseg
    )
    # Permet de choisir la stratégie d'agrégation des segments
    average: str = config.get("average", "mean")
    # Permet de choisir la densité ou la puissance intégrée
    scaling: str = config.get("density")
    # Regroupe les paramètres bornés pour l'appel Welch
    return window, effective_nperseg, effective_noverlap, average, scaling


def x__prepare_welch_parameters__mutmut_40(
    config: Mapping[str, Any], n_times: int
) -> Tuple[str | Iterable[float], int, int | None, str, str]:
    """Calcule des paramètres Welch bornés pour éviter les avertissements."""

    # Applique une fenêtre lisse pour limiter les fuites fréquentielles
    window: str | Iterable[float] = _validate_welch_window(config.get("window", "hann"))
    # Permet d'ajuster la taille de segment pour contrôler la résolution
    effective_nperseg = _sanitize_nperseg(config.get("nperseg"), n_times)
    # Offre un recouvrement configurable pour stabiliser l'estimation
    effective_noverlap = _sanitize_noverlap(
        config.get("noverlap"), effective_nperseg=effective_nperseg
    )
    # Permet de choisir la stratégie d'agrégation des segments
    average: str = config.get("average", "mean")
    # Permet de choisir la densité ou la puissance intégrée
    scaling: str = config.get("scaling", )
    # Regroupe les paramètres bornés pour l'appel Welch
    return window, effective_nperseg, effective_noverlap, average, scaling


def x__prepare_welch_parameters__mutmut_41(
    config: Mapping[str, Any], n_times: int
) -> Tuple[str | Iterable[float], int, int | None, str, str]:
    """Calcule des paramètres Welch bornés pour éviter les avertissements."""

    # Applique une fenêtre lisse pour limiter les fuites fréquentielles
    window: str | Iterable[float] = _validate_welch_window(config.get("window", "hann"))
    # Permet d'ajuster la taille de segment pour contrôler la résolution
    effective_nperseg = _sanitize_nperseg(config.get("nperseg"), n_times)
    # Offre un recouvrement configurable pour stabiliser l'estimation
    effective_noverlap = _sanitize_noverlap(
        config.get("noverlap"), effective_nperseg=effective_nperseg
    )
    # Permet de choisir la stratégie d'agrégation des segments
    average: str = config.get("average", "mean")
    # Permet de choisir la densité ou la puissance intégrée
    scaling: str = config.get("XXscalingXX", "density")
    # Regroupe les paramètres bornés pour l'appel Welch
    return window, effective_nperseg, effective_noverlap, average, scaling


def x__prepare_welch_parameters__mutmut_42(
    config: Mapping[str, Any], n_times: int
) -> Tuple[str | Iterable[float], int, int | None, str, str]:
    """Calcule des paramètres Welch bornés pour éviter les avertissements."""

    # Applique une fenêtre lisse pour limiter les fuites fréquentielles
    window: str | Iterable[float] = _validate_welch_window(config.get("window", "hann"))
    # Permet d'ajuster la taille de segment pour contrôler la résolution
    effective_nperseg = _sanitize_nperseg(config.get("nperseg"), n_times)
    # Offre un recouvrement configurable pour stabiliser l'estimation
    effective_noverlap = _sanitize_noverlap(
        config.get("noverlap"), effective_nperseg=effective_nperseg
    )
    # Permet de choisir la stratégie d'agrégation des segments
    average: str = config.get("average", "mean")
    # Permet de choisir la densité ou la puissance intégrée
    scaling: str = config.get("SCALING", "density")
    # Regroupe les paramètres bornés pour l'appel Welch
    return window, effective_nperseg, effective_noverlap, average, scaling


def x__prepare_welch_parameters__mutmut_43(
    config: Mapping[str, Any], n_times: int
) -> Tuple[str | Iterable[float], int, int | None, str, str]:
    """Calcule des paramètres Welch bornés pour éviter les avertissements."""

    # Applique une fenêtre lisse pour limiter les fuites fréquentielles
    window: str | Iterable[float] = _validate_welch_window(config.get("window", "hann"))
    # Permet d'ajuster la taille de segment pour contrôler la résolution
    effective_nperseg = _sanitize_nperseg(config.get("nperseg"), n_times)
    # Offre un recouvrement configurable pour stabiliser l'estimation
    effective_noverlap = _sanitize_noverlap(
        config.get("noverlap"), effective_nperseg=effective_nperseg
    )
    # Permet de choisir la stratégie d'agrégation des segments
    average: str = config.get("average", "mean")
    # Permet de choisir la densité ou la puissance intégrée
    scaling: str = config.get("scaling", "XXdensityXX")
    # Regroupe les paramètres bornés pour l'appel Welch
    return window, effective_nperseg, effective_noverlap, average, scaling


def x__prepare_welch_parameters__mutmut_44(
    config: Mapping[str, Any], n_times: int
) -> Tuple[str | Iterable[float], int, int | None, str, str]:
    """Calcule des paramètres Welch bornés pour éviter les avertissements."""

    # Applique une fenêtre lisse pour limiter les fuites fréquentielles
    window: str | Iterable[float] = _validate_welch_window(config.get("window", "hann"))
    # Permet d'ajuster la taille de segment pour contrôler la résolution
    effective_nperseg = _sanitize_nperseg(config.get("nperseg"), n_times)
    # Offre un recouvrement configurable pour stabiliser l'estimation
    effective_noverlap = _sanitize_noverlap(
        config.get("noverlap"), effective_nperseg=effective_nperseg
    )
    # Permet de choisir la stratégie d'agrégation des segments
    average: str = config.get("average", "mean")
    # Permet de choisir la densité ou la puissance intégrée
    scaling: str = config.get("scaling", "DENSITY")
    # Regroupe les paramètres bornés pour l'appel Welch
    return window, effective_nperseg, effective_noverlap, average, scaling

x__prepare_welch_parameters__mutmut_mutants : ClassVar[MutantDict] = {
'x__prepare_welch_parameters__mutmut_1': x__prepare_welch_parameters__mutmut_1, 
    'x__prepare_welch_parameters__mutmut_2': x__prepare_welch_parameters__mutmut_2, 
    'x__prepare_welch_parameters__mutmut_3': x__prepare_welch_parameters__mutmut_3, 
    'x__prepare_welch_parameters__mutmut_4': x__prepare_welch_parameters__mutmut_4, 
    'x__prepare_welch_parameters__mutmut_5': x__prepare_welch_parameters__mutmut_5, 
    'x__prepare_welch_parameters__mutmut_6': x__prepare_welch_parameters__mutmut_6, 
    'x__prepare_welch_parameters__mutmut_7': x__prepare_welch_parameters__mutmut_7, 
    'x__prepare_welch_parameters__mutmut_8': x__prepare_welch_parameters__mutmut_8, 
    'x__prepare_welch_parameters__mutmut_9': x__prepare_welch_parameters__mutmut_9, 
    'x__prepare_welch_parameters__mutmut_10': x__prepare_welch_parameters__mutmut_10, 
    'x__prepare_welch_parameters__mutmut_11': x__prepare_welch_parameters__mutmut_11, 
    'x__prepare_welch_parameters__mutmut_12': x__prepare_welch_parameters__mutmut_12, 
    'x__prepare_welch_parameters__mutmut_13': x__prepare_welch_parameters__mutmut_13, 
    'x__prepare_welch_parameters__mutmut_14': x__prepare_welch_parameters__mutmut_14, 
    'x__prepare_welch_parameters__mutmut_15': x__prepare_welch_parameters__mutmut_15, 
    'x__prepare_welch_parameters__mutmut_16': x__prepare_welch_parameters__mutmut_16, 
    'x__prepare_welch_parameters__mutmut_17': x__prepare_welch_parameters__mutmut_17, 
    'x__prepare_welch_parameters__mutmut_18': x__prepare_welch_parameters__mutmut_18, 
    'x__prepare_welch_parameters__mutmut_19': x__prepare_welch_parameters__mutmut_19, 
    'x__prepare_welch_parameters__mutmut_20': x__prepare_welch_parameters__mutmut_20, 
    'x__prepare_welch_parameters__mutmut_21': x__prepare_welch_parameters__mutmut_21, 
    'x__prepare_welch_parameters__mutmut_22': x__prepare_welch_parameters__mutmut_22, 
    'x__prepare_welch_parameters__mutmut_23': x__prepare_welch_parameters__mutmut_23, 
    'x__prepare_welch_parameters__mutmut_24': x__prepare_welch_parameters__mutmut_24, 
    'x__prepare_welch_parameters__mutmut_25': x__prepare_welch_parameters__mutmut_25, 
    'x__prepare_welch_parameters__mutmut_26': x__prepare_welch_parameters__mutmut_26, 
    'x__prepare_welch_parameters__mutmut_27': x__prepare_welch_parameters__mutmut_27, 
    'x__prepare_welch_parameters__mutmut_28': x__prepare_welch_parameters__mutmut_28, 
    'x__prepare_welch_parameters__mutmut_29': x__prepare_welch_parameters__mutmut_29, 
    'x__prepare_welch_parameters__mutmut_30': x__prepare_welch_parameters__mutmut_30, 
    'x__prepare_welch_parameters__mutmut_31': x__prepare_welch_parameters__mutmut_31, 
    'x__prepare_welch_parameters__mutmut_32': x__prepare_welch_parameters__mutmut_32, 
    'x__prepare_welch_parameters__mutmut_33': x__prepare_welch_parameters__mutmut_33, 
    'x__prepare_welch_parameters__mutmut_34': x__prepare_welch_parameters__mutmut_34, 
    'x__prepare_welch_parameters__mutmut_35': x__prepare_welch_parameters__mutmut_35, 
    'x__prepare_welch_parameters__mutmut_36': x__prepare_welch_parameters__mutmut_36, 
    'x__prepare_welch_parameters__mutmut_37': x__prepare_welch_parameters__mutmut_37, 
    'x__prepare_welch_parameters__mutmut_38': x__prepare_welch_parameters__mutmut_38, 
    'x__prepare_welch_parameters__mutmut_39': x__prepare_welch_parameters__mutmut_39, 
    'x__prepare_welch_parameters__mutmut_40': x__prepare_welch_parameters__mutmut_40, 
    'x__prepare_welch_parameters__mutmut_41': x__prepare_welch_parameters__mutmut_41, 
    'x__prepare_welch_parameters__mutmut_42': x__prepare_welch_parameters__mutmut_42, 
    'x__prepare_welch_parameters__mutmut_43': x__prepare_welch_parameters__mutmut_43, 
    'x__prepare_welch_parameters__mutmut_44': x__prepare_welch_parameters__mutmut_44
}

def _prepare_welch_parameters(*args, **kwargs):
    result = _mutmut_trampoline(x__prepare_welch_parameters__mutmut_orig, x__prepare_welch_parameters__mutmut_mutants, args, kwargs)
    return result 

_prepare_welch_parameters.__signature__ = _mutmut_signature(x__prepare_welch_parameters__mutmut_orig)
x__prepare_welch_parameters__mutmut_orig.__name__ = 'x__prepare_welch_parameters'


def x__validate_welch_window__mutmut_orig(window: str | Iterable[float]) -> str | Iterable[float]:
    """Valide la fenêtre Welch pour éviter des appels non déterministes."""

    if isinstance(window, str):
        if not window.strip():
            raise ValueError("Welch window name must be a non-empty string.")
        return window
    if isinstance(window, Iterable):
        try:
            window_tuple: Tuple[float, ...] = tuple(float(value) for value in window)
        except (TypeError, ValueError) as exc:
            raise ValueError(
                "Welch window iterable must contain numeric values."
            ) from exc
        if len(window_tuple) == 0:
            raise ValueError("Welch window iterable cannot be empty.")
        return window_tuple
    raise ValueError("Welch window must be a string or an iterable.")


def x__validate_welch_window__mutmut_1(window: str | Iterable[float]) -> str | Iterable[float]:
    """Valide la fenêtre Welch pour éviter des appels non déterministes."""

    if isinstance(window, str):
        if window.strip():
            raise ValueError("Welch window name must be a non-empty string.")
        return window
    if isinstance(window, Iterable):
        try:
            window_tuple: Tuple[float, ...] = tuple(float(value) for value in window)
        except (TypeError, ValueError) as exc:
            raise ValueError(
                "Welch window iterable must contain numeric values."
            ) from exc
        if len(window_tuple) == 0:
            raise ValueError("Welch window iterable cannot be empty.")
        return window_tuple
    raise ValueError("Welch window must be a string or an iterable.")


def x__validate_welch_window__mutmut_2(window: str | Iterable[float]) -> str | Iterable[float]:
    """Valide la fenêtre Welch pour éviter des appels non déterministes."""

    if isinstance(window, str):
        if not window.strip():
            raise ValueError(None)
        return window
    if isinstance(window, Iterable):
        try:
            window_tuple: Tuple[float, ...] = tuple(float(value) for value in window)
        except (TypeError, ValueError) as exc:
            raise ValueError(
                "Welch window iterable must contain numeric values."
            ) from exc
        if len(window_tuple) == 0:
            raise ValueError("Welch window iterable cannot be empty.")
        return window_tuple
    raise ValueError("Welch window must be a string or an iterable.")


def x__validate_welch_window__mutmut_3(window: str | Iterable[float]) -> str | Iterable[float]:
    """Valide la fenêtre Welch pour éviter des appels non déterministes."""

    if isinstance(window, str):
        if not window.strip():
            raise ValueError("XXWelch window name must be a non-empty string.XX")
        return window
    if isinstance(window, Iterable):
        try:
            window_tuple: Tuple[float, ...] = tuple(float(value) for value in window)
        except (TypeError, ValueError) as exc:
            raise ValueError(
                "Welch window iterable must contain numeric values."
            ) from exc
        if len(window_tuple) == 0:
            raise ValueError("Welch window iterable cannot be empty.")
        return window_tuple
    raise ValueError("Welch window must be a string or an iterable.")


def x__validate_welch_window__mutmut_4(window: str | Iterable[float]) -> str | Iterable[float]:
    """Valide la fenêtre Welch pour éviter des appels non déterministes."""

    if isinstance(window, str):
        if not window.strip():
            raise ValueError("welch window name must be a non-empty string.")
        return window
    if isinstance(window, Iterable):
        try:
            window_tuple: Tuple[float, ...] = tuple(float(value) for value in window)
        except (TypeError, ValueError) as exc:
            raise ValueError(
                "Welch window iterable must contain numeric values."
            ) from exc
        if len(window_tuple) == 0:
            raise ValueError("Welch window iterable cannot be empty.")
        return window_tuple
    raise ValueError("Welch window must be a string or an iterable.")


def x__validate_welch_window__mutmut_5(window: str | Iterable[float]) -> str | Iterable[float]:
    """Valide la fenêtre Welch pour éviter des appels non déterministes."""

    if isinstance(window, str):
        if not window.strip():
            raise ValueError("WELCH WINDOW NAME MUST BE A NON-EMPTY STRING.")
        return window
    if isinstance(window, Iterable):
        try:
            window_tuple: Tuple[float, ...] = tuple(float(value) for value in window)
        except (TypeError, ValueError) as exc:
            raise ValueError(
                "Welch window iterable must contain numeric values."
            ) from exc
        if len(window_tuple) == 0:
            raise ValueError("Welch window iterable cannot be empty.")
        return window_tuple
    raise ValueError("Welch window must be a string or an iterable.")

x__validate_welch_window__mutmut_mutants : ClassVar[MutantDict] = {
'x__validate_welch_window__mutmut_1': x__validate_welch_window__mutmut_1, 
    'x__validate_welch_window__mutmut_2': x__validate_welch_window__mutmut_2, 
    'x__validate_welch_window__mutmut_3': x__validate_welch_window__mutmut_3, 
    'x__validate_welch_window__mutmut_4': x__validate_welch_window__mutmut_4, 
    'x__validate_welch_window__mutmut_5': x__validate_welch_window__mutmut_5
}

def _validate_welch_window(*args, **kwargs):
    result = _mutmut_trampoline(x__validate_welch_window__mutmut_orig, x__validate_welch_window__mutmut_mutants, args, kwargs)
    return result 

_validate_welch_window.__signature__ = _mutmut_signature(x__validate_welch_window__mutmut_orig)
x__validate_welch_window__mutmut_orig.__name__ = 'x__validate_welch_window'


def x__sanitize_nperseg__mutmut_orig(nperseg: Any, n_times: int) -> int:
    """Valide et borne nperseg pour conserver une fenêtre positive."""

    if nperseg is None:
        return n_times
    if not isinstance(nperseg, int):
        raise ValueError("Welch nperseg must be an integer or None.")
    if nperseg <= 0:
        return n_times
    return min(nperseg, n_times)


def x__sanitize_nperseg__mutmut_1(nperseg: Any, n_times: int) -> int:
    """Valide et borne nperseg pour conserver une fenêtre positive."""

    if nperseg is not None:
        return n_times
    if not isinstance(nperseg, int):
        raise ValueError("Welch nperseg must be an integer or None.")
    if nperseg <= 0:
        return n_times
    return min(nperseg, n_times)


def x__sanitize_nperseg__mutmut_2(nperseg: Any, n_times: int) -> int:
    """Valide et borne nperseg pour conserver une fenêtre positive."""

    if nperseg is None:
        return n_times
    if isinstance(nperseg, int):
        raise ValueError("Welch nperseg must be an integer or None.")
    if nperseg <= 0:
        return n_times
    return min(nperseg, n_times)


def x__sanitize_nperseg__mutmut_3(nperseg: Any, n_times: int) -> int:
    """Valide et borne nperseg pour conserver une fenêtre positive."""

    if nperseg is None:
        return n_times
    if not isinstance(nperseg, int):
        raise ValueError(None)
    if nperseg <= 0:
        return n_times
    return min(nperseg, n_times)


def x__sanitize_nperseg__mutmut_4(nperseg: Any, n_times: int) -> int:
    """Valide et borne nperseg pour conserver une fenêtre positive."""

    if nperseg is None:
        return n_times
    if not isinstance(nperseg, int):
        raise ValueError("XXWelch nperseg must be an integer or None.XX")
    if nperseg <= 0:
        return n_times
    return min(nperseg, n_times)


def x__sanitize_nperseg__mutmut_5(nperseg: Any, n_times: int) -> int:
    """Valide et borne nperseg pour conserver une fenêtre positive."""

    if nperseg is None:
        return n_times
    if not isinstance(nperseg, int):
        raise ValueError("welch nperseg must be an integer or none.")
    if nperseg <= 0:
        return n_times
    return min(nperseg, n_times)


def x__sanitize_nperseg__mutmut_6(nperseg: Any, n_times: int) -> int:
    """Valide et borne nperseg pour conserver une fenêtre positive."""

    if nperseg is None:
        return n_times
    if not isinstance(nperseg, int):
        raise ValueError("WELCH NPERSEG MUST BE AN INTEGER OR NONE.")
    if nperseg <= 0:
        return n_times
    return min(nperseg, n_times)


def x__sanitize_nperseg__mutmut_7(nperseg: Any, n_times: int) -> int:
    """Valide et borne nperseg pour conserver une fenêtre positive."""

    if nperseg is None:
        return n_times
    if not isinstance(nperseg, int):
        raise ValueError("Welch nperseg must be an integer or None.")
    if nperseg < 0:
        return n_times
    return min(nperseg, n_times)


def x__sanitize_nperseg__mutmut_8(nperseg: Any, n_times: int) -> int:
    """Valide et borne nperseg pour conserver une fenêtre positive."""

    if nperseg is None:
        return n_times
    if not isinstance(nperseg, int):
        raise ValueError("Welch nperseg must be an integer or None.")
    if nperseg <= 1:
        return n_times
    return min(nperseg, n_times)


def x__sanitize_nperseg__mutmut_9(nperseg: Any, n_times: int) -> int:
    """Valide et borne nperseg pour conserver une fenêtre positive."""

    if nperseg is None:
        return n_times
    if not isinstance(nperseg, int):
        raise ValueError("Welch nperseg must be an integer or None.")
    if nperseg <= 0:
        return n_times
    return min(None, n_times)


def x__sanitize_nperseg__mutmut_10(nperseg: Any, n_times: int) -> int:
    """Valide et borne nperseg pour conserver une fenêtre positive."""

    if nperseg is None:
        return n_times
    if not isinstance(nperseg, int):
        raise ValueError("Welch nperseg must be an integer or None.")
    if nperseg <= 0:
        return n_times
    return min(nperseg, None)


def x__sanitize_nperseg__mutmut_11(nperseg: Any, n_times: int) -> int:
    """Valide et borne nperseg pour conserver une fenêtre positive."""

    if nperseg is None:
        return n_times
    if not isinstance(nperseg, int):
        raise ValueError("Welch nperseg must be an integer or None.")
    if nperseg <= 0:
        return n_times
    return min(n_times)


def x__sanitize_nperseg__mutmut_12(nperseg: Any, n_times: int) -> int:
    """Valide et borne nperseg pour conserver une fenêtre positive."""

    if nperseg is None:
        return n_times
    if not isinstance(nperseg, int):
        raise ValueError("Welch nperseg must be an integer or None.")
    if nperseg <= 0:
        return n_times
    return min(nperseg, )

x__sanitize_nperseg__mutmut_mutants : ClassVar[MutantDict] = {
'x__sanitize_nperseg__mutmut_1': x__sanitize_nperseg__mutmut_1, 
    'x__sanitize_nperseg__mutmut_2': x__sanitize_nperseg__mutmut_2, 
    'x__sanitize_nperseg__mutmut_3': x__sanitize_nperseg__mutmut_3, 
    'x__sanitize_nperseg__mutmut_4': x__sanitize_nperseg__mutmut_4, 
    'x__sanitize_nperseg__mutmut_5': x__sanitize_nperseg__mutmut_5, 
    'x__sanitize_nperseg__mutmut_6': x__sanitize_nperseg__mutmut_6, 
    'x__sanitize_nperseg__mutmut_7': x__sanitize_nperseg__mutmut_7, 
    'x__sanitize_nperseg__mutmut_8': x__sanitize_nperseg__mutmut_8, 
    'x__sanitize_nperseg__mutmut_9': x__sanitize_nperseg__mutmut_9, 
    'x__sanitize_nperseg__mutmut_10': x__sanitize_nperseg__mutmut_10, 
    'x__sanitize_nperseg__mutmut_11': x__sanitize_nperseg__mutmut_11, 
    'x__sanitize_nperseg__mutmut_12': x__sanitize_nperseg__mutmut_12
}

def _sanitize_nperseg(*args, **kwargs):
    result = _mutmut_trampoline(x__sanitize_nperseg__mutmut_orig, x__sanitize_nperseg__mutmut_mutants, args, kwargs)
    return result 

_sanitize_nperseg.__signature__ = _mutmut_signature(x__sanitize_nperseg__mutmut_orig)
x__sanitize_nperseg__mutmut_orig.__name__ = 'x__sanitize_nperseg'


def x__sanitize_noverlap__mutmut_orig(noverlap: Any, *, effective_nperseg: int) -> int | None:
    """Valide le recouvrement en conservant une fenêtre strictement positive."""

    if noverlap is None:
        return None
    if not isinstance(noverlap, int):
        raise ValueError("Welch noverlap must be a non-negative integer or None.")
    return max(0, min(noverlap, effective_nperseg - 1))


def x__sanitize_noverlap__mutmut_1(noverlap: Any, *, effective_nperseg: int) -> int | None:
    """Valide le recouvrement en conservant une fenêtre strictement positive."""

    if noverlap is not None:
        return None
    if not isinstance(noverlap, int):
        raise ValueError("Welch noverlap must be a non-negative integer or None.")
    return max(0, min(noverlap, effective_nperseg - 1))


def x__sanitize_noverlap__mutmut_2(noverlap: Any, *, effective_nperseg: int) -> int | None:
    """Valide le recouvrement en conservant une fenêtre strictement positive."""

    if noverlap is None:
        return None
    if isinstance(noverlap, int):
        raise ValueError("Welch noverlap must be a non-negative integer or None.")
    return max(0, min(noverlap, effective_nperseg - 1))


def x__sanitize_noverlap__mutmut_3(noverlap: Any, *, effective_nperseg: int) -> int | None:
    """Valide le recouvrement en conservant une fenêtre strictement positive."""

    if noverlap is None:
        return None
    if not isinstance(noverlap, int):
        raise ValueError(None)
    return max(0, min(noverlap, effective_nperseg - 1))


def x__sanitize_noverlap__mutmut_4(noverlap: Any, *, effective_nperseg: int) -> int | None:
    """Valide le recouvrement en conservant une fenêtre strictement positive."""

    if noverlap is None:
        return None
    if not isinstance(noverlap, int):
        raise ValueError("XXWelch noverlap must be a non-negative integer or None.XX")
    return max(0, min(noverlap, effective_nperseg - 1))


def x__sanitize_noverlap__mutmut_5(noverlap: Any, *, effective_nperseg: int) -> int | None:
    """Valide le recouvrement en conservant une fenêtre strictement positive."""

    if noverlap is None:
        return None
    if not isinstance(noverlap, int):
        raise ValueError("welch noverlap must be a non-negative integer or none.")
    return max(0, min(noverlap, effective_nperseg - 1))


def x__sanitize_noverlap__mutmut_6(noverlap: Any, *, effective_nperseg: int) -> int | None:
    """Valide le recouvrement en conservant une fenêtre strictement positive."""

    if noverlap is None:
        return None
    if not isinstance(noverlap, int):
        raise ValueError("WELCH NOVERLAP MUST BE A NON-NEGATIVE INTEGER OR NONE.")
    return max(0, min(noverlap, effective_nperseg - 1))


def x__sanitize_noverlap__mutmut_7(noverlap: Any, *, effective_nperseg: int) -> int | None:
    """Valide le recouvrement en conservant une fenêtre strictement positive."""

    if noverlap is None:
        return None
    if not isinstance(noverlap, int):
        raise ValueError("Welch noverlap must be a non-negative integer or None.")
    return max(None, min(noverlap, effective_nperseg - 1))


def x__sanitize_noverlap__mutmut_8(noverlap: Any, *, effective_nperseg: int) -> int | None:
    """Valide le recouvrement en conservant une fenêtre strictement positive."""

    if noverlap is None:
        return None
    if not isinstance(noverlap, int):
        raise ValueError("Welch noverlap must be a non-negative integer or None.")
    return max(0, None)


def x__sanitize_noverlap__mutmut_9(noverlap: Any, *, effective_nperseg: int) -> int | None:
    """Valide le recouvrement en conservant une fenêtre strictement positive."""

    if noverlap is None:
        return None
    if not isinstance(noverlap, int):
        raise ValueError("Welch noverlap must be a non-negative integer or None.")
    return max(min(noverlap, effective_nperseg - 1))


def x__sanitize_noverlap__mutmut_10(noverlap: Any, *, effective_nperseg: int) -> int | None:
    """Valide le recouvrement en conservant une fenêtre strictement positive."""

    if noverlap is None:
        return None
    if not isinstance(noverlap, int):
        raise ValueError("Welch noverlap must be a non-negative integer or None.")
    return max(0, )


def x__sanitize_noverlap__mutmut_11(noverlap: Any, *, effective_nperseg: int) -> int | None:
    """Valide le recouvrement en conservant une fenêtre strictement positive."""

    if noverlap is None:
        return None
    if not isinstance(noverlap, int):
        raise ValueError("Welch noverlap must be a non-negative integer or None.")
    return max(1, min(noverlap, effective_nperseg - 1))


def x__sanitize_noverlap__mutmut_12(noverlap: Any, *, effective_nperseg: int) -> int | None:
    """Valide le recouvrement en conservant une fenêtre strictement positive."""

    if noverlap is None:
        return None
    if not isinstance(noverlap, int):
        raise ValueError("Welch noverlap must be a non-negative integer or None.")
    return max(0, min(None, effective_nperseg - 1))


def x__sanitize_noverlap__mutmut_13(noverlap: Any, *, effective_nperseg: int) -> int | None:
    """Valide le recouvrement en conservant une fenêtre strictement positive."""

    if noverlap is None:
        return None
    if not isinstance(noverlap, int):
        raise ValueError("Welch noverlap must be a non-negative integer or None.")
    return max(0, min(noverlap, None))


def x__sanitize_noverlap__mutmut_14(noverlap: Any, *, effective_nperseg: int) -> int | None:
    """Valide le recouvrement en conservant une fenêtre strictement positive."""

    if noverlap is None:
        return None
    if not isinstance(noverlap, int):
        raise ValueError("Welch noverlap must be a non-negative integer or None.")
    return max(0, min(effective_nperseg - 1))


def x__sanitize_noverlap__mutmut_15(noverlap: Any, *, effective_nperseg: int) -> int | None:
    """Valide le recouvrement en conservant une fenêtre strictement positive."""

    if noverlap is None:
        return None
    if not isinstance(noverlap, int):
        raise ValueError("Welch noverlap must be a non-negative integer or None.")
    return max(0, min(noverlap, ))


def x__sanitize_noverlap__mutmut_16(noverlap: Any, *, effective_nperseg: int) -> int | None:
    """Valide le recouvrement en conservant une fenêtre strictement positive."""

    if noverlap is None:
        return None
    if not isinstance(noverlap, int):
        raise ValueError("Welch noverlap must be a non-negative integer or None.")
    return max(0, min(noverlap, effective_nperseg + 1))


def x__sanitize_noverlap__mutmut_17(noverlap: Any, *, effective_nperseg: int) -> int | None:
    """Valide le recouvrement en conservant une fenêtre strictement positive."""

    if noverlap is None:
        return None
    if not isinstance(noverlap, int):
        raise ValueError("Welch noverlap must be a non-negative integer or None.")
    return max(0, min(noverlap, effective_nperseg - 2))

x__sanitize_noverlap__mutmut_mutants : ClassVar[MutantDict] = {
'x__sanitize_noverlap__mutmut_1': x__sanitize_noverlap__mutmut_1, 
    'x__sanitize_noverlap__mutmut_2': x__sanitize_noverlap__mutmut_2, 
    'x__sanitize_noverlap__mutmut_3': x__sanitize_noverlap__mutmut_3, 
    'x__sanitize_noverlap__mutmut_4': x__sanitize_noverlap__mutmut_4, 
    'x__sanitize_noverlap__mutmut_5': x__sanitize_noverlap__mutmut_5, 
    'x__sanitize_noverlap__mutmut_6': x__sanitize_noverlap__mutmut_6, 
    'x__sanitize_noverlap__mutmut_7': x__sanitize_noverlap__mutmut_7, 
    'x__sanitize_noverlap__mutmut_8': x__sanitize_noverlap__mutmut_8, 
    'x__sanitize_noverlap__mutmut_9': x__sanitize_noverlap__mutmut_9, 
    'x__sanitize_noverlap__mutmut_10': x__sanitize_noverlap__mutmut_10, 
    'x__sanitize_noverlap__mutmut_11': x__sanitize_noverlap__mutmut_11, 
    'x__sanitize_noverlap__mutmut_12': x__sanitize_noverlap__mutmut_12, 
    'x__sanitize_noverlap__mutmut_13': x__sanitize_noverlap__mutmut_13, 
    'x__sanitize_noverlap__mutmut_14': x__sanitize_noverlap__mutmut_14, 
    'x__sanitize_noverlap__mutmut_15': x__sanitize_noverlap__mutmut_15, 
    'x__sanitize_noverlap__mutmut_16': x__sanitize_noverlap__mutmut_16, 
    'x__sanitize_noverlap__mutmut_17': x__sanitize_noverlap__mutmut_17
}

def _sanitize_noverlap(*args, **kwargs):
    result = _mutmut_trampoline(x__sanitize_noverlap__mutmut_orig, x__sanitize_noverlap__mutmut_mutants, args, kwargs)
    return result 

_sanitize_noverlap.__signature__ = _mutmut_signature(x__sanitize_noverlap__mutmut_orig)
x__sanitize_noverlap__mutmut_orig.__name__ = 'x__sanitize_noverlap'


def x__normalize_wavelet_name__mutmut_orig(wavelet_name: Any) -> str:
    """Valide le nom de wavelet et applique un nettoyage minimal."""

    if not isinstance(wavelet_name, str):
        raise ValueError(
            "Wavelet selection must be a non-empty string (e.g., 'morlet')."
        )
    cleaned = wavelet_name.strip().lower()
    if not cleaned:
        raise ValueError(
            "Wavelet selection must be a non-empty string (e.g., 'morlet')."
        )
    if cleaned != "morlet":
        raise ValueError(f"Unsupported wavelet: {wavelet_name!r}. Use 'morlet'.")
    return cleaned


def x__normalize_wavelet_name__mutmut_1(wavelet_name: Any) -> str:
    """Valide le nom de wavelet et applique un nettoyage minimal."""

    if isinstance(wavelet_name, str):
        raise ValueError(
            "Wavelet selection must be a non-empty string (e.g., 'morlet')."
        )
    cleaned = wavelet_name.strip().lower()
    if not cleaned:
        raise ValueError(
            "Wavelet selection must be a non-empty string (e.g., 'morlet')."
        )
    if cleaned != "morlet":
        raise ValueError(f"Unsupported wavelet: {wavelet_name!r}. Use 'morlet'.")
    return cleaned


def x__normalize_wavelet_name__mutmut_2(wavelet_name: Any) -> str:
    """Valide le nom de wavelet et applique un nettoyage minimal."""

    if not isinstance(wavelet_name, str):
        raise ValueError(
            None
        )
    cleaned = wavelet_name.strip().lower()
    if not cleaned:
        raise ValueError(
            "Wavelet selection must be a non-empty string (e.g., 'morlet')."
        )
    if cleaned != "morlet":
        raise ValueError(f"Unsupported wavelet: {wavelet_name!r}. Use 'morlet'.")
    return cleaned


def x__normalize_wavelet_name__mutmut_3(wavelet_name: Any) -> str:
    """Valide le nom de wavelet et applique un nettoyage minimal."""

    if not isinstance(wavelet_name, str):
        raise ValueError(
            "XXWavelet selection must be a non-empty string (e.g., 'morlet').XX"
        )
    cleaned = wavelet_name.strip().lower()
    if not cleaned:
        raise ValueError(
            "Wavelet selection must be a non-empty string (e.g., 'morlet')."
        )
    if cleaned != "morlet":
        raise ValueError(f"Unsupported wavelet: {wavelet_name!r}. Use 'morlet'.")
    return cleaned


def x__normalize_wavelet_name__mutmut_4(wavelet_name: Any) -> str:
    """Valide le nom de wavelet et applique un nettoyage minimal."""

    if not isinstance(wavelet_name, str):
        raise ValueError(
            "wavelet selection must be a non-empty string (e.g., 'morlet')."
        )
    cleaned = wavelet_name.strip().lower()
    if not cleaned:
        raise ValueError(
            "Wavelet selection must be a non-empty string (e.g., 'morlet')."
        )
    if cleaned != "morlet":
        raise ValueError(f"Unsupported wavelet: {wavelet_name!r}. Use 'morlet'.")
    return cleaned


def x__normalize_wavelet_name__mutmut_5(wavelet_name: Any) -> str:
    """Valide le nom de wavelet et applique un nettoyage minimal."""

    if not isinstance(wavelet_name, str):
        raise ValueError(
            "WAVELET SELECTION MUST BE A NON-EMPTY STRING (E.G., 'MORLET')."
        )
    cleaned = wavelet_name.strip().lower()
    if not cleaned:
        raise ValueError(
            "Wavelet selection must be a non-empty string (e.g., 'morlet')."
        )
    if cleaned != "morlet":
        raise ValueError(f"Unsupported wavelet: {wavelet_name!r}. Use 'morlet'.")
    return cleaned


def x__normalize_wavelet_name__mutmut_6(wavelet_name: Any) -> str:
    """Valide le nom de wavelet et applique un nettoyage minimal."""

    if not isinstance(wavelet_name, str):
        raise ValueError(
            "Wavelet selection must be a non-empty string (e.g., 'morlet')."
        )
    cleaned = None
    if not cleaned:
        raise ValueError(
            "Wavelet selection must be a non-empty string (e.g., 'morlet')."
        )
    if cleaned != "morlet":
        raise ValueError(f"Unsupported wavelet: {wavelet_name!r}. Use 'morlet'.")
    return cleaned


def x__normalize_wavelet_name__mutmut_7(wavelet_name: Any) -> str:
    """Valide le nom de wavelet et applique un nettoyage minimal."""

    if not isinstance(wavelet_name, str):
        raise ValueError(
            "Wavelet selection must be a non-empty string (e.g., 'morlet')."
        )
    cleaned = wavelet_name.strip().upper()
    if not cleaned:
        raise ValueError(
            "Wavelet selection must be a non-empty string (e.g., 'morlet')."
        )
    if cleaned != "morlet":
        raise ValueError(f"Unsupported wavelet: {wavelet_name!r}. Use 'morlet'.")
    return cleaned


def x__normalize_wavelet_name__mutmut_8(wavelet_name: Any) -> str:
    """Valide le nom de wavelet et applique un nettoyage minimal."""

    if not isinstance(wavelet_name, str):
        raise ValueError(
            "Wavelet selection must be a non-empty string (e.g., 'morlet')."
        )
    cleaned = wavelet_name.strip().lower()
    if cleaned:
        raise ValueError(
            "Wavelet selection must be a non-empty string (e.g., 'morlet')."
        )
    if cleaned != "morlet":
        raise ValueError(f"Unsupported wavelet: {wavelet_name!r}. Use 'morlet'.")
    return cleaned


def x__normalize_wavelet_name__mutmut_9(wavelet_name: Any) -> str:
    """Valide le nom de wavelet et applique un nettoyage minimal."""

    if not isinstance(wavelet_name, str):
        raise ValueError(
            "Wavelet selection must be a non-empty string (e.g., 'morlet')."
        )
    cleaned = wavelet_name.strip().lower()
    if not cleaned:
        raise ValueError(
            "Wavelet selection must be a non-empty string (e.g., 'morlet')."
        )
    if cleaned == "morlet":
        raise ValueError(f"Unsupported wavelet: {wavelet_name!r}. Use 'morlet'.")
    return cleaned


def x__normalize_wavelet_name__mutmut_10(wavelet_name: Any) -> str:
    """Valide le nom de wavelet et applique un nettoyage minimal."""

    if not isinstance(wavelet_name, str):
        raise ValueError(
            "Wavelet selection must be a non-empty string (e.g., 'morlet')."
        )
    cleaned = wavelet_name.strip().lower()
    if not cleaned:
        raise ValueError(
            "Wavelet selection must be a non-empty string (e.g., 'morlet')."
        )
    if cleaned != "XXmorletXX":
        raise ValueError(f"Unsupported wavelet: {wavelet_name!r}. Use 'morlet'.")
    return cleaned


def x__normalize_wavelet_name__mutmut_11(wavelet_name: Any) -> str:
    """Valide le nom de wavelet et applique un nettoyage minimal."""

    if not isinstance(wavelet_name, str):
        raise ValueError(
            "Wavelet selection must be a non-empty string (e.g., 'morlet')."
        )
    cleaned = wavelet_name.strip().lower()
    if not cleaned:
        raise ValueError(
            "Wavelet selection must be a non-empty string (e.g., 'morlet')."
        )
    if cleaned != "MORLET":
        raise ValueError(f"Unsupported wavelet: {wavelet_name!r}. Use 'morlet'.")
    return cleaned


def x__normalize_wavelet_name__mutmut_12(wavelet_name: Any) -> str:
    """Valide le nom de wavelet et applique un nettoyage minimal."""

    if not isinstance(wavelet_name, str):
        raise ValueError(
            "Wavelet selection must be a non-empty string (e.g., 'morlet')."
        )
    cleaned = wavelet_name.strip().lower()
    if not cleaned:
        raise ValueError(
            "Wavelet selection must be a non-empty string (e.g., 'morlet')."
        )
    if cleaned != "morlet":
        raise ValueError(None)
    return cleaned

x__normalize_wavelet_name__mutmut_mutants : ClassVar[MutantDict] = {
'x__normalize_wavelet_name__mutmut_1': x__normalize_wavelet_name__mutmut_1, 
    'x__normalize_wavelet_name__mutmut_2': x__normalize_wavelet_name__mutmut_2, 
    'x__normalize_wavelet_name__mutmut_3': x__normalize_wavelet_name__mutmut_3, 
    'x__normalize_wavelet_name__mutmut_4': x__normalize_wavelet_name__mutmut_4, 
    'x__normalize_wavelet_name__mutmut_5': x__normalize_wavelet_name__mutmut_5, 
    'x__normalize_wavelet_name__mutmut_6': x__normalize_wavelet_name__mutmut_6, 
    'x__normalize_wavelet_name__mutmut_7': x__normalize_wavelet_name__mutmut_7, 
    'x__normalize_wavelet_name__mutmut_8': x__normalize_wavelet_name__mutmut_8, 
    'x__normalize_wavelet_name__mutmut_9': x__normalize_wavelet_name__mutmut_9, 
    'x__normalize_wavelet_name__mutmut_10': x__normalize_wavelet_name__mutmut_10, 
    'x__normalize_wavelet_name__mutmut_11': x__normalize_wavelet_name__mutmut_11, 
    'x__normalize_wavelet_name__mutmut_12': x__normalize_wavelet_name__mutmut_12
}

def _normalize_wavelet_name(*args, **kwargs):
    result = _mutmut_trampoline(x__normalize_wavelet_name__mutmut_orig, x__normalize_wavelet_name__mutmut_mutants, args, kwargs)
    return result 

_normalize_wavelet_name.__signature__ = _mutmut_signature(x__normalize_wavelet_name__mutmut_orig)
x__normalize_wavelet_name__mutmut_orig.__name__ = 'x__normalize_wavelet_name'


def x__compute_welch_band_powers__mutmut_orig(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule les puissances de bandes via Welch avec bornes sécurisées."""

    # Stocke le nombre d'échantillons pour calibrer les fenêtres de Welch
    n_times: int = data.shape[-1]
    # Calcule les paramètres Welch pour un appel robuste
    window, effective_nperseg, effective_noverlap, average, scaling = (
        _prepare_welch_parameters(config, n_times)
    )
    # Calcule la densité spectrale de puissance par canal et par essai
    freqs, psd = signal.welch(
        data,
        sfreq,
        window=window,
        nperseg=effective_nperseg,
        noverlap=effective_noverlap,
        axis=-1,
        average=average,
        scaling=scaling,
    )
    # Accumule les puissances de bande pour chaque intervalle demandé
    band_powers: List[np.ndarray] = []
    # Parcourt les bandes dans l'ordre pour garantir la stabilité des colonnes
    for _, (low, high) in band_ranges.items():
        # Construit un masque fréquentiel pour isoler l'intervalle cible
        band_mask = (freqs >= low) & (freqs <= high)
        # Renvoie des zéros si aucune fréquence n'est disponible dans la bande
        if not np.any(band_mask):
            # Fournit un tenseur nul pour préserver la forme de sortie
            band_powers.append(np.zeros(psd.shape[:2]))
        else:
            # Moyenne la PSD sur la bande pour réduire la dimension temporelle
            band_powers.append(psd[:, :, band_mask].mean(axis=-1))
    # Empile les bandes pour conserver la structure epochs x canaux x bandes
    return np.stack(band_powers, axis=2)


def x__compute_welch_band_powers__mutmut_1(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule les puissances de bandes via Welch avec bornes sécurisées."""

    # Stocke le nombre d'échantillons pour calibrer les fenêtres de Welch
    n_times: int = None
    # Calcule les paramètres Welch pour un appel robuste
    window, effective_nperseg, effective_noverlap, average, scaling = (
        _prepare_welch_parameters(config, n_times)
    )
    # Calcule la densité spectrale de puissance par canal et par essai
    freqs, psd = signal.welch(
        data,
        sfreq,
        window=window,
        nperseg=effective_nperseg,
        noverlap=effective_noverlap,
        axis=-1,
        average=average,
        scaling=scaling,
    )
    # Accumule les puissances de bande pour chaque intervalle demandé
    band_powers: List[np.ndarray] = []
    # Parcourt les bandes dans l'ordre pour garantir la stabilité des colonnes
    for _, (low, high) in band_ranges.items():
        # Construit un masque fréquentiel pour isoler l'intervalle cible
        band_mask = (freqs >= low) & (freqs <= high)
        # Renvoie des zéros si aucune fréquence n'est disponible dans la bande
        if not np.any(band_mask):
            # Fournit un tenseur nul pour préserver la forme de sortie
            band_powers.append(np.zeros(psd.shape[:2]))
        else:
            # Moyenne la PSD sur la bande pour réduire la dimension temporelle
            band_powers.append(psd[:, :, band_mask].mean(axis=-1))
    # Empile les bandes pour conserver la structure epochs x canaux x bandes
    return np.stack(band_powers, axis=2)


def x__compute_welch_band_powers__mutmut_2(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule les puissances de bandes via Welch avec bornes sécurisées."""

    # Stocke le nombre d'échantillons pour calibrer les fenêtres de Welch
    n_times: int = data.shape[+1]
    # Calcule les paramètres Welch pour un appel robuste
    window, effective_nperseg, effective_noverlap, average, scaling = (
        _prepare_welch_parameters(config, n_times)
    )
    # Calcule la densité spectrale de puissance par canal et par essai
    freqs, psd = signal.welch(
        data,
        sfreq,
        window=window,
        nperseg=effective_nperseg,
        noverlap=effective_noverlap,
        axis=-1,
        average=average,
        scaling=scaling,
    )
    # Accumule les puissances de bande pour chaque intervalle demandé
    band_powers: List[np.ndarray] = []
    # Parcourt les bandes dans l'ordre pour garantir la stabilité des colonnes
    for _, (low, high) in band_ranges.items():
        # Construit un masque fréquentiel pour isoler l'intervalle cible
        band_mask = (freqs >= low) & (freqs <= high)
        # Renvoie des zéros si aucune fréquence n'est disponible dans la bande
        if not np.any(band_mask):
            # Fournit un tenseur nul pour préserver la forme de sortie
            band_powers.append(np.zeros(psd.shape[:2]))
        else:
            # Moyenne la PSD sur la bande pour réduire la dimension temporelle
            band_powers.append(psd[:, :, band_mask].mean(axis=-1))
    # Empile les bandes pour conserver la structure epochs x canaux x bandes
    return np.stack(band_powers, axis=2)


def x__compute_welch_band_powers__mutmut_3(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule les puissances de bandes via Welch avec bornes sécurisées."""

    # Stocke le nombre d'échantillons pour calibrer les fenêtres de Welch
    n_times: int = data.shape[-2]
    # Calcule les paramètres Welch pour un appel robuste
    window, effective_nperseg, effective_noverlap, average, scaling = (
        _prepare_welch_parameters(config, n_times)
    )
    # Calcule la densité spectrale de puissance par canal et par essai
    freqs, psd = signal.welch(
        data,
        sfreq,
        window=window,
        nperseg=effective_nperseg,
        noverlap=effective_noverlap,
        axis=-1,
        average=average,
        scaling=scaling,
    )
    # Accumule les puissances de bande pour chaque intervalle demandé
    band_powers: List[np.ndarray] = []
    # Parcourt les bandes dans l'ordre pour garantir la stabilité des colonnes
    for _, (low, high) in band_ranges.items():
        # Construit un masque fréquentiel pour isoler l'intervalle cible
        band_mask = (freqs >= low) & (freqs <= high)
        # Renvoie des zéros si aucune fréquence n'est disponible dans la bande
        if not np.any(band_mask):
            # Fournit un tenseur nul pour préserver la forme de sortie
            band_powers.append(np.zeros(psd.shape[:2]))
        else:
            # Moyenne la PSD sur la bande pour réduire la dimension temporelle
            band_powers.append(psd[:, :, band_mask].mean(axis=-1))
    # Empile les bandes pour conserver la structure epochs x canaux x bandes
    return np.stack(band_powers, axis=2)


def x__compute_welch_band_powers__mutmut_4(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule les puissances de bandes via Welch avec bornes sécurisées."""

    # Stocke le nombre d'échantillons pour calibrer les fenêtres de Welch
    n_times: int = data.shape[-1]
    # Calcule les paramètres Welch pour un appel robuste
    window, effective_nperseg, effective_noverlap, average, scaling = None
    # Calcule la densité spectrale de puissance par canal et par essai
    freqs, psd = signal.welch(
        data,
        sfreq,
        window=window,
        nperseg=effective_nperseg,
        noverlap=effective_noverlap,
        axis=-1,
        average=average,
        scaling=scaling,
    )
    # Accumule les puissances de bande pour chaque intervalle demandé
    band_powers: List[np.ndarray] = []
    # Parcourt les bandes dans l'ordre pour garantir la stabilité des colonnes
    for _, (low, high) in band_ranges.items():
        # Construit un masque fréquentiel pour isoler l'intervalle cible
        band_mask = (freqs >= low) & (freqs <= high)
        # Renvoie des zéros si aucune fréquence n'est disponible dans la bande
        if not np.any(band_mask):
            # Fournit un tenseur nul pour préserver la forme de sortie
            band_powers.append(np.zeros(psd.shape[:2]))
        else:
            # Moyenne la PSD sur la bande pour réduire la dimension temporelle
            band_powers.append(psd[:, :, band_mask].mean(axis=-1))
    # Empile les bandes pour conserver la structure epochs x canaux x bandes
    return np.stack(band_powers, axis=2)


def x__compute_welch_band_powers__mutmut_5(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule les puissances de bandes via Welch avec bornes sécurisées."""

    # Stocke le nombre d'échantillons pour calibrer les fenêtres de Welch
    n_times: int = data.shape[-1]
    # Calcule les paramètres Welch pour un appel robuste
    window, effective_nperseg, effective_noverlap, average, scaling = (
        _prepare_welch_parameters(None, n_times)
    )
    # Calcule la densité spectrale de puissance par canal et par essai
    freqs, psd = signal.welch(
        data,
        sfreq,
        window=window,
        nperseg=effective_nperseg,
        noverlap=effective_noverlap,
        axis=-1,
        average=average,
        scaling=scaling,
    )
    # Accumule les puissances de bande pour chaque intervalle demandé
    band_powers: List[np.ndarray] = []
    # Parcourt les bandes dans l'ordre pour garantir la stabilité des colonnes
    for _, (low, high) in band_ranges.items():
        # Construit un masque fréquentiel pour isoler l'intervalle cible
        band_mask = (freqs >= low) & (freqs <= high)
        # Renvoie des zéros si aucune fréquence n'est disponible dans la bande
        if not np.any(band_mask):
            # Fournit un tenseur nul pour préserver la forme de sortie
            band_powers.append(np.zeros(psd.shape[:2]))
        else:
            # Moyenne la PSD sur la bande pour réduire la dimension temporelle
            band_powers.append(psd[:, :, band_mask].mean(axis=-1))
    # Empile les bandes pour conserver la structure epochs x canaux x bandes
    return np.stack(band_powers, axis=2)


def x__compute_welch_band_powers__mutmut_6(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule les puissances de bandes via Welch avec bornes sécurisées."""

    # Stocke le nombre d'échantillons pour calibrer les fenêtres de Welch
    n_times: int = data.shape[-1]
    # Calcule les paramètres Welch pour un appel robuste
    window, effective_nperseg, effective_noverlap, average, scaling = (
        _prepare_welch_parameters(config, None)
    )
    # Calcule la densité spectrale de puissance par canal et par essai
    freqs, psd = signal.welch(
        data,
        sfreq,
        window=window,
        nperseg=effective_nperseg,
        noverlap=effective_noverlap,
        axis=-1,
        average=average,
        scaling=scaling,
    )
    # Accumule les puissances de bande pour chaque intervalle demandé
    band_powers: List[np.ndarray] = []
    # Parcourt les bandes dans l'ordre pour garantir la stabilité des colonnes
    for _, (low, high) in band_ranges.items():
        # Construit un masque fréquentiel pour isoler l'intervalle cible
        band_mask = (freqs >= low) & (freqs <= high)
        # Renvoie des zéros si aucune fréquence n'est disponible dans la bande
        if not np.any(band_mask):
            # Fournit un tenseur nul pour préserver la forme de sortie
            band_powers.append(np.zeros(psd.shape[:2]))
        else:
            # Moyenne la PSD sur la bande pour réduire la dimension temporelle
            band_powers.append(psd[:, :, band_mask].mean(axis=-1))
    # Empile les bandes pour conserver la structure epochs x canaux x bandes
    return np.stack(band_powers, axis=2)


def x__compute_welch_band_powers__mutmut_7(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule les puissances de bandes via Welch avec bornes sécurisées."""

    # Stocke le nombre d'échantillons pour calibrer les fenêtres de Welch
    n_times: int = data.shape[-1]
    # Calcule les paramètres Welch pour un appel robuste
    window, effective_nperseg, effective_noverlap, average, scaling = (
        _prepare_welch_parameters(n_times)
    )
    # Calcule la densité spectrale de puissance par canal et par essai
    freqs, psd = signal.welch(
        data,
        sfreq,
        window=window,
        nperseg=effective_nperseg,
        noverlap=effective_noverlap,
        axis=-1,
        average=average,
        scaling=scaling,
    )
    # Accumule les puissances de bande pour chaque intervalle demandé
    band_powers: List[np.ndarray] = []
    # Parcourt les bandes dans l'ordre pour garantir la stabilité des colonnes
    for _, (low, high) in band_ranges.items():
        # Construit un masque fréquentiel pour isoler l'intervalle cible
        band_mask = (freqs >= low) & (freqs <= high)
        # Renvoie des zéros si aucune fréquence n'est disponible dans la bande
        if not np.any(band_mask):
            # Fournit un tenseur nul pour préserver la forme de sortie
            band_powers.append(np.zeros(psd.shape[:2]))
        else:
            # Moyenne la PSD sur la bande pour réduire la dimension temporelle
            band_powers.append(psd[:, :, band_mask].mean(axis=-1))
    # Empile les bandes pour conserver la structure epochs x canaux x bandes
    return np.stack(band_powers, axis=2)


def x__compute_welch_band_powers__mutmut_8(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule les puissances de bandes via Welch avec bornes sécurisées."""

    # Stocke le nombre d'échantillons pour calibrer les fenêtres de Welch
    n_times: int = data.shape[-1]
    # Calcule les paramètres Welch pour un appel robuste
    window, effective_nperseg, effective_noverlap, average, scaling = (
        _prepare_welch_parameters(config, )
    )
    # Calcule la densité spectrale de puissance par canal et par essai
    freqs, psd = signal.welch(
        data,
        sfreq,
        window=window,
        nperseg=effective_nperseg,
        noverlap=effective_noverlap,
        axis=-1,
        average=average,
        scaling=scaling,
    )
    # Accumule les puissances de bande pour chaque intervalle demandé
    band_powers: List[np.ndarray] = []
    # Parcourt les bandes dans l'ordre pour garantir la stabilité des colonnes
    for _, (low, high) in band_ranges.items():
        # Construit un masque fréquentiel pour isoler l'intervalle cible
        band_mask = (freqs >= low) & (freqs <= high)
        # Renvoie des zéros si aucune fréquence n'est disponible dans la bande
        if not np.any(band_mask):
            # Fournit un tenseur nul pour préserver la forme de sortie
            band_powers.append(np.zeros(psd.shape[:2]))
        else:
            # Moyenne la PSD sur la bande pour réduire la dimension temporelle
            band_powers.append(psd[:, :, band_mask].mean(axis=-1))
    # Empile les bandes pour conserver la structure epochs x canaux x bandes
    return np.stack(band_powers, axis=2)


def x__compute_welch_band_powers__mutmut_9(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule les puissances de bandes via Welch avec bornes sécurisées."""

    # Stocke le nombre d'échantillons pour calibrer les fenêtres de Welch
    n_times: int = data.shape[-1]
    # Calcule les paramètres Welch pour un appel robuste
    window, effective_nperseg, effective_noverlap, average, scaling = (
        _prepare_welch_parameters(config, n_times)
    )
    # Calcule la densité spectrale de puissance par canal et par essai
    freqs, psd = None
    # Accumule les puissances de bande pour chaque intervalle demandé
    band_powers: List[np.ndarray] = []
    # Parcourt les bandes dans l'ordre pour garantir la stabilité des colonnes
    for _, (low, high) in band_ranges.items():
        # Construit un masque fréquentiel pour isoler l'intervalle cible
        band_mask = (freqs >= low) & (freqs <= high)
        # Renvoie des zéros si aucune fréquence n'est disponible dans la bande
        if not np.any(band_mask):
            # Fournit un tenseur nul pour préserver la forme de sortie
            band_powers.append(np.zeros(psd.shape[:2]))
        else:
            # Moyenne la PSD sur la bande pour réduire la dimension temporelle
            band_powers.append(psd[:, :, band_mask].mean(axis=-1))
    # Empile les bandes pour conserver la structure epochs x canaux x bandes
    return np.stack(band_powers, axis=2)


def x__compute_welch_band_powers__mutmut_10(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule les puissances de bandes via Welch avec bornes sécurisées."""

    # Stocke le nombre d'échantillons pour calibrer les fenêtres de Welch
    n_times: int = data.shape[-1]
    # Calcule les paramètres Welch pour un appel robuste
    window, effective_nperseg, effective_noverlap, average, scaling = (
        _prepare_welch_parameters(config, n_times)
    )
    # Calcule la densité spectrale de puissance par canal et par essai
    freqs, psd = signal.welch(
        None,
        sfreq,
        window=window,
        nperseg=effective_nperseg,
        noverlap=effective_noverlap,
        axis=-1,
        average=average,
        scaling=scaling,
    )
    # Accumule les puissances de bande pour chaque intervalle demandé
    band_powers: List[np.ndarray] = []
    # Parcourt les bandes dans l'ordre pour garantir la stabilité des colonnes
    for _, (low, high) in band_ranges.items():
        # Construit un masque fréquentiel pour isoler l'intervalle cible
        band_mask = (freqs >= low) & (freqs <= high)
        # Renvoie des zéros si aucune fréquence n'est disponible dans la bande
        if not np.any(band_mask):
            # Fournit un tenseur nul pour préserver la forme de sortie
            band_powers.append(np.zeros(psd.shape[:2]))
        else:
            # Moyenne la PSD sur la bande pour réduire la dimension temporelle
            band_powers.append(psd[:, :, band_mask].mean(axis=-1))
    # Empile les bandes pour conserver la structure epochs x canaux x bandes
    return np.stack(band_powers, axis=2)


def x__compute_welch_band_powers__mutmut_11(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule les puissances de bandes via Welch avec bornes sécurisées."""

    # Stocke le nombre d'échantillons pour calibrer les fenêtres de Welch
    n_times: int = data.shape[-1]
    # Calcule les paramètres Welch pour un appel robuste
    window, effective_nperseg, effective_noverlap, average, scaling = (
        _prepare_welch_parameters(config, n_times)
    )
    # Calcule la densité spectrale de puissance par canal et par essai
    freqs, psd = signal.welch(
        data,
        None,
        window=window,
        nperseg=effective_nperseg,
        noverlap=effective_noverlap,
        axis=-1,
        average=average,
        scaling=scaling,
    )
    # Accumule les puissances de bande pour chaque intervalle demandé
    band_powers: List[np.ndarray] = []
    # Parcourt les bandes dans l'ordre pour garantir la stabilité des colonnes
    for _, (low, high) in band_ranges.items():
        # Construit un masque fréquentiel pour isoler l'intervalle cible
        band_mask = (freqs >= low) & (freqs <= high)
        # Renvoie des zéros si aucune fréquence n'est disponible dans la bande
        if not np.any(band_mask):
            # Fournit un tenseur nul pour préserver la forme de sortie
            band_powers.append(np.zeros(psd.shape[:2]))
        else:
            # Moyenne la PSD sur la bande pour réduire la dimension temporelle
            band_powers.append(psd[:, :, band_mask].mean(axis=-1))
    # Empile les bandes pour conserver la structure epochs x canaux x bandes
    return np.stack(band_powers, axis=2)


def x__compute_welch_band_powers__mutmut_12(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule les puissances de bandes via Welch avec bornes sécurisées."""

    # Stocke le nombre d'échantillons pour calibrer les fenêtres de Welch
    n_times: int = data.shape[-1]
    # Calcule les paramètres Welch pour un appel robuste
    window, effective_nperseg, effective_noverlap, average, scaling = (
        _prepare_welch_parameters(config, n_times)
    )
    # Calcule la densité spectrale de puissance par canal et par essai
    freqs, psd = signal.welch(
        data,
        sfreq,
        window=None,
        nperseg=effective_nperseg,
        noverlap=effective_noverlap,
        axis=-1,
        average=average,
        scaling=scaling,
    )
    # Accumule les puissances de bande pour chaque intervalle demandé
    band_powers: List[np.ndarray] = []
    # Parcourt les bandes dans l'ordre pour garantir la stabilité des colonnes
    for _, (low, high) in band_ranges.items():
        # Construit un masque fréquentiel pour isoler l'intervalle cible
        band_mask = (freqs >= low) & (freqs <= high)
        # Renvoie des zéros si aucune fréquence n'est disponible dans la bande
        if not np.any(band_mask):
            # Fournit un tenseur nul pour préserver la forme de sortie
            band_powers.append(np.zeros(psd.shape[:2]))
        else:
            # Moyenne la PSD sur la bande pour réduire la dimension temporelle
            band_powers.append(psd[:, :, band_mask].mean(axis=-1))
    # Empile les bandes pour conserver la structure epochs x canaux x bandes
    return np.stack(band_powers, axis=2)


def x__compute_welch_band_powers__mutmut_13(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule les puissances de bandes via Welch avec bornes sécurisées."""

    # Stocke le nombre d'échantillons pour calibrer les fenêtres de Welch
    n_times: int = data.shape[-1]
    # Calcule les paramètres Welch pour un appel robuste
    window, effective_nperseg, effective_noverlap, average, scaling = (
        _prepare_welch_parameters(config, n_times)
    )
    # Calcule la densité spectrale de puissance par canal et par essai
    freqs, psd = signal.welch(
        data,
        sfreq,
        window=window,
        nperseg=None,
        noverlap=effective_noverlap,
        axis=-1,
        average=average,
        scaling=scaling,
    )
    # Accumule les puissances de bande pour chaque intervalle demandé
    band_powers: List[np.ndarray] = []
    # Parcourt les bandes dans l'ordre pour garantir la stabilité des colonnes
    for _, (low, high) in band_ranges.items():
        # Construit un masque fréquentiel pour isoler l'intervalle cible
        band_mask = (freqs >= low) & (freqs <= high)
        # Renvoie des zéros si aucune fréquence n'est disponible dans la bande
        if not np.any(band_mask):
            # Fournit un tenseur nul pour préserver la forme de sortie
            band_powers.append(np.zeros(psd.shape[:2]))
        else:
            # Moyenne la PSD sur la bande pour réduire la dimension temporelle
            band_powers.append(psd[:, :, band_mask].mean(axis=-1))
    # Empile les bandes pour conserver la structure epochs x canaux x bandes
    return np.stack(band_powers, axis=2)


def x__compute_welch_band_powers__mutmut_14(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule les puissances de bandes via Welch avec bornes sécurisées."""

    # Stocke le nombre d'échantillons pour calibrer les fenêtres de Welch
    n_times: int = data.shape[-1]
    # Calcule les paramètres Welch pour un appel robuste
    window, effective_nperseg, effective_noverlap, average, scaling = (
        _prepare_welch_parameters(config, n_times)
    )
    # Calcule la densité spectrale de puissance par canal et par essai
    freqs, psd = signal.welch(
        data,
        sfreq,
        window=window,
        nperseg=effective_nperseg,
        noverlap=None,
        axis=-1,
        average=average,
        scaling=scaling,
    )
    # Accumule les puissances de bande pour chaque intervalle demandé
    band_powers: List[np.ndarray] = []
    # Parcourt les bandes dans l'ordre pour garantir la stabilité des colonnes
    for _, (low, high) in band_ranges.items():
        # Construit un masque fréquentiel pour isoler l'intervalle cible
        band_mask = (freqs >= low) & (freqs <= high)
        # Renvoie des zéros si aucune fréquence n'est disponible dans la bande
        if not np.any(band_mask):
            # Fournit un tenseur nul pour préserver la forme de sortie
            band_powers.append(np.zeros(psd.shape[:2]))
        else:
            # Moyenne la PSD sur la bande pour réduire la dimension temporelle
            band_powers.append(psd[:, :, band_mask].mean(axis=-1))
    # Empile les bandes pour conserver la structure epochs x canaux x bandes
    return np.stack(band_powers, axis=2)


def x__compute_welch_band_powers__mutmut_15(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule les puissances de bandes via Welch avec bornes sécurisées."""

    # Stocke le nombre d'échantillons pour calibrer les fenêtres de Welch
    n_times: int = data.shape[-1]
    # Calcule les paramètres Welch pour un appel robuste
    window, effective_nperseg, effective_noverlap, average, scaling = (
        _prepare_welch_parameters(config, n_times)
    )
    # Calcule la densité spectrale de puissance par canal et par essai
    freqs, psd = signal.welch(
        data,
        sfreq,
        window=window,
        nperseg=effective_nperseg,
        noverlap=effective_noverlap,
        axis=None,
        average=average,
        scaling=scaling,
    )
    # Accumule les puissances de bande pour chaque intervalle demandé
    band_powers: List[np.ndarray] = []
    # Parcourt les bandes dans l'ordre pour garantir la stabilité des colonnes
    for _, (low, high) in band_ranges.items():
        # Construit un masque fréquentiel pour isoler l'intervalle cible
        band_mask = (freqs >= low) & (freqs <= high)
        # Renvoie des zéros si aucune fréquence n'est disponible dans la bande
        if not np.any(band_mask):
            # Fournit un tenseur nul pour préserver la forme de sortie
            band_powers.append(np.zeros(psd.shape[:2]))
        else:
            # Moyenne la PSD sur la bande pour réduire la dimension temporelle
            band_powers.append(psd[:, :, band_mask].mean(axis=-1))
    # Empile les bandes pour conserver la structure epochs x canaux x bandes
    return np.stack(band_powers, axis=2)


def x__compute_welch_band_powers__mutmut_16(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule les puissances de bandes via Welch avec bornes sécurisées."""

    # Stocke le nombre d'échantillons pour calibrer les fenêtres de Welch
    n_times: int = data.shape[-1]
    # Calcule les paramètres Welch pour un appel robuste
    window, effective_nperseg, effective_noverlap, average, scaling = (
        _prepare_welch_parameters(config, n_times)
    )
    # Calcule la densité spectrale de puissance par canal et par essai
    freqs, psd = signal.welch(
        data,
        sfreq,
        window=window,
        nperseg=effective_nperseg,
        noverlap=effective_noverlap,
        axis=-1,
        average=None,
        scaling=scaling,
    )
    # Accumule les puissances de bande pour chaque intervalle demandé
    band_powers: List[np.ndarray] = []
    # Parcourt les bandes dans l'ordre pour garantir la stabilité des colonnes
    for _, (low, high) in band_ranges.items():
        # Construit un masque fréquentiel pour isoler l'intervalle cible
        band_mask = (freqs >= low) & (freqs <= high)
        # Renvoie des zéros si aucune fréquence n'est disponible dans la bande
        if not np.any(band_mask):
            # Fournit un tenseur nul pour préserver la forme de sortie
            band_powers.append(np.zeros(psd.shape[:2]))
        else:
            # Moyenne la PSD sur la bande pour réduire la dimension temporelle
            band_powers.append(psd[:, :, band_mask].mean(axis=-1))
    # Empile les bandes pour conserver la structure epochs x canaux x bandes
    return np.stack(band_powers, axis=2)


def x__compute_welch_band_powers__mutmut_17(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule les puissances de bandes via Welch avec bornes sécurisées."""

    # Stocke le nombre d'échantillons pour calibrer les fenêtres de Welch
    n_times: int = data.shape[-1]
    # Calcule les paramètres Welch pour un appel robuste
    window, effective_nperseg, effective_noverlap, average, scaling = (
        _prepare_welch_parameters(config, n_times)
    )
    # Calcule la densité spectrale de puissance par canal et par essai
    freqs, psd = signal.welch(
        data,
        sfreq,
        window=window,
        nperseg=effective_nperseg,
        noverlap=effective_noverlap,
        axis=-1,
        average=average,
        scaling=None,
    )
    # Accumule les puissances de bande pour chaque intervalle demandé
    band_powers: List[np.ndarray] = []
    # Parcourt les bandes dans l'ordre pour garantir la stabilité des colonnes
    for _, (low, high) in band_ranges.items():
        # Construit un masque fréquentiel pour isoler l'intervalle cible
        band_mask = (freqs >= low) & (freqs <= high)
        # Renvoie des zéros si aucune fréquence n'est disponible dans la bande
        if not np.any(band_mask):
            # Fournit un tenseur nul pour préserver la forme de sortie
            band_powers.append(np.zeros(psd.shape[:2]))
        else:
            # Moyenne la PSD sur la bande pour réduire la dimension temporelle
            band_powers.append(psd[:, :, band_mask].mean(axis=-1))
    # Empile les bandes pour conserver la structure epochs x canaux x bandes
    return np.stack(band_powers, axis=2)


def x__compute_welch_band_powers__mutmut_18(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule les puissances de bandes via Welch avec bornes sécurisées."""

    # Stocke le nombre d'échantillons pour calibrer les fenêtres de Welch
    n_times: int = data.shape[-1]
    # Calcule les paramètres Welch pour un appel robuste
    window, effective_nperseg, effective_noverlap, average, scaling = (
        _prepare_welch_parameters(config, n_times)
    )
    # Calcule la densité spectrale de puissance par canal et par essai
    freqs, psd = signal.welch(
        sfreq,
        window=window,
        nperseg=effective_nperseg,
        noverlap=effective_noverlap,
        axis=-1,
        average=average,
        scaling=scaling,
    )
    # Accumule les puissances de bande pour chaque intervalle demandé
    band_powers: List[np.ndarray] = []
    # Parcourt les bandes dans l'ordre pour garantir la stabilité des colonnes
    for _, (low, high) in band_ranges.items():
        # Construit un masque fréquentiel pour isoler l'intervalle cible
        band_mask = (freqs >= low) & (freqs <= high)
        # Renvoie des zéros si aucune fréquence n'est disponible dans la bande
        if not np.any(band_mask):
            # Fournit un tenseur nul pour préserver la forme de sortie
            band_powers.append(np.zeros(psd.shape[:2]))
        else:
            # Moyenne la PSD sur la bande pour réduire la dimension temporelle
            band_powers.append(psd[:, :, band_mask].mean(axis=-1))
    # Empile les bandes pour conserver la structure epochs x canaux x bandes
    return np.stack(band_powers, axis=2)


def x__compute_welch_band_powers__mutmut_19(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule les puissances de bandes via Welch avec bornes sécurisées."""

    # Stocke le nombre d'échantillons pour calibrer les fenêtres de Welch
    n_times: int = data.shape[-1]
    # Calcule les paramètres Welch pour un appel robuste
    window, effective_nperseg, effective_noverlap, average, scaling = (
        _prepare_welch_parameters(config, n_times)
    )
    # Calcule la densité spectrale de puissance par canal et par essai
    freqs, psd = signal.welch(
        data,
        window=window,
        nperseg=effective_nperseg,
        noverlap=effective_noverlap,
        axis=-1,
        average=average,
        scaling=scaling,
    )
    # Accumule les puissances de bande pour chaque intervalle demandé
    band_powers: List[np.ndarray] = []
    # Parcourt les bandes dans l'ordre pour garantir la stabilité des colonnes
    for _, (low, high) in band_ranges.items():
        # Construit un masque fréquentiel pour isoler l'intervalle cible
        band_mask = (freqs >= low) & (freqs <= high)
        # Renvoie des zéros si aucune fréquence n'est disponible dans la bande
        if not np.any(band_mask):
            # Fournit un tenseur nul pour préserver la forme de sortie
            band_powers.append(np.zeros(psd.shape[:2]))
        else:
            # Moyenne la PSD sur la bande pour réduire la dimension temporelle
            band_powers.append(psd[:, :, band_mask].mean(axis=-1))
    # Empile les bandes pour conserver la structure epochs x canaux x bandes
    return np.stack(band_powers, axis=2)


def x__compute_welch_band_powers__mutmut_20(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule les puissances de bandes via Welch avec bornes sécurisées."""

    # Stocke le nombre d'échantillons pour calibrer les fenêtres de Welch
    n_times: int = data.shape[-1]
    # Calcule les paramètres Welch pour un appel robuste
    window, effective_nperseg, effective_noverlap, average, scaling = (
        _prepare_welch_parameters(config, n_times)
    )
    # Calcule la densité spectrale de puissance par canal et par essai
    freqs, psd = signal.welch(
        data,
        sfreq,
        nperseg=effective_nperseg,
        noverlap=effective_noverlap,
        axis=-1,
        average=average,
        scaling=scaling,
    )
    # Accumule les puissances de bande pour chaque intervalle demandé
    band_powers: List[np.ndarray] = []
    # Parcourt les bandes dans l'ordre pour garantir la stabilité des colonnes
    for _, (low, high) in band_ranges.items():
        # Construit un masque fréquentiel pour isoler l'intervalle cible
        band_mask = (freqs >= low) & (freqs <= high)
        # Renvoie des zéros si aucune fréquence n'est disponible dans la bande
        if not np.any(band_mask):
            # Fournit un tenseur nul pour préserver la forme de sortie
            band_powers.append(np.zeros(psd.shape[:2]))
        else:
            # Moyenne la PSD sur la bande pour réduire la dimension temporelle
            band_powers.append(psd[:, :, band_mask].mean(axis=-1))
    # Empile les bandes pour conserver la structure epochs x canaux x bandes
    return np.stack(band_powers, axis=2)


def x__compute_welch_band_powers__mutmut_21(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule les puissances de bandes via Welch avec bornes sécurisées."""

    # Stocke le nombre d'échantillons pour calibrer les fenêtres de Welch
    n_times: int = data.shape[-1]
    # Calcule les paramètres Welch pour un appel robuste
    window, effective_nperseg, effective_noverlap, average, scaling = (
        _prepare_welch_parameters(config, n_times)
    )
    # Calcule la densité spectrale de puissance par canal et par essai
    freqs, psd = signal.welch(
        data,
        sfreq,
        window=window,
        noverlap=effective_noverlap,
        axis=-1,
        average=average,
        scaling=scaling,
    )
    # Accumule les puissances de bande pour chaque intervalle demandé
    band_powers: List[np.ndarray] = []
    # Parcourt les bandes dans l'ordre pour garantir la stabilité des colonnes
    for _, (low, high) in band_ranges.items():
        # Construit un masque fréquentiel pour isoler l'intervalle cible
        band_mask = (freqs >= low) & (freqs <= high)
        # Renvoie des zéros si aucune fréquence n'est disponible dans la bande
        if not np.any(band_mask):
            # Fournit un tenseur nul pour préserver la forme de sortie
            band_powers.append(np.zeros(psd.shape[:2]))
        else:
            # Moyenne la PSD sur la bande pour réduire la dimension temporelle
            band_powers.append(psd[:, :, band_mask].mean(axis=-1))
    # Empile les bandes pour conserver la structure epochs x canaux x bandes
    return np.stack(band_powers, axis=2)


def x__compute_welch_band_powers__mutmut_22(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule les puissances de bandes via Welch avec bornes sécurisées."""

    # Stocke le nombre d'échantillons pour calibrer les fenêtres de Welch
    n_times: int = data.shape[-1]
    # Calcule les paramètres Welch pour un appel robuste
    window, effective_nperseg, effective_noverlap, average, scaling = (
        _prepare_welch_parameters(config, n_times)
    )
    # Calcule la densité spectrale de puissance par canal et par essai
    freqs, psd = signal.welch(
        data,
        sfreq,
        window=window,
        nperseg=effective_nperseg,
        axis=-1,
        average=average,
        scaling=scaling,
    )
    # Accumule les puissances de bande pour chaque intervalle demandé
    band_powers: List[np.ndarray] = []
    # Parcourt les bandes dans l'ordre pour garantir la stabilité des colonnes
    for _, (low, high) in band_ranges.items():
        # Construit un masque fréquentiel pour isoler l'intervalle cible
        band_mask = (freqs >= low) & (freqs <= high)
        # Renvoie des zéros si aucune fréquence n'est disponible dans la bande
        if not np.any(band_mask):
            # Fournit un tenseur nul pour préserver la forme de sortie
            band_powers.append(np.zeros(psd.shape[:2]))
        else:
            # Moyenne la PSD sur la bande pour réduire la dimension temporelle
            band_powers.append(psd[:, :, band_mask].mean(axis=-1))
    # Empile les bandes pour conserver la structure epochs x canaux x bandes
    return np.stack(band_powers, axis=2)


def x__compute_welch_band_powers__mutmut_23(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule les puissances de bandes via Welch avec bornes sécurisées."""

    # Stocke le nombre d'échantillons pour calibrer les fenêtres de Welch
    n_times: int = data.shape[-1]
    # Calcule les paramètres Welch pour un appel robuste
    window, effective_nperseg, effective_noverlap, average, scaling = (
        _prepare_welch_parameters(config, n_times)
    )
    # Calcule la densité spectrale de puissance par canal et par essai
    freqs, psd = signal.welch(
        data,
        sfreq,
        window=window,
        nperseg=effective_nperseg,
        noverlap=effective_noverlap,
        average=average,
        scaling=scaling,
    )
    # Accumule les puissances de bande pour chaque intervalle demandé
    band_powers: List[np.ndarray] = []
    # Parcourt les bandes dans l'ordre pour garantir la stabilité des colonnes
    for _, (low, high) in band_ranges.items():
        # Construit un masque fréquentiel pour isoler l'intervalle cible
        band_mask = (freqs >= low) & (freqs <= high)
        # Renvoie des zéros si aucune fréquence n'est disponible dans la bande
        if not np.any(band_mask):
            # Fournit un tenseur nul pour préserver la forme de sortie
            band_powers.append(np.zeros(psd.shape[:2]))
        else:
            # Moyenne la PSD sur la bande pour réduire la dimension temporelle
            band_powers.append(psd[:, :, band_mask].mean(axis=-1))
    # Empile les bandes pour conserver la structure epochs x canaux x bandes
    return np.stack(band_powers, axis=2)


def x__compute_welch_band_powers__mutmut_24(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule les puissances de bandes via Welch avec bornes sécurisées."""

    # Stocke le nombre d'échantillons pour calibrer les fenêtres de Welch
    n_times: int = data.shape[-1]
    # Calcule les paramètres Welch pour un appel robuste
    window, effective_nperseg, effective_noverlap, average, scaling = (
        _prepare_welch_parameters(config, n_times)
    )
    # Calcule la densité spectrale de puissance par canal et par essai
    freqs, psd = signal.welch(
        data,
        sfreq,
        window=window,
        nperseg=effective_nperseg,
        noverlap=effective_noverlap,
        axis=-1,
        scaling=scaling,
    )
    # Accumule les puissances de bande pour chaque intervalle demandé
    band_powers: List[np.ndarray] = []
    # Parcourt les bandes dans l'ordre pour garantir la stabilité des colonnes
    for _, (low, high) in band_ranges.items():
        # Construit un masque fréquentiel pour isoler l'intervalle cible
        band_mask = (freqs >= low) & (freqs <= high)
        # Renvoie des zéros si aucune fréquence n'est disponible dans la bande
        if not np.any(band_mask):
            # Fournit un tenseur nul pour préserver la forme de sortie
            band_powers.append(np.zeros(psd.shape[:2]))
        else:
            # Moyenne la PSD sur la bande pour réduire la dimension temporelle
            band_powers.append(psd[:, :, band_mask].mean(axis=-1))
    # Empile les bandes pour conserver la structure epochs x canaux x bandes
    return np.stack(band_powers, axis=2)


def x__compute_welch_band_powers__mutmut_25(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule les puissances de bandes via Welch avec bornes sécurisées."""

    # Stocke le nombre d'échantillons pour calibrer les fenêtres de Welch
    n_times: int = data.shape[-1]
    # Calcule les paramètres Welch pour un appel robuste
    window, effective_nperseg, effective_noverlap, average, scaling = (
        _prepare_welch_parameters(config, n_times)
    )
    # Calcule la densité spectrale de puissance par canal et par essai
    freqs, psd = signal.welch(
        data,
        sfreq,
        window=window,
        nperseg=effective_nperseg,
        noverlap=effective_noverlap,
        axis=-1,
        average=average,
        )
    # Accumule les puissances de bande pour chaque intervalle demandé
    band_powers: List[np.ndarray] = []
    # Parcourt les bandes dans l'ordre pour garantir la stabilité des colonnes
    for _, (low, high) in band_ranges.items():
        # Construit un masque fréquentiel pour isoler l'intervalle cible
        band_mask = (freqs >= low) & (freqs <= high)
        # Renvoie des zéros si aucune fréquence n'est disponible dans la bande
        if not np.any(band_mask):
            # Fournit un tenseur nul pour préserver la forme de sortie
            band_powers.append(np.zeros(psd.shape[:2]))
        else:
            # Moyenne la PSD sur la bande pour réduire la dimension temporelle
            band_powers.append(psd[:, :, band_mask].mean(axis=-1))
    # Empile les bandes pour conserver la structure epochs x canaux x bandes
    return np.stack(band_powers, axis=2)


def x__compute_welch_band_powers__mutmut_26(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule les puissances de bandes via Welch avec bornes sécurisées."""

    # Stocke le nombre d'échantillons pour calibrer les fenêtres de Welch
    n_times: int = data.shape[-1]
    # Calcule les paramètres Welch pour un appel robuste
    window, effective_nperseg, effective_noverlap, average, scaling = (
        _prepare_welch_parameters(config, n_times)
    )
    # Calcule la densité spectrale de puissance par canal et par essai
    freqs, psd = signal.welch(
        data,
        sfreq,
        window=window,
        nperseg=effective_nperseg,
        noverlap=effective_noverlap,
        axis=+1,
        average=average,
        scaling=scaling,
    )
    # Accumule les puissances de bande pour chaque intervalle demandé
    band_powers: List[np.ndarray] = []
    # Parcourt les bandes dans l'ordre pour garantir la stabilité des colonnes
    for _, (low, high) in band_ranges.items():
        # Construit un masque fréquentiel pour isoler l'intervalle cible
        band_mask = (freqs >= low) & (freqs <= high)
        # Renvoie des zéros si aucune fréquence n'est disponible dans la bande
        if not np.any(band_mask):
            # Fournit un tenseur nul pour préserver la forme de sortie
            band_powers.append(np.zeros(psd.shape[:2]))
        else:
            # Moyenne la PSD sur la bande pour réduire la dimension temporelle
            band_powers.append(psd[:, :, band_mask].mean(axis=-1))
    # Empile les bandes pour conserver la structure epochs x canaux x bandes
    return np.stack(band_powers, axis=2)


def x__compute_welch_band_powers__mutmut_27(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule les puissances de bandes via Welch avec bornes sécurisées."""

    # Stocke le nombre d'échantillons pour calibrer les fenêtres de Welch
    n_times: int = data.shape[-1]
    # Calcule les paramètres Welch pour un appel robuste
    window, effective_nperseg, effective_noverlap, average, scaling = (
        _prepare_welch_parameters(config, n_times)
    )
    # Calcule la densité spectrale de puissance par canal et par essai
    freqs, psd = signal.welch(
        data,
        sfreq,
        window=window,
        nperseg=effective_nperseg,
        noverlap=effective_noverlap,
        axis=-2,
        average=average,
        scaling=scaling,
    )
    # Accumule les puissances de bande pour chaque intervalle demandé
    band_powers: List[np.ndarray] = []
    # Parcourt les bandes dans l'ordre pour garantir la stabilité des colonnes
    for _, (low, high) in band_ranges.items():
        # Construit un masque fréquentiel pour isoler l'intervalle cible
        band_mask = (freqs >= low) & (freqs <= high)
        # Renvoie des zéros si aucune fréquence n'est disponible dans la bande
        if not np.any(band_mask):
            # Fournit un tenseur nul pour préserver la forme de sortie
            band_powers.append(np.zeros(psd.shape[:2]))
        else:
            # Moyenne la PSD sur la bande pour réduire la dimension temporelle
            band_powers.append(psd[:, :, band_mask].mean(axis=-1))
    # Empile les bandes pour conserver la structure epochs x canaux x bandes
    return np.stack(band_powers, axis=2)


def x__compute_welch_band_powers__mutmut_28(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule les puissances de bandes via Welch avec bornes sécurisées."""

    # Stocke le nombre d'échantillons pour calibrer les fenêtres de Welch
    n_times: int = data.shape[-1]
    # Calcule les paramètres Welch pour un appel robuste
    window, effective_nperseg, effective_noverlap, average, scaling = (
        _prepare_welch_parameters(config, n_times)
    )
    # Calcule la densité spectrale de puissance par canal et par essai
    freqs, psd = signal.welch(
        data,
        sfreq,
        window=window,
        nperseg=effective_nperseg,
        noverlap=effective_noverlap,
        axis=-1,
        average=average,
        scaling=scaling,
    )
    # Accumule les puissances de bande pour chaque intervalle demandé
    band_powers: List[np.ndarray] = None
    # Parcourt les bandes dans l'ordre pour garantir la stabilité des colonnes
    for _, (low, high) in band_ranges.items():
        # Construit un masque fréquentiel pour isoler l'intervalle cible
        band_mask = (freqs >= low) & (freqs <= high)
        # Renvoie des zéros si aucune fréquence n'est disponible dans la bande
        if not np.any(band_mask):
            # Fournit un tenseur nul pour préserver la forme de sortie
            band_powers.append(np.zeros(psd.shape[:2]))
        else:
            # Moyenne la PSD sur la bande pour réduire la dimension temporelle
            band_powers.append(psd[:, :, band_mask].mean(axis=-1))
    # Empile les bandes pour conserver la structure epochs x canaux x bandes
    return np.stack(band_powers, axis=2)


def x__compute_welch_band_powers__mutmut_29(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule les puissances de bandes via Welch avec bornes sécurisées."""

    # Stocke le nombre d'échantillons pour calibrer les fenêtres de Welch
    n_times: int = data.shape[-1]
    # Calcule les paramètres Welch pour un appel robuste
    window, effective_nperseg, effective_noverlap, average, scaling = (
        _prepare_welch_parameters(config, n_times)
    )
    # Calcule la densité spectrale de puissance par canal et par essai
    freqs, psd = signal.welch(
        data,
        sfreq,
        window=window,
        nperseg=effective_nperseg,
        noverlap=effective_noverlap,
        axis=-1,
        average=average,
        scaling=scaling,
    )
    # Accumule les puissances de bande pour chaque intervalle demandé
    band_powers: List[np.ndarray] = []
    # Parcourt les bandes dans l'ordre pour garantir la stabilité des colonnes
    for _, (low, high) in band_ranges.items():
        # Construit un masque fréquentiel pour isoler l'intervalle cible
        band_mask = None
        # Renvoie des zéros si aucune fréquence n'est disponible dans la bande
        if not np.any(band_mask):
            # Fournit un tenseur nul pour préserver la forme de sortie
            band_powers.append(np.zeros(psd.shape[:2]))
        else:
            # Moyenne la PSD sur la bande pour réduire la dimension temporelle
            band_powers.append(psd[:, :, band_mask].mean(axis=-1))
    # Empile les bandes pour conserver la structure epochs x canaux x bandes
    return np.stack(band_powers, axis=2)


def x__compute_welch_band_powers__mutmut_30(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule les puissances de bandes via Welch avec bornes sécurisées."""

    # Stocke le nombre d'échantillons pour calibrer les fenêtres de Welch
    n_times: int = data.shape[-1]
    # Calcule les paramètres Welch pour un appel robuste
    window, effective_nperseg, effective_noverlap, average, scaling = (
        _prepare_welch_parameters(config, n_times)
    )
    # Calcule la densité spectrale de puissance par canal et par essai
    freqs, psd = signal.welch(
        data,
        sfreq,
        window=window,
        nperseg=effective_nperseg,
        noverlap=effective_noverlap,
        axis=-1,
        average=average,
        scaling=scaling,
    )
    # Accumule les puissances de bande pour chaque intervalle demandé
    band_powers: List[np.ndarray] = []
    # Parcourt les bandes dans l'ordre pour garantir la stabilité des colonnes
    for _, (low, high) in band_ranges.items():
        # Construit un masque fréquentiel pour isoler l'intervalle cible
        band_mask = (freqs >= low) | (freqs <= high)
        # Renvoie des zéros si aucune fréquence n'est disponible dans la bande
        if not np.any(band_mask):
            # Fournit un tenseur nul pour préserver la forme de sortie
            band_powers.append(np.zeros(psd.shape[:2]))
        else:
            # Moyenne la PSD sur la bande pour réduire la dimension temporelle
            band_powers.append(psd[:, :, band_mask].mean(axis=-1))
    # Empile les bandes pour conserver la structure epochs x canaux x bandes
    return np.stack(band_powers, axis=2)


def x__compute_welch_band_powers__mutmut_31(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule les puissances de bandes via Welch avec bornes sécurisées."""

    # Stocke le nombre d'échantillons pour calibrer les fenêtres de Welch
    n_times: int = data.shape[-1]
    # Calcule les paramètres Welch pour un appel robuste
    window, effective_nperseg, effective_noverlap, average, scaling = (
        _prepare_welch_parameters(config, n_times)
    )
    # Calcule la densité spectrale de puissance par canal et par essai
    freqs, psd = signal.welch(
        data,
        sfreq,
        window=window,
        nperseg=effective_nperseg,
        noverlap=effective_noverlap,
        axis=-1,
        average=average,
        scaling=scaling,
    )
    # Accumule les puissances de bande pour chaque intervalle demandé
    band_powers: List[np.ndarray] = []
    # Parcourt les bandes dans l'ordre pour garantir la stabilité des colonnes
    for _, (low, high) in band_ranges.items():
        # Construit un masque fréquentiel pour isoler l'intervalle cible
        band_mask = (freqs > low) & (freqs <= high)
        # Renvoie des zéros si aucune fréquence n'est disponible dans la bande
        if not np.any(band_mask):
            # Fournit un tenseur nul pour préserver la forme de sortie
            band_powers.append(np.zeros(psd.shape[:2]))
        else:
            # Moyenne la PSD sur la bande pour réduire la dimension temporelle
            band_powers.append(psd[:, :, band_mask].mean(axis=-1))
    # Empile les bandes pour conserver la structure epochs x canaux x bandes
    return np.stack(band_powers, axis=2)


def x__compute_welch_band_powers__mutmut_32(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule les puissances de bandes via Welch avec bornes sécurisées."""

    # Stocke le nombre d'échantillons pour calibrer les fenêtres de Welch
    n_times: int = data.shape[-1]
    # Calcule les paramètres Welch pour un appel robuste
    window, effective_nperseg, effective_noverlap, average, scaling = (
        _prepare_welch_parameters(config, n_times)
    )
    # Calcule la densité spectrale de puissance par canal et par essai
    freqs, psd = signal.welch(
        data,
        sfreq,
        window=window,
        nperseg=effective_nperseg,
        noverlap=effective_noverlap,
        axis=-1,
        average=average,
        scaling=scaling,
    )
    # Accumule les puissances de bande pour chaque intervalle demandé
    band_powers: List[np.ndarray] = []
    # Parcourt les bandes dans l'ordre pour garantir la stabilité des colonnes
    for _, (low, high) in band_ranges.items():
        # Construit un masque fréquentiel pour isoler l'intervalle cible
        band_mask = (freqs >= low) & (freqs < high)
        # Renvoie des zéros si aucune fréquence n'est disponible dans la bande
        if not np.any(band_mask):
            # Fournit un tenseur nul pour préserver la forme de sortie
            band_powers.append(np.zeros(psd.shape[:2]))
        else:
            # Moyenne la PSD sur la bande pour réduire la dimension temporelle
            band_powers.append(psd[:, :, band_mask].mean(axis=-1))
    # Empile les bandes pour conserver la structure epochs x canaux x bandes
    return np.stack(band_powers, axis=2)


def x__compute_welch_band_powers__mutmut_33(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule les puissances de bandes via Welch avec bornes sécurisées."""

    # Stocke le nombre d'échantillons pour calibrer les fenêtres de Welch
    n_times: int = data.shape[-1]
    # Calcule les paramètres Welch pour un appel robuste
    window, effective_nperseg, effective_noverlap, average, scaling = (
        _prepare_welch_parameters(config, n_times)
    )
    # Calcule la densité spectrale de puissance par canal et par essai
    freqs, psd = signal.welch(
        data,
        sfreq,
        window=window,
        nperseg=effective_nperseg,
        noverlap=effective_noverlap,
        axis=-1,
        average=average,
        scaling=scaling,
    )
    # Accumule les puissances de bande pour chaque intervalle demandé
    band_powers: List[np.ndarray] = []
    # Parcourt les bandes dans l'ordre pour garantir la stabilité des colonnes
    for _, (low, high) in band_ranges.items():
        # Construit un masque fréquentiel pour isoler l'intervalle cible
        band_mask = (freqs >= low) & (freqs <= high)
        # Renvoie des zéros si aucune fréquence n'est disponible dans la bande
        if np.any(band_mask):
            # Fournit un tenseur nul pour préserver la forme de sortie
            band_powers.append(np.zeros(psd.shape[:2]))
        else:
            # Moyenne la PSD sur la bande pour réduire la dimension temporelle
            band_powers.append(psd[:, :, band_mask].mean(axis=-1))
    # Empile les bandes pour conserver la structure epochs x canaux x bandes
    return np.stack(band_powers, axis=2)


def x__compute_welch_band_powers__mutmut_34(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule les puissances de bandes via Welch avec bornes sécurisées."""

    # Stocke le nombre d'échantillons pour calibrer les fenêtres de Welch
    n_times: int = data.shape[-1]
    # Calcule les paramètres Welch pour un appel robuste
    window, effective_nperseg, effective_noverlap, average, scaling = (
        _prepare_welch_parameters(config, n_times)
    )
    # Calcule la densité spectrale de puissance par canal et par essai
    freqs, psd = signal.welch(
        data,
        sfreq,
        window=window,
        nperseg=effective_nperseg,
        noverlap=effective_noverlap,
        axis=-1,
        average=average,
        scaling=scaling,
    )
    # Accumule les puissances de bande pour chaque intervalle demandé
    band_powers: List[np.ndarray] = []
    # Parcourt les bandes dans l'ordre pour garantir la stabilité des colonnes
    for _, (low, high) in band_ranges.items():
        # Construit un masque fréquentiel pour isoler l'intervalle cible
        band_mask = (freqs >= low) & (freqs <= high)
        # Renvoie des zéros si aucune fréquence n'est disponible dans la bande
        if not np.any(None):
            # Fournit un tenseur nul pour préserver la forme de sortie
            band_powers.append(np.zeros(psd.shape[:2]))
        else:
            # Moyenne la PSD sur la bande pour réduire la dimension temporelle
            band_powers.append(psd[:, :, band_mask].mean(axis=-1))
    # Empile les bandes pour conserver la structure epochs x canaux x bandes
    return np.stack(band_powers, axis=2)


def x__compute_welch_band_powers__mutmut_35(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule les puissances de bandes via Welch avec bornes sécurisées."""

    # Stocke le nombre d'échantillons pour calibrer les fenêtres de Welch
    n_times: int = data.shape[-1]
    # Calcule les paramètres Welch pour un appel robuste
    window, effective_nperseg, effective_noverlap, average, scaling = (
        _prepare_welch_parameters(config, n_times)
    )
    # Calcule la densité spectrale de puissance par canal et par essai
    freqs, psd = signal.welch(
        data,
        sfreq,
        window=window,
        nperseg=effective_nperseg,
        noverlap=effective_noverlap,
        axis=-1,
        average=average,
        scaling=scaling,
    )
    # Accumule les puissances de bande pour chaque intervalle demandé
    band_powers: List[np.ndarray] = []
    # Parcourt les bandes dans l'ordre pour garantir la stabilité des colonnes
    for _, (low, high) in band_ranges.items():
        # Construit un masque fréquentiel pour isoler l'intervalle cible
        band_mask = (freqs >= low) & (freqs <= high)
        # Renvoie des zéros si aucune fréquence n'est disponible dans la bande
        if not np.any(band_mask):
            # Fournit un tenseur nul pour préserver la forme de sortie
            band_powers.append(None)
        else:
            # Moyenne la PSD sur la bande pour réduire la dimension temporelle
            band_powers.append(psd[:, :, band_mask].mean(axis=-1))
    # Empile les bandes pour conserver la structure epochs x canaux x bandes
    return np.stack(band_powers, axis=2)


def x__compute_welch_band_powers__mutmut_36(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule les puissances de bandes via Welch avec bornes sécurisées."""

    # Stocke le nombre d'échantillons pour calibrer les fenêtres de Welch
    n_times: int = data.shape[-1]
    # Calcule les paramètres Welch pour un appel robuste
    window, effective_nperseg, effective_noverlap, average, scaling = (
        _prepare_welch_parameters(config, n_times)
    )
    # Calcule la densité spectrale de puissance par canal et par essai
    freqs, psd = signal.welch(
        data,
        sfreq,
        window=window,
        nperseg=effective_nperseg,
        noverlap=effective_noverlap,
        axis=-1,
        average=average,
        scaling=scaling,
    )
    # Accumule les puissances de bande pour chaque intervalle demandé
    band_powers: List[np.ndarray] = []
    # Parcourt les bandes dans l'ordre pour garantir la stabilité des colonnes
    for _, (low, high) in band_ranges.items():
        # Construit un masque fréquentiel pour isoler l'intervalle cible
        band_mask = (freqs >= low) & (freqs <= high)
        # Renvoie des zéros si aucune fréquence n'est disponible dans la bande
        if not np.any(band_mask):
            # Fournit un tenseur nul pour préserver la forme de sortie
            band_powers.append(np.zeros(None))
        else:
            # Moyenne la PSD sur la bande pour réduire la dimension temporelle
            band_powers.append(psd[:, :, band_mask].mean(axis=-1))
    # Empile les bandes pour conserver la structure epochs x canaux x bandes
    return np.stack(band_powers, axis=2)


def x__compute_welch_band_powers__mutmut_37(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule les puissances de bandes via Welch avec bornes sécurisées."""

    # Stocke le nombre d'échantillons pour calibrer les fenêtres de Welch
    n_times: int = data.shape[-1]
    # Calcule les paramètres Welch pour un appel robuste
    window, effective_nperseg, effective_noverlap, average, scaling = (
        _prepare_welch_parameters(config, n_times)
    )
    # Calcule la densité spectrale de puissance par canal et par essai
    freqs, psd = signal.welch(
        data,
        sfreq,
        window=window,
        nperseg=effective_nperseg,
        noverlap=effective_noverlap,
        axis=-1,
        average=average,
        scaling=scaling,
    )
    # Accumule les puissances de bande pour chaque intervalle demandé
    band_powers: List[np.ndarray] = []
    # Parcourt les bandes dans l'ordre pour garantir la stabilité des colonnes
    for _, (low, high) in band_ranges.items():
        # Construit un masque fréquentiel pour isoler l'intervalle cible
        band_mask = (freqs >= low) & (freqs <= high)
        # Renvoie des zéros si aucune fréquence n'est disponible dans la bande
        if not np.any(band_mask):
            # Fournit un tenseur nul pour préserver la forme de sortie
            band_powers.append(np.zeros(psd.shape[:3]))
        else:
            # Moyenne la PSD sur la bande pour réduire la dimension temporelle
            band_powers.append(psd[:, :, band_mask].mean(axis=-1))
    # Empile les bandes pour conserver la structure epochs x canaux x bandes
    return np.stack(band_powers, axis=2)


def x__compute_welch_band_powers__mutmut_38(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule les puissances de bandes via Welch avec bornes sécurisées."""

    # Stocke le nombre d'échantillons pour calibrer les fenêtres de Welch
    n_times: int = data.shape[-1]
    # Calcule les paramètres Welch pour un appel robuste
    window, effective_nperseg, effective_noverlap, average, scaling = (
        _prepare_welch_parameters(config, n_times)
    )
    # Calcule la densité spectrale de puissance par canal et par essai
    freqs, psd = signal.welch(
        data,
        sfreq,
        window=window,
        nperseg=effective_nperseg,
        noverlap=effective_noverlap,
        axis=-1,
        average=average,
        scaling=scaling,
    )
    # Accumule les puissances de bande pour chaque intervalle demandé
    band_powers: List[np.ndarray] = []
    # Parcourt les bandes dans l'ordre pour garantir la stabilité des colonnes
    for _, (low, high) in band_ranges.items():
        # Construit un masque fréquentiel pour isoler l'intervalle cible
        band_mask = (freqs >= low) & (freqs <= high)
        # Renvoie des zéros si aucune fréquence n'est disponible dans la bande
        if not np.any(band_mask):
            # Fournit un tenseur nul pour préserver la forme de sortie
            band_powers.append(np.zeros(psd.shape[:2]))
        else:
            # Moyenne la PSD sur la bande pour réduire la dimension temporelle
            band_powers.append(None)
    # Empile les bandes pour conserver la structure epochs x canaux x bandes
    return np.stack(band_powers, axis=2)


def x__compute_welch_band_powers__mutmut_39(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule les puissances de bandes via Welch avec bornes sécurisées."""

    # Stocke le nombre d'échantillons pour calibrer les fenêtres de Welch
    n_times: int = data.shape[-1]
    # Calcule les paramètres Welch pour un appel robuste
    window, effective_nperseg, effective_noverlap, average, scaling = (
        _prepare_welch_parameters(config, n_times)
    )
    # Calcule la densité spectrale de puissance par canal et par essai
    freqs, psd = signal.welch(
        data,
        sfreq,
        window=window,
        nperseg=effective_nperseg,
        noverlap=effective_noverlap,
        axis=-1,
        average=average,
        scaling=scaling,
    )
    # Accumule les puissances de bande pour chaque intervalle demandé
    band_powers: List[np.ndarray] = []
    # Parcourt les bandes dans l'ordre pour garantir la stabilité des colonnes
    for _, (low, high) in band_ranges.items():
        # Construit un masque fréquentiel pour isoler l'intervalle cible
        band_mask = (freqs >= low) & (freqs <= high)
        # Renvoie des zéros si aucune fréquence n'est disponible dans la bande
        if not np.any(band_mask):
            # Fournit un tenseur nul pour préserver la forme de sortie
            band_powers.append(np.zeros(psd.shape[:2]))
        else:
            # Moyenne la PSD sur la bande pour réduire la dimension temporelle
            band_powers.append(psd[:, :, band_mask].mean(axis=None))
    # Empile les bandes pour conserver la structure epochs x canaux x bandes
    return np.stack(band_powers, axis=2)


def x__compute_welch_band_powers__mutmut_40(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule les puissances de bandes via Welch avec bornes sécurisées."""

    # Stocke le nombre d'échantillons pour calibrer les fenêtres de Welch
    n_times: int = data.shape[-1]
    # Calcule les paramètres Welch pour un appel robuste
    window, effective_nperseg, effective_noverlap, average, scaling = (
        _prepare_welch_parameters(config, n_times)
    )
    # Calcule la densité spectrale de puissance par canal et par essai
    freqs, psd = signal.welch(
        data,
        sfreq,
        window=window,
        nperseg=effective_nperseg,
        noverlap=effective_noverlap,
        axis=-1,
        average=average,
        scaling=scaling,
    )
    # Accumule les puissances de bande pour chaque intervalle demandé
    band_powers: List[np.ndarray] = []
    # Parcourt les bandes dans l'ordre pour garantir la stabilité des colonnes
    for _, (low, high) in band_ranges.items():
        # Construit un masque fréquentiel pour isoler l'intervalle cible
        band_mask = (freqs >= low) & (freqs <= high)
        # Renvoie des zéros si aucune fréquence n'est disponible dans la bande
        if not np.any(band_mask):
            # Fournit un tenseur nul pour préserver la forme de sortie
            band_powers.append(np.zeros(psd.shape[:2]))
        else:
            # Moyenne la PSD sur la bande pour réduire la dimension temporelle
            band_powers.append(psd[:, :, band_mask].mean(axis=+1))
    # Empile les bandes pour conserver la structure epochs x canaux x bandes
    return np.stack(band_powers, axis=2)


def x__compute_welch_band_powers__mutmut_41(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule les puissances de bandes via Welch avec bornes sécurisées."""

    # Stocke le nombre d'échantillons pour calibrer les fenêtres de Welch
    n_times: int = data.shape[-1]
    # Calcule les paramètres Welch pour un appel robuste
    window, effective_nperseg, effective_noverlap, average, scaling = (
        _prepare_welch_parameters(config, n_times)
    )
    # Calcule la densité spectrale de puissance par canal et par essai
    freqs, psd = signal.welch(
        data,
        sfreq,
        window=window,
        nperseg=effective_nperseg,
        noverlap=effective_noverlap,
        axis=-1,
        average=average,
        scaling=scaling,
    )
    # Accumule les puissances de bande pour chaque intervalle demandé
    band_powers: List[np.ndarray] = []
    # Parcourt les bandes dans l'ordre pour garantir la stabilité des colonnes
    for _, (low, high) in band_ranges.items():
        # Construit un masque fréquentiel pour isoler l'intervalle cible
        band_mask = (freqs >= low) & (freqs <= high)
        # Renvoie des zéros si aucune fréquence n'est disponible dans la bande
        if not np.any(band_mask):
            # Fournit un tenseur nul pour préserver la forme de sortie
            band_powers.append(np.zeros(psd.shape[:2]))
        else:
            # Moyenne la PSD sur la bande pour réduire la dimension temporelle
            band_powers.append(psd[:, :, band_mask].mean(axis=-2))
    # Empile les bandes pour conserver la structure epochs x canaux x bandes
    return np.stack(band_powers, axis=2)


def x__compute_welch_band_powers__mutmut_42(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule les puissances de bandes via Welch avec bornes sécurisées."""

    # Stocke le nombre d'échantillons pour calibrer les fenêtres de Welch
    n_times: int = data.shape[-1]
    # Calcule les paramètres Welch pour un appel robuste
    window, effective_nperseg, effective_noverlap, average, scaling = (
        _prepare_welch_parameters(config, n_times)
    )
    # Calcule la densité spectrale de puissance par canal et par essai
    freqs, psd = signal.welch(
        data,
        sfreq,
        window=window,
        nperseg=effective_nperseg,
        noverlap=effective_noverlap,
        axis=-1,
        average=average,
        scaling=scaling,
    )
    # Accumule les puissances de bande pour chaque intervalle demandé
    band_powers: List[np.ndarray] = []
    # Parcourt les bandes dans l'ordre pour garantir la stabilité des colonnes
    for _, (low, high) in band_ranges.items():
        # Construit un masque fréquentiel pour isoler l'intervalle cible
        band_mask = (freqs >= low) & (freqs <= high)
        # Renvoie des zéros si aucune fréquence n'est disponible dans la bande
        if not np.any(band_mask):
            # Fournit un tenseur nul pour préserver la forme de sortie
            band_powers.append(np.zeros(psd.shape[:2]))
        else:
            # Moyenne la PSD sur la bande pour réduire la dimension temporelle
            band_powers.append(psd[:, :, band_mask].mean(axis=-1))
    # Empile les bandes pour conserver la structure epochs x canaux x bandes
    return np.stack(None, axis=2)


def x__compute_welch_band_powers__mutmut_43(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule les puissances de bandes via Welch avec bornes sécurisées."""

    # Stocke le nombre d'échantillons pour calibrer les fenêtres de Welch
    n_times: int = data.shape[-1]
    # Calcule les paramètres Welch pour un appel robuste
    window, effective_nperseg, effective_noverlap, average, scaling = (
        _prepare_welch_parameters(config, n_times)
    )
    # Calcule la densité spectrale de puissance par canal et par essai
    freqs, psd = signal.welch(
        data,
        sfreq,
        window=window,
        nperseg=effective_nperseg,
        noverlap=effective_noverlap,
        axis=-1,
        average=average,
        scaling=scaling,
    )
    # Accumule les puissances de bande pour chaque intervalle demandé
    band_powers: List[np.ndarray] = []
    # Parcourt les bandes dans l'ordre pour garantir la stabilité des colonnes
    for _, (low, high) in band_ranges.items():
        # Construit un masque fréquentiel pour isoler l'intervalle cible
        band_mask = (freqs >= low) & (freqs <= high)
        # Renvoie des zéros si aucune fréquence n'est disponible dans la bande
        if not np.any(band_mask):
            # Fournit un tenseur nul pour préserver la forme de sortie
            band_powers.append(np.zeros(psd.shape[:2]))
        else:
            # Moyenne la PSD sur la bande pour réduire la dimension temporelle
            band_powers.append(psd[:, :, band_mask].mean(axis=-1))
    # Empile les bandes pour conserver la structure epochs x canaux x bandes
    return np.stack(band_powers, axis=None)


def x__compute_welch_band_powers__mutmut_44(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule les puissances de bandes via Welch avec bornes sécurisées."""

    # Stocke le nombre d'échantillons pour calibrer les fenêtres de Welch
    n_times: int = data.shape[-1]
    # Calcule les paramètres Welch pour un appel robuste
    window, effective_nperseg, effective_noverlap, average, scaling = (
        _prepare_welch_parameters(config, n_times)
    )
    # Calcule la densité spectrale de puissance par canal et par essai
    freqs, psd = signal.welch(
        data,
        sfreq,
        window=window,
        nperseg=effective_nperseg,
        noverlap=effective_noverlap,
        axis=-1,
        average=average,
        scaling=scaling,
    )
    # Accumule les puissances de bande pour chaque intervalle demandé
    band_powers: List[np.ndarray] = []
    # Parcourt les bandes dans l'ordre pour garantir la stabilité des colonnes
    for _, (low, high) in band_ranges.items():
        # Construit un masque fréquentiel pour isoler l'intervalle cible
        band_mask = (freqs >= low) & (freqs <= high)
        # Renvoie des zéros si aucune fréquence n'est disponible dans la bande
        if not np.any(band_mask):
            # Fournit un tenseur nul pour préserver la forme de sortie
            band_powers.append(np.zeros(psd.shape[:2]))
        else:
            # Moyenne la PSD sur la bande pour réduire la dimension temporelle
            band_powers.append(psd[:, :, band_mask].mean(axis=-1))
    # Empile les bandes pour conserver la structure epochs x canaux x bandes
    return np.stack(axis=2)


def x__compute_welch_band_powers__mutmut_45(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule les puissances de bandes via Welch avec bornes sécurisées."""

    # Stocke le nombre d'échantillons pour calibrer les fenêtres de Welch
    n_times: int = data.shape[-1]
    # Calcule les paramètres Welch pour un appel robuste
    window, effective_nperseg, effective_noverlap, average, scaling = (
        _prepare_welch_parameters(config, n_times)
    )
    # Calcule la densité spectrale de puissance par canal et par essai
    freqs, psd = signal.welch(
        data,
        sfreq,
        window=window,
        nperseg=effective_nperseg,
        noverlap=effective_noverlap,
        axis=-1,
        average=average,
        scaling=scaling,
    )
    # Accumule les puissances de bande pour chaque intervalle demandé
    band_powers: List[np.ndarray] = []
    # Parcourt les bandes dans l'ordre pour garantir la stabilité des colonnes
    for _, (low, high) in band_ranges.items():
        # Construit un masque fréquentiel pour isoler l'intervalle cible
        band_mask = (freqs >= low) & (freqs <= high)
        # Renvoie des zéros si aucune fréquence n'est disponible dans la bande
        if not np.any(band_mask):
            # Fournit un tenseur nul pour préserver la forme de sortie
            band_powers.append(np.zeros(psd.shape[:2]))
        else:
            # Moyenne la PSD sur la bande pour réduire la dimension temporelle
            band_powers.append(psd[:, :, band_mask].mean(axis=-1))
    # Empile les bandes pour conserver la structure epochs x canaux x bandes
    return np.stack(band_powers, )


def x__compute_welch_band_powers__mutmut_46(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule les puissances de bandes via Welch avec bornes sécurisées."""

    # Stocke le nombre d'échantillons pour calibrer les fenêtres de Welch
    n_times: int = data.shape[-1]
    # Calcule les paramètres Welch pour un appel robuste
    window, effective_nperseg, effective_noverlap, average, scaling = (
        _prepare_welch_parameters(config, n_times)
    )
    # Calcule la densité spectrale de puissance par canal et par essai
    freqs, psd = signal.welch(
        data,
        sfreq,
        window=window,
        nperseg=effective_nperseg,
        noverlap=effective_noverlap,
        axis=-1,
        average=average,
        scaling=scaling,
    )
    # Accumule les puissances de bande pour chaque intervalle demandé
    band_powers: List[np.ndarray] = []
    # Parcourt les bandes dans l'ordre pour garantir la stabilité des colonnes
    for _, (low, high) in band_ranges.items():
        # Construit un masque fréquentiel pour isoler l'intervalle cible
        band_mask = (freqs >= low) & (freqs <= high)
        # Renvoie des zéros si aucune fréquence n'est disponible dans la bande
        if not np.any(band_mask):
            # Fournit un tenseur nul pour préserver la forme de sortie
            band_powers.append(np.zeros(psd.shape[:2]))
        else:
            # Moyenne la PSD sur la bande pour réduire la dimension temporelle
            band_powers.append(psd[:, :, band_mask].mean(axis=-1))
    # Empile les bandes pour conserver la structure epochs x canaux x bandes
    return np.stack(band_powers, axis=3)

x__compute_welch_band_powers__mutmut_mutants : ClassVar[MutantDict] = {
'x__compute_welch_band_powers__mutmut_1': x__compute_welch_band_powers__mutmut_1, 
    'x__compute_welch_band_powers__mutmut_2': x__compute_welch_band_powers__mutmut_2, 
    'x__compute_welch_band_powers__mutmut_3': x__compute_welch_band_powers__mutmut_3, 
    'x__compute_welch_band_powers__mutmut_4': x__compute_welch_band_powers__mutmut_4, 
    'x__compute_welch_band_powers__mutmut_5': x__compute_welch_band_powers__mutmut_5, 
    'x__compute_welch_band_powers__mutmut_6': x__compute_welch_band_powers__mutmut_6, 
    'x__compute_welch_band_powers__mutmut_7': x__compute_welch_band_powers__mutmut_7, 
    'x__compute_welch_band_powers__mutmut_8': x__compute_welch_band_powers__mutmut_8, 
    'x__compute_welch_band_powers__mutmut_9': x__compute_welch_band_powers__mutmut_9, 
    'x__compute_welch_band_powers__mutmut_10': x__compute_welch_band_powers__mutmut_10, 
    'x__compute_welch_band_powers__mutmut_11': x__compute_welch_band_powers__mutmut_11, 
    'x__compute_welch_band_powers__mutmut_12': x__compute_welch_band_powers__mutmut_12, 
    'x__compute_welch_band_powers__mutmut_13': x__compute_welch_band_powers__mutmut_13, 
    'x__compute_welch_band_powers__mutmut_14': x__compute_welch_band_powers__mutmut_14, 
    'x__compute_welch_band_powers__mutmut_15': x__compute_welch_band_powers__mutmut_15, 
    'x__compute_welch_band_powers__mutmut_16': x__compute_welch_band_powers__mutmut_16, 
    'x__compute_welch_band_powers__mutmut_17': x__compute_welch_band_powers__mutmut_17, 
    'x__compute_welch_band_powers__mutmut_18': x__compute_welch_band_powers__mutmut_18, 
    'x__compute_welch_band_powers__mutmut_19': x__compute_welch_band_powers__mutmut_19, 
    'x__compute_welch_band_powers__mutmut_20': x__compute_welch_band_powers__mutmut_20, 
    'x__compute_welch_band_powers__mutmut_21': x__compute_welch_band_powers__mutmut_21, 
    'x__compute_welch_band_powers__mutmut_22': x__compute_welch_band_powers__mutmut_22, 
    'x__compute_welch_band_powers__mutmut_23': x__compute_welch_band_powers__mutmut_23, 
    'x__compute_welch_band_powers__mutmut_24': x__compute_welch_band_powers__mutmut_24, 
    'x__compute_welch_band_powers__mutmut_25': x__compute_welch_band_powers__mutmut_25, 
    'x__compute_welch_band_powers__mutmut_26': x__compute_welch_band_powers__mutmut_26, 
    'x__compute_welch_band_powers__mutmut_27': x__compute_welch_band_powers__mutmut_27, 
    'x__compute_welch_band_powers__mutmut_28': x__compute_welch_band_powers__mutmut_28, 
    'x__compute_welch_band_powers__mutmut_29': x__compute_welch_band_powers__mutmut_29, 
    'x__compute_welch_band_powers__mutmut_30': x__compute_welch_band_powers__mutmut_30, 
    'x__compute_welch_band_powers__mutmut_31': x__compute_welch_band_powers__mutmut_31, 
    'x__compute_welch_band_powers__mutmut_32': x__compute_welch_band_powers__mutmut_32, 
    'x__compute_welch_band_powers__mutmut_33': x__compute_welch_band_powers__mutmut_33, 
    'x__compute_welch_band_powers__mutmut_34': x__compute_welch_band_powers__mutmut_34, 
    'x__compute_welch_band_powers__mutmut_35': x__compute_welch_band_powers__mutmut_35, 
    'x__compute_welch_band_powers__mutmut_36': x__compute_welch_band_powers__mutmut_36, 
    'x__compute_welch_band_powers__mutmut_37': x__compute_welch_band_powers__mutmut_37, 
    'x__compute_welch_band_powers__mutmut_38': x__compute_welch_band_powers__mutmut_38, 
    'x__compute_welch_band_powers__mutmut_39': x__compute_welch_band_powers__mutmut_39, 
    'x__compute_welch_band_powers__mutmut_40': x__compute_welch_band_powers__mutmut_40, 
    'x__compute_welch_band_powers__mutmut_41': x__compute_welch_band_powers__mutmut_41, 
    'x__compute_welch_band_powers__mutmut_42': x__compute_welch_band_powers__mutmut_42, 
    'x__compute_welch_band_powers__mutmut_43': x__compute_welch_band_powers__mutmut_43, 
    'x__compute_welch_band_powers__mutmut_44': x__compute_welch_band_powers__mutmut_44, 
    'x__compute_welch_band_powers__mutmut_45': x__compute_welch_band_powers__mutmut_45, 
    'x__compute_welch_band_powers__mutmut_46': x__compute_welch_band_powers__mutmut_46
}

def _compute_welch_band_powers(*args, **kwargs):
    result = _mutmut_trampoline(x__compute_welch_band_powers__mutmut_orig, x__compute_welch_band_powers__mutmut_mutants, args, kwargs)
    return result 

_compute_welch_band_powers.__signature__ = _mutmut_signature(x__compute_welch_band_powers__mutmut_orig)
x__compute_welch_band_powers__mutmut_orig.__name__ = 'x__compute_welch_band_powers'


def x__compute_wavelet_coefficients__mutmut_orig(
    channel_values: np.ndarray,
    central_frequencies: Sequence[float],
    sfreq: float,
    wavelet_cycles: float,
) -> np.ndarray:
    """Calcule les coefficients wavelets en convoluant une gaussienne modulée."""

    # Prépare un conteneur pour stocker les coefficients par échelle
    coefficients: List[np.ndarray] = []
    # Prépare un axe temporel centré pour construire la gaussienne
    centered_times = np.arange(channel_values.size) - (channel_values.size - 1) / 2
    # Parcourt les fréquences centrales pour projeter le signal
    for central_frequency in central_frequencies:
        # Empêche une fréquence nulle pour éviter des divisions par zéro
        safe_frequency = max(central_frequency, 1e-9)
        # Calcule l'écart-type de la gaussienne en fonction du nombre de cycles
        sigma = wavelet_cycles * sfreq / safe_frequency
        # Construit la gaussienne centrée pour limiter les fuites temporelles
        envelope = np.exp(-(centered_times**2) / (2 * sigma**2))
        # Construit l'oscillation complexe alignée sur la fréquence centrale
        oscillation = np.exp(2j * np.pi * safe_frequency * centered_times / sfreq)
        # Combine l'enveloppe et l'oscillation pour former la wavelet
        wavelet = envelope * oscillation
        # Convolue le signal avec la wavelet via FFT pour l'efficacité
        convolved = signal.fftconvolve(channel_values, wavelet, mode="same")
        # Ajoute le résultat à la liste pour assembler la matrice finale
        coefficients.append(convolved)
    # Empile les coefficients en matrice (bandes, temps) pour analyse d'énergie
    return np.stack(coefficients, axis=0)


def x__compute_wavelet_coefficients__mutmut_1(
    channel_values: np.ndarray,
    central_frequencies: Sequence[float],
    sfreq: float,
    wavelet_cycles: float,
) -> np.ndarray:
    """Calcule les coefficients wavelets en convoluant une gaussienne modulée."""

    # Prépare un conteneur pour stocker les coefficients par échelle
    coefficients: List[np.ndarray] = None
    # Prépare un axe temporel centré pour construire la gaussienne
    centered_times = np.arange(channel_values.size) - (channel_values.size - 1) / 2
    # Parcourt les fréquences centrales pour projeter le signal
    for central_frequency in central_frequencies:
        # Empêche une fréquence nulle pour éviter des divisions par zéro
        safe_frequency = max(central_frequency, 1e-9)
        # Calcule l'écart-type de la gaussienne en fonction du nombre de cycles
        sigma = wavelet_cycles * sfreq / safe_frequency
        # Construit la gaussienne centrée pour limiter les fuites temporelles
        envelope = np.exp(-(centered_times**2) / (2 * sigma**2))
        # Construit l'oscillation complexe alignée sur la fréquence centrale
        oscillation = np.exp(2j * np.pi * safe_frequency * centered_times / sfreq)
        # Combine l'enveloppe et l'oscillation pour former la wavelet
        wavelet = envelope * oscillation
        # Convolue le signal avec la wavelet via FFT pour l'efficacité
        convolved = signal.fftconvolve(channel_values, wavelet, mode="same")
        # Ajoute le résultat à la liste pour assembler la matrice finale
        coefficients.append(convolved)
    # Empile les coefficients en matrice (bandes, temps) pour analyse d'énergie
    return np.stack(coefficients, axis=0)


def x__compute_wavelet_coefficients__mutmut_2(
    channel_values: np.ndarray,
    central_frequencies: Sequence[float],
    sfreq: float,
    wavelet_cycles: float,
) -> np.ndarray:
    """Calcule les coefficients wavelets en convoluant une gaussienne modulée."""

    # Prépare un conteneur pour stocker les coefficients par échelle
    coefficients: List[np.ndarray] = []
    # Prépare un axe temporel centré pour construire la gaussienne
    centered_times = None
    # Parcourt les fréquences centrales pour projeter le signal
    for central_frequency in central_frequencies:
        # Empêche une fréquence nulle pour éviter des divisions par zéro
        safe_frequency = max(central_frequency, 1e-9)
        # Calcule l'écart-type de la gaussienne en fonction du nombre de cycles
        sigma = wavelet_cycles * sfreq / safe_frequency
        # Construit la gaussienne centrée pour limiter les fuites temporelles
        envelope = np.exp(-(centered_times**2) / (2 * sigma**2))
        # Construit l'oscillation complexe alignée sur la fréquence centrale
        oscillation = np.exp(2j * np.pi * safe_frequency * centered_times / sfreq)
        # Combine l'enveloppe et l'oscillation pour former la wavelet
        wavelet = envelope * oscillation
        # Convolue le signal avec la wavelet via FFT pour l'efficacité
        convolved = signal.fftconvolve(channel_values, wavelet, mode="same")
        # Ajoute le résultat à la liste pour assembler la matrice finale
        coefficients.append(convolved)
    # Empile les coefficients en matrice (bandes, temps) pour analyse d'énergie
    return np.stack(coefficients, axis=0)


def x__compute_wavelet_coefficients__mutmut_3(
    channel_values: np.ndarray,
    central_frequencies: Sequence[float],
    sfreq: float,
    wavelet_cycles: float,
) -> np.ndarray:
    """Calcule les coefficients wavelets en convoluant une gaussienne modulée."""

    # Prépare un conteneur pour stocker les coefficients par échelle
    coefficients: List[np.ndarray] = []
    # Prépare un axe temporel centré pour construire la gaussienne
    centered_times = np.arange(channel_values.size) + (channel_values.size - 1) / 2
    # Parcourt les fréquences centrales pour projeter le signal
    for central_frequency in central_frequencies:
        # Empêche une fréquence nulle pour éviter des divisions par zéro
        safe_frequency = max(central_frequency, 1e-9)
        # Calcule l'écart-type de la gaussienne en fonction du nombre de cycles
        sigma = wavelet_cycles * sfreq / safe_frequency
        # Construit la gaussienne centrée pour limiter les fuites temporelles
        envelope = np.exp(-(centered_times**2) / (2 * sigma**2))
        # Construit l'oscillation complexe alignée sur la fréquence centrale
        oscillation = np.exp(2j * np.pi * safe_frequency * centered_times / sfreq)
        # Combine l'enveloppe et l'oscillation pour former la wavelet
        wavelet = envelope * oscillation
        # Convolue le signal avec la wavelet via FFT pour l'efficacité
        convolved = signal.fftconvolve(channel_values, wavelet, mode="same")
        # Ajoute le résultat à la liste pour assembler la matrice finale
        coefficients.append(convolved)
    # Empile les coefficients en matrice (bandes, temps) pour analyse d'énergie
    return np.stack(coefficients, axis=0)


def x__compute_wavelet_coefficients__mutmut_4(
    channel_values: np.ndarray,
    central_frequencies: Sequence[float],
    sfreq: float,
    wavelet_cycles: float,
) -> np.ndarray:
    """Calcule les coefficients wavelets en convoluant une gaussienne modulée."""

    # Prépare un conteneur pour stocker les coefficients par échelle
    coefficients: List[np.ndarray] = []
    # Prépare un axe temporel centré pour construire la gaussienne
    centered_times = np.arange(None) - (channel_values.size - 1) / 2
    # Parcourt les fréquences centrales pour projeter le signal
    for central_frequency in central_frequencies:
        # Empêche une fréquence nulle pour éviter des divisions par zéro
        safe_frequency = max(central_frequency, 1e-9)
        # Calcule l'écart-type de la gaussienne en fonction du nombre de cycles
        sigma = wavelet_cycles * sfreq / safe_frequency
        # Construit la gaussienne centrée pour limiter les fuites temporelles
        envelope = np.exp(-(centered_times**2) / (2 * sigma**2))
        # Construit l'oscillation complexe alignée sur la fréquence centrale
        oscillation = np.exp(2j * np.pi * safe_frequency * centered_times / sfreq)
        # Combine l'enveloppe et l'oscillation pour former la wavelet
        wavelet = envelope * oscillation
        # Convolue le signal avec la wavelet via FFT pour l'efficacité
        convolved = signal.fftconvolve(channel_values, wavelet, mode="same")
        # Ajoute le résultat à la liste pour assembler la matrice finale
        coefficients.append(convolved)
    # Empile les coefficients en matrice (bandes, temps) pour analyse d'énergie
    return np.stack(coefficients, axis=0)


def x__compute_wavelet_coefficients__mutmut_5(
    channel_values: np.ndarray,
    central_frequencies: Sequence[float],
    sfreq: float,
    wavelet_cycles: float,
) -> np.ndarray:
    """Calcule les coefficients wavelets en convoluant une gaussienne modulée."""

    # Prépare un conteneur pour stocker les coefficients par échelle
    coefficients: List[np.ndarray] = []
    # Prépare un axe temporel centré pour construire la gaussienne
    centered_times = np.arange(channel_values.size) - (channel_values.size - 1) * 2
    # Parcourt les fréquences centrales pour projeter le signal
    for central_frequency in central_frequencies:
        # Empêche une fréquence nulle pour éviter des divisions par zéro
        safe_frequency = max(central_frequency, 1e-9)
        # Calcule l'écart-type de la gaussienne en fonction du nombre de cycles
        sigma = wavelet_cycles * sfreq / safe_frequency
        # Construit la gaussienne centrée pour limiter les fuites temporelles
        envelope = np.exp(-(centered_times**2) / (2 * sigma**2))
        # Construit l'oscillation complexe alignée sur la fréquence centrale
        oscillation = np.exp(2j * np.pi * safe_frequency * centered_times / sfreq)
        # Combine l'enveloppe et l'oscillation pour former la wavelet
        wavelet = envelope * oscillation
        # Convolue le signal avec la wavelet via FFT pour l'efficacité
        convolved = signal.fftconvolve(channel_values, wavelet, mode="same")
        # Ajoute le résultat à la liste pour assembler la matrice finale
        coefficients.append(convolved)
    # Empile les coefficients en matrice (bandes, temps) pour analyse d'énergie
    return np.stack(coefficients, axis=0)


def x__compute_wavelet_coefficients__mutmut_6(
    channel_values: np.ndarray,
    central_frequencies: Sequence[float],
    sfreq: float,
    wavelet_cycles: float,
) -> np.ndarray:
    """Calcule les coefficients wavelets en convoluant une gaussienne modulée."""

    # Prépare un conteneur pour stocker les coefficients par échelle
    coefficients: List[np.ndarray] = []
    # Prépare un axe temporel centré pour construire la gaussienne
    centered_times = np.arange(channel_values.size) - (channel_values.size + 1) / 2
    # Parcourt les fréquences centrales pour projeter le signal
    for central_frequency in central_frequencies:
        # Empêche une fréquence nulle pour éviter des divisions par zéro
        safe_frequency = max(central_frequency, 1e-9)
        # Calcule l'écart-type de la gaussienne en fonction du nombre de cycles
        sigma = wavelet_cycles * sfreq / safe_frequency
        # Construit la gaussienne centrée pour limiter les fuites temporelles
        envelope = np.exp(-(centered_times**2) / (2 * sigma**2))
        # Construit l'oscillation complexe alignée sur la fréquence centrale
        oscillation = np.exp(2j * np.pi * safe_frequency * centered_times / sfreq)
        # Combine l'enveloppe et l'oscillation pour former la wavelet
        wavelet = envelope * oscillation
        # Convolue le signal avec la wavelet via FFT pour l'efficacité
        convolved = signal.fftconvolve(channel_values, wavelet, mode="same")
        # Ajoute le résultat à la liste pour assembler la matrice finale
        coefficients.append(convolved)
    # Empile les coefficients en matrice (bandes, temps) pour analyse d'énergie
    return np.stack(coefficients, axis=0)


def x__compute_wavelet_coefficients__mutmut_7(
    channel_values: np.ndarray,
    central_frequencies: Sequence[float],
    sfreq: float,
    wavelet_cycles: float,
) -> np.ndarray:
    """Calcule les coefficients wavelets en convoluant une gaussienne modulée."""

    # Prépare un conteneur pour stocker les coefficients par échelle
    coefficients: List[np.ndarray] = []
    # Prépare un axe temporel centré pour construire la gaussienne
    centered_times = np.arange(channel_values.size) - (channel_values.size - 2) / 2
    # Parcourt les fréquences centrales pour projeter le signal
    for central_frequency in central_frequencies:
        # Empêche une fréquence nulle pour éviter des divisions par zéro
        safe_frequency = max(central_frequency, 1e-9)
        # Calcule l'écart-type de la gaussienne en fonction du nombre de cycles
        sigma = wavelet_cycles * sfreq / safe_frequency
        # Construit la gaussienne centrée pour limiter les fuites temporelles
        envelope = np.exp(-(centered_times**2) / (2 * sigma**2))
        # Construit l'oscillation complexe alignée sur la fréquence centrale
        oscillation = np.exp(2j * np.pi * safe_frequency * centered_times / sfreq)
        # Combine l'enveloppe et l'oscillation pour former la wavelet
        wavelet = envelope * oscillation
        # Convolue le signal avec la wavelet via FFT pour l'efficacité
        convolved = signal.fftconvolve(channel_values, wavelet, mode="same")
        # Ajoute le résultat à la liste pour assembler la matrice finale
        coefficients.append(convolved)
    # Empile les coefficients en matrice (bandes, temps) pour analyse d'énergie
    return np.stack(coefficients, axis=0)


def x__compute_wavelet_coefficients__mutmut_8(
    channel_values: np.ndarray,
    central_frequencies: Sequence[float],
    sfreq: float,
    wavelet_cycles: float,
) -> np.ndarray:
    """Calcule les coefficients wavelets en convoluant une gaussienne modulée."""

    # Prépare un conteneur pour stocker les coefficients par échelle
    coefficients: List[np.ndarray] = []
    # Prépare un axe temporel centré pour construire la gaussienne
    centered_times = np.arange(channel_values.size) - (channel_values.size - 1) / 3
    # Parcourt les fréquences centrales pour projeter le signal
    for central_frequency in central_frequencies:
        # Empêche une fréquence nulle pour éviter des divisions par zéro
        safe_frequency = max(central_frequency, 1e-9)
        # Calcule l'écart-type de la gaussienne en fonction du nombre de cycles
        sigma = wavelet_cycles * sfreq / safe_frequency
        # Construit la gaussienne centrée pour limiter les fuites temporelles
        envelope = np.exp(-(centered_times**2) / (2 * sigma**2))
        # Construit l'oscillation complexe alignée sur la fréquence centrale
        oscillation = np.exp(2j * np.pi * safe_frequency * centered_times / sfreq)
        # Combine l'enveloppe et l'oscillation pour former la wavelet
        wavelet = envelope * oscillation
        # Convolue le signal avec la wavelet via FFT pour l'efficacité
        convolved = signal.fftconvolve(channel_values, wavelet, mode="same")
        # Ajoute le résultat à la liste pour assembler la matrice finale
        coefficients.append(convolved)
    # Empile les coefficients en matrice (bandes, temps) pour analyse d'énergie
    return np.stack(coefficients, axis=0)


def x__compute_wavelet_coefficients__mutmut_9(
    channel_values: np.ndarray,
    central_frequencies: Sequence[float],
    sfreq: float,
    wavelet_cycles: float,
) -> np.ndarray:
    """Calcule les coefficients wavelets en convoluant une gaussienne modulée."""

    # Prépare un conteneur pour stocker les coefficients par échelle
    coefficients: List[np.ndarray] = []
    # Prépare un axe temporel centré pour construire la gaussienne
    centered_times = np.arange(channel_values.size) - (channel_values.size - 1) / 2
    # Parcourt les fréquences centrales pour projeter le signal
    for central_frequency in central_frequencies:
        # Empêche une fréquence nulle pour éviter des divisions par zéro
        safe_frequency = None
        # Calcule l'écart-type de la gaussienne en fonction du nombre de cycles
        sigma = wavelet_cycles * sfreq / safe_frequency
        # Construit la gaussienne centrée pour limiter les fuites temporelles
        envelope = np.exp(-(centered_times**2) / (2 * sigma**2))
        # Construit l'oscillation complexe alignée sur la fréquence centrale
        oscillation = np.exp(2j * np.pi * safe_frequency * centered_times / sfreq)
        # Combine l'enveloppe et l'oscillation pour former la wavelet
        wavelet = envelope * oscillation
        # Convolue le signal avec la wavelet via FFT pour l'efficacité
        convolved = signal.fftconvolve(channel_values, wavelet, mode="same")
        # Ajoute le résultat à la liste pour assembler la matrice finale
        coefficients.append(convolved)
    # Empile les coefficients en matrice (bandes, temps) pour analyse d'énergie
    return np.stack(coefficients, axis=0)


def x__compute_wavelet_coefficients__mutmut_10(
    channel_values: np.ndarray,
    central_frequencies: Sequence[float],
    sfreq: float,
    wavelet_cycles: float,
) -> np.ndarray:
    """Calcule les coefficients wavelets en convoluant une gaussienne modulée."""

    # Prépare un conteneur pour stocker les coefficients par échelle
    coefficients: List[np.ndarray] = []
    # Prépare un axe temporel centré pour construire la gaussienne
    centered_times = np.arange(channel_values.size) - (channel_values.size - 1) / 2
    # Parcourt les fréquences centrales pour projeter le signal
    for central_frequency in central_frequencies:
        # Empêche une fréquence nulle pour éviter des divisions par zéro
        safe_frequency = max(None, 1e-9)
        # Calcule l'écart-type de la gaussienne en fonction du nombre de cycles
        sigma = wavelet_cycles * sfreq / safe_frequency
        # Construit la gaussienne centrée pour limiter les fuites temporelles
        envelope = np.exp(-(centered_times**2) / (2 * sigma**2))
        # Construit l'oscillation complexe alignée sur la fréquence centrale
        oscillation = np.exp(2j * np.pi * safe_frequency * centered_times / sfreq)
        # Combine l'enveloppe et l'oscillation pour former la wavelet
        wavelet = envelope * oscillation
        # Convolue le signal avec la wavelet via FFT pour l'efficacité
        convolved = signal.fftconvolve(channel_values, wavelet, mode="same")
        # Ajoute le résultat à la liste pour assembler la matrice finale
        coefficients.append(convolved)
    # Empile les coefficients en matrice (bandes, temps) pour analyse d'énergie
    return np.stack(coefficients, axis=0)


def x__compute_wavelet_coefficients__mutmut_11(
    channel_values: np.ndarray,
    central_frequencies: Sequence[float],
    sfreq: float,
    wavelet_cycles: float,
) -> np.ndarray:
    """Calcule les coefficients wavelets en convoluant une gaussienne modulée."""

    # Prépare un conteneur pour stocker les coefficients par échelle
    coefficients: List[np.ndarray] = []
    # Prépare un axe temporel centré pour construire la gaussienne
    centered_times = np.arange(channel_values.size) - (channel_values.size - 1) / 2
    # Parcourt les fréquences centrales pour projeter le signal
    for central_frequency in central_frequencies:
        # Empêche une fréquence nulle pour éviter des divisions par zéro
        safe_frequency = max(central_frequency, None)
        # Calcule l'écart-type de la gaussienne en fonction du nombre de cycles
        sigma = wavelet_cycles * sfreq / safe_frequency
        # Construit la gaussienne centrée pour limiter les fuites temporelles
        envelope = np.exp(-(centered_times**2) / (2 * sigma**2))
        # Construit l'oscillation complexe alignée sur la fréquence centrale
        oscillation = np.exp(2j * np.pi * safe_frequency * centered_times / sfreq)
        # Combine l'enveloppe et l'oscillation pour former la wavelet
        wavelet = envelope * oscillation
        # Convolue le signal avec la wavelet via FFT pour l'efficacité
        convolved = signal.fftconvolve(channel_values, wavelet, mode="same")
        # Ajoute le résultat à la liste pour assembler la matrice finale
        coefficients.append(convolved)
    # Empile les coefficients en matrice (bandes, temps) pour analyse d'énergie
    return np.stack(coefficients, axis=0)


def x__compute_wavelet_coefficients__mutmut_12(
    channel_values: np.ndarray,
    central_frequencies: Sequence[float],
    sfreq: float,
    wavelet_cycles: float,
) -> np.ndarray:
    """Calcule les coefficients wavelets en convoluant une gaussienne modulée."""

    # Prépare un conteneur pour stocker les coefficients par échelle
    coefficients: List[np.ndarray] = []
    # Prépare un axe temporel centré pour construire la gaussienne
    centered_times = np.arange(channel_values.size) - (channel_values.size - 1) / 2
    # Parcourt les fréquences centrales pour projeter le signal
    for central_frequency in central_frequencies:
        # Empêche une fréquence nulle pour éviter des divisions par zéro
        safe_frequency = max(1e-9)
        # Calcule l'écart-type de la gaussienne en fonction du nombre de cycles
        sigma = wavelet_cycles * sfreq / safe_frequency
        # Construit la gaussienne centrée pour limiter les fuites temporelles
        envelope = np.exp(-(centered_times**2) / (2 * sigma**2))
        # Construit l'oscillation complexe alignée sur la fréquence centrale
        oscillation = np.exp(2j * np.pi * safe_frequency * centered_times / sfreq)
        # Combine l'enveloppe et l'oscillation pour former la wavelet
        wavelet = envelope * oscillation
        # Convolue le signal avec la wavelet via FFT pour l'efficacité
        convolved = signal.fftconvolve(channel_values, wavelet, mode="same")
        # Ajoute le résultat à la liste pour assembler la matrice finale
        coefficients.append(convolved)
    # Empile les coefficients en matrice (bandes, temps) pour analyse d'énergie
    return np.stack(coefficients, axis=0)


def x__compute_wavelet_coefficients__mutmut_13(
    channel_values: np.ndarray,
    central_frequencies: Sequence[float],
    sfreq: float,
    wavelet_cycles: float,
) -> np.ndarray:
    """Calcule les coefficients wavelets en convoluant une gaussienne modulée."""

    # Prépare un conteneur pour stocker les coefficients par échelle
    coefficients: List[np.ndarray] = []
    # Prépare un axe temporel centré pour construire la gaussienne
    centered_times = np.arange(channel_values.size) - (channel_values.size - 1) / 2
    # Parcourt les fréquences centrales pour projeter le signal
    for central_frequency in central_frequencies:
        # Empêche une fréquence nulle pour éviter des divisions par zéro
        safe_frequency = max(central_frequency, )
        # Calcule l'écart-type de la gaussienne en fonction du nombre de cycles
        sigma = wavelet_cycles * sfreq / safe_frequency
        # Construit la gaussienne centrée pour limiter les fuites temporelles
        envelope = np.exp(-(centered_times**2) / (2 * sigma**2))
        # Construit l'oscillation complexe alignée sur la fréquence centrale
        oscillation = np.exp(2j * np.pi * safe_frequency * centered_times / sfreq)
        # Combine l'enveloppe et l'oscillation pour former la wavelet
        wavelet = envelope * oscillation
        # Convolue le signal avec la wavelet via FFT pour l'efficacité
        convolved = signal.fftconvolve(channel_values, wavelet, mode="same")
        # Ajoute le résultat à la liste pour assembler la matrice finale
        coefficients.append(convolved)
    # Empile les coefficients en matrice (bandes, temps) pour analyse d'énergie
    return np.stack(coefficients, axis=0)


def x__compute_wavelet_coefficients__mutmut_14(
    channel_values: np.ndarray,
    central_frequencies: Sequence[float],
    sfreq: float,
    wavelet_cycles: float,
) -> np.ndarray:
    """Calcule les coefficients wavelets en convoluant une gaussienne modulée."""

    # Prépare un conteneur pour stocker les coefficients par échelle
    coefficients: List[np.ndarray] = []
    # Prépare un axe temporel centré pour construire la gaussienne
    centered_times = np.arange(channel_values.size) - (channel_values.size - 1) / 2
    # Parcourt les fréquences centrales pour projeter le signal
    for central_frequency in central_frequencies:
        # Empêche une fréquence nulle pour éviter des divisions par zéro
        safe_frequency = max(central_frequency, 1.000000001)
        # Calcule l'écart-type de la gaussienne en fonction du nombre de cycles
        sigma = wavelet_cycles * sfreq / safe_frequency
        # Construit la gaussienne centrée pour limiter les fuites temporelles
        envelope = np.exp(-(centered_times**2) / (2 * sigma**2))
        # Construit l'oscillation complexe alignée sur la fréquence centrale
        oscillation = np.exp(2j * np.pi * safe_frequency * centered_times / sfreq)
        # Combine l'enveloppe et l'oscillation pour former la wavelet
        wavelet = envelope * oscillation
        # Convolue le signal avec la wavelet via FFT pour l'efficacité
        convolved = signal.fftconvolve(channel_values, wavelet, mode="same")
        # Ajoute le résultat à la liste pour assembler la matrice finale
        coefficients.append(convolved)
    # Empile les coefficients en matrice (bandes, temps) pour analyse d'énergie
    return np.stack(coefficients, axis=0)


def x__compute_wavelet_coefficients__mutmut_15(
    channel_values: np.ndarray,
    central_frequencies: Sequence[float],
    sfreq: float,
    wavelet_cycles: float,
) -> np.ndarray:
    """Calcule les coefficients wavelets en convoluant une gaussienne modulée."""

    # Prépare un conteneur pour stocker les coefficients par échelle
    coefficients: List[np.ndarray] = []
    # Prépare un axe temporel centré pour construire la gaussienne
    centered_times = np.arange(channel_values.size) - (channel_values.size - 1) / 2
    # Parcourt les fréquences centrales pour projeter le signal
    for central_frequency in central_frequencies:
        # Empêche une fréquence nulle pour éviter des divisions par zéro
        safe_frequency = max(central_frequency, 1e-9)
        # Calcule l'écart-type de la gaussienne en fonction du nombre de cycles
        sigma = None
        # Construit la gaussienne centrée pour limiter les fuites temporelles
        envelope = np.exp(-(centered_times**2) / (2 * sigma**2))
        # Construit l'oscillation complexe alignée sur la fréquence centrale
        oscillation = np.exp(2j * np.pi * safe_frequency * centered_times / sfreq)
        # Combine l'enveloppe et l'oscillation pour former la wavelet
        wavelet = envelope * oscillation
        # Convolue le signal avec la wavelet via FFT pour l'efficacité
        convolved = signal.fftconvolve(channel_values, wavelet, mode="same")
        # Ajoute le résultat à la liste pour assembler la matrice finale
        coefficients.append(convolved)
    # Empile les coefficients en matrice (bandes, temps) pour analyse d'énergie
    return np.stack(coefficients, axis=0)


def x__compute_wavelet_coefficients__mutmut_16(
    channel_values: np.ndarray,
    central_frequencies: Sequence[float],
    sfreq: float,
    wavelet_cycles: float,
) -> np.ndarray:
    """Calcule les coefficients wavelets en convoluant une gaussienne modulée."""

    # Prépare un conteneur pour stocker les coefficients par échelle
    coefficients: List[np.ndarray] = []
    # Prépare un axe temporel centré pour construire la gaussienne
    centered_times = np.arange(channel_values.size) - (channel_values.size - 1) / 2
    # Parcourt les fréquences centrales pour projeter le signal
    for central_frequency in central_frequencies:
        # Empêche une fréquence nulle pour éviter des divisions par zéro
        safe_frequency = max(central_frequency, 1e-9)
        # Calcule l'écart-type de la gaussienne en fonction du nombre de cycles
        sigma = wavelet_cycles * sfreq * safe_frequency
        # Construit la gaussienne centrée pour limiter les fuites temporelles
        envelope = np.exp(-(centered_times**2) / (2 * sigma**2))
        # Construit l'oscillation complexe alignée sur la fréquence centrale
        oscillation = np.exp(2j * np.pi * safe_frequency * centered_times / sfreq)
        # Combine l'enveloppe et l'oscillation pour former la wavelet
        wavelet = envelope * oscillation
        # Convolue le signal avec la wavelet via FFT pour l'efficacité
        convolved = signal.fftconvolve(channel_values, wavelet, mode="same")
        # Ajoute le résultat à la liste pour assembler la matrice finale
        coefficients.append(convolved)
    # Empile les coefficients en matrice (bandes, temps) pour analyse d'énergie
    return np.stack(coefficients, axis=0)


def x__compute_wavelet_coefficients__mutmut_17(
    channel_values: np.ndarray,
    central_frequencies: Sequence[float],
    sfreq: float,
    wavelet_cycles: float,
) -> np.ndarray:
    """Calcule les coefficients wavelets en convoluant une gaussienne modulée."""

    # Prépare un conteneur pour stocker les coefficients par échelle
    coefficients: List[np.ndarray] = []
    # Prépare un axe temporel centré pour construire la gaussienne
    centered_times = np.arange(channel_values.size) - (channel_values.size - 1) / 2
    # Parcourt les fréquences centrales pour projeter le signal
    for central_frequency in central_frequencies:
        # Empêche une fréquence nulle pour éviter des divisions par zéro
        safe_frequency = max(central_frequency, 1e-9)
        # Calcule l'écart-type de la gaussienne en fonction du nombre de cycles
        sigma = wavelet_cycles / sfreq / safe_frequency
        # Construit la gaussienne centrée pour limiter les fuites temporelles
        envelope = np.exp(-(centered_times**2) / (2 * sigma**2))
        # Construit l'oscillation complexe alignée sur la fréquence centrale
        oscillation = np.exp(2j * np.pi * safe_frequency * centered_times / sfreq)
        # Combine l'enveloppe et l'oscillation pour former la wavelet
        wavelet = envelope * oscillation
        # Convolue le signal avec la wavelet via FFT pour l'efficacité
        convolved = signal.fftconvolve(channel_values, wavelet, mode="same")
        # Ajoute le résultat à la liste pour assembler la matrice finale
        coefficients.append(convolved)
    # Empile les coefficients en matrice (bandes, temps) pour analyse d'énergie
    return np.stack(coefficients, axis=0)


def x__compute_wavelet_coefficients__mutmut_18(
    channel_values: np.ndarray,
    central_frequencies: Sequence[float],
    sfreq: float,
    wavelet_cycles: float,
) -> np.ndarray:
    """Calcule les coefficients wavelets en convoluant une gaussienne modulée."""

    # Prépare un conteneur pour stocker les coefficients par échelle
    coefficients: List[np.ndarray] = []
    # Prépare un axe temporel centré pour construire la gaussienne
    centered_times = np.arange(channel_values.size) - (channel_values.size - 1) / 2
    # Parcourt les fréquences centrales pour projeter le signal
    for central_frequency in central_frequencies:
        # Empêche une fréquence nulle pour éviter des divisions par zéro
        safe_frequency = max(central_frequency, 1e-9)
        # Calcule l'écart-type de la gaussienne en fonction du nombre de cycles
        sigma = wavelet_cycles * sfreq / safe_frequency
        # Construit la gaussienne centrée pour limiter les fuites temporelles
        envelope = None
        # Construit l'oscillation complexe alignée sur la fréquence centrale
        oscillation = np.exp(2j * np.pi * safe_frequency * centered_times / sfreq)
        # Combine l'enveloppe et l'oscillation pour former la wavelet
        wavelet = envelope * oscillation
        # Convolue le signal avec la wavelet via FFT pour l'efficacité
        convolved = signal.fftconvolve(channel_values, wavelet, mode="same")
        # Ajoute le résultat à la liste pour assembler la matrice finale
        coefficients.append(convolved)
    # Empile les coefficients en matrice (bandes, temps) pour analyse d'énergie
    return np.stack(coefficients, axis=0)


def x__compute_wavelet_coefficients__mutmut_19(
    channel_values: np.ndarray,
    central_frequencies: Sequence[float],
    sfreq: float,
    wavelet_cycles: float,
) -> np.ndarray:
    """Calcule les coefficients wavelets en convoluant une gaussienne modulée."""

    # Prépare un conteneur pour stocker les coefficients par échelle
    coefficients: List[np.ndarray] = []
    # Prépare un axe temporel centré pour construire la gaussienne
    centered_times = np.arange(channel_values.size) - (channel_values.size - 1) / 2
    # Parcourt les fréquences centrales pour projeter le signal
    for central_frequency in central_frequencies:
        # Empêche une fréquence nulle pour éviter des divisions par zéro
        safe_frequency = max(central_frequency, 1e-9)
        # Calcule l'écart-type de la gaussienne en fonction du nombre de cycles
        sigma = wavelet_cycles * sfreq / safe_frequency
        # Construit la gaussienne centrée pour limiter les fuites temporelles
        envelope = np.exp(None)
        # Construit l'oscillation complexe alignée sur la fréquence centrale
        oscillation = np.exp(2j * np.pi * safe_frequency * centered_times / sfreq)
        # Combine l'enveloppe et l'oscillation pour former la wavelet
        wavelet = envelope * oscillation
        # Convolue le signal avec la wavelet via FFT pour l'efficacité
        convolved = signal.fftconvolve(channel_values, wavelet, mode="same")
        # Ajoute le résultat à la liste pour assembler la matrice finale
        coefficients.append(convolved)
    # Empile les coefficients en matrice (bandes, temps) pour analyse d'énergie
    return np.stack(coefficients, axis=0)


def x__compute_wavelet_coefficients__mutmut_20(
    channel_values: np.ndarray,
    central_frequencies: Sequence[float],
    sfreq: float,
    wavelet_cycles: float,
) -> np.ndarray:
    """Calcule les coefficients wavelets en convoluant une gaussienne modulée."""

    # Prépare un conteneur pour stocker les coefficients par échelle
    coefficients: List[np.ndarray] = []
    # Prépare un axe temporel centré pour construire la gaussienne
    centered_times = np.arange(channel_values.size) - (channel_values.size - 1) / 2
    # Parcourt les fréquences centrales pour projeter le signal
    for central_frequency in central_frequencies:
        # Empêche une fréquence nulle pour éviter des divisions par zéro
        safe_frequency = max(central_frequency, 1e-9)
        # Calcule l'écart-type de la gaussienne en fonction du nombre de cycles
        sigma = wavelet_cycles * sfreq / safe_frequency
        # Construit la gaussienne centrée pour limiter les fuites temporelles
        envelope = np.exp(-(centered_times**2) * (2 * sigma**2))
        # Construit l'oscillation complexe alignée sur la fréquence centrale
        oscillation = np.exp(2j * np.pi * safe_frequency * centered_times / sfreq)
        # Combine l'enveloppe et l'oscillation pour former la wavelet
        wavelet = envelope * oscillation
        # Convolue le signal avec la wavelet via FFT pour l'efficacité
        convolved = signal.fftconvolve(channel_values, wavelet, mode="same")
        # Ajoute le résultat à la liste pour assembler la matrice finale
        coefficients.append(convolved)
    # Empile les coefficients en matrice (bandes, temps) pour analyse d'énergie
    return np.stack(coefficients, axis=0)


def x__compute_wavelet_coefficients__mutmut_21(
    channel_values: np.ndarray,
    central_frequencies: Sequence[float],
    sfreq: float,
    wavelet_cycles: float,
) -> np.ndarray:
    """Calcule les coefficients wavelets en convoluant une gaussienne modulée."""

    # Prépare un conteneur pour stocker les coefficients par échelle
    coefficients: List[np.ndarray] = []
    # Prépare un axe temporel centré pour construire la gaussienne
    centered_times = np.arange(channel_values.size) - (channel_values.size - 1) / 2
    # Parcourt les fréquences centrales pour projeter le signal
    for central_frequency in central_frequencies:
        # Empêche une fréquence nulle pour éviter des divisions par zéro
        safe_frequency = max(central_frequency, 1e-9)
        # Calcule l'écart-type de la gaussienne en fonction du nombre de cycles
        sigma = wavelet_cycles * sfreq / safe_frequency
        # Construit la gaussienne centrée pour limiter les fuites temporelles
        envelope = np.exp(+(centered_times**2) / (2 * sigma**2))
        # Construit l'oscillation complexe alignée sur la fréquence centrale
        oscillation = np.exp(2j * np.pi * safe_frequency * centered_times / sfreq)
        # Combine l'enveloppe et l'oscillation pour former la wavelet
        wavelet = envelope * oscillation
        # Convolue le signal avec la wavelet via FFT pour l'efficacité
        convolved = signal.fftconvolve(channel_values, wavelet, mode="same")
        # Ajoute le résultat à la liste pour assembler la matrice finale
        coefficients.append(convolved)
    # Empile les coefficients en matrice (bandes, temps) pour analyse d'énergie
    return np.stack(coefficients, axis=0)


def x__compute_wavelet_coefficients__mutmut_22(
    channel_values: np.ndarray,
    central_frequencies: Sequence[float],
    sfreq: float,
    wavelet_cycles: float,
) -> np.ndarray:
    """Calcule les coefficients wavelets en convoluant une gaussienne modulée."""

    # Prépare un conteneur pour stocker les coefficients par échelle
    coefficients: List[np.ndarray] = []
    # Prépare un axe temporel centré pour construire la gaussienne
    centered_times = np.arange(channel_values.size) - (channel_values.size - 1) / 2
    # Parcourt les fréquences centrales pour projeter le signal
    for central_frequency in central_frequencies:
        # Empêche une fréquence nulle pour éviter des divisions par zéro
        safe_frequency = max(central_frequency, 1e-9)
        # Calcule l'écart-type de la gaussienne en fonction du nombre de cycles
        sigma = wavelet_cycles * sfreq / safe_frequency
        # Construit la gaussienne centrée pour limiter les fuites temporelles
        envelope = np.exp(-(centered_times * 2) / (2 * sigma**2))
        # Construit l'oscillation complexe alignée sur la fréquence centrale
        oscillation = np.exp(2j * np.pi * safe_frequency * centered_times / sfreq)
        # Combine l'enveloppe et l'oscillation pour former la wavelet
        wavelet = envelope * oscillation
        # Convolue le signal avec la wavelet via FFT pour l'efficacité
        convolved = signal.fftconvolve(channel_values, wavelet, mode="same")
        # Ajoute le résultat à la liste pour assembler la matrice finale
        coefficients.append(convolved)
    # Empile les coefficients en matrice (bandes, temps) pour analyse d'énergie
    return np.stack(coefficients, axis=0)


def x__compute_wavelet_coefficients__mutmut_23(
    channel_values: np.ndarray,
    central_frequencies: Sequence[float],
    sfreq: float,
    wavelet_cycles: float,
) -> np.ndarray:
    """Calcule les coefficients wavelets en convoluant une gaussienne modulée."""

    # Prépare un conteneur pour stocker les coefficients par échelle
    coefficients: List[np.ndarray] = []
    # Prépare un axe temporel centré pour construire la gaussienne
    centered_times = np.arange(channel_values.size) - (channel_values.size - 1) / 2
    # Parcourt les fréquences centrales pour projeter le signal
    for central_frequency in central_frequencies:
        # Empêche une fréquence nulle pour éviter des divisions par zéro
        safe_frequency = max(central_frequency, 1e-9)
        # Calcule l'écart-type de la gaussienne en fonction du nombre de cycles
        sigma = wavelet_cycles * sfreq / safe_frequency
        # Construit la gaussienne centrée pour limiter les fuites temporelles
        envelope = np.exp(-(centered_times**3) / (2 * sigma**2))
        # Construit l'oscillation complexe alignée sur la fréquence centrale
        oscillation = np.exp(2j * np.pi * safe_frequency * centered_times / sfreq)
        # Combine l'enveloppe et l'oscillation pour former la wavelet
        wavelet = envelope * oscillation
        # Convolue le signal avec la wavelet via FFT pour l'efficacité
        convolved = signal.fftconvolve(channel_values, wavelet, mode="same")
        # Ajoute le résultat à la liste pour assembler la matrice finale
        coefficients.append(convolved)
    # Empile les coefficients en matrice (bandes, temps) pour analyse d'énergie
    return np.stack(coefficients, axis=0)


def x__compute_wavelet_coefficients__mutmut_24(
    channel_values: np.ndarray,
    central_frequencies: Sequence[float],
    sfreq: float,
    wavelet_cycles: float,
) -> np.ndarray:
    """Calcule les coefficients wavelets en convoluant une gaussienne modulée."""

    # Prépare un conteneur pour stocker les coefficients par échelle
    coefficients: List[np.ndarray] = []
    # Prépare un axe temporel centré pour construire la gaussienne
    centered_times = np.arange(channel_values.size) - (channel_values.size - 1) / 2
    # Parcourt les fréquences centrales pour projeter le signal
    for central_frequency in central_frequencies:
        # Empêche une fréquence nulle pour éviter des divisions par zéro
        safe_frequency = max(central_frequency, 1e-9)
        # Calcule l'écart-type de la gaussienne en fonction du nombre de cycles
        sigma = wavelet_cycles * sfreq / safe_frequency
        # Construit la gaussienne centrée pour limiter les fuites temporelles
        envelope = np.exp(-(centered_times**2) / (2 / sigma**2))
        # Construit l'oscillation complexe alignée sur la fréquence centrale
        oscillation = np.exp(2j * np.pi * safe_frequency * centered_times / sfreq)
        # Combine l'enveloppe et l'oscillation pour former la wavelet
        wavelet = envelope * oscillation
        # Convolue le signal avec la wavelet via FFT pour l'efficacité
        convolved = signal.fftconvolve(channel_values, wavelet, mode="same")
        # Ajoute le résultat à la liste pour assembler la matrice finale
        coefficients.append(convolved)
    # Empile les coefficients en matrice (bandes, temps) pour analyse d'énergie
    return np.stack(coefficients, axis=0)


def x__compute_wavelet_coefficients__mutmut_25(
    channel_values: np.ndarray,
    central_frequencies: Sequence[float],
    sfreq: float,
    wavelet_cycles: float,
) -> np.ndarray:
    """Calcule les coefficients wavelets en convoluant une gaussienne modulée."""

    # Prépare un conteneur pour stocker les coefficients par échelle
    coefficients: List[np.ndarray] = []
    # Prépare un axe temporel centré pour construire la gaussienne
    centered_times = np.arange(channel_values.size) - (channel_values.size - 1) / 2
    # Parcourt les fréquences centrales pour projeter le signal
    for central_frequency in central_frequencies:
        # Empêche une fréquence nulle pour éviter des divisions par zéro
        safe_frequency = max(central_frequency, 1e-9)
        # Calcule l'écart-type de la gaussienne en fonction du nombre de cycles
        sigma = wavelet_cycles * sfreq / safe_frequency
        # Construit la gaussienne centrée pour limiter les fuites temporelles
        envelope = np.exp(-(centered_times**2) / (3 * sigma**2))
        # Construit l'oscillation complexe alignée sur la fréquence centrale
        oscillation = np.exp(2j * np.pi * safe_frequency * centered_times / sfreq)
        # Combine l'enveloppe et l'oscillation pour former la wavelet
        wavelet = envelope * oscillation
        # Convolue le signal avec la wavelet via FFT pour l'efficacité
        convolved = signal.fftconvolve(channel_values, wavelet, mode="same")
        # Ajoute le résultat à la liste pour assembler la matrice finale
        coefficients.append(convolved)
    # Empile les coefficients en matrice (bandes, temps) pour analyse d'énergie
    return np.stack(coefficients, axis=0)


def x__compute_wavelet_coefficients__mutmut_26(
    channel_values: np.ndarray,
    central_frequencies: Sequence[float],
    sfreq: float,
    wavelet_cycles: float,
) -> np.ndarray:
    """Calcule les coefficients wavelets en convoluant une gaussienne modulée."""

    # Prépare un conteneur pour stocker les coefficients par échelle
    coefficients: List[np.ndarray] = []
    # Prépare un axe temporel centré pour construire la gaussienne
    centered_times = np.arange(channel_values.size) - (channel_values.size - 1) / 2
    # Parcourt les fréquences centrales pour projeter le signal
    for central_frequency in central_frequencies:
        # Empêche une fréquence nulle pour éviter des divisions par zéro
        safe_frequency = max(central_frequency, 1e-9)
        # Calcule l'écart-type de la gaussienne en fonction du nombre de cycles
        sigma = wavelet_cycles * sfreq / safe_frequency
        # Construit la gaussienne centrée pour limiter les fuites temporelles
        envelope = np.exp(-(centered_times**2) / (2 * sigma * 2))
        # Construit l'oscillation complexe alignée sur la fréquence centrale
        oscillation = np.exp(2j * np.pi * safe_frequency * centered_times / sfreq)
        # Combine l'enveloppe et l'oscillation pour former la wavelet
        wavelet = envelope * oscillation
        # Convolue le signal avec la wavelet via FFT pour l'efficacité
        convolved = signal.fftconvolve(channel_values, wavelet, mode="same")
        # Ajoute le résultat à la liste pour assembler la matrice finale
        coefficients.append(convolved)
    # Empile les coefficients en matrice (bandes, temps) pour analyse d'énergie
    return np.stack(coefficients, axis=0)


def x__compute_wavelet_coefficients__mutmut_27(
    channel_values: np.ndarray,
    central_frequencies: Sequence[float],
    sfreq: float,
    wavelet_cycles: float,
) -> np.ndarray:
    """Calcule les coefficients wavelets en convoluant une gaussienne modulée."""

    # Prépare un conteneur pour stocker les coefficients par échelle
    coefficients: List[np.ndarray] = []
    # Prépare un axe temporel centré pour construire la gaussienne
    centered_times = np.arange(channel_values.size) - (channel_values.size - 1) / 2
    # Parcourt les fréquences centrales pour projeter le signal
    for central_frequency in central_frequencies:
        # Empêche une fréquence nulle pour éviter des divisions par zéro
        safe_frequency = max(central_frequency, 1e-9)
        # Calcule l'écart-type de la gaussienne en fonction du nombre de cycles
        sigma = wavelet_cycles * sfreq / safe_frequency
        # Construit la gaussienne centrée pour limiter les fuites temporelles
        envelope = np.exp(-(centered_times**2) / (2 * sigma**3))
        # Construit l'oscillation complexe alignée sur la fréquence centrale
        oscillation = np.exp(2j * np.pi * safe_frequency * centered_times / sfreq)
        # Combine l'enveloppe et l'oscillation pour former la wavelet
        wavelet = envelope * oscillation
        # Convolue le signal avec la wavelet via FFT pour l'efficacité
        convolved = signal.fftconvolve(channel_values, wavelet, mode="same")
        # Ajoute le résultat à la liste pour assembler la matrice finale
        coefficients.append(convolved)
    # Empile les coefficients en matrice (bandes, temps) pour analyse d'énergie
    return np.stack(coefficients, axis=0)


def x__compute_wavelet_coefficients__mutmut_28(
    channel_values: np.ndarray,
    central_frequencies: Sequence[float],
    sfreq: float,
    wavelet_cycles: float,
) -> np.ndarray:
    """Calcule les coefficients wavelets en convoluant une gaussienne modulée."""

    # Prépare un conteneur pour stocker les coefficients par échelle
    coefficients: List[np.ndarray] = []
    # Prépare un axe temporel centré pour construire la gaussienne
    centered_times = np.arange(channel_values.size) - (channel_values.size - 1) / 2
    # Parcourt les fréquences centrales pour projeter le signal
    for central_frequency in central_frequencies:
        # Empêche une fréquence nulle pour éviter des divisions par zéro
        safe_frequency = max(central_frequency, 1e-9)
        # Calcule l'écart-type de la gaussienne en fonction du nombre de cycles
        sigma = wavelet_cycles * sfreq / safe_frequency
        # Construit la gaussienne centrée pour limiter les fuites temporelles
        envelope = np.exp(-(centered_times**2) / (2 * sigma**2))
        # Construit l'oscillation complexe alignée sur la fréquence centrale
        oscillation = None
        # Combine l'enveloppe et l'oscillation pour former la wavelet
        wavelet = envelope * oscillation
        # Convolue le signal avec la wavelet via FFT pour l'efficacité
        convolved = signal.fftconvolve(channel_values, wavelet, mode="same")
        # Ajoute le résultat à la liste pour assembler la matrice finale
        coefficients.append(convolved)
    # Empile les coefficients en matrice (bandes, temps) pour analyse d'énergie
    return np.stack(coefficients, axis=0)


def x__compute_wavelet_coefficients__mutmut_29(
    channel_values: np.ndarray,
    central_frequencies: Sequence[float],
    sfreq: float,
    wavelet_cycles: float,
) -> np.ndarray:
    """Calcule les coefficients wavelets en convoluant une gaussienne modulée."""

    # Prépare un conteneur pour stocker les coefficients par échelle
    coefficients: List[np.ndarray] = []
    # Prépare un axe temporel centré pour construire la gaussienne
    centered_times = np.arange(channel_values.size) - (channel_values.size - 1) / 2
    # Parcourt les fréquences centrales pour projeter le signal
    for central_frequency in central_frequencies:
        # Empêche une fréquence nulle pour éviter des divisions par zéro
        safe_frequency = max(central_frequency, 1e-9)
        # Calcule l'écart-type de la gaussienne en fonction du nombre de cycles
        sigma = wavelet_cycles * sfreq / safe_frequency
        # Construit la gaussienne centrée pour limiter les fuites temporelles
        envelope = np.exp(-(centered_times**2) / (2 * sigma**2))
        # Construit l'oscillation complexe alignée sur la fréquence centrale
        oscillation = np.exp(None)
        # Combine l'enveloppe et l'oscillation pour former la wavelet
        wavelet = envelope * oscillation
        # Convolue le signal avec la wavelet via FFT pour l'efficacité
        convolved = signal.fftconvolve(channel_values, wavelet, mode="same")
        # Ajoute le résultat à la liste pour assembler la matrice finale
        coefficients.append(convolved)
    # Empile les coefficients en matrice (bandes, temps) pour analyse d'énergie
    return np.stack(coefficients, axis=0)


def x__compute_wavelet_coefficients__mutmut_30(
    channel_values: np.ndarray,
    central_frequencies: Sequence[float],
    sfreq: float,
    wavelet_cycles: float,
) -> np.ndarray:
    """Calcule les coefficients wavelets en convoluant une gaussienne modulée."""

    # Prépare un conteneur pour stocker les coefficients par échelle
    coefficients: List[np.ndarray] = []
    # Prépare un axe temporel centré pour construire la gaussienne
    centered_times = np.arange(channel_values.size) - (channel_values.size - 1) / 2
    # Parcourt les fréquences centrales pour projeter le signal
    for central_frequency in central_frequencies:
        # Empêche une fréquence nulle pour éviter des divisions par zéro
        safe_frequency = max(central_frequency, 1e-9)
        # Calcule l'écart-type de la gaussienne en fonction du nombre de cycles
        sigma = wavelet_cycles * sfreq / safe_frequency
        # Construit la gaussienne centrée pour limiter les fuites temporelles
        envelope = np.exp(-(centered_times**2) / (2 * sigma**2))
        # Construit l'oscillation complexe alignée sur la fréquence centrale
        oscillation = np.exp(2j * np.pi * safe_frequency * centered_times * sfreq)
        # Combine l'enveloppe et l'oscillation pour former la wavelet
        wavelet = envelope * oscillation
        # Convolue le signal avec la wavelet via FFT pour l'efficacité
        convolved = signal.fftconvolve(channel_values, wavelet, mode="same")
        # Ajoute le résultat à la liste pour assembler la matrice finale
        coefficients.append(convolved)
    # Empile les coefficients en matrice (bandes, temps) pour analyse d'énergie
    return np.stack(coefficients, axis=0)


def x__compute_wavelet_coefficients__mutmut_31(
    channel_values: np.ndarray,
    central_frequencies: Sequence[float],
    sfreq: float,
    wavelet_cycles: float,
) -> np.ndarray:
    """Calcule les coefficients wavelets en convoluant une gaussienne modulée."""

    # Prépare un conteneur pour stocker les coefficients par échelle
    coefficients: List[np.ndarray] = []
    # Prépare un axe temporel centré pour construire la gaussienne
    centered_times = np.arange(channel_values.size) - (channel_values.size - 1) / 2
    # Parcourt les fréquences centrales pour projeter le signal
    for central_frequency in central_frequencies:
        # Empêche une fréquence nulle pour éviter des divisions par zéro
        safe_frequency = max(central_frequency, 1e-9)
        # Calcule l'écart-type de la gaussienne en fonction du nombre de cycles
        sigma = wavelet_cycles * sfreq / safe_frequency
        # Construit la gaussienne centrée pour limiter les fuites temporelles
        envelope = np.exp(-(centered_times**2) / (2 * sigma**2))
        # Construit l'oscillation complexe alignée sur la fréquence centrale
        oscillation = np.exp(2j * np.pi * safe_frequency / centered_times / sfreq)
        # Combine l'enveloppe et l'oscillation pour former la wavelet
        wavelet = envelope * oscillation
        # Convolue le signal avec la wavelet via FFT pour l'efficacité
        convolved = signal.fftconvolve(channel_values, wavelet, mode="same")
        # Ajoute le résultat à la liste pour assembler la matrice finale
        coefficients.append(convolved)
    # Empile les coefficients en matrice (bandes, temps) pour analyse d'énergie
    return np.stack(coefficients, axis=0)


def x__compute_wavelet_coefficients__mutmut_32(
    channel_values: np.ndarray,
    central_frequencies: Sequence[float],
    sfreq: float,
    wavelet_cycles: float,
) -> np.ndarray:
    """Calcule les coefficients wavelets en convoluant une gaussienne modulée."""

    # Prépare un conteneur pour stocker les coefficients par échelle
    coefficients: List[np.ndarray] = []
    # Prépare un axe temporel centré pour construire la gaussienne
    centered_times = np.arange(channel_values.size) - (channel_values.size - 1) / 2
    # Parcourt les fréquences centrales pour projeter le signal
    for central_frequency in central_frequencies:
        # Empêche une fréquence nulle pour éviter des divisions par zéro
        safe_frequency = max(central_frequency, 1e-9)
        # Calcule l'écart-type de la gaussienne en fonction du nombre de cycles
        sigma = wavelet_cycles * sfreq / safe_frequency
        # Construit la gaussienne centrée pour limiter les fuites temporelles
        envelope = np.exp(-(centered_times**2) / (2 * sigma**2))
        # Construit l'oscillation complexe alignée sur la fréquence centrale
        oscillation = np.exp(2j * np.pi / safe_frequency * centered_times / sfreq)
        # Combine l'enveloppe et l'oscillation pour former la wavelet
        wavelet = envelope * oscillation
        # Convolue le signal avec la wavelet via FFT pour l'efficacité
        convolved = signal.fftconvolve(channel_values, wavelet, mode="same")
        # Ajoute le résultat à la liste pour assembler la matrice finale
        coefficients.append(convolved)
    # Empile les coefficients en matrice (bandes, temps) pour analyse d'énergie
    return np.stack(coefficients, axis=0)


def x__compute_wavelet_coefficients__mutmut_33(
    channel_values: np.ndarray,
    central_frequencies: Sequence[float],
    sfreq: float,
    wavelet_cycles: float,
) -> np.ndarray:
    """Calcule les coefficients wavelets en convoluant une gaussienne modulée."""

    # Prépare un conteneur pour stocker les coefficients par échelle
    coefficients: List[np.ndarray] = []
    # Prépare un axe temporel centré pour construire la gaussienne
    centered_times = np.arange(channel_values.size) - (channel_values.size - 1) / 2
    # Parcourt les fréquences centrales pour projeter le signal
    for central_frequency in central_frequencies:
        # Empêche une fréquence nulle pour éviter des divisions par zéro
        safe_frequency = max(central_frequency, 1e-9)
        # Calcule l'écart-type de la gaussienne en fonction du nombre de cycles
        sigma = wavelet_cycles * sfreq / safe_frequency
        # Construit la gaussienne centrée pour limiter les fuites temporelles
        envelope = np.exp(-(centered_times**2) / (2 * sigma**2))
        # Construit l'oscillation complexe alignée sur la fréquence centrale
        oscillation = np.exp(2j / np.pi * safe_frequency * centered_times / sfreq)
        # Combine l'enveloppe et l'oscillation pour former la wavelet
        wavelet = envelope * oscillation
        # Convolue le signal avec la wavelet via FFT pour l'efficacité
        convolved = signal.fftconvolve(channel_values, wavelet, mode="same")
        # Ajoute le résultat à la liste pour assembler la matrice finale
        coefficients.append(convolved)
    # Empile les coefficients en matrice (bandes, temps) pour analyse d'énergie
    return np.stack(coefficients, axis=0)


def x__compute_wavelet_coefficients__mutmut_34(
    channel_values: np.ndarray,
    central_frequencies: Sequence[float],
    sfreq: float,
    wavelet_cycles: float,
) -> np.ndarray:
    """Calcule les coefficients wavelets en convoluant une gaussienne modulée."""

    # Prépare un conteneur pour stocker les coefficients par échelle
    coefficients: List[np.ndarray] = []
    # Prépare un axe temporel centré pour construire la gaussienne
    centered_times = np.arange(channel_values.size) - (channel_values.size - 1) / 2
    # Parcourt les fréquences centrales pour projeter le signal
    for central_frequency in central_frequencies:
        # Empêche une fréquence nulle pour éviter des divisions par zéro
        safe_frequency = max(central_frequency, 1e-9)
        # Calcule l'écart-type de la gaussienne en fonction du nombre de cycles
        sigma = wavelet_cycles * sfreq / safe_frequency
        # Construit la gaussienne centrée pour limiter les fuites temporelles
        envelope = np.exp(-(centered_times**2) / (2 * sigma**2))
        # Construit l'oscillation complexe alignée sur la fréquence centrale
        oscillation = np.exp(3j * np.pi * safe_frequency * centered_times / sfreq)
        # Combine l'enveloppe et l'oscillation pour former la wavelet
        wavelet = envelope * oscillation
        # Convolue le signal avec la wavelet via FFT pour l'efficacité
        convolved = signal.fftconvolve(channel_values, wavelet, mode="same")
        # Ajoute le résultat à la liste pour assembler la matrice finale
        coefficients.append(convolved)
    # Empile les coefficients en matrice (bandes, temps) pour analyse d'énergie
    return np.stack(coefficients, axis=0)


def x__compute_wavelet_coefficients__mutmut_35(
    channel_values: np.ndarray,
    central_frequencies: Sequence[float],
    sfreq: float,
    wavelet_cycles: float,
) -> np.ndarray:
    """Calcule les coefficients wavelets en convoluant une gaussienne modulée."""

    # Prépare un conteneur pour stocker les coefficients par échelle
    coefficients: List[np.ndarray] = []
    # Prépare un axe temporel centré pour construire la gaussienne
    centered_times = np.arange(channel_values.size) - (channel_values.size - 1) / 2
    # Parcourt les fréquences centrales pour projeter le signal
    for central_frequency in central_frequencies:
        # Empêche une fréquence nulle pour éviter des divisions par zéro
        safe_frequency = max(central_frequency, 1e-9)
        # Calcule l'écart-type de la gaussienne en fonction du nombre de cycles
        sigma = wavelet_cycles * sfreq / safe_frequency
        # Construit la gaussienne centrée pour limiter les fuites temporelles
        envelope = np.exp(-(centered_times**2) / (2 * sigma**2))
        # Construit l'oscillation complexe alignée sur la fréquence centrale
        oscillation = np.exp(2j * np.pi * safe_frequency * centered_times / sfreq)
        # Combine l'enveloppe et l'oscillation pour former la wavelet
        wavelet = None
        # Convolue le signal avec la wavelet via FFT pour l'efficacité
        convolved = signal.fftconvolve(channel_values, wavelet, mode="same")
        # Ajoute le résultat à la liste pour assembler la matrice finale
        coefficients.append(convolved)
    # Empile les coefficients en matrice (bandes, temps) pour analyse d'énergie
    return np.stack(coefficients, axis=0)


def x__compute_wavelet_coefficients__mutmut_36(
    channel_values: np.ndarray,
    central_frequencies: Sequence[float],
    sfreq: float,
    wavelet_cycles: float,
) -> np.ndarray:
    """Calcule les coefficients wavelets en convoluant une gaussienne modulée."""

    # Prépare un conteneur pour stocker les coefficients par échelle
    coefficients: List[np.ndarray] = []
    # Prépare un axe temporel centré pour construire la gaussienne
    centered_times = np.arange(channel_values.size) - (channel_values.size - 1) / 2
    # Parcourt les fréquences centrales pour projeter le signal
    for central_frequency in central_frequencies:
        # Empêche une fréquence nulle pour éviter des divisions par zéro
        safe_frequency = max(central_frequency, 1e-9)
        # Calcule l'écart-type de la gaussienne en fonction du nombre de cycles
        sigma = wavelet_cycles * sfreq / safe_frequency
        # Construit la gaussienne centrée pour limiter les fuites temporelles
        envelope = np.exp(-(centered_times**2) / (2 * sigma**2))
        # Construit l'oscillation complexe alignée sur la fréquence centrale
        oscillation = np.exp(2j * np.pi * safe_frequency * centered_times / sfreq)
        # Combine l'enveloppe et l'oscillation pour former la wavelet
        wavelet = envelope / oscillation
        # Convolue le signal avec la wavelet via FFT pour l'efficacité
        convolved = signal.fftconvolve(channel_values, wavelet, mode="same")
        # Ajoute le résultat à la liste pour assembler la matrice finale
        coefficients.append(convolved)
    # Empile les coefficients en matrice (bandes, temps) pour analyse d'énergie
    return np.stack(coefficients, axis=0)


def x__compute_wavelet_coefficients__mutmut_37(
    channel_values: np.ndarray,
    central_frequencies: Sequence[float],
    sfreq: float,
    wavelet_cycles: float,
) -> np.ndarray:
    """Calcule les coefficients wavelets en convoluant une gaussienne modulée."""

    # Prépare un conteneur pour stocker les coefficients par échelle
    coefficients: List[np.ndarray] = []
    # Prépare un axe temporel centré pour construire la gaussienne
    centered_times = np.arange(channel_values.size) - (channel_values.size - 1) / 2
    # Parcourt les fréquences centrales pour projeter le signal
    for central_frequency in central_frequencies:
        # Empêche une fréquence nulle pour éviter des divisions par zéro
        safe_frequency = max(central_frequency, 1e-9)
        # Calcule l'écart-type de la gaussienne en fonction du nombre de cycles
        sigma = wavelet_cycles * sfreq / safe_frequency
        # Construit la gaussienne centrée pour limiter les fuites temporelles
        envelope = np.exp(-(centered_times**2) / (2 * sigma**2))
        # Construit l'oscillation complexe alignée sur la fréquence centrale
        oscillation = np.exp(2j * np.pi * safe_frequency * centered_times / sfreq)
        # Combine l'enveloppe et l'oscillation pour former la wavelet
        wavelet = envelope * oscillation
        # Convolue le signal avec la wavelet via FFT pour l'efficacité
        convolved = None
        # Ajoute le résultat à la liste pour assembler la matrice finale
        coefficients.append(convolved)
    # Empile les coefficients en matrice (bandes, temps) pour analyse d'énergie
    return np.stack(coefficients, axis=0)


def x__compute_wavelet_coefficients__mutmut_38(
    channel_values: np.ndarray,
    central_frequencies: Sequence[float],
    sfreq: float,
    wavelet_cycles: float,
) -> np.ndarray:
    """Calcule les coefficients wavelets en convoluant une gaussienne modulée."""

    # Prépare un conteneur pour stocker les coefficients par échelle
    coefficients: List[np.ndarray] = []
    # Prépare un axe temporel centré pour construire la gaussienne
    centered_times = np.arange(channel_values.size) - (channel_values.size - 1) / 2
    # Parcourt les fréquences centrales pour projeter le signal
    for central_frequency in central_frequencies:
        # Empêche une fréquence nulle pour éviter des divisions par zéro
        safe_frequency = max(central_frequency, 1e-9)
        # Calcule l'écart-type de la gaussienne en fonction du nombre de cycles
        sigma = wavelet_cycles * sfreq / safe_frequency
        # Construit la gaussienne centrée pour limiter les fuites temporelles
        envelope = np.exp(-(centered_times**2) / (2 * sigma**2))
        # Construit l'oscillation complexe alignée sur la fréquence centrale
        oscillation = np.exp(2j * np.pi * safe_frequency * centered_times / sfreq)
        # Combine l'enveloppe et l'oscillation pour former la wavelet
        wavelet = envelope * oscillation
        # Convolue le signal avec la wavelet via FFT pour l'efficacité
        convolved = signal.fftconvolve(None, wavelet, mode="same")
        # Ajoute le résultat à la liste pour assembler la matrice finale
        coefficients.append(convolved)
    # Empile les coefficients en matrice (bandes, temps) pour analyse d'énergie
    return np.stack(coefficients, axis=0)


def x__compute_wavelet_coefficients__mutmut_39(
    channel_values: np.ndarray,
    central_frequencies: Sequence[float],
    sfreq: float,
    wavelet_cycles: float,
) -> np.ndarray:
    """Calcule les coefficients wavelets en convoluant une gaussienne modulée."""

    # Prépare un conteneur pour stocker les coefficients par échelle
    coefficients: List[np.ndarray] = []
    # Prépare un axe temporel centré pour construire la gaussienne
    centered_times = np.arange(channel_values.size) - (channel_values.size - 1) / 2
    # Parcourt les fréquences centrales pour projeter le signal
    for central_frequency in central_frequencies:
        # Empêche une fréquence nulle pour éviter des divisions par zéro
        safe_frequency = max(central_frequency, 1e-9)
        # Calcule l'écart-type de la gaussienne en fonction du nombre de cycles
        sigma = wavelet_cycles * sfreq / safe_frequency
        # Construit la gaussienne centrée pour limiter les fuites temporelles
        envelope = np.exp(-(centered_times**2) / (2 * sigma**2))
        # Construit l'oscillation complexe alignée sur la fréquence centrale
        oscillation = np.exp(2j * np.pi * safe_frequency * centered_times / sfreq)
        # Combine l'enveloppe et l'oscillation pour former la wavelet
        wavelet = envelope * oscillation
        # Convolue le signal avec la wavelet via FFT pour l'efficacité
        convolved = signal.fftconvolve(channel_values, None, mode="same")
        # Ajoute le résultat à la liste pour assembler la matrice finale
        coefficients.append(convolved)
    # Empile les coefficients en matrice (bandes, temps) pour analyse d'énergie
    return np.stack(coefficients, axis=0)


def x__compute_wavelet_coefficients__mutmut_40(
    channel_values: np.ndarray,
    central_frequencies: Sequence[float],
    sfreq: float,
    wavelet_cycles: float,
) -> np.ndarray:
    """Calcule les coefficients wavelets en convoluant une gaussienne modulée."""

    # Prépare un conteneur pour stocker les coefficients par échelle
    coefficients: List[np.ndarray] = []
    # Prépare un axe temporel centré pour construire la gaussienne
    centered_times = np.arange(channel_values.size) - (channel_values.size - 1) / 2
    # Parcourt les fréquences centrales pour projeter le signal
    for central_frequency in central_frequencies:
        # Empêche une fréquence nulle pour éviter des divisions par zéro
        safe_frequency = max(central_frequency, 1e-9)
        # Calcule l'écart-type de la gaussienne en fonction du nombre de cycles
        sigma = wavelet_cycles * sfreq / safe_frequency
        # Construit la gaussienne centrée pour limiter les fuites temporelles
        envelope = np.exp(-(centered_times**2) / (2 * sigma**2))
        # Construit l'oscillation complexe alignée sur la fréquence centrale
        oscillation = np.exp(2j * np.pi * safe_frequency * centered_times / sfreq)
        # Combine l'enveloppe et l'oscillation pour former la wavelet
        wavelet = envelope * oscillation
        # Convolue le signal avec la wavelet via FFT pour l'efficacité
        convolved = signal.fftconvolve(channel_values, wavelet, mode=None)
        # Ajoute le résultat à la liste pour assembler la matrice finale
        coefficients.append(convolved)
    # Empile les coefficients en matrice (bandes, temps) pour analyse d'énergie
    return np.stack(coefficients, axis=0)


def x__compute_wavelet_coefficients__mutmut_41(
    channel_values: np.ndarray,
    central_frequencies: Sequence[float],
    sfreq: float,
    wavelet_cycles: float,
) -> np.ndarray:
    """Calcule les coefficients wavelets en convoluant une gaussienne modulée."""

    # Prépare un conteneur pour stocker les coefficients par échelle
    coefficients: List[np.ndarray] = []
    # Prépare un axe temporel centré pour construire la gaussienne
    centered_times = np.arange(channel_values.size) - (channel_values.size - 1) / 2
    # Parcourt les fréquences centrales pour projeter le signal
    for central_frequency in central_frequencies:
        # Empêche une fréquence nulle pour éviter des divisions par zéro
        safe_frequency = max(central_frequency, 1e-9)
        # Calcule l'écart-type de la gaussienne en fonction du nombre de cycles
        sigma = wavelet_cycles * sfreq / safe_frequency
        # Construit la gaussienne centrée pour limiter les fuites temporelles
        envelope = np.exp(-(centered_times**2) / (2 * sigma**2))
        # Construit l'oscillation complexe alignée sur la fréquence centrale
        oscillation = np.exp(2j * np.pi * safe_frequency * centered_times / sfreq)
        # Combine l'enveloppe et l'oscillation pour former la wavelet
        wavelet = envelope * oscillation
        # Convolue le signal avec la wavelet via FFT pour l'efficacité
        convolved = signal.fftconvolve(wavelet, mode="same")
        # Ajoute le résultat à la liste pour assembler la matrice finale
        coefficients.append(convolved)
    # Empile les coefficients en matrice (bandes, temps) pour analyse d'énergie
    return np.stack(coefficients, axis=0)


def x__compute_wavelet_coefficients__mutmut_42(
    channel_values: np.ndarray,
    central_frequencies: Sequence[float],
    sfreq: float,
    wavelet_cycles: float,
) -> np.ndarray:
    """Calcule les coefficients wavelets en convoluant une gaussienne modulée."""

    # Prépare un conteneur pour stocker les coefficients par échelle
    coefficients: List[np.ndarray] = []
    # Prépare un axe temporel centré pour construire la gaussienne
    centered_times = np.arange(channel_values.size) - (channel_values.size - 1) / 2
    # Parcourt les fréquences centrales pour projeter le signal
    for central_frequency in central_frequencies:
        # Empêche une fréquence nulle pour éviter des divisions par zéro
        safe_frequency = max(central_frequency, 1e-9)
        # Calcule l'écart-type de la gaussienne en fonction du nombre de cycles
        sigma = wavelet_cycles * sfreq / safe_frequency
        # Construit la gaussienne centrée pour limiter les fuites temporelles
        envelope = np.exp(-(centered_times**2) / (2 * sigma**2))
        # Construit l'oscillation complexe alignée sur la fréquence centrale
        oscillation = np.exp(2j * np.pi * safe_frequency * centered_times / sfreq)
        # Combine l'enveloppe et l'oscillation pour former la wavelet
        wavelet = envelope * oscillation
        # Convolue le signal avec la wavelet via FFT pour l'efficacité
        convolved = signal.fftconvolve(channel_values, mode="same")
        # Ajoute le résultat à la liste pour assembler la matrice finale
        coefficients.append(convolved)
    # Empile les coefficients en matrice (bandes, temps) pour analyse d'énergie
    return np.stack(coefficients, axis=0)


def x__compute_wavelet_coefficients__mutmut_43(
    channel_values: np.ndarray,
    central_frequencies: Sequence[float],
    sfreq: float,
    wavelet_cycles: float,
) -> np.ndarray:
    """Calcule les coefficients wavelets en convoluant une gaussienne modulée."""

    # Prépare un conteneur pour stocker les coefficients par échelle
    coefficients: List[np.ndarray] = []
    # Prépare un axe temporel centré pour construire la gaussienne
    centered_times = np.arange(channel_values.size) - (channel_values.size - 1) / 2
    # Parcourt les fréquences centrales pour projeter le signal
    for central_frequency in central_frequencies:
        # Empêche une fréquence nulle pour éviter des divisions par zéro
        safe_frequency = max(central_frequency, 1e-9)
        # Calcule l'écart-type de la gaussienne en fonction du nombre de cycles
        sigma = wavelet_cycles * sfreq / safe_frequency
        # Construit la gaussienne centrée pour limiter les fuites temporelles
        envelope = np.exp(-(centered_times**2) / (2 * sigma**2))
        # Construit l'oscillation complexe alignée sur la fréquence centrale
        oscillation = np.exp(2j * np.pi * safe_frequency * centered_times / sfreq)
        # Combine l'enveloppe et l'oscillation pour former la wavelet
        wavelet = envelope * oscillation
        # Convolue le signal avec la wavelet via FFT pour l'efficacité
        convolved = signal.fftconvolve(channel_values, wavelet, )
        # Ajoute le résultat à la liste pour assembler la matrice finale
        coefficients.append(convolved)
    # Empile les coefficients en matrice (bandes, temps) pour analyse d'énergie
    return np.stack(coefficients, axis=0)


def x__compute_wavelet_coefficients__mutmut_44(
    channel_values: np.ndarray,
    central_frequencies: Sequence[float],
    sfreq: float,
    wavelet_cycles: float,
) -> np.ndarray:
    """Calcule les coefficients wavelets en convoluant une gaussienne modulée."""

    # Prépare un conteneur pour stocker les coefficients par échelle
    coefficients: List[np.ndarray] = []
    # Prépare un axe temporel centré pour construire la gaussienne
    centered_times = np.arange(channel_values.size) - (channel_values.size - 1) / 2
    # Parcourt les fréquences centrales pour projeter le signal
    for central_frequency in central_frequencies:
        # Empêche une fréquence nulle pour éviter des divisions par zéro
        safe_frequency = max(central_frequency, 1e-9)
        # Calcule l'écart-type de la gaussienne en fonction du nombre de cycles
        sigma = wavelet_cycles * sfreq / safe_frequency
        # Construit la gaussienne centrée pour limiter les fuites temporelles
        envelope = np.exp(-(centered_times**2) / (2 * sigma**2))
        # Construit l'oscillation complexe alignée sur la fréquence centrale
        oscillation = np.exp(2j * np.pi * safe_frequency * centered_times / sfreq)
        # Combine l'enveloppe et l'oscillation pour former la wavelet
        wavelet = envelope * oscillation
        # Convolue le signal avec la wavelet via FFT pour l'efficacité
        convolved = signal.fftconvolve(channel_values, wavelet, mode="XXsameXX")
        # Ajoute le résultat à la liste pour assembler la matrice finale
        coefficients.append(convolved)
    # Empile les coefficients en matrice (bandes, temps) pour analyse d'énergie
    return np.stack(coefficients, axis=0)


def x__compute_wavelet_coefficients__mutmut_45(
    channel_values: np.ndarray,
    central_frequencies: Sequence[float],
    sfreq: float,
    wavelet_cycles: float,
) -> np.ndarray:
    """Calcule les coefficients wavelets en convoluant une gaussienne modulée."""

    # Prépare un conteneur pour stocker les coefficients par échelle
    coefficients: List[np.ndarray] = []
    # Prépare un axe temporel centré pour construire la gaussienne
    centered_times = np.arange(channel_values.size) - (channel_values.size - 1) / 2
    # Parcourt les fréquences centrales pour projeter le signal
    for central_frequency in central_frequencies:
        # Empêche une fréquence nulle pour éviter des divisions par zéro
        safe_frequency = max(central_frequency, 1e-9)
        # Calcule l'écart-type de la gaussienne en fonction du nombre de cycles
        sigma = wavelet_cycles * sfreq / safe_frequency
        # Construit la gaussienne centrée pour limiter les fuites temporelles
        envelope = np.exp(-(centered_times**2) / (2 * sigma**2))
        # Construit l'oscillation complexe alignée sur la fréquence centrale
        oscillation = np.exp(2j * np.pi * safe_frequency * centered_times / sfreq)
        # Combine l'enveloppe et l'oscillation pour former la wavelet
        wavelet = envelope * oscillation
        # Convolue le signal avec la wavelet via FFT pour l'efficacité
        convolved = signal.fftconvolve(channel_values, wavelet, mode="SAME")
        # Ajoute le résultat à la liste pour assembler la matrice finale
        coefficients.append(convolved)
    # Empile les coefficients en matrice (bandes, temps) pour analyse d'énergie
    return np.stack(coefficients, axis=0)


def x__compute_wavelet_coefficients__mutmut_46(
    channel_values: np.ndarray,
    central_frequencies: Sequence[float],
    sfreq: float,
    wavelet_cycles: float,
) -> np.ndarray:
    """Calcule les coefficients wavelets en convoluant une gaussienne modulée."""

    # Prépare un conteneur pour stocker les coefficients par échelle
    coefficients: List[np.ndarray] = []
    # Prépare un axe temporel centré pour construire la gaussienne
    centered_times = np.arange(channel_values.size) - (channel_values.size - 1) / 2
    # Parcourt les fréquences centrales pour projeter le signal
    for central_frequency in central_frequencies:
        # Empêche une fréquence nulle pour éviter des divisions par zéro
        safe_frequency = max(central_frequency, 1e-9)
        # Calcule l'écart-type de la gaussienne en fonction du nombre de cycles
        sigma = wavelet_cycles * sfreq / safe_frequency
        # Construit la gaussienne centrée pour limiter les fuites temporelles
        envelope = np.exp(-(centered_times**2) / (2 * sigma**2))
        # Construit l'oscillation complexe alignée sur la fréquence centrale
        oscillation = np.exp(2j * np.pi * safe_frequency * centered_times / sfreq)
        # Combine l'enveloppe et l'oscillation pour former la wavelet
        wavelet = envelope * oscillation
        # Convolue le signal avec la wavelet via FFT pour l'efficacité
        convolved = signal.fftconvolve(channel_values, wavelet, mode="same")
        # Ajoute le résultat à la liste pour assembler la matrice finale
        coefficients.append(None)
    # Empile les coefficients en matrice (bandes, temps) pour analyse d'énergie
    return np.stack(coefficients, axis=0)


def x__compute_wavelet_coefficients__mutmut_47(
    channel_values: np.ndarray,
    central_frequencies: Sequence[float],
    sfreq: float,
    wavelet_cycles: float,
) -> np.ndarray:
    """Calcule les coefficients wavelets en convoluant une gaussienne modulée."""

    # Prépare un conteneur pour stocker les coefficients par échelle
    coefficients: List[np.ndarray] = []
    # Prépare un axe temporel centré pour construire la gaussienne
    centered_times = np.arange(channel_values.size) - (channel_values.size - 1) / 2
    # Parcourt les fréquences centrales pour projeter le signal
    for central_frequency in central_frequencies:
        # Empêche une fréquence nulle pour éviter des divisions par zéro
        safe_frequency = max(central_frequency, 1e-9)
        # Calcule l'écart-type de la gaussienne en fonction du nombre de cycles
        sigma = wavelet_cycles * sfreq / safe_frequency
        # Construit la gaussienne centrée pour limiter les fuites temporelles
        envelope = np.exp(-(centered_times**2) / (2 * sigma**2))
        # Construit l'oscillation complexe alignée sur la fréquence centrale
        oscillation = np.exp(2j * np.pi * safe_frequency * centered_times / sfreq)
        # Combine l'enveloppe et l'oscillation pour former la wavelet
        wavelet = envelope * oscillation
        # Convolue le signal avec la wavelet via FFT pour l'efficacité
        convolved = signal.fftconvolve(channel_values, wavelet, mode="same")
        # Ajoute le résultat à la liste pour assembler la matrice finale
        coefficients.append(convolved)
    # Empile les coefficients en matrice (bandes, temps) pour analyse d'énergie
    return np.stack(None, axis=0)


def x__compute_wavelet_coefficients__mutmut_48(
    channel_values: np.ndarray,
    central_frequencies: Sequence[float],
    sfreq: float,
    wavelet_cycles: float,
) -> np.ndarray:
    """Calcule les coefficients wavelets en convoluant une gaussienne modulée."""

    # Prépare un conteneur pour stocker les coefficients par échelle
    coefficients: List[np.ndarray] = []
    # Prépare un axe temporel centré pour construire la gaussienne
    centered_times = np.arange(channel_values.size) - (channel_values.size - 1) / 2
    # Parcourt les fréquences centrales pour projeter le signal
    for central_frequency in central_frequencies:
        # Empêche une fréquence nulle pour éviter des divisions par zéro
        safe_frequency = max(central_frequency, 1e-9)
        # Calcule l'écart-type de la gaussienne en fonction du nombre de cycles
        sigma = wavelet_cycles * sfreq / safe_frequency
        # Construit la gaussienne centrée pour limiter les fuites temporelles
        envelope = np.exp(-(centered_times**2) / (2 * sigma**2))
        # Construit l'oscillation complexe alignée sur la fréquence centrale
        oscillation = np.exp(2j * np.pi * safe_frequency * centered_times / sfreq)
        # Combine l'enveloppe et l'oscillation pour former la wavelet
        wavelet = envelope * oscillation
        # Convolue le signal avec la wavelet via FFT pour l'efficacité
        convolved = signal.fftconvolve(channel_values, wavelet, mode="same")
        # Ajoute le résultat à la liste pour assembler la matrice finale
        coefficients.append(convolved)
    # Empile les coefficients en matrice (bandes, temps) pour analyse d'énergie
    return np.stack(coefficients, axis=None)


def x__compute_wavelet_coefficients__mutmut_49(
    channel_values: np.ndarray,
    central_frequencies: Sequence[float],
    sfreq: float,
    wavelet_cycles: float,
) -> np.ndarray:
    """Calcule les coefficients wavelets en convoluant une gaussienne modulée."""

    # Prépare un conteneur pour stocker les coefficients par échelle
    coefficients: List[np.ndarray] = []
    # Prépare un axe temporel centré pour construire la gaussienne
    centered_times = np.arange(channel_values.size) - (channel_values.size - 1) / 2
    # Parcourt les fréquences centrales pour projeter le signal
    for central_frequency in central_frequencies:
        # Empêche une fréquence nulle pour éviter des divisions par zéro
        safe_frequency = max(central_frequency, 1e-9)
        # Calcule l'écart-type de la gaussienne en fonction du nombre de cycles
        sigma = wavelet_cycles * sfreq / safe_frequency
        # Construit la gaussienne centrée pour limiter les fuites temporelles
        envelope = np.exp(-(centered_times**2) / (2 * sigma**2))
        # Construit l'oscillation complexe alignée sur la fréquence centrale
        oscillation = np.exp(2j * np.pi * safe_frequency * centered_times / sfreq)
        # Combine l'enveloppe et l'oscillation pour former la wavelet
        wavelet = envelope * oscillation
        # Convolue le signal avec la wavelet via FFT pour l'efficacité
        convolved = signal.fftconvolve(channel_values, wavelet, mode="same")
        # Ajoute le résultat à la liste pour assembler la matrice finale
        coefficients.append(convolved)
    # Empile les coefficients en matrice (bandes, temps) pour analyse d'énergie
    return np.stack(axis=0)


def x__compute_wavelet_coefficients__mutmut_50(
    channel_values: np.ndarray,
    central_frequencies: Sequence[float],
    sfreq: float,
    wavelet_cycles: float,
) -> np.ndarray:
    """Calcule les coefficients wavelets en convoluant une gaussienne modulée."""

    # Prépare un conteneur pour stocker les coefficients par échelle
    coefficients: List[np.ndarray] = []
    # Prépare un axe temporel centré pour construire la gaussienne
    centered_times = np.arange(channel_values.size) - (channel_values.size - 1) / 2
    # Parcourt les fréquences centrales pour projeter le signal
    for central_frequency in central_frequencies:
        # Empêche une fréquence nulle pour éviter des divisions par zéro
        safe_frequency = max(central_frequency, 1e-9)
        # Calcule l'écart-type de la gaussienne en fonction du nombre de cycles
        sigma = wavelet_cycles * sfreq / safe_frequency
        # Construit la gaussienne centrée pour limiter les fuites temporelles
        envelope = np.exp(-(centered_times**2) / (2 * sigma**2))
        # Construit l'oscillation complexe alignée sur la fréquence centrale
        oscillation = np.exp(2j * np.pi * safe_frequency * centered_times / sfreq)
        # Combine l'enveloppe et l'oscillation pour former la wavelet
        wavelet = envelope * oscillation
        # Convolue le signal avec la wavelet via FFT pour l'efficacité
        convolved = signal.fftconvolve(channel_values, wavelet, mode="same")
        # Ajoute le résultat à la liste pour assembler la matrice finale
        coefficients.append(convolved)
    # Empile les coefficients en matrice (bandes, temps) pour analyse d'énergie
    return np.stack(coefficients, )


def x__compute_wavelet_coefficients__mutmut_51(
    channel_values: np.ndarray,
    central_frequencies: Sequence[float],
    sfreq: float,
    wavelet_cycles: float,
) -> np.ndarray:
    """Calcule les coefficients wavelets en convoluant une gaussienne modulée."""

    # Prépare un conteneur pour stocker les coefficients par échelle
    coefficients: List[np.ndarray] = []
    # Prépare un axe temporel centré pour construire la gaussienne
    centered_times = np.arange(channel_values.size) - (channel_values.size - 1) / 2
    # Parcourt les fréquences centrales pour projeter le signal
    for central_frequency in central_frequencies:
        # Empêche une fréquence nulle pour éviter des divisions par zéro
        safe_frequency = max(central_frequency, 1e-9)
        # Calcule l'écart-type de la gaussienne en fonction du nombre de cycles
        sigma = wavelet_cycles * sfreq / safe_frequency
        # Construit la gaussienne centrée pour limiter les fuites temporelles
        envelope = np.exp(-(centered_times**2) / (2 * sigma**2))
        # Construit l'oscillation complexe alignée sur la fréquence centrale
        oscillation = np.exp(2j * np.pi * safe_frequency * centered_times / sfreq)
        # Combine l'enveloppe et l'oscillation pour former la wavelet
        wavelet = envelope * oscillation
        # Convolue le signal avec la wavelet via FFT pour l'efficacité
        convolved = signal.fftconvolve(channel_values, wavelet, mode="same")
        # Ajoute le résultat à la liste pour assembler la matrice finale
        coefficients.append(convolved)
    # Empile les coefficients en matrice (bandes, temps) pour analyse d'énergie
    return np.stack(coefficients, axis=1)

x__compute_wavelet_coefficients__mutmut_mutants : ClassVar[MutantDict] = {
'x__compute_wavelet_coefficients__mutmut_1': x__compute_wavelet_coefficients__mutmut_1, 
    'x__compute_wavelet_coefficients__mutmut_2': x__compute_wavelet_coefficients__mutmut_2, 
    'x__compute_wavelet_coefficients__mutmut_3': x__compute_wavelet_coefficients__mutmut_3, 
    'x__compute_wavelet_coefficients__mutmut_4': x__compute_wavelet_coefficients__mutmut_4, 
    'x__compute_wavelet_coefficients__mutmut_5': x__compute_wavelet_coefficients__mutmut_5, 
    'x__compute_wavelet_coefficients__mutmut_6': x__compute_wavelet_coefficients__mutmut_6, 
    'x__compute_wavelet_coefficients__mutmut_7': x__compute_wavelet_coefficients__mutmut_7, 
    'x__compute_wavelet_coefficients__mutmut_8': x__compute_wavelet_coefficients__mutmut_8, 
    'x__compute_wavelet_coefficients__mutmut_9': x__compute_wavelet_coefficients__mutmut_9, 
    'x__compute_wavelet_coefficients__mutmut_10': x__compute_wavelet_coefficients__mutmut_10, 
    'x__compute_wavelet_coefficients__mutmut_11': x__compute_wavelet_coefficients__mutmut_11, 
    'x__compute_wavelet_coefficients__mutmut_12': x__compute_wavelet_coefficients__mutmut_12, 
    'x__compute_wavelet_coefficients__mutmut_13': x__compute_wavelet_coefficients__mutmut_13, 
    'x__compute_wavelet_coefficients__mutmut_14': x__compute_wavelet_coefficients__mutmut_14, 
    'x__compute_wavelet_coefficients__mutmut_15': x__compute_wavelet_coefficients__mutmut_15, 
    'x__compute_wavelet_coefficients__mutmut_16': x__compute_wavelet_coefficients__mutmut_16, 
    'x__compute_wavelet_coefficients__mutmut_17': x__compute_wavelet_coefficients__mutmut_17, 
    'x__compute_wavelet_coefficients__mutmut_18': x__compute_wavelet_coefficients__mutmut_18, 
    'x__compute_wavelet_coefficients__mutmut_19': x__compute_wavelet_coefficients__mutmut_19, 
    'x__compute_wavelet_coefficients__mutmut_20': x__compute_wavelet_coefficients__mutmut_20, 
    'x__compute_wavelet_coefficients__mutmut_21': x__compute_wavelet_coefficients__mutmut_21, 
    'x__compute_wavelet_coefficients__mutmut_22': x__compute_wavelet_coefficients__mutmut_22, 
    'x__compute_wavelet_coefficients__mutmut_23': x__compute_wavelet_coefficients__mutmut_23, 
    'x__compute_wavelet_coefficients__mutmut_24': x__compute_wavelet_coefficients__mutmut_24, 
    'x__compute_wavelet_coefficients__mutmut_25': x__compute_wavelet_coefficients__mutmut_25, 
    'x__compute_wavelet_coefficients__mutmut_26': x__compute_wavelet_coefficients__mutmut_26, 
    'x__compute_wavelet_coefficients__mutmut_27': x__compute_wavelet_coefficients__mutmut_27, 
    'x__compute_wavelet_coefficients__mutmut_28': x__compute_wavelet_coefficients__mutmut_28, 
    'x__compute_wavelet_coefficients__mutmut_29': x__compute_wavelet_coefficients__mutmut_29, 
    'x__compute_wavelet_coefficients__mutmut_30': x__compute_wavelet_coefficients__mutmut_30, 
    'x__compute_wavelet_coefficients__mutmut_31': x__compute_wavelet_coefficients__mutmut_31, 
    'x__compute_wavelet_coefficients__mutmut_32': x__compute_wavelet_coefficients__mutmut_32, 
    'x__compute_wavelet_coefficients__mutmut_33': x__compute_wavelet_coefficients__mutmut_33, 
    'x__compute_wavelet_coefficients__mutmut_34': x__compute_wavelet_coefficients__mutmut_34, 
    'x__compute_wavelet_coefficients__mutmut_35': x__compute_wavelet_coefficients__mutmut_35, 
    'x__compute_wavelet_coefficients__mutmut_36': x__compute_wavelet_coefficients__mutmut_36, 
    'x__compute_wavelet_coefficients__mutmut_37': x__compute_wavelet_coefficients__mutmut_37, 
    'x__compute_wavelet_coefficients__mutmut_38': x__compute_wavelet_coefficients__mutmut_38, 
    'x__compute_wavelet_coefficients__mutmut_39': x__compute_wavelet_coefficients__mutmut_39, 
    'x__compute_wavelet_coefficients__mutmut_40': x__compute_wavelet_coefficients__mutmut_40, 
    'x__compute_wavelet_coefficients__mutmut_41': x__compute_wavelet_coefficients__mutmut_41, 
    'x__compute_wavelet_coefficients__mutmut_42': x__compute_wavelet_coefficients__mutmut_42, 
    'x__compute_wavelet_coefficients__mutmut_43': x__compute_wavelet_coefficients__mutmut_43, 
    'x__compute_wavelet_coefficients__mutmut_44': x__compute_wavelet_coefficients__mutmut_44, 
    'x__compute_wavelet_coefficients__mutmut_45': x__compute_wavelet_coefficients__mutmut_45, 
    'x__compute_wavelet_coefficients__mutmut_46': x__compute_wavelet_coefficients__mutmut_46, 
    'x__compute_wavelet_coefficients__mutmut_47': x__compute_wavelet_coefficients__mutmut_47, 
    'x__compute_wavelet_coefficients__mutmut_48': x__compute_wavelet_coefficients__mutmut_48, 
    'x__compute_wavelet_coefficients__mutmut_49': x__compute_wavelet_coefficients__mutmut_49, 
    'x__compute_wavelet_coefficients__mutmut_50': x__compute_wavelet_coefficients__mutmut_50, 
    'x__compute_wavelet_coefficients__mutmut_51': x__compute_wavelet_coefficients__mutmut_51
}

def _compute_wavelet_coefficients(*args, **kwargs):
    result = _mutmut_trampoline(x__compute_wavelet_coefficients__mutmut_orig, x__compute_wavelet_coefficients__mutmut_mutants, args, kwargs)
    return result 

_compute_wavelet_coefficients.__signature__ = _mutmut_signature(x__compute_wavelet_coefficients__mutmut_orig)
x__compute_wavelet_coefficients__mutmut_orig.__name__ = 'x__compute_wavelet_coefficients'


def x__compute_wavelet_band_powers__mutmut_orig(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule l'énergie de bandes via une CWT Morlet paramétrable."""

    # Valide le nom de wavelet demandé pour éviter les comportements implicites
    _normalize_wavelet_name(config.get("wavelet", "morlet"))
    if not band_ranges:
        raise ValueError("At least one wavelet band must be provided.")
    # Configure la largeur de la wavelet pour ajuster la résolution temps-fréquence
    wavelet_cycles: float = float(config.get("wavelet_width", 6.0))
    validated_bands: List[Tuple[str, Tuple[float, float]]] = []
    for band_name, (low, high) in band_ranges.items():
        if high <= low:
            raise ValueError(
                f"Wavelet band {band_name!r} must have low < high (got {low}, {high})."
            )
        validated_bands.append((band_name, (float(low), float(high))))
    # Calcule la fréquence centrale de chaque bande pour cibler la wavelet
    central_frequencies: List[float] = [
        (low + high) / 2.0 for _, (low, high) in validated_bands
    ]
    if not central_frequencies:
        raise ValueError(
            "Wavelet central frequencies are empty. Check band configuration."
        )
    # Prépare un tableau pour stocker l'énergie par essai, canal et bande
    band_powers: np.ndarray = np.zeros(
        (data.shape[0], data.shape[1], len(validated_bands))
    )
    # Parcourt chaque essai pour éviter des allocations massives inutiles
    for epoch_index, epoch_data in enumerate(data):
        # Parcourt chaque canal pour projeter le signal sur les échelles ciblées
        for channel_index, channel_values in enumerate(epoch_data):
            # Calcule les coefficients CWT sur les échelles demandées
            coefficients = _compute_wavelet_coefficients(
                channel_values,
                central_frequencies,
                sfreq,
                wavelet_cycles,
            )
            if coefficients.size == 0:
                raise ValueError(
                    "Wavelet coefficients computation returned an empty array. "
                    "Verify band configuration."
                )
            # Calcule la puissance moyenne par bande en intégrant la magnitude
            band_energy = np.abs(coefficients) ** 2
            # Moyenne temporelle pour stabiliser l'énergie de chaque bande
            band_powers[epoch_index, channel_index, :] = band_energy.mean(axis=1)
    # Retourne le tenseur énergie pour alignement avec les étiquettes de bandes
    return band_powers


def x__compute_wavelet_band_powers__mutmut_1(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule l'énergie de bandes via une CWT Morlet paramétrable."""

    # Valide le nom de wavelet demandé pour éviter les comportements implicites
    _normalize_wavelet_name(None)
    if not band_ranges:
        raise ValueError("At least one wavelet band must be provided.")
    # Configure la largeur de la wavelet pour ajuster la résolution temps-fréquence
    wavelet_cycles: float = float(config.get("wavelet_width", 6.0))
    validated_bands: List[Tuple[str, Tuple[float, float]]] = []
    for band_name, (low, high) in band_ranges.items():
        if high <= low:
            raise ValueError(
                f"Wavelet band {band_name!r} must have low < high (got {low}, {high})."
            )
        validated_bands.append((band_name, (float(low), float(high))))
    # Calcule la fréquence centrale de chaque bande pour cibler la wavelet
    central_frequencies: List[float] = [
        (low + high) / 2.0 for _, (low, high) in validated_bands
    ]
    if not central_frequencies:
        raise ValueError(
            "Wavelet central frequencies are empty. Check band configuration."
        )
    # Prépare un tableau pour stocker l'énergie par essai, canal et bande
    band_powers: np.ndarray = np.zeros(
        (data.shape[0], data.shape[1], len(validated_bands))
    )
    # Parcourt chaque essai pour éviter des allocations massives inutiles
    for epoch_index, epoch_data in enumerate(data):
        # Parcourt chaque canal pour projeter le signal sur les échelles ciblées
        for channel_index, channel_values in enumerate(epoch_data):
            # Calcule les coefficients CWT sur les échelles demandées
            coefficients = _compute_wavelet_coefficients(
                channel_values,
                central_frequencies,
                sfreq,
                wavelet_cycles,
            )
            if coefficients.size == 0:
                raise ValueError(
                    "Wavelet coefficients computation returned an empty array. "
                    "Verify band configuration."
                )
            # Calcule la puissance moyenne par bande en intégrant la magnitude
            band_energy = np.abs(coefficients) ** 2
            # Moyenne temporelle pour stabiliser l'énergie de chaque bande
            band_powers[epoch_index, channel_index, :] = band_energy.mean(axis=1)
    # Retourne le tenseur énergie pour alignement avec les étiquettes de bandes
    return band_powers


def x__compute_wavelet_band_powers__mutmut_2(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule l'énergie de bandes via une CWT Morlet paramétrable."""

    # Valide le nom de wavelet demandé pour éviter les comportements implicites
    _normalize_wavelet_name(config.get(None, "morlet"))
    if not band_ranges:
        raise ValueError("At least one wavelet band must be provided.")
    # Configure la largeur de la wavelet pour ajuster la résolution temps-fréquence
    wavelet_cycles: float = float(config.get("wavelet_width", 6.0))
    validated_bands: List[Tuple[str, Tuple[float, float]]] = []
    for band_name, (low, high) in band_ranges.items():
        if high <= low:
            raise ValueError(
                f"Wavelet band {band_name!r} must have low < high (got {low}, {high})."
            )
        validated_bands.append((band_name, (float(low), float(high))))
    # Calcule la fréquence centrale de chaque bande pour cibler la wavelet
    central_frequencies: List[float] = [
        (low + high) / 2.0 for _, (low, high) in validated_bands
    ]
    if not central_frequencies:
        raise ValueError(
            "Wavelet central frequencies are empty. Check band configuration."
        )
    # Prépare un tableau pour stocker l'énergie par essai, canal et bande
    band_powers: np.ndarray = np.zeros(
        (data.shape[0], data.shape[1], len(validated_bands))
    )
    # Parcourt chaque essai pour éviter des allocations massives inutiles
    for epoch_index, epoch_data in enumerate(data):
        # Parcourt chaque canal pour projeter le signal sur les échelles ciblées
        for channel_index, channel_values in enumerate(epoch_data):
            # Calcule les coefficients CWT sur les échelles demandées
            coefficients = _compute_wavelet_coefficients(
                channel_values,
                central_frequencies,
                sfreq,
                wavelet_cycles,
            )
            if coefficients.size == 0:
                raise ValueError(
                    "Wavelet coefficients computation returned an empty array. "
                    "Verify band configuration."
                )
            # Calcule la puissance moyenne par bande en intégrant la magnitude
            band_energy = np.abs(coefficients) ** 2
            # Moyenne temporelle pour stabiliser l'énergie de chaque bande
            band_powers[epoch_index, channel_index, :] = band_energy.mean(axis=1)
    # Retourne le tenseur énergie pour alignement avec les étiquettes de bandes
    return band_powers


def x__compute_wavelet_band_powers__mutmut_3(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule l'énergie de bandes via une CWT Morlet paramétrable."""

    # Valide le nom de wavelet demandé pour éviter les comportements implicites
    _normalize_wavelet_name(config.get("wavelet", None))
    if not band_ranges:
        raise ValueError("At least one wavelet band must be provided.")
    # Configure la largeur de la wavelet pour ajuster la résolution temps-fréquence
    wavelet_cycles: float = float(config.get("wavelet_width", 6.0))
    validated_bands: List[Tuple[str, Tuple[float, float]]] = []
    for band_name, (low, high) in band_ranges.items():
        if high <= low:
            raise ValueError(
                f"Wavelet band {band_name!r} must have low < high (got {low}, {high})."
            )
        validated_bands.append((band_name, (float(low), float(high))))
    # Calcule la fréquence centrale de chaque bande pour cibler la wavelet
    central_frequencies: List[float] = [
        (low + high) / 2.0 for _, (low, high) in validated_bands
    ]
    if not central_frequencies:
        raise ValueError(
            "Wavelet central frequencies are empty. Check band configuration."
        )
    # Prépare un tableau pour stocker l'énergie par essai, canal et bande
    band_powers: np.ndarray = np.zeros(
        (data.shape[0], data.shape[1], len(validated_bands))
    )
    # Parcourt chaque essai pour éviter des allocations massives inutiles
    for epoch_index, epoch_data in enumerate(data):
        # Parcourt chaque canal pour projeter le signal sur les échelles ciblées
        for channel_index, channel_values in enumerate(epoch_data):
            # Calcule les coefficients CWT sur les échelles demandées
            coefficients = _compute_wavelet_coefficients(
                channel_values,
                central_frequencies,
                sfreq,
                wavelet_cycles,
            )
            if coefficients.size == 0:
                raise ValueError(
                    "Wavelet coefficients computation returned an empty array. "
                    "Verify band configuration."
                )
            # Calcule la puissance moyenne par bande en intégrant la magnitude
            band_energy = np.abs(coefficients) ** 2
            # Moyenne temporelle pour stabiliser l'énergie de chaque bande
            band_powers[epoch_index, channel_index, :] = band_energy.mean(axis=1)
    # Retourne le tenseur énergie pour alignement avec les étiquettes de bandes
    return band_powers


def x__compute_wavelet_band_powers__mutmut_4(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule l'énergie de bandes via une CWT Morlet paramétrable."""

    # Valide le nom de wavelet demandé pour éviter les comportements implicites
    _normalize_wavelet_name(config.get("morlet"))
    if not band_ranges:
        raise ValueError("At least one wavelet band must be provided.")
    # Configure la largeur de la wavelet pour ajuster la résolution temps-fréquence
    wavelet_cycles: float = float(config.get("wavelet_width", 6.0))
    validated_bands: List[Tuple[str, Tuple[float, float]]] = []
    for band_name, (low, high) in band_ranges.items():
        if high <= low:
            raise ValueError(
                f"Wavelet band {band_name!r} must have low < high (got {low}, {high})."
            )
        validated_bands.append((band_name, (float(low), float(high))))
    # Calcule la fréquence centrale de chaque bande pour cibler la wavelet
    central_frequencies: List[float] = [
        (low + high) / 2.0 for _, (low, high) in validated_bands
    ]
    if not central_frequencies:
        raise ValueError(
            "Wavelet central frequencies are empty. Check band configuration."
        )
    # Prépare un tableau pour stocker l'énergie par essai, canal et bande
    band_powers: np.ndarray = np.zeros(
        (data.shape[0], data.shape[1], len(validated_bands))
    )
    # Parcourt chaque essai pour éviter des allocations massives inutiles
    for epoch_index, epoch_data in enumerate(data):
        # Parcourt chaque canal pour projeter le signal sur les échelles ciblées
        for channel_index, channel_values in enumerate(epoch_data):
            # Calcule les coefficients CWT sur les échelles demandées
            coefficients = _compute_wavelet_coefficients(
                channel_values,
                central_frequencies,
                sfreq,
                wavelet_cycles,
            )
            if coefficients.size == 0:
                raise ValueError(
                    "Wavelet coefficients computation returned an empty array. "
                    "Verify band configuration."
                )
            # Calcule la puissance moyenne par bande en intégrant la magnitude
            band_energy = np.abs(coefficients) ** 2
            # Moyenne temporelle pour stabiliser l'énergie de chaque bande
            band_powers[epoch_index, channel_index, :] = band_energy.mean(axis=1)
    # Retourne le tenseur énergie pour alignement avec les étiquettes de bandes
    return band_powers


def x__compute_wavelet_band_powers__mutmut_5(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule l'énergie de bandes via une CWT Morlet paramétrable."""

    # Valide le nom de wavelet demandé pour éviter les comportements implicites
    _normalize_wavelet_name(config.get("wavelet", ))
    if not band_ranges:
        raise ValueError("At least one wavelet band must be provided.")
    # Configure la largeur de la wavelet pour ajuster la résolution temps-fréquence
    wavelet_cycles: float = float(config.get("wavelet_width", 6.0))
    validated_bands: List[Tuple[str, Tuple[float, float]]] = []
    for band_name, (low, high) in band_ranges.items():
        if high <= low:
            raise ValueError(
                f"Wavelet band {band_name!r} must have low < high (got {low}, {high})."
            )
        validated_bands.append((band_name, (float(low), float(high))))
    # Calcule la fréquence centrale de chaque bande pour cibler la wavelet
    central_frequencies: List[float] = [
        (low + high) / 2.0 for _, (low, high) in validated_bands
    ]
    if not central_frequencies:
        raise ValueError(
            "Wavelet central frequencies are empty. Check band configuration."
        )
    # Prépare un tableau pour stocker l'énergie par essai, canal et bande
    band_powers: np.ndarray = np.zeros(
        (data.shape[0], data.shape[1], len(validated_bands))
    )
    # Parcourt chaque essai pour éviter des allocations massives inutiles
    for epoch_index, epoch_data in enumerate(data):
        # Parcourt chaque canal pour projeter le signal sur les échelles ciblées
        for channel_index, channel_values in enumerate(epoch_data):
            # Calcule les coefficients CWT sur les échelles demandées
            coefficients = _compute_wavelet_coefficients(
                channel_values,
                central_frequencies,
                sfreq,
                wavelet_cycles,
            )
            if coefficients.size == 0:
                raise ValueError(
                    "Wavelet coefficients computation returned an empty array. "
                    "Verify band configuration."
                )
            # Calcule la puissance moyenne par bande en intégrant la magnitude
            band_energy = np.abs(coefficients) ** 2
            # Moyenne temporelle pour stabiliser l'énergie de chaque bande
            band_powers[epoch_index, channel_index, :] = band_energy.mean(axis=1)
    # Retourne le tenseur énergie pour alignement avec les étiquettes de bandes
    return band_powers


def x__compute_wavelet_band_powers__mutmut_6(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule l'énergie de bandes via une CWT Morlet paramétrable."""

    # Valide le nom de wavelet demandé pour éviter les comportements implicites
    _normalize_wavelet_name(config.get("XXwaveletXX", "morlet"))
    if not band_ranges:
        raise ValueError("At least one wavelet band must be provided.")
    # Configure la largeur de la wavelet pour ajuster la résolution temps-fréquence
    wavelet_cycles: float = float(config.get("wavelet_width", 6.0))
    validated_bands: List[Tuple[str, Tuple[float, float]]] = []
    for band_name, (low, high) in band_ranges.items():
        if high <= low:
            raise ValueError(
                f"Wavelet band {band_name!r} must have low < high (got {low}, {high})."
            )
        validated_bands.append((band_name, (float(low), float(high))))
    # Calcule la fréquence centrale de chaque bande pour cibler la wavelet
    central_frequencies: List[float] = [
        (low + high) / 2.0 for _, (low, high) in validated_bands
    ]
    if not central_frequencies:
        raise ValueError(
            "Wavelet central frequencies are empty. Check band configuration."
        )
    # Prépare un tableau pour stocker l'énergie par essai, canal et bande
    band_powers: np.ndarray = np.zeros(
        (data.shape[0], data.shape[1], len(validated_bands))
    )
    # Parcourt chaque essai pour éviter des allocations massives inutiles
    for epoch_index, epoch_data in enumerate(data):
        # Parcourt chaque canal pour projeter le signal sur les échelles ciblées
        for channel_index, channel_values in enumerate(epoch_data):
            # Calcule les coefficients CWT sur les échelles demandées
            coefficients = _compute_wavelet_coefficients(
                channel_values,
                central_frequencies,
                sfreq,
                wavelet_cycles,
            )
            if coefficients.size == 0:
                raise ValueError(
                    "Wavelet coefficients computation returned an empty array. "
                    "Verify band configuration."
                )
            # Calcule la puissance moyenne par bande en intégrant la magnitude
            band_energy = np.abs(coefficients) ** 2
            # Moyenne temporelle pour stabiliser l'énergie de chaque bande
            band_powers[epoch_index, channel_index, :] = band_energy.mean(axis=1)
    # Retourne le tenseur énergie pour alignement avec les étiquettes de bandes
    return band_powers


def x__compute_wavelet_band_powers__mutmut_7(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule l'énergie de bandes via une CWT Morlet paramétrable."""

    # Valide le nom de wavelet demandé pour éviter les comportements implicites
    _normalize_wavelet_name(config.get("WAVELET", "morlet"))
    if not band_ranges:
        raise ValueError("At least one wavelet band must be provided.")
    # Configure la largeur de la wavelet pour ajuster la résolution temps-fréquence
    wavelet_cycles: float = float(config.get("wavelet_width", 6.0))
    validated_bands: List[Tuple[str, Tuple[float, float]]] = []
    for band_name, (low, high) in band_ranges.items():
        if high <= low:
            raise ValueError(
                f"Wavelet band {band_name!r} must have low < high (got {low}, {high})."
            )
        validated_bands.append((band_name, (float(low), float(high))))
    # Calcule la fréquence centrale de chaque bande pour cibler la wavelet
    central_frequencies: List[float] = [
        (low + high) / 2.0 for _, (low, high) in validated_bands
    ]
    if not central_frequencies:
        raise ValueError(
            "Wavelet central frequencies are empty. Check band configuration."
        )
    # Prépare un tableau pour stocker l'énergie par essai, canal et bande
    band_powers: np.ndarray = np.zeros(
        (data.shape[0], data.shape[1], len(validated_bands))
    )
    # Parcourt chaque essai pour éviter des allocations massives inutiles
    for epoch_index, epoch_data in enumerate(data):
        # Parcourt chaque canal pour projeter le signal sur les échelles ciblées
        for channel_index, channel_values in enumerate(epoch_data):
            # Calcule les coefficients CWT sur les échelles demandées
            coefficients = _compute_wavelet_coefficients(
                channel_values,
                central_frequencies,
                sfreq,
                wavelet_cycles,
            )
            if coefficients.size == 0:
                raise ValueError(
                    "Wavelet coefficients computation returned an empty array. "
                    "Verify band configuration."
                )
            # Calcule la puissance moyenne par bande en intégrant la magnitude
            band_energy = np.abs(coefficients) ** 2
            # Moyenne temporelle pour stabiliser l'énergie de chaque bande
            band_powers[epoch_index, channel_index, :] = band_energy.mean(axis=1)
    # Retourne le tenseur énergie pour alignement avec les étiquettes de bandes
    return band_powers


def x__compute_wavelet_band_powers__mutmut_8(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule l'énergie de bandes via une CWT Morlet paramétrable."""

    # Valide le nom de wavelet demandé pour éviter les comportements implicites
    _normalize_wavelet_name(config.get("wavelet", "XXmorletXX"))
    if not band_ranges:
        raise ValueError("At least one wavelet band must be provided.")
    # Configure la largeur de la wavelet pour ajuster la résolution temps-fréquence
    wavelet_cycles: float = float(config.get("wavelet_width", 6.0))
    validated_bands: List[Tuple[str, Tuple[float, float]]] = []
    for band_name, (low, high) in band_ranges.items():
        if high <= low:
            raise ValueError(
                f"Wavelet band {band_name!r} must have low < high (got {low}, {high})."
            )
        validated_bands.append((band_name, (float(low), float(high))))
    # Calcule la fréquence centrale de chaque bande pour cibler la wavelet
    central_frequencies: List[float] = [
        (low + high) / 2.0 for _, (low, high) in validated_bands
    ]
    if not central_frequencies:
        raise ValueError(
            "Wavelet central frequencies are empty. Check band configuration."
        )
    # Prépare un tableau pour stocker l'énergie par essai, canal et bande
    band_powers: np.ndarray = np.zeros(
        (data.shape[0], data.shape[1], len(validated_bands))
    )
    # Parcourt chaque essai pour éviter des allocations massives inutiles
    for epoch_index, epoch_data in enumerate(data):
        # Parcourt chaque canal pour projeter le signal sur les échelles ciblées
        for channel_index, channel_values in enumerate(epoch_data):
            # Calcule les coefficients CWT sur les échelles demandées
            coefficients = _compute_wavelet_coefficients(
                channel_values,
                central_frequencies,
                sfreq,
                wavelet_cycles,
            )
            if coefficients.size == 0:
                raise ValueError(
                    "Wavelet coefficients computation returned an empty array. "
                    "Verify band configuration."
                )
            # Calcule la puissance moyenne par bande en intégrant la magnitude
            band_energy = np.abs(coefficients) ** 2
            # Moyenne temporelle pour stabiliser l'énergie de chaque bande
            band_powers[epoch_index, channel_index, :] = band_energy.mean(axis=1)
    # Retourne le tenseur énergie pour alignement avec les étiquettes de bandes
    return band_powers


def x__compute_wavelet_band_powers__mutmut_9(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule l'énergie de bandes via une CWT Morlet paramétrable."""

    # Valide le nom de wavelet demandé pour éviter les comportements implicites
    _normalize_wavelet_name(config.get("wavelet", "MORLET"))
    if not band_ranges:
        raise ValueError("At least one wavelet band must be provided.")
    # Configure la largeur de la wavelet pour ajuster la résolution temps-fréquence
    wavelet_cycles: float = float(config.get("wavelet_width", 6.0))
    validated_bands: List[Tuple[str, Tuple[float, float]]] = []
    for band_name, (low, high) in band_ranges.items():
        if high <= low:
            raise ValueError(
                f"Wavelet band {band_name!r} must have low < high (got {low}, {high})."
            )
        validated_bands.append((band_name, (float(low), float(high))))
    # Calcule la fréquence centrale de chaque bande pour cibler la wavelet
    central_frequencies: List[float] = [
        (low + high) / 2.0 for _, (low, high) in validated_bands
    ]
    if not central_frequencies:
        raise ValueError(
            "Wavelet central frequencies are empty. Check band configuration."
        )
    # Prépare un tableau pour stocker l'énergie par essai, canal et bande
    band_powers: np.ndarray = np.zeros(
        (data.shape[0], data.shape[1], len(validated_bands))
    )
    # Parcourt chaque essai pour éviter des allocations massives inutiles
    for epoch_index, epoch_data in enumerate(data):
        # Parcourt chaque canal pour projeter le signal sur les échelles ciblées
        for channel_index, channel_values in enumerate(epoch_data):
            # Calcule les coefficients CWT sur les échelles demandées
            coefficients = _compute_wavelet_coefficients(
                channel_values,
                central_frequencies,
                sfreq,
                wavelet_cycles,
            )
            if coefficients.size == 0:
                raise ValueError(
                    "Wavelet coefficients computation returned an empty array. "
                    "Verify band configuration."
                )
            # Calcule la puissance moyenne par bande en intégrant la magnitude
            band_energy = np.abs(coefficients) ** 2
            # Moyenne temporelle pour stabiliser l'énergie de chaque bande
            band_powers[epoch_index, channel_index, :] = band_energy.mean(axis=1)
    # Retourne le tenseur énergie pour alignement avec les étiquettes de bandes
    return band_powers


def x__compute_wavelet_band_powers__mutmut_10(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule l'énergie de bandes via une CWT Morlet paramétrable."""

    # Valide le nom de wavelet demandé pour éviter les comportements implicites
    _normalize_wavelet_name(config.get("wavelet", "morlet"))
    if band_ranges:
        raise ValueError("At least one wavelet band must be provided.")
    # Configure la largeur de la wavelet pour ajuster la résolution temps-fréquence
    wavelet_cycles: float = float(config.get("wavelet_width", 6.0))
    validated_bands: List[Tuple[str, Tuple[float, float]]] = []
    for band_name, (low, high) in band_ranges.items():
        if high <= low:
            raise ValueError(
                f"Wavelet band {band_name!r} must have low < high (got {low}, {high})."
            )
        validated_bands.append((band_name, (float(low), float(high))))
    # Calcule la fréquence centrale de chaque bande pour cibler la wavelet
    central_frequencies: List[float] = [
        (low + high) / 2.0 for _, (low, high) in validated_bands
    ]
    if not central_frequencies:
        raise ValueError(
            "Wavelet central frequencies are empty. Check band configuration."
        )
    # Prépare un tableau pour stocker l'énergie par essai, canal et bande
    band_powers: np.ndarray = np.zeros(
        (data.shape[0], data.shape[1], len(validated_bands))
    )
    # Parcourt chaque essai pour éviter des allocations massives inutiles
    for epoch_index, epoch_data in enumerate(data):
        # Parcourt chaque canal pour projeter le signal sur les échelles ciblées
        for channel_index, channel_values in enumerate(epoch_data):
            # Calcule les coefficients CWT sur les échelles demandées
            coefficients = _compute_wavelet_coefficients(
                channel_values,
                central_frequencies,
                sfreq,
                wavelet_cycles,
            )
            if coefficients.size == 0:
                raise ValueError(
                    "Wavelet coefficients computation returned an empty array. "
                    "Verify band configuration."
                )
            # Calcule la puissance moyenne par bande en intégrant la magnitude
            band_energy = np.abs(coefficients) ** 2
            # Moyenne temporelle pour stabiliser l'énergie de chaque bande
            band_powers[epoch_index, channel_index, :] = band_energy.mean(axis=1)
    # Retourne le tenseur énergie pour alignement avec les étiquettes de bandes
    return band_powers


def x__compute_wavelet_band_powers__mutmut_11(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule l'énergie de bandes via une CWT Morlet paramétrable."""

    # Valide le nom de wavelet demandé pour éviter les comportements implicites
    _normalize_wavelet_name(config.get("wavelet", "morlet"))
    if not band_ranges:
        raise ValueError("At least one wavelet band must be provided.")
    # Configure la largeur de la wavelet pour ajuster la résolution temps-fréquence
    wavelet_cycles: float = None
    validated_bands: List[Tuple[str, Tuple[float, float]]] = []
    for band_name, (low, high) in band_ranges.items():
        if high <= low:
            raise ValueError(
                f"Wavelet band {band_name!r} must have low < high (got {low}, {high})."
            )
        validated_bands.append((band_name, (float(low), float(high))))
    # Calcule la fréquence centrale de chaque bande pour cibler la wavelet
    central_frequencies: List[float] = [
        (low + high) / 2.0 for _, (low, high) in validated_bands
    ]
    if not central_frequencies:
        raise ValueError(
            "Wavelet central frequencies are empty. Check band configuration."
        )
    # Prépare un tableau pour stocker l'énergie par essai, canal et bande
    band_powers: np.ndarray = np.zeros(
        (data.shape[0], data.shape[1], len(validated_bands))
    )
    # Parcourt chaque essai pour éviter des allocations massives inutiles
    for epoch_index, epoch_data in enumerate(data):
        # Parcourt chaque canal pour projeter le signal sur les échelles ciblées
        for channel_index, channel_values in enumerate(epoch_data):
            # Calcule les coefficients CWT sur les échelles demandées
            coefficients = _compute_wavelet_coefficients(
                channel_values,
                central_frequencies,
                sfreq,
                wavelet_cycles,
            )
            if coefficients.size == 0:
                raise ValueError(
                    "Wavelet coefficients computation returned an empty array. "
                    "Verify band configuration."
                )
            # Calcule la puissance moyenne par bande en intégrant la magnitude
            band_energy = np.abs(coefficients) ** 2
            # Moyenne temporelle pour stabiliser l'énergie de chaque bande
            band_powers[epoch_index, channel_index, :] = band_energy.mean(axis=1)
    # Retourne le tenseur énergie pour alignement avec les étiquettes de bandes
    return band_powers


def x__compute_wavelet_band_powers__mutmut_12(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule l'énergie de bandes via une CWT Morlet paramétrable."""

    # Valide le nom de wavelet demandé pour éviter les comportements implicites
    _normalize_wavelet_name(config.get("wavelet", "morlet"))
    if not band_ranges:
        raise ValueError("At least one wavelet band must be provided.")
    # Configure la largeur de la wavelet pour ajuster la résolution temps-fréquence
    wavelet_cycles: float = float(None)
    validated_bands: List[Tuple[str, Tuple[float, float]]] = []
    for band_name, (low, high) in band_ranges.items():
        if high <= low:
            raise ValueError(
                f"Wavelet band {band_name!r} must have low < high (got {low}, {high})."
            )
        validated_bands.append((band_name, (float(low), float(high))))
    # Calcule la fréquence centrale de chaque bande pour cibler la wavelet
    central_frequencies: List[float] = [
        (low + high) / 2.0 for _, (low, high) in validated_bands
    ]
    if not central_frequencies:
        raise ValueError(
            "Wavelet central frequencies are empty. Check band configuration."
        )
    # Prépare un tableau pour stocker l'énergie par essai, canal et bande
    band_powers: np.ndarray = np.zeros(
        (data.shape[0], data.shape[1], len(validated_bands))
    )
    # Parcourt chaque essai pour éviter des allocations massives inutiles
    for epoch_index, epoch_data in enumerate(data):
        # Parcourt chaque canal pour projeter le signal sur les échelles ciblées
        for channel_index, channel_values in enumerate(epoch_data):
            # Calcule les coefficients CWT sur les échelles demandées
            coefficients = _compute_wavelet_coefficients(
                channel_values,
                central_frequencies,
                sfreq,
                wavelet_cycles,
            )
            if coefficients.size == 0:
                raise ValueError(
                    "Wavelet coefficients computation returned an empty array. "
                    "Verify band configuration."
                )
            # Calcule la puissance moyenne par bande en intégrant la magnitude
            band_energy = np.abs(coefficients) ** 2
            # Moyenne temporelle pour stabiliser l'énergie de chaque bande
            band_powers[epoch_index, channel_index, :] = band_energy.mean(axis=1)
    # Retourne le tenseur énergie pour alignement avec les étiquettes de bandes
    return band_powers


def x__compute_wavelet_band_powers__mutmut_13(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule l'énergie de bandes via une CWT Morlet paramétrable."""

    # Valide le nom de wavelet demandé pour éviter les comportements implicites
    _normalize_wavelet_name(config.get("wavelet", "morlet"))
    if not band_ranges:
        raise ValueError("At least one wavelet band must be provided.")
    # Configure la largeur de la wavelet pour ajuster la résolution temps-fréquence
    wavelet_cycles: float = float(config.get(None, 6.0))
    validated_bands: List[Tuple[str, Tuple[float, float]]] = []
    for band_name, (low, high) in band_ranges.items():
        if high <= low:
            raise ValueError(
                f"Wavelet band {band_name!r} must have low < high (got {low}, {high})."
            )
        validated_bands.append((band_name, (float(low), float(high))))
    # Calcule la fréquence centrale de chaque bande pour cibler la wavelet
    central_frequencies: List[float] = [
        (low + high) / 2.0 for _, (low, high) in validated_bands
    ]
    if not central_frequencies:
        raise ValueError(
            "Wavelet central frequencies are empty. Check band configuration."
        )
    # Prépare un tableau pour stocker l'énergie par essai, canal et bande
    band_powers: np.ndarray = np.zeros(
        (data.shape[0], data.shape[1], len(validated_bands))
    )
    # Parcourt chaque essai pour éviter des allocations massives inutiles
    for epoch_index, epoch_data in enumerate(data):
        # Parcourt chaque canal pour projeter le signal sur les échelles ciblées
        for channel_index, channel_values in enumerate(epoch_data):
            # Calcule les coefficients CWT sur les échelles demandées
            coefficients = _compute_wavelet_coefficients(
                channel_values,
                central_frequencies,
                sfreq,
                wavelet_cycles,
            )
            if coefficients.size == 0:
                raise ValueError(
                    "Wavelet coefficients computation returned an empty array. "
                    "Verify band configuration."
                )
            # Calcule la puissance moyenne par bande en intégrant la magnitude
            band_energy = np.abs(coefficients) ** 2
            # Moyenne temporelle pour stabiliser l'énergie de chaque bande
            band_powers[epoch_index, channel_index, :] = band_energy.mean(axis=1)
    # Retourne le tenseur énergie pour alignement avec les étiquettes de bandes
    return band_powers


def x__compute_wavelet_band_powers__mutmut_14(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule l'énergie de bandes via une CWT Morlet paramétrable."""

    # Valide le nom de wavelet demandé pour éviter les comportements implicites
    _normalize_wavelet_name(config.get("wavelet", "morlet"))
    if not band_ranges:
        raise ValueError("At least one wavelet band must be provided.")
    # Configure la largeur de la wavelet pour ajuster la résolution temps-fréquence
    wavelet_cycles: float = float(config.get("wavelet_width", None))
    validated_bands: List[Tuple[str, Tuple[float, float]]] = []
    for band_name, (low, high) in band_ranges.items():
        if high <= low:
            raise ValueError(
                f"Wavelet band {band_name!r} must have low < high (got {low}, {high})."
            )
        validated_bands.append((band_name, (float(low), float(high))))
    # Calcule la fréquence centrale de chaque bande pour cibler la wavelet
    central_frequencies: List[float] = [
        (low + high) / 2.0 for _, (low, high) in validated_bands
    ]
    if not central_frequencies:
        raise ValueError(
            "Wavelet central frequencies are empty. Check band configuration."
        )
    # Prépare un tableau pour stocker l'énergie par essai, canal et bande
    band_powers: np.ndarray = np.zeros(
        (data.shape[0], data.shape[1], len(validated_bands))
    )
    # Parcourt chaque essai pour éviter des allocations massives inutiles
    for epoch_index, epoch_data in enumerate(data):
        # Parcourt chaque canal pour projeter le signal sur les échelles ciblées
        for channel_index, channel_values in enumerate(epoch_data):
            # Calcule les coefficients CWT sur les échelles demandées
            coefficients = _compute_wavelet_coefficients(
                channel_values,
                central_frequencies,
                sfreq,
                wavelet_cycles,
            )
            if coefficients.size == 0:
                raise ValueError(
                    "Wavelet coefficients computation returned an empty array. "
                    "Verify band configuration."
                )
            # Calcule la puissance moyenne par bande en intégrant la magnitude
            band_energy = np.abs(coefficients) ** 2
            # Moyenne temporelle pour stabiliser l'énergie de chaque bande
            band_powers[epoch_index, channel_index, :] = band_energy.mean(axis=1)
    # Retourne le tenseur énergie pour alignement avec les étiquettes de bandes
    return band_powers


def x__compute_wavelet_band_powers__mutmut_15(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule l'énergie de bandes via une CWT Morlet paramétrable."""

    # Valide le nom de wavelet demandé pour éviter les comportements implicites
    _normalize_wavelet_name(config.get("wavelet", "morlet"))
    if not band_ranges:
        raise ValueError("At least one wavelet band must be provided.")
    # Configure la largeur de la wavelet pour ajuster la résolution temps-fréquence
    wavelet_cycles: float = float(config.get(6.0))
    validated_bands: List[Tuple[str, Tuple[float, float]]] = []
    for band_name, (low, high) in band_ranges.items():
        if high <= low:
            raise ValueError(
                f"Wavelet band {band_name!r} must have low < high (got {low}, {high})."
            )
        validated_bands.append((band_name, (float(low), float(high))))
    # Calcule la fréquence centrale de chaque bande pour cibler la wavelet
    central_frequencies: List[float] = [
        (low + high) / 2.0 for _, (low, high) in validated_bands
    ]
    if not central_frequencies:
        raise ValueError(
            "Wavelet central frequencies are empty. Check band configuration."
        )
    # Prépare un tableau pour stocker l'énergie par essai, canal et bande
    band_powers: np.ndarray = np.zeros(
        (data.shape[0], data.shape[1], len(validated_bands))
    )
    # Parcourt chaque essai pour éviter des allocations massives inutiles
    for epoch_index, epoch_data in enumerate(data):
        # Parcourt chaque canal pour projeter le signal sur les échelles ciblées
        for channel_index, channel_values in enumerate(epoch_data):
            # Calcule les coefficients CWT sur les échelles demandées
            coefficients = _compute_wavelet_coefficients(
                channel_values,
                central_frequencies,
                sfreq,
                wavelet_cycles,
            )
            if coefficients.size == 0:
                raise ValueError(
                    "Wavelet coefficients computation returned an empty array. "
                    "Verify band configuration."
                )
            # Calcule la puissance moyenne par bande en intégrant la magnitude
            band_energy = np.abs(coefficients) ** 2
            # Moyenne temporelle pour stabiliser l'énergie de chaque bande
            band_powers[epoch_index, channel_index, :] = band_energy.mean(axis=1)
    # Retourne le tenseur énergie pour alignement avec les étiquettes de bandes
    return band_powers


def x__compute_wavelet_band_powers__mutmut_16(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule l'énergie de bandes via une CWT Morlet paramétrable."""

    # Valide le nom de wavelet demandé pour éviter les comportements implicites
    _normalize_wavelet_name(config.get("wavelet", "morlet"))
    if not band_ranges:
        raise ValueError("At least one wavelet band must be provided.")
    # Configure la largeur de la wavelet pour ajuster la résolution temps-fréquence
    wavelet_cycles: float = float(config.get("wavelet_width", ))
    validated_bands: List[Tuple[str, Tuple[float, float]]] = []
    for band_name, (low, high) in band_ranges.items():
        if high <= low:
            raise ValueError(
                f"Wavelet band {band_name!r} must have low < high (got {low}, {high})."
            )
        validated_bands.append((band_name, (float(low), float(high))))
    # Calcule la fréquence centrale de chaque bande pour cibler la wavelet
    central_frequencies: List[float] = [
        (low + high) / 2.0 for _, (low, high) in validated_bands
    ]
    if not central_frequencies:
        raise ValueError(
            "Wavelet central frequencies are empty. Check band configuration."
        )
    # Prépare un tableau pour stocker l'énergie par essai, canal et bande
    band_powers: np.ndarray = np.zeros(
        (data.shape[0], data.shape[1], len(validated_bands))
    )
    # Parcourt chaque essai pour éviter des allocations massives inutiles
    for epoch_index, epoch_data in enumerate(data):
        # Parcourt chaque canal pour projeter le signal sur les échelles ciblées
        for channel_index, channel_values in enumerate(epoch_data):
            # Calcule les coefficients CWT sur les échelles demandées
            coefficients = _compute_wavelet_coefficients(
                channel_values,
                central_frequencies,
                sfreq,
                wavelet_cycles,
            )
            if coefficients.size == 0:
                raise ValueError(
                    "Wavelet coefficients computation returned an empty array. "
                    "Verify band configuration."
                )
            # Calcule la puissance moyenne par bande en intégrant la magnitude
            band_energy = np.abs(coefficients) ** 2
            # Moyenne temporelle pour stabiliser l'énergie de chaque bande
            band_powers[epoch_index, channel_index, :] = band_energy.mean(axis=1)
    # Retourne le tenseur énergie pour alignement avec les étiquettes de bandes
    return band_powers


def x__compute_wavelet_band_powers__mutmut_17(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule l'énergie de bandes via une CWT Morlet paramétrable."""

    # Valide le nom de wavelet demandé pour éviter les comportements implicites
    _normalize_wavelet_name(config.get("wavelet", "morlet"))
    if not band_ranges:
        raise ValueError("At least one wavelet band must be provided.")
    # Configure la largeur de la wavelet pour ajuster la résolution temps-fréquence
    wavelet_cycles: float = float(config.get("XXwavelet_widthXX", 6.0))
    validated_bands: List[Tuple[str, Tuple[float, float]]] = []
    for band_name, (low, high) in band_ranges.items():
        if high <= low:
            raise ValueError(
                f"Wavelet band {band_name!r} must have low < high (got {low}, {high})."
            )
        validated_bands.append((band_name, (float(low), float(high))))
    # Calcule la fréquence centrale de chaque bande pour cibler la wavelet
    central_frequencies: List[float] = [
        (low + high) / 2.0 for _, (low, high) in validated_bands
    ]
    if not central_frequencies:
        raise ValueError(
            "Wavelet central frequencies are empty. Check band configuration."
        )
    # Prépare un tableau pour stocker l'énergie par essai, canal et bande
    band_powers: np.ndarray = np.zeros(
        (data.shape[0], data.shape[1], len(validated_bands))
    )
    # Parcourt chaque essai pour éviter des allocations massives inutiles
    for epoch_index, epoch_data in enumerate(data):
        # Parcourt chaque canal pour projeter le signal sur les échelles ciblées
        for channel_index, channel_values in enumerate(epoch_data):
            # Calcule les coefficients CWT sur les échelles demandées
            coefficients = _compute_wavelet_coefficients(
                channel_values,
                central_frequencies,
                sfreq,
                wavelet_cycles,
            )
            if coefficients.size == 0:
                raise ValueError(
                    "Wavelet coefficients computation returned an empty array. "
                    "Verify band configuration."
                )
            # Calcule la puissance moyenne par bande en intégrant la magnitude
            band_energy = np.abs(coefficients) ** 2
            # Moyenne temporelle pour stabiliser l'énergie de chaque bande
            band_powers[epoch_index, channel_index, :] = band_energy.mean(axis=1)
    # Retourne le tenseur énergie pour alignement avec les étiquettes de bandes
    return band_powers


def x__compute_wavelet_band_powers__mutmut_18(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule l'énergie de bandes via une CWT Morlet paramétrable."""

    # Valide le nom de wavelet demandé pour éviter les comportements implicites
    _normalize_wavelet_name(config.get("wavelet", "morlet"))
    if not band_ranges:
        raise ValueError("At least one wavelet band must be provided.")
    # Configure la largeur de la wavelet pour ajuster la résolution temps-fréquence
    wavelet_cycles: float = float(config.get("WAVELET_WIDTH", 6.0))
    validated_bands: List[Tuple[str, Tuple[float, float]]] = []
    for band_name, (low, high) in band_ranges.items():
        if high <= low:
            raise ValueError(
                f"Wavelet band {band_name!r} must have low < high (got {low}, {high})."
            )
        validated_bands.append((band_name, (float(low), float(high))))
    # Calcule la fréquence centrale de chaque bande pour cibler la wavelet
    central_frequencies: List[float] = [
        (low + high) / 2.0 for _, (low, high) in validated_bands
    ]
    if not central_frequencies:
        raise ValueError(
            "Wavelet central frequencies are empty. Check band configuration."
        )
    # Prépare un tableau pour stocker l'énergie par essai, canal et bande
    band_powers: np.ndarray = np.zeros(
        (data.shape[0], data.shape[1], len(validated_bands))
    )
    # Parcourt chaque essai pour éviter des allocations massives inutiles
    for epoch_index, epoch_data in enumerate(data):
        # Parcourt chaque canal pour projeter le signal sur les échelles ciblées
        for channel_index, channel_values in enumerate(epoch_data):
            # Calcule les coefficients CWT sur les échelles demandées
            coefficients = _compute_wavelet_coefficients(
                channel_values,
                central_frequencies,
                sfreq,
                wavelet_cycles,
            )
            if coefficients.size == 0:
                raise ValueError(
                    "Wavelet coefficients computation returned an empty array. "
                    "Verify band configuration."
                )
            # Calcule la puissance moyenne par bande en intégrant la magnitude
            band_energy = np.abs(coefficients) ** 2
            # Moyenne temporelle pour stabiliser l'énergie de chaque bande
            band_powers[epoch_index, channel_index, :] = band_energy.mean(axis=1)
    # Retourne le tenseur énergie pour alignement avec les étiquettes de bandes
    return band_powers


def x__compute_wavelet_band_powers__mutmut_19(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule l'énergie de bandes via une CWT Morlet paramétrable."""

    # Valide le nom de wavelet demandé pour éviter les comportements implicites
    _normalize_wavelet_name(config.get("wavelet", "morlet"))
    if not band_ranges:
        raise ValueError("At least one wavelet band must be provided.")
    # Configure la largeur de la wavelet pour ajuster la résolution temps-fréquence
    wavelet_cycles: float = float(config.get("wavelet_width", 7.0))
    validated_bands: List[Tuple[str, Tuple[float, float]]] = []
    for band_name, (low, high) in band_ranges.items():
        if high <= low:
            raise ValueError(
                f"Wavelet band {band_name!r} must have low < high (got {low}, {high})."
            )
        validated_bands.append((band_name, (float(low), float(high))))
    # Calcule la fréquence centrale de chaque bande pour cibler la wavelet
    central_frequencies: List[float] = [
        (low + high) / 2.0 for _, (low, high) in validated_bands
    ]
    if not central_frequencies:
        raise ValueError(
            "Wavelet central frequencies are empty. Check band configuration."
        )
    # Prépare un tableau pour stocker l'énergie par essai, canal et bande
    band_powers: np.ndarray = np.zeros(
        (data.shape[0], data.shape[1], len(validated_bands))
    )
    # Parcourt chaque essai pour éviter des allocations massives inutiles
    for epoch_index, epoch_data in enumerate(data):
        # Parcourt chaque canal pour projeter le signal sur les échelles ciblées
        for channel_index, channel_values in enumerate(epoch_data):
            # Calcule les coefficients CWT sur les échelles demandées
            coefficients = _compute_wavelet_coefficients(
                channel_values,
                central_frequencies,
                sfreq,
                wavelet_cycles,
            )
            if coefficients.size == 0:
                raise ValueError(
                    "Wavelet coefficients computation returned an empty array. "
                    "Verify band configuration."
                )
            # Calcule la puissance moyenne par bande en intégrant la magnitude
            band_energy = np.abs(coefficients) ** 2
            # Moyenne temporelle pour stabiliser l'énergie de chaque bande
            band_powers[epoch_index, channel_index, :] = band_energy.mean(axis=1)
    # Retourne le tenseur énergie pour alignement avec les étiquettes de bandes
    return band_powers


def x__compute_wavelet_band_powers__mutmut_20(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule l'énergie de bandes via une CWT Morlet paramétrable."""

    # Valide le nom de wavelet demandé pour éviter les comportements implicites
    _normalize_wavelet_name(config.get("wavelet", "morlet"))
    if not band_ranges:
        raise ValueError("At least one wavelet band must be provided.")
    # Configure la largeur de la wavelet pour ajuster la résolution temps-fréquence
    wavelet_cycles: float = float(config.get("wavelet_width", 6.0))
    validated_bands: List[Tuple[str, Tuple[float, float]]] = None
    for band_name, (low, high) in band_ranges.items():
        if high <= low:
            raise ValueError(
                f"Wavelet band {band_name!r} must have low < high (got {low}, {high})."
            )
        validated_bands.append((band_name, (float(low), float(high))))
    # Calcule la fréquence centrale de chaque bande pour cibler la wavelet
    central_frequencies: List[float] = [
        (low + high) / 2.0 for _, (low, high) in validated_bands
    ]
    if not central_frequencies:
        raise ValueError(
            "Wavelet central frequencies are empty. Check band configuration."
        )
    # Prépare un tableau pour stocker l'énergie par essai, canal et bande
    band_powers: np.ndarray = np.zeros(
        (data.shape[0], data.shape[1], len(validated_bands))
    )
    # Parcourt chaque essai pour éviter des allocations massives inutiles
    for epoch_index, epoch_data in enumerate(data):
        # Parcourt chaque canal pour projeter le signal sur les échelles ciblées
        for channel_index, channel_values in enumerate(epoch_data):
            # Calcule les coefficients CWT sur les échelles demandées
            coefficients = _compute_wavelet_coefficients(
                channel_values,
                central_frequencies,
                sfreq,
                wavelet_cycles,
            )
            if coefficients.size == 0:
                raise ValueError(
                    "Wavelet coefficients computation returned an empty array. "
                    "Verify band configuration."
                )
            # Calcule la puissance moyenne par bande en intégrant la magnitude
            band_energy = np.abs(coefficients) ** 2
            # Moyenne temporelle pour stabiliser l'énergie de chaque bande
            band_powers[epoch_index, channel_index, :] = band_energy.mean(axis=1)
    # Retourne le tenseur énergie pour alignement avec les étiquettes de bandes
    return band_powers


def x__compute_wavelet_band_powers__mutmut_21(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule l'énergie de bandes via une CWT Morlet paramétrable."""

    # Valide le nom de wavelet demandé pour éviter les comportements implicites
    _normalize_wavelet_name(config.get("wavelet", "morlet"))
    if not band_ranges:
        raise ValueError("At least one wavelet band must be provided.")
    # Configure la largeur de la wavelet pour ajuster la résolution temps-fréquence
    wavelet_cycles: float = float(config.get("wavelet_width", 6.0))
    validated_bands: List[Tuple[str, Tuple[float, float]]] = []
    for band_name, (low, high) in band_ranges.items():
        if high < low:
            raise ValueError(
                f"Wavelet band {band_name!r} must have low < high (got {low}, {high})."
            )
        validated_bands.append((band_name, (float(low), float(high))))
    # Calcule la fréquence centrale de chaque bande pour cibler la wavelet
    central_frequencies: List[float] = [
        (low + high) / 2.0 for _, (low, high) in validated_bands
    ]
    if not central_frequencies:
        raise ValueError(
            "Wavelet central frequencies are empty. Check band configuration."
        )
    # Prépare un tableau pour stocker l'énergie par essai, canal et bande
    band_powers: np.ndarray = np.zeros(
        (data.shape[0], data.shape[1], len(validated_bands))
    )
    # Parcourt chaque essai pour éviter des allocations massives inutiles
    for epoch_index, epoch_data in enumerate(data):
        # Parcourt chaque canal pour projeter le signal sur les échelles ciblées
        for channel_index, channel_values in enumerate(epoch_data):
            # Calcule les coefficients CWT sur les échelles demandées
            coefficients = _compute_wavelet_coefficients(
                channel_values,
                central_frequencies,
                sfreq,
                wavelet_cycles,
            )
            if coefficients.size == 0:
                raise ValueError(
                    "Wavelet coefficients computation returned an empty array. "
                    "Verify band configuration."
                )
            # Calcule la puissance moyenne par bande en intégrant la magnitude
            band_energy = np.abs(coefficients) ** 2
            # Moyenne temporelle pour stabiliser l'énergie de chaque bande
            band_powers[epoch_index, channel_index, :] = band_energy.mean(axis=1)
    # Retourne le tenseur énergie pour alignement avec les étiquettes de bandes
    return band_powers


def x__compute_wavelet_band_powers__mutmut_22(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule l'énergie de bandes via une CWT Morlet paramétrable."""

    # Valide le nom de wavelet demandé pour éviter les comportements implicites
    _normalize_wavelet_name(config.get("wavelet", "morlet"))
    if not band_ranges:
        raise ValueError("At least one wavelet band must be provided.")
    # Configure la largeur de la wavelet pour ajuster la résolution temps-fréquence
    wavelet_cycles: float = float(config.get("wavelet_width", 6.0))
    validated_bands: List[Tuple[str, Tuple[float, float]]] = []
    for band_name, (low, high) in band_ranges.items():
        if high <= low:
            raise ValueError(
                None
            )
        validated_bands.append((band_name, (float(low), float(high))))
    # Calcule la fréquence centrale de chaque bande pour cibler la wavelet
    central_frequencies: List[float] = [
        (low + high) / 2.0 for _, (low, high) in validated_bands
    ]
    if not central_frequencies:
        raise ValueError(
            "Wavelet central frequencies are empty. Check band configuration."
        )
    # Prépare un tableau pour stocker l'énergie par essai, canal et bande
    band_powers: np.ndarray = np.zeros(
        (data.shape[0], data.shape[1], len(validated_bands))
    )
    # Parcourt chaque essai pour éviter des allocations massives inutiles
    for epoch_index, epoch_data in enumerate(data):
        # Parcourt chaque canal pour projeter le signal sur les échelles ciblées
        for channel_index, channel_values in enumerate(epoch_data):
            # Calcule les coefficients CWT sur les échelles demandées
            coefficients = _compute_wavelet_coefficients(
                channel_values,
                central_frequencies,
                sfreq,
                wavelet_cycles,
            )
            if coefficients.size == 0:
                raise ValueError(
                    "Wavelet coefficients computation returned an empty array. "
                    "Verify band configuration."
                )
            # Calcule la puissance moyenne par bande en intégrant la magnitude
            band_energy = np.abs(coefficients) ** 2
            # Moyenne temporelle pour stabiliser l'énergie de chaque bande
            band_powers[epoch_index, channel_index, :] = band_energy.mean(axis=1)
    # Retourne le tenseur énergie pour alignement avec les étiquettes de bandes
    return band_powers


def x__compute_wavelet_band_powers__mutmut_23(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule l'énergie de bandes via une CWT Morlet paramétrable."""

    # Valide le nom de wavelet demandé pour éviter les comportements implicites
    _normalize_wavelet_name(config.get("wavelet", "morlet"))
    if not band_ranges:
        raise ValueError("At least one wavelet band must be provided.")
    # Configure la largeur de la wavelet pour ajuster la résolution temps-fréquence
    wavelet_cycles: float = float(config.get("wavelet_width", 6.0))
    validated_bands: List[Tuple[str, Tuple[float, float]]] = []
    for band_name, (low, high) in band_ranges.items():
        if high <= low:
            raise ValueError(
                f"Wavelet band {band_name!r} must have low < high (got {low}, {high})."
            )
        validated_bands.append(None)
    # Calcule la fréquence centrale de chaque bande pour cibler la wavelet
    central_frequencies: List[float] = [
        (low + high) / 2.0 for _, (low, high) in validated_bands
    ]
    if not central_frequencies:
        raise ValueError(
            "Wavelet central frequencies are empty. Check band configuration."
        )
    # Prépare un tableau pour stocker l'énergie par essai, canal et bande
    band_powers: np.ndarray = np.zeros(
        (data.shape[0], data.shape[1], len(validated_bands))
    )
    # Parcourt chaque essai pour éviter des allocations massives inutiles
    for epoch_index, epoch_data in enumerate(data):
        # Parcourt chaque canal pour projeter le signal sur les échelles ciblées
        for channel_index, channel_values in enumerate(epoch_data):
            # Calcule les coefficients CWT sur les échelles demandées
            coefficients = _compute_wavelet_coefficients(
                channel_values,
                central_frequencies,
                sfreq,
                wavelet_cycles,
            )
            if coefficients.size == 0:
                raise ValueError(
                    "Wavelet coefficients computation returned an empty array. "
                    "Verify band configuration."
                )
            # Calcule la puissance moyenne par bande en intégrant la magnitude
            band_energy = np.abs(coefficients) ** 2
            # Moyenne temporelle pour stabiliser l'énergie de chaque bande
            band_powers[epoch_index, channel_index, :] = band_energy.mean(axis=1)
    # Retourne le tenseur énergie pour alignement avec les étiquettes de bandes
    return band_powers


def x__compute_wavelet_band_powers__mutmut_24(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule l'énergie de bandes via une CWT Morlet paramétrable."""

    # Valide le nom de wavelet demandé pour éviter les comportements implicites
    _normalize_wavelet_name(config.get("wavelet", "morlet"))
    if not band_ranges:
        raise ValueError("At least one wavelet band must be provided.")
    # Configure la largeur de la wavelet pour ajuster la résolution temps-fréquence
    wavelet_cycles: float = float(config.get("wavelet_width", 6.0))
    validated_bands: List[Tuple[str, Tuple[float, float]]] = []
    for band_name, (low, high) in band_ranges.items():
        if high <= low:
            raise ValueError(
                f"Wavelet band {band_name!r} must have low < high (got {low}, {high})."
            )
        validated_bands.append((band_name, (float(None), float(high))))
    # Calcule la fréquence centrale de chaque bande pour cibler la wavelet
    central_frequencies: List[float] = [
        (low + high) / 2.0 for _, (low, high) in validated_bands
    ]
    if not central_frequencies:
        raise ValueError(
            "Wavelet central frequencies are empty. Check band configuration."
        )
    # Prépare un tableau pour stocker l'énergie par essai, canal et bande
    band_powers: np.ndarray = np.zeros(
        (data.shape[0], data.shape[1], len(validated_bands))
    )
    # Parcourt chaque essai pour éviter des allocations massives inutiles
    for epoch_index, epoch_data in enumerate(data):
        # Parcourt chaque canal pour projeter le signal sur les échelles ciblées
        for channel_index, channel_values in enumerate(epoch_data):
            # Calcule les coefficients CWT sur les échelles demandées
            coefficients = _compute_wavelet_coefficients(
                channel_values,
                central_frequencies,
                sfreq,
                wavelet_cycles,
            )
            if coefficients.size == 0:
                raise ValueError(
                    "Wavelet coefficients computation returned an empty array. "
                    "Verify band configuration."
                )
            # Calcule la puissance moyenne par bande en intégrant la magnitude
            band_energy = np.abs(coefficients) ** 2
            # Moyenne temporelle pour stabiliser l'énergie de chaque bande
            band_powers[epoch_index, channel_index, :] = band_energy.mean(axis=1)
    # Retourne le tenseur énergie pour alignement avec les étiquettes de bandes
    return band_powers


def x__compute_wavelet_band_powers__mutmut_25(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule l'énergie de bandes via une CWT Morlet paramétrable."""

    # Valide le nom de wavelet demandé pour éviter les comportements implicites
    _normalize_wavelet_name(config.get("wavelet", "morlet"))
    if not band_ranges:
        raise ValueError("At least one wavelet band must be provided.")
    # Configure la largeur de la wavelet pour ajuster la résolution temps-fréquence
    wavelet_cycles: float = float(config.get("wavelet_width", 6.0))
    validated_bands: List[Tuple[str, Tuple[float, float]]] = []
    for band_name, (low, high) in band_ranges.items():
        if high <= low:
            raise ValueError(
                f"Wavelet band {band_name!r} must have low < high (got {low}, {high})."
            )
        validated_bands.append((band_name, (float(low), float(None))))
    # Calcule la fréquence centrale de chaque bande pour cibler la wavelet
    central_frequencies: List[float] = [
        (low + high) / 2.0 for _, (low, high) in validated_bands
    ]
    if not central_frequencies:
        raise ValueError(
            "Wavelet central frequencies are empty. Check band configuration."
        )
    # Prépare un tableau pour stocker l'énergie par essai, canal et bande
    band_powers: np.ndarray = np.zeros(
        (data.shape[0], data.shape[1], len(validated_bands))
    )
    # Parcourt chaque essai pour éviter des allocations massives inutiles
    for epoch_index, epoch_data in enumerate(data):
        # Parcourt chaque canal pour projeter le signal sur les échelles ciblées
        for channel_index, channel_values in enumerate(epoch_data):
            # Calcule les coefficients CWT sur les échelles demandées
            coefficients = _compute_wavelet_coefficients(
                channel_values,
                central_frequencies,
                sfreq,
                wavelet_cycles,
            )
            if coefficients.size == 0:
                raise ValueError(
                    "Wavelet coefficients computation returned an empty array. "
                    "Verify band configuration."
                )
            # Calcule la puissance moyenne par bande en intégrant la magnitude
            band_energy = np.abs(coefficients) ** 2
            # Moyenne temporelle pour stabiliser l'énergie de chaque bande
            band_powers[epoch_index, channel_index, :] = band_energy.mean(axis=1)
    # Retourne le tenseur énergie pour alignement avec les étiquettes de bandes
    return band_powers


def x__compute_wavelet_band_powers__mutmut_26(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule l'énergie de bandes via une CWT Morlet paramétrable."""

    # Valide le nom de wavelet demandé pour éviter les comportements implicites
    _normalize_wavelet_name(config.get("wavelet", "morlet"))
    if not band_ranges:
        raise ValueError("At least one wavelet band must be provided.")
    # Configure la largeur de la wavelet pour ajuster la résolution temps-fréquence
    wavelet_cycles: float = float(config.get("wavelet_width", 6.0))
    validated_bands: List[Tuple[str, Tuple[float, float]]] = []
    for band_name, (low, high) in band_ranges.items():
        if high <= low:
            raise ValueError(
                f"Wavelet band {band_name!r} must have low < high (got {low}, {high})."
            )
        validated_bands.append((band_name, (float(low), float(high))))
    # Calcule la fréquence centrale de chaque bande pour cibler la wavelet
    central_frequencies: List[float] = None
    if not central_frequencies:
        raise ValueError(
            "Wavelet central frequencies are empty. Check band configuration."
        )
    # Prépare un tableau pour stocker l'énergie par essai, canal et bande
    band_powers: np.ndarray = np.zeros(
        (data.shape[0], data.shape[1], len(validated_bands))
    )
    # Parcourt chaque essai pour éviter des allocations massives inutiles
    for epoch_index, epoch_data in enumerate(data):
        # Parcourt chaque canal pour projeter le signal sur les échelles ciblées
        for channel_index, channel_values in enumerate(epoch_data):
            # Calcule les coefficients CWT sur les échelles demandées
            coefficients = _compute_wavelet_coefficients(
                channel_values,
                central_frequencies,
                sfreq,
                wavelet_cycles,
            )
            if coefficients.size == 0:
                raise ValueError(
                    "Wavelet coefficients computation returned an empty array. "
                    "Verify band configuration."
                )
            # Calcule la puissance moyenne par bande en intégrant la magnitude
            band_energy = np.abs(coefficients) ** 2
            # Moyenne temporelle pour stabiliser l'énergie de chaque bande
            band_powers[epoch_index, channel_index, :] = band_energy.mean(axis=1)
    # Retourne le tenseur énergie pour alignement avec les étiquettes de bandes
    return band_powers


def x__compute_wavelet_band_powers__mutmut_27(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule l'énergie de bandes via une CWT Morlet paramétrable."""

    # Valide le nom de wavelet demandé pour éviter les comportements implicites
    _normalize_wavelet_name(config.get("wavelet", "morlet"))
    if not band_ranges:
        raise ValueError("At least one wavelet band must be provided.")
    # Configure la largeur de la wavelet pour ajuster la résolution temps-fréquence
    wavelet_cycles: float = float(config.get("wavelet_width", 6.0))
    validated_bands: List[Tuple[str, Tuple[float, float]]] = []
    for band_name, (low, high) in band_ranges.items():
        if high <= low:
            raise ValueError(
                f"Wavelet band {band_name!r} must have low < high (got {low}, {high})."
            )
        validated_bands.append((band_name, (float(low), float(high))))
    # Calcule la fréquence centrale de chaque bande pour cibler la wavelet
    central_frequencies: List[float] = [
        (low + high) * 2.0 for _, (low, high) in validated_bands
    ]
    if not central_frequencies:
        raise ValueError(
            "Wavelet central frequencies are empty. Check band configuration."
        )
    # Prépare un tableau pour stocker l'énergie par essai, canal et bande
    band_powers: np.ndarray = np.zeros(
        (data.shape[0], data.shape[1], len(validated_bands))
    )
    # Parcourt chaque essai pour éviter des allocations massives inutiles
    for epoch_index, epoch_data in enumerate(data):
        # Parcourt chaque canal pour projeter le signal sur les échelles ciblées
        for channel_index, channel_values in enumerate(epoch_data):
            # Calcule les coefficients CWT sur les échelles demandées
            coefficients = _compute_wavelet_coefficients(
                channel_values,
                central_frequencies,
                sfreq,
                wavelet_cycles,
            )
            if coefficients.size == 0:
                raise ValueError(
                    "Wavelet coefficients computation returned an empty array. "
                    "Verify band configuration."
                )
            # Calcule la puissance moyenne par bande en intégrant la magnitude
            band_energy = np.abs(coefficients) ** 2
            # Moyenne temporelle pour stabiliser l'énergie de chaque bande
            band_powers[epoch_index, channel_index, :] = band_energy.mean(axis=1)
    # Retourne le tenseur énergie pour alignement avec les étiquettes de bandes
    return band_powers


def x__compute_wavelet_band_powers__mutmut_28(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule l'énergie de bandes via une CWT Morlet paramétrable."""

    # Valide le nom de wavelet demandé pour éviter les comportements implicites
    _normalize_wavelet_name(config.get("wavelet", "morlet"))
    if not band_ranges:
        raise ValueError("At least one wavelet band must be provided.")
    # Configure la largeur de la wavelet pour ajuster la résolution temps-fréquence
    wavelet_cycles: float = float(config.get("wavelet_width", 6.0))
    validated_bands: List[Tuple[str, Tuple[float, float]]] = []
    for band_name, (low, high) in band_ranges.items():
        if high <= low:
            raise ValueError(
                f"Wavelet band {band_name!r} must have low < high (got {low}, {high})."
            )
        validated_bands.append((band_name, (float(low), float(high))))
    # Calcule la fréquence centrale de chaque bande pour cibler la wavelet
    central_frequencies: List[float] = [
        (low - high) / 2.0 for _, (low, high) in validated_bands
    ]
    if not central_frequencies:
        raise ValueError(
            "Wavelet central frequencies are empty. Check band configuration."
        )
    # Prépare un tableau pour stocker l'énergie par essai, canal et bande
    band_powers: np.ndarray = np.zeros(
        (data.shape[0], data.shape[1], len(validated_bands))
    )
    # Parcourt chaque essai pour éviter des allocations massives inutiles
    for epoch_index, epoch_data in enumerate(data):
        # Parcourt chaque canal pour projeter le signal sur les échelles ciblées
        for channel_index, channel_values in enumerate(epoch_data):
            # Calcule les coefficients CWT sur les échelles demandées
            coefficients = _compute_wavelet_coefficients(
                channel_values,
                central_frequencies,
                sfreq,
                wavelet_cycles,
            )
            if coefficients.size == 0:
                raise ValueError(
                    "Wavelet coefficients computation returned an empty array. "
                    "Verify band configuration."
                )
            # Calcule la puissance moyenne par bande en intégrant la magnitude
            band_energy = np.abs(coefficients) ** 2
            # Moyenne temporelle pour stabiliser l'énergie de chaque bande
            band_powers[epoch_index, channel_index, :] = band_energy.mean(axis=1)
    # Retourne le tenseur énergie pour alignement avec les étiquettes de bandes
    return band_powers


def x__compute_wavelet_band_powers__mutmut_29(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule l'énergie de bandes via une CWT Morlet paramétrable."""

    # Valide le nom de wavelet demandé pour éviter les comportements implicites
    _normalize_wavelet_name(config.get("wavelet", "morlet"))
    if not band_ranges:
        raise ValueError("At least one wavelet band must be provided.")
    # Configure la largeur de la wavelet pour ajuster la résolution temps-fréquence
    wavelet_cycles: float = float(config.get("wavelet_width", 6.0))
    validated_bands: List[Tuple[str, Tuple[float, float]]] = []
    for band_name, (low, high) in band_ranges.items():
        if high <= low:
            raise ValueError(
                f"Wavelet band {band_name!r} must have low < high (got {low}, {high})."
            )
        validated_bands.append((band_name, (float(low), float(high))))
    # Calcule la fréquence centrale de chaque bande pour cibler la wavelet
    central_frequencies: List[float] = [
        (low + high) / 3.0 for _, (low, high) in validated_bands
    ]
    if not central_frequencies:
        raise ValueError(
            "Wavelet central frequencies are empty. Check band configuration."
        )
    # Prépare un tableau pour stocker l'énergie par essai, canal et bande
    band_powers: np.ndarray = np.zeros(
        (data.shape[0], data.shape[1], len(validated_bands))
    )
    # Parcourt chaque essai pour éviter des allocations massives inutiles
    for epoch_index, epoch_data in enumerate(data):
        # Parcourt chaque canal pour projeter le signal sur les échelles ciblées
        for channel_index, channel_values in enumerate(epoch_data):
            # Calcule les coefficients CWT sur les échelles demandées
            coefficients = _compute_wavelet_coefficients(
                channel_values,
                central_frequencies,
                sfreq,
                wavelet_cycles,
            )
            if coefficients.size == 0:
                raise ValueError(
                    "Wavelet coefficients computation returned an empty array. "
                    "Verify band configuration."
                )
            # Calcule la puissance moyenne par bande en intégrant la magnitude
            band_energy = np.abs(coefficients) ** 2
            # Moyenne temporelle pour stabiliser l'énergie de chaque bande
            band_powers[epoch_index, channel_index, :] = band_energy.mean(axis=1)
    # Retourne le tenseur énergie pour alignement avec les étiquettes de bandes
    return band_powers


def x__compute_wavelet_band_powers__mutmut_30(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule l'énergie de bandes via une CWT Morlet paramétrable."""

    # Valide le nom de wavelet demandé pour éviter les comportements implicites
    _normalize_wavelet_name(config.get("wavelet", "morlet"))
    if not band_ranges:
        raise ValueError("At least one wavelet band must be provided.")
    # Configure la largeur de la wavelet pour ajuster la résolution temps-fréquence
    wavelet_cycles: float = float(config.get("wavelet_width", 6.0))
    validated_bands: List[Tuple[str, Tuple[float, float]]] = []
    for band_name, (low, high) in band_ranges.items():
        if high <= low:
            raise ValueError(
                f"Wavelet band {band_name!r} must have low < high (got {low}, {high})."
            )
        validated_bands.append((band_name, (float(low), float(high))))
    # Calcule la fréquence centrale de chaque bande pour cibler la wavelet
    central_frequencies: List[float] = [
        (low + high) / 2.0 for _, (low, high) in validated_bands
    ]
    if central_frequencies:
        raise ValueError(
            "Wavelet central frequencies are empty. Check band configuration."
        )
    # Prépare un tableau pour stocker l'énergie par essai, canal et bande
    band_powers: np.ndarray = np.zeros(
        (data.shape[0], data.shape[1], len(validated_bands))
    )
    # Parcourt chaque essai pour éviter des allocations massives inutiles
    for epoch_index, epoch_data in enumerate(data):
        # Parcourt chaque canal pour projeter le signal sur les échelles ciblées
        for channel_index, channel_values in enumerate(epoch_data):
            # Calcule les coefficients CWT sur les échelles demandées
            coefficients = _compute_wavelet_coefficients(
                channel_values,
                central_frequencies,
                sfreq,
                wavelet_cycles,
            )
            if coefficients.size == 0:
                raise ValueError(
                    "Wavelet coefficients computation returned an empty array. "
                    "Verify band configuration."
                )
            # Calcule la puissance moyenne par bande en intégrant la magnitude
            band_energy = np.abs(coefficients) ** 2
            # Moyenne temporelle pour stabiliser l'énergie de chaque bande
            band_powers[epoch_index, channel_index, :] = band_energy.mean(axis=1)
    # Retourne le tenseur énergie pour alignement avec les étiquettes de bandes
    return band_powers


def x__compute_wavelet_band_powers__mutmut_31(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule l'énergie de bandes via une CWT Morlet paramétrable."""

    # Valide le nom de wavelet demandé pour éviter les comportements implicites
    _normalize_wavelet_name(config.get("wavelet", "morlet"))
    if not band_ranges:
        raise ValueError("At least one wavelet band must be provided.")
    # Configure la largeur de la wavelet pour ajuster la résolution temps-fréquence
    wavelet_cycles: float = float(config.get("wavelet_width", 6.0))
    validated_bands: List[Tuple[str, Tuple[float, float]]] = []
    for band_name, (low, high) in band_ranges.items():
        if high <= low:
            raise ValueError(
                f"Wavelet band {band_name!r} must have low < high (got {low}, {high})."
            )
        validated_bands.append((band_name, (float(low), float(high))))
    # Calcule la fréquence centrale de chaque bande pour cibler la wavelet
    central_frequencies: List[float] = [
        (low + high) / 2.0 for _, (low, high) in validated_bands
    ]
    if not central_frequencies:
        raise ValueError(
            "Wavelet central frequencies are empty. Check band configuration."
        )
    # Prépare un tableau pour stocker l'énergie par essai, canal et bande
    band_powers: np.ndarray = None
    # Parcourt chaque essai pour éviter des allocations massives inutiles
    for epoch_index, epoch_data in enumerate(data):
        # Parcourt chaque canal pour projeter le signal sur les échelles ciblées
        for channel_index, channel_values in enumerate(epoch_data):
            # Calcule les coefficients CWT sur les échelles demandées
            coefficients = _compute_wavelet_coefficients(
                channel_values,
                central_frequencies,
                sfreq,
                wavelet_cycles,
            )
            if coefficients.size == 0:
                raise ValueError(
                    "Wavelet coefficients computation returned an empty array. "
                    "Verify band configuration."
                )
            # Calcule la puissance moyenne par bande en intégrant la magnitude
            band_energy = np.abs(coefficients) ** 2
            # Moyenne temporelle pour stabiliser l'énergie de chaque bande
            band_powers[epoch_index, channel_index, :] = band_energy.mean(axis=1)
    # Retourne le tenseur énergie pour alignement avec les étiquettes de bandes
    return band_powers


def x__compute_wavelet_band_powers__mutmut_32(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule l'énergie de bandes via une CWT Morlet paramétrable."""

    # Valide le nom de wavelet demandé pour éviter les comportements implicites
    _normalize_wavelet_name(config.get("wavelet", "morlet"))
    if not band_ranges:
        raise ValueError("At least one wavelet band must be provided.")
    # Configure la largeur de la wavelet pour ajuster la résolution temps-fréquence
    wavelet_cycles: float = float(config.get("wavelet_width", 6.0))
    validated_bands: List[Tuple[str, Tuple[float, float]]] = []
    for band_name, (low, high) in band_ranges.items():
        if high <= low:
            raise ValueError(
                f"Wavelet band {band_name!r} must have low < high (got {low}, {high})."
            )
        validated_bands.append((band_name, (float(low), float(high))))
    # Calcule la fréquence centrale de chaque bande pour cibler la wavelet
    central_frequencies: List[float] = [
        (low + high) / 2.0 for _, (low, high) in validated_bands
    ]
    if not central_frequencies:
        raise ValueError(
            "Wavelet central frequencies are empty. Check band configuration."
        )
    # Prépare un tableau pour stocker l'énergie par essai, canal et bande
    band_powers: np.ndarray = np.zeros(
        None
    )
    # Parcourt chaque essai pour éviter des allocations massives inutiles
    for epoch_index, epoch_data in enumerate(data):
        # Parcourt chaque canal pour projeter le signal sur les échelles ciblées
        for channel_index, channel_values in enumerate(epoch_data):
            # Calcule les coefficients CWT sur les échelles demandées
            coefficients = _compute_wavelet_coefficients(
                channel_values,
                central_frequencies,
                sfreq,
                wavelet_cycles,
            )
            if coefficients.size == 0:
                raise ValueError(
                    "Wavelet coefficients computation returned an empty array. "
                    "Verify band configuration."
                )
            # Calcule la puissance moyenne par bande en intégrant la magnitude
            band_energy = np.abs(coefficients) ** 2
            # Moyenne temporelle pour stabiliser l'énergie de chaque bande
            band_powers[epoch_index, channel_index, :] = band_energy.mean(axis=1)
    # Retourne le tenseur énergie pour alignement avec les étiquettes de bandes
    return band_powers


def x__compute_wavelet_band_powers__mutmut_33(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule l'énergie de bandes via une CWT Morlet paramétrable."""

    # Valide le nom de wavelet demandé pour éviter les comportements implicites
    _normalize_wavelet_name(config.get("wavelet", "morlet"))
    if not band_ranges:
        raise ValueError("At least one wavelet band must be provided.")
    # Configure la largeur de la wavelet pour ajuster la résolution temps-fréquence
    wavelet_cycles: float = float(config.get("wavelet_width", 6.0))
    validated_bands: List[Tuple[str, Tuple[float, float]]] = []
    for band_name, (low, high) in band_ranges.items():
        if high <= low:
            raise ValueError(
                f"Wavelet band {band_name!r} must have low < high (got {low}, {high})."
            )
        validated_bands.append((band_name, (float(low), float(high))))
    # Calcule la fréquence centrale de chaque bande pour cibler la wavelet
    central_frequencies: List[float] = [
        (low + high) / 2.0 for _, (low, high) in validated_bands
    ]
    if not central_frequencies:
        raise ValueError(
            "Wavelet central frequencies are empty. Check band configuration."
        )
    # Prépare un tableau pour stocker l'énergie par essai, canal et bande
    band_powers: np.ndarray = np.zeros(
        (data.shape[1], data.shape[1], len(validated_bands))
    )
    # Parcourt chaque essai pour éviter des allocations massives inutiles
    for epoch_index, epoch_data in enumerate(data):
        # Parcourt chaque canal pour projeter le signal sur les échelles ciblées
        for channel_index, channel_values in enumerate(epoch_data):
            # Calcule les coefficients CWT sur les échelles demandées
            coefficients = _compute_wavelet_coefficients(
                channel_values,
                central_frequencies,
                sfreq,
                wavelet_cycles,
            )
            if coefficients.size == 0:
                raise ValueError(
                    "Wavelet coefficients computation returned an empty array. "
                    "Verify band configuration."
                )
            # Calcule la puissance moyenne par bande en intégrant la magnitude
            band_energy = np.abs(coefficients) ** 2
            # Moyenne temporelle pour stabiliser l'énergie de chaque bande
            band_powers[epoch_index, channel_index, :] = band_energy.mean(axis=1)
    # Retourne le tenseur énergie pour alignement avec les étiquettes de bandes
    return band_powers


def x__compute_wavelet_band_powers__mutmut_34(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule l'énergie de bandes via une CWT Morlet paramétrable."""

    # Valide le nom de wavelet demandé pour éviter les comportements implicites
    _normalize_wavelet_name(config.get("wavelet", "morlet"))
    if not band_ranges:
        raise ValueError("At least one wavelet band must be provided.")
    # Configure la largeur de la wavelet pour ajuster la résolution temps-fréquence
    wavelet_cycles: float = float(config.get("wavelet_width", 6.0))
    validated_bands: List[Tuple[str, Tuple[float, float]]] = []
    for band_name, (low, high) in band_ranges.items():
        if high <= low:
            raise ValueError(
                f"Wavelet band {band_name!r} must have low < high (got {low}, {high})."
            )
        validated_bands.append((band_name, (float(low), float(high))))
    # Calcule la fréquence centrale de chaque bande pour cibler la wavelet
    central_frequencies: List[float] = [
        (low + high) / 2.0 for _, (low, high) in validated_bands
    ]
    if not central_frequencies:
        raise ValueError(
            "Wavelet central frequencies are empty. Check band configuration."
        )
    # Prépare un tableau pour stocker l'énergie par essai, canal et bande
    band_powers: np.ndarray = np.zeros(
        (data.shape[0], data.shape[2], len(validated_bands))
    )
    # Parcourt chaque essai pour éviter des allocations massives inutiles
    for epoch_index, epoch_data in enumerate(data):
        # Parcourt chaque canal pour projeter le signal sur les échelles ciblées
        for channel_index, channel_values in enumerate(epoch_data):
            # Calcule les coefficients CWT sur les échelles demandées
            coefficients = _compute_wavelet_coefficients(
                channel_values,
                central_frequencies,
                sfreq,
                wavelet_cycles,
            )
            if coefficients.size == 0:
                raise ValueError(
                    "Wavelet coefficients computation returned an empty array. "
                    "Verify band configuration."
                )
            # Calcule la puissance moyenne par bande en intégrant la magnitude
            band_energy = np.abs(coefficients) ** 2
            # Moyenne temporelle pour stabiliser l'énergie de chaque bande
            band_powers[epoch_index, channel_index, :] = band_energy.mean(axis=1)
    # Retourne le tenseur énergie pour alignement avec les étiquettes de bandes
    return band_powers


def x__compute_wavelet_band_powers__mutmut_35(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule l'énergie de bandes via une CWT Morlet paramétrable."""

    # Valide le nom de wavelet demandé pour éviter les comportements implicites
    _normalize_wavelet_name(config.get("wavelet", "morlet"))
    if not band_ranges:
        raise ValueError("At least one wavelet band must be provided.")
    # Configure la largeur de la wavelet pour ajuster la résolution temps-fréquence
    wavelet_cycles: float = float(config.get("wavelet_width", 6.0))
    validated_bands: List[Tuple[str, Tuple[float, float]]] = []
    for band_name, (low, high) in band_ranges.items():
        if high <= low:
            raise ValueError(
                f"Wavelet band {band_name!r} must have low < high (got {low}, {high})."
            )
        validated_bands.append((band_name, (float(low), float(high))))
    # Calcule la fréquence centrale de chaque bande pour cibler la wavelet
    central_frequencies: List[float] = [
        (low + high) / 2.0 for _, (low, high) in validated_bands
    ]
    if not central_frequencies:
        raise ValueError(
            "Wavelet central frequencies are empty. Check band configuration."
        )
    # Prépare un tableau pour stocker l'énergie par essai, canal et bande
    band_powers: np.ndarray = np.zeros(
        (data.shape[0], data.shape[1], len(validated_bands))
    )
    # Parcourt chaque essai pour éviter des allocations massives inutiles
    for epoch_index, epoch_data in enumerate(None):
        # Parcourt chaque canal pour projeter le signal sur les échelles ciblées
        for channel_index, channel_values in enumerate(epoch_data):
            # Calcule les coefficients CWT sur les échelles demandées
            coefficients = _compute_wavelet_coefficients(
                channel_values,
                central_frequencies,
                sfreq,
                wavelet_cycles,
            )
            if coefficients.size == 0:
                raise ValueError(
                    "Wavelet coefficients computation returned an empty array. "
                    "Verify band configuration."
                )
            # Calcule la puissance moyenne par bande en intégrant la magnitude
            band_energy = np.abs(coefficients) ** 2
            # Moyenne temporelle pour stabiliser l'énergie de chaque bande
            band_powers[epoch_index, channel_index, :] = band_energy.mean(axis=1)
    # Retourne le tenseur énergie pour alignement avec les étiquettes de bandes
    return band_powers


def x__compute_wavelet_band_powers__mutmut_36(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule l'énergie de bandes via une CWT Morlet paramétrable."""

    # Valide le nom de wavelet demandé pour éviter les comportements implicites
    _normalize_wavelet_name(config.get("wavelet", "morlet"))
    if not band_ranges:
        raise ValueError("At least one wavelet band must be provided.")
    # Configure la largeur de la wavelet pour ajuster la résolution temps-fréquence
    wavelet_cycles: float = float(config.get("wavelet_width", 6.0))
    validated_bands: List[Tuple[str, Tuple[float, float]]] = []
    for band_name, (low, high) in band_ranges.items():
        if high <= low:
            raise ValueError(
                f"Wavelet band {band_name!r} must have low < high (got {low}, {high})."
            )
        validated_bands.append((band_name, (float(low), float(high))))
    # Calcule la fréquence centrale de chaque bande pour cibler la wavelet
    central_frequencies: List[float] = [
        (low + high) / 2.0 for _, (low, high) in validated_bands
    ]
    if not central_frequencies:
        raise ValueError(
            "Wavelet central frequencies are empty. Check band configuration."
        )
    # Prépare un tableau pour stocker l'énergie par essai, canal et bande
    band_powers: np.ndarray = np.zeros(
        (data.shape[0], data.shape[1], len(validated_bands))
    )
    # Parcourt chaque essai pour éviter des allocations massives inutiles
    for epoch_index, epoch_data in enumerate(data):
        # Parcourt chaque canal pour projeter le signal sur les échelles ciblées
        for channel_index, channel_values in enumerate(None):
            # Calcule les coefficients CWT sur les échelles demandées
            coefficients = _compute_wavelet_coefficients(
                channel_values,
                central_frequencies,
                sfreq,
                wavelet_cycles,
            )
            if coefficients.size == 0:
                raise ValueError(
                    "Wavelet coefficients computation returned an empty array. "
                    "Verify band configuration."
                )
            # Calcule la puissance moyenne par bande en intégrant la magnitude
            band_energy = np.abs(coefficients) ** 2
            # Moyenne temporelle pour stabiliser l'énergie de chaque bande
            band_powers[epoch_index, channel_index, :] = band_energy.mean(axis=1)
    # Retourne le tenseur énergie pour alignement avec les étiquettes de bandes
    return band_powers


def x__compute_wavelet_band_powers__mutmut_37(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule l'énergie de bandes via une CWT Morlet paramétrable."""

    # Valide le nom de wavelet demandé pour éviter les comportements implicites
    _normalize_wavelet_name(config.get("wavelet", "morlet"))
    if not band_ranges:
        raise ValueError("At least one wavelet band must be provided.")
    # Configure la largeur de la wavelet pour ajuster la résolution temps-fréquence
    wavelet_cycles: float = float(config.get("wavelet_width", 6.0))
    validated_bands: List[Tuple[str, Tuple[float, float]]] = []
    for band_name, (low, high) in band_ranges.items():
        if high <= low:
            raise ValueError(
                f"Wavelet band {band_name!r} must have low < high (got {low}, {high})."
            )
        validated_bands.append((band_name, (float(low), float(high))))
    # Calcule la fréquence centrale de chaque bande pour cibler la wavelet
    central_frequencies: List[float] = [
        (low + high) / 2.0 for _, (low, high) in validated_bands
    ]
    if not central_frequencies:
        raise ValueError(
            "Wavelet central frequencies are empty. Check band configuration."
        )
    # Prépare un tableau pour stocker l'énergie par essai, canal et bande
    band_powers: np.ndarray = np.zeros(
        (data.shape[0], data.shape[1], len(validated_bands))
    )
    # Parcourt chaque essai pour éviter des allocations massives inutiles
    for epoch_index, epoch_data in enumerate(data):
        # Parcourt chaque canal pour projeter le signal sur les échelles ciblées
        for channel_index, channel_values in enumerate(epoch_data):
            # Calcule les coefficients CWT sur les échelles demandées
            coefficients = None
            if coefficients.size == 0:
                raise ValueError(
                    "Wavelet coefficients computation returned an empty array. "
                    "Verify band configuration."
                )
            # Calcule la puissance moyenne par bande en intégrant la magnitude
            band_energy = np.abs(coefficients) ** 2
            # Moyenne temporelle pour stabiliser l'énergie de chaque bande
            band_powers[epoch_index, channel_index, :] = band_energy.mean(axis=1)
    # Retourne le tenseur énergie pour alignement avec les étiquettes de bandes
    return band_powers


def x__compute_wavelet_band_powers__mutmut_38(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule l'énergie de bandes via une CWT Morlet paramétrable."""

    # Valide le nom de wavelet demandé pour éviter les comportements implicites
    _normalize_wavelet_name(config.get("wavelet", "morlet"))
    if not band_ranges:
        raise ValueError("At least one wavelet band must be provided.")
    # Configure la largeur de la wavelet pour ajuster la résolution temps-fréquence
    wavelet_cycles: float = float(config.get("wavelet_width", 6.0))
    validated_bands: List[Tuple[str, Tuple[float, float]]] = []
    for band_name, (low, high) in band_ranges.items():
        if high <= low:
            raise ValueError(
                f"Wavelet band {band_name!r} must have low < high (got {low}, {high})."
            )
        validated_bands.append((band_name, (float(low), float(high))))
    # Calcule la fréquence centrale de chaque bande pour cibler la wavelet
    central_frequencies: List[float] = [
        (low + high) / 2.0 for _, (low, high) in validated_bands
    ]
    if not central_frequencies:
        raise ValueError(
            "Wavelet central frequencies are empty. Check band configuration."
        )
    # Prépare un tableau pour stocker l'énergie par essai, canal et bande
    band_powers: np.ndarray = np.zeros(
        (data.shape[0], data.shape[1], len(validated_bands))
    )
    # Parcourt chaque essai pour éviter des allocations massives inutiles
    for epoch_index, epoch_data in enumerate(data):
        # Parcourt chaque canal pour projeter le signal sur les échelles ciblées
        for channel_index, channel_values in enumerate(epoch_data):
            # Calcule les coefficients CWT sur les échelles demandées
            coefficients = _compute_wavelet_coefficients(
                None,
                central_frequencies,
                sfreq,
                wavelet_cycles,
            )
            if coefficients.size == 0:
                raise ValueError(
                    "Wavelet coefficients computation returned an empty array. "
                    "Verify band configuration."
                )
            # Calcule la puissance moyenne par bande en intégrant la magnitude
            band_energy = np.abs(coefficients) ** 2
            # Moyenne temporelle pour stabiliser l'énergie de chaque bande
            band_powers[epoch_index, channel_index, :] = band_energy.mean(axis=1)
    # Retourne le tenseur énergie pour alignement avec les étiquettes de bandes
    return band_powers


def x__compute_wavelet_band_powers__mutmut_39(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule l'énergie de bandes via une CWT Morlet paramétrable."""

    # Valide le nom de wavelet demandé pour éviter les comportements implicites
    _normalize_wavelet_name(config.get("wavelet", "morlet"))
    if not band_ranges:
        raise ValueError("At least one wavelet band must be provided.")
    # Configure la largeur de la wavelet pour ajuster la résolution temps-fréquence
    wavelet_cycles: float = float(config.get("wavelet_width", 6.0))
    validated_bands: List[Tuple[str, Tuple[float, float]]] = []
    for band_name, (low, high) in band_ranges.items():
        if high <= low:
            raise ValueError(
                f"Wavelet band {band_name!r} must have low < high (got {low}, {high})."
            )
        validated_bands.append((band_name, (float(low), float(high))))
    # Calcule la fréquence centrale de chaque bande pour cibler la wavelet
    central_frequencies: List[float] = [
        (low + high) / 2.0 for _, (low, high) in validated_bands
    ]
    if not central_frequencies:
        raise ValueError(
            "Wavelet central frequencies are empty. Check band configuration."
        )
    # Prépare un tableau pour stocker l'énergie par essai, canal et bande
    band_powers: np.ndarray = np.zeros(
        (data.shape[0], data.shape[1], len(validated_bands))
    )
    # Parcourt chaque essai pour éviter des allocations massives inutiles
    for epoch_index, epoch_data in enumerate(data):
        # Parcourt chaque canal pour projeter le signal sur les échelles ciblées
        for channel_index, channel_values in enumerate(epoch_data):
            # Calcule les coefficients CWT sur les échelles demandées
            coefficients = _compute_wavelet_coefficients(
                channel_values,
                None,
                sfreq,
                wavelet_cycles,
            )
            if coefficients.size == 0:
                raise ValueError(
                    "Wavelet coefficients computation returned an empty array. "
                    "Verify band configuration."
                )
            # Calcule la puissance moyenne par bande en intégrant la magnitude
            band_energy = np.abs(coefficients) ** 2
            # Moyenne temporelle pour stabiliser l'énergie de chaque bande
            band_powers[epoch_index, channel_index, :] = band_energy.mean(axis=1)
    # Retourne le tenseur énergie pour alignement avec les étiquettes de bandes
    return band_powers


def x__compute_wavelet_band_powers__mutmut_40(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule l'énergie de bandes via une CWT Morlet paramétrable."""

    # Valide le nom de wavelet demandé pour éviter les comportements implicites
    _normalize_wavelet_name(config.get("wavelet", "morlet"))
    if not band_ranges:
        raise ValueError("At least one wavelet band must be provided.")
    # Configure la largeur de la wavelet pour ajuster la résolution temps-fréquence
    wavelet_cycles: float = float(config.get("wavelet_width", 6.0))
    validated_bands: List[Tuple[str, Tuple[float, float]]] = []
    for band_name, (low, high) in band_ranges.items():
        if high <= low:
            raise ValueError(
                f"Wavelet band {band_name!r} must have low < high (got {low}, {high})."
            )
        validated_bands.append((band_name, (float(low), float(high))))
    # Calcule la fréquence centrale de chaque bande pour cibler la wavelet
    central_frequencies: List[float] = [
        (low + high) / 2.0 for _, (low, high) in validated_bands
    ]
    if not central_frequencies:
        raise ValueError(
            "Wavelet central frequencies are empty. Check band configuration."
        )
    # Prépare un tableau pour stocker l'énergie par essai, canal et bande
    band_powers: np.ndarray = np.zeros(
        (data.shape[0], data.shape[1], len(validated_bands))
    )
    # Parcourt chaque essai pour éviter des allocations massives inutiles
    for epoch_index, epoch_data in enumerate(data):
        # Parcourt chaque canal pour projeter le signal sur les échelles ciblées
        for channel_index, channel_values in enumerate(epoch_data):
            # Calcule les coefficients CWT sur les échelles demandées
            coefficients = _compute_wavelet_coefficients(
                channel_values,
                central_frequencies,
                None,
                wavelet_cycles,
            )
            if coefficients.size == 0:
                raise ValueError(
                    "Wavelet coefficients computation returned an empty array. "
                    "Verify band configuration."
                )
            # Calcule la puissance moyenne par bande en intégrant la magnitude
            band_energy = np.abs(coefficients) ** 2
            # Moyenne temporelle pour stabiliser l'énergie de chaque bande
            band_powers[epoch_index, channel_index, :] = band_energy.mean(axis=1)
    # Retourne le tenseur énergie pour alignement avec les étiquettes de bandes
    return band_powers


def x__compute_wavelet_band_powers__mutmut_41(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule l'énergie de bandes via une CWT Morlet paramétrable."""

    # Valide le nom de wavelet demandé pour éviter les comportements implicites
    _normalize_wavelet_name(config.get("wavelet", "morlet"))
    if not band_ranges:
        raise ValueError("At least one wavelet band must be provided.")
    # Configure la largeur de la wavelet pour ajuster la résolution temps-fréquence
    wavelet_cycles: float = float(config.get("wavelet_width", 6.0))
    validated_bands: List[Tuple[str, Tuple[float, float]]] = []
    for band_name, (low, high) in band_ranges.items():
        if high <= low:
            raise ValueError(
                f"Wavelet band {band_name!r} must have low < high (got {low}, {high})."
            )
        validated_bands.append((band_name, (float(low), float(high))))
    # Calcule la fréquence centrale de chaque bande pour cibler la wavelet
    central_frequencies: List[float] = [
        (low + high) / 2.0 for _, (low, high) in validated_bands
    ]
    if not central_frequencies:
        raise ValueError(
            "Wavelet central frequencies are empty. Check band configuration."
        )
    # Prépare un tableau pour stocker l'énergie par essai, canal et bande
    band_powers: np.ndarray = np.zeros(
        (data.shape[0], data.shape[1], len(validated_bands))
    )
    # Parcourt chaque essai pour éviter des allocations massives inutiles
    for epoch_index, epoch_data in enumerate(data):
        # Parcourt chaque canal pour projeter le signal sur les échelles ciblées
        for channel_index, channel_values in enumerate(epoch_data):
            # Calcule les coefficients CWT sur les échelles demandées
            coefficients = _compute_wavelet_coefficients(
                channel_values,
                central_frequencies,
                sfreq,
                None,
            )
            if coefficients.size == 0:
                raise ValueError(
                    "Wavelet coefficients computation returned an empty array. "
                    "Verify band configuration."
                )
            # Calcule la puissance moyenne par bande en intégrant la magnitude
            band_energy = np.abs(coefficients) ** 2
            # Moyenne temporelle pour stabiliser l'énergie de chaque bande
            band_powers[epoch_index, channel_index, :] = band_energy.mean(axis=1)
    # Retourne le tenseur énergie pour alignement avec les étiquettes de bandes
    return band_powers


def x__compute_wavelet_band_powers__mutmut_42(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule l'énergie de bandes via une CWT Morlet paramétrable."""

    # Valide le nom de wavelet demandé pour éviter les comportements implicites
    _normalize_wavelet_name(config.get("wavelet", "morlet"))
    if not band_ranges:
        raise ValueError("At least one wavelet band must be provided.")
    # Configure la largeur de la wavelet pour ajuster la résolution temps-fréquence
    wavelet_cycles: float = float(config.get("wavelet_width", 6.0))
    validated_bands: List[Tuple[str, Tuple[float, float]]] = []
    for band_name, (low, high) in band_ranges.items():
        if high <= low:
            raise ValueError(
                f"Wavelet band {band_name!r} must have low < high (got {low}, {high})."
            )
        validated_bands.append((band_name, (float(low), float(high))))
    # Calcule la fréquence centrale de chaque bande pour cibler la wavelet
    central_frequencies: List[float] = [
        (low + high) / 2.0 for _, (low, high) in validated_bands
    ]
    if not central_frequencies:
        raise ValueError(
            "Wavelet central frequencies are empty. Check band configuration."
        )
    # Prépare un tableau pour stocker l'énergie par essai, canal et bande
    band_powers: np.ndarray = np.zeros(
        (data.shape[0], data.shape[1], len(validated_bands))
    )
    # Parcourt chaque essai pour éviter des allocations massives inutiles
    for epoch_index, epoch_data in enumerate(data):
        # Parcourt chaque canal pour projeter le signal sur les échelles ciblées
        for channel_index, channel_values in enumerate(epoch_data):
            # Calcule les coefficients CWT sur les échelles demandées
            coefficients = _compute_wavelet_coefficients(
                central_frequencies,
                sfreq,
                wavelet_cycles,
            )
            if coefficients.size == 0:
                raise ValueError(
                    "Wavelet coefficients computation returned an empty array. "
                    "Verify band configuration."
                )
            # Calcule la puissance moyenne par bande en intégrant la magnitude
            band_energy = np.abs(coefficients) ** 2
            # Moyenne temporelle pour stabiliser l'énergie de chaque bande
            band_powers[epoch_index, channel_index, :] = band_energy.mean(axis=1)
    # Retourne le tenseur énergie pour alignement avec les étiquettes de bandes
    return band_powers


def x__compute_wavelet_band_powers__mutmut_43(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule l'énergie de bandes via une CWT Morlet paramétrable."""

    # Valide le nom de wavelet demandé pour éviter les comportements implicites
    _normalize_wavelet_name(config.get("wavelet", "morlet"))
    if not band_ranges:
        raise ValueError("At least one wavelet band must be provided.")
    # Configure la largeur de la wavelet pour ajuster la résolution temps-fréquence
    wavelet_cycles: float = float(config.get("wavelet_width", 6.0))
    validated_bands: List[Tuple[str, Tuple[float, float]]] = []
    for band_name, (low, high) in band_ranges.items():
        if high <= low:
            raise ValueError(
                f"Wavelet band {band_name!r} must have low < high (got {low}, {high})."
            )
        validated_bands.append((band_name, (float(low), float(high))))
    # Calcule la fréquence centrale de chaque bande pour cibler la wavelet
    central_frequencies: List[float] = [
        (low + high) / 2.0 for _, (low, high) in validated_bands
    ]
    if not central_frequencies:
        raise ValueError(
            "Wavelet central frequencies are empty. Check band configuration."
        )
    # Prépare un tableau pour stocker l'énergie par essai, canal et bande
    band_powers: np.ndarray = np.zeros(
        (data.shape[0], data.shape[1], len(validated_bands))
    )
    # Parcourt chaque essai pour éviter des allocations massives inutiles
    for epoch_index, epoch_data in enumerate(data):
        # Parcourt chaque canal pour projeter le signal sur les échelles ciblées
        for channel_index, channel_values in enumerate(epoch_data):
            # Calcule les coefficients CWT sur les échelles demandées
            coefficients = _compute_wavelet_coefficients(
                channel_values,
                sfreq,
                wavelet_cycles,
            )
            if coefficients.size == 0:
                raise ValueError(
                    "Wavelet coefficients computation returned an empty array. "
                    "Verify band configuration."
                )
            # Calcule la puissance moyenne par bande en intégrant la magnitude
            band_energy = np.abs(coefficients) ** 2
            # Moyenne temporelle pour stabiliser l'énergie de chaque bande
            band_powers[epoch_index, channel_index, :] = band_energy.mean(axis=1)
    # Retourne le tenseur énergie pour alignement avec les étiquettes de bandes
    return band_powers


def x__compute_wavelet_band_powers__mutmut_44(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule l'énergie de bandes via une CWT Morlet paramétrable."""

    # Valide le nom de wavelet demandé pour éviter les comportements implicites
    _normalize_wavelet_name(config.get("wavelet", "morlet"))
    if not band_ranges:
        raise ValueError("At least one wavelet band must be provided.")
    # Configure la largeur de la wavelet pour ajuster la résolution temps-fréquence
    wavelet_cycles: float = float(config.get("wavelet_width", 6.0))
    validated_bands: List[Tuple[str, Tuple[float, float]]] = []
    for band_name, (low, high) in band_ranges.items():
        if high <= low:
            raise ValueError(
                f"Wavelet band {band_name!r} must have low < high (got {low}, {high})."
            )
        validated_bands.append((band_name, (float(low), float(high))))
    # Calcule la fréquence centrale de chaque bande pour cibler la wavelet
    central_frequencies: List[float] = [
        (low + high) / 2.0 for _, (low, high) in validated_bands
    ]
    if not central_frequencies:
        raise ValueError(
            "Wavelet central frequencies are empty. Check band configuration."
        )
    # Prépare un tableau pour stocker l'énergie par essai, canal et bande
    band_powers: np.ndarray = np.zeros(
        (data.shape[0], data.shape[1], len(validated_bands))
    )
    # Parcourt chaque essai pour éviter des allocations massives inutiles
    for epoch_index, epoch_data in enumerate(data):
        # Parcourt chaque canal pour projeter le signal sur les échelles ciblées
        for channel_index, channel_values in enumerate(epoch_data):
            # Calcule les coefficients CWT sur les échelles demandées
            coefficients = _compute_wavelet_coefficients(
                channel_values,
                central_frequencies,
                wavelet_cycles,
            )
            if coefficients.size == 0:
                raise ValueError(
                    "Wavelet coefficients computation returned an empty array. "
                    "Verify band configuration."
                )
            # Calcule la puissance moyenne par bande en intégrant la magnitude
            band_energy = np.abs(coefficients) ** 2
            # Moyenne temporelle pour stabiliser l'énergie de chaque bande
            band_powers[epoch_index, channel_index, :] = band_energy.mean(axis=1)
    # Retourne le tenseur énergie pour alignement avec les étiquettes de bandes
    return band_powers


def x__compute_wavelet_band_powers__mutmut_45(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule l'énergie de bandes via une CWT Morlet paramétrable."""

    # Valide le nom de wavelet demandé pour éviter les comportements implicites
    _normalize_wavelet_name(config.get("wavelet", "morlet"))
    if not band_ranges:
        raise ValueError("At least one wavelet band must be provided.")
    # Configure la largeur de la wavelet pour ajuster la résolution temps-fréquence
    wavelet_cycles: float = float(config.get("wavelet_width", 6.0))
    validated_bands: List[Tuple[str, Tuple[float, float]]] = []
    for band_name, (low, high) in band_ranges.items():
        if high <= low:
            raise ValueError(
                f"Wavelet band {band_name!r} must have low < high (got {low}, {high})."
            )
        validated_bands.append((band_name, (float(low), float(high))))
    # Calcule la fréquence centrale de chaque bande pour cibler la wavelet
    central_frequencies: List[float] = [
        (low + high) / 2.0 for _, (low, high) in validated_bands
    ]
    if not central_frequencies:
        raise ValueError(
            "Wavelet central frequencies are empty. Check band configuration."
        )
    # Prépare un tableau pour stocker l'énergie par essai, canal et bande
    band_powers: np.ndarray = np.zeros(
        (data.shape[0], data.shape[1], len(validated_bands))
    )
    # Parcourt chaque essai pour éviter des allocations massives inutiles
    for epoch_index, epoch_data in enumerate(data):
        # Parcourt chaque canal pour projeter le signal sur les échelles ciblées
        for channel_index, channel_values in enumerate(epoch_data):
            # Calcule les coefficients CWT sur les échelles demandées
            coefficients = _compute_wavelet_coefficients(
                channel_values,
                central_frequencies,
                sfreq,
                )
            if coefficients.size == 0:
                raise ValueError(
                    "Wavelet coefficients computation returned an empty array. "
                    "Verify band configuration."
                )
            # Calcule la puissance moyenne par bande en intégrant la magnitude
            band_energy = np.abs(coefficients) ** 2
            # Moyenne temporelle pour stabiliser l'énergie de chaque bande
            band_powers[epoch_index, channel_index, :] = band_energy.mean(axis=1)
    # Retourne le tenseur énergie pour alignement avec les étiquettes de bandes
    return band_powers


def x__compute_wavelet_band_powers__mutmut_46(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule l'énergie de bandes via une CWT Morlet paramétrable."""

    # Valide le nom de wavelet demandé pour éviter les comportements implicites
    _normalize_wavelet_name(config.get("wavelet", "morlet"))
    if not band_ranges:
        raise ValueError("At least one wavelet band must be provided.")
    # Configure la largeur de la wavelet pour ajuster la résolution temps-fréquence
    wavelet_cycles: float = float(config.get("wavelet_width", 6.0))
    validated_bands: List[Tuple[str, Tuple[float, float]]] = []
    for band_name, (low, high) in band_ranges.items():
        if high <= low:
            raise ValueError(
                f"Wavelet band {band_name!r} must have low < high (got {low}, {high})."
            )
        validated_bands.append((band_name, (float(low), float(high))))
    # Calcule la fréquence centrale de chaque bande pour cibler la wavelet
    central_frequencies: List[float] = [
        (low + high) / 2.0 for _, (low, high) in validated_bands
    ]
    if not central_frequencies:
        raise ValueError(
            "Wavelet central frequencies are empty. Check band configuration."
        )
    # Prépare un tableau pour stocker l'énergie par essai, canal et bande
    band_powers: np.ndarray = np.zeros(
        (data.shape[0], data.shape[1], len(validated_bands))
    )
    # Parcourt chaque essai pour éviter des allocations massives inutiles
    for epoch_index, epoch_data in enumerate(data):
        # Parcourt chaque canal pour projeter le signal sur les échelles ciblées
        for channel_index, channel_values in enumerate(epoch_data):
            # Calcule les coefficients CWT sur les échelles demandées
            coefficients = _compute_wavelet_coefficients(
                channel_values,
                central_frequencies,
                sfreq,
                wavelet_cycles,
            )
            if coefficients.size != 0:
                raise ValueError(
                    "Wavelet coefficients computation returned an empty array. "
                    "Verify band configuration."
                )
            # Calcule la puissance moyenne par bande en intégrant la magnitude
            band_energy = np.abs(coefficients) ** 2
            # Moyenne temporelle pour stabiliser l'énergie de chaque bande
            band_powers[epoch_index, channel_index, :] = band_energy.mean(axis=1)
    # Retourne le tenseur énergie pour alignement avec les étiquettes de bandes
    return band_powers


def x__compute_wavelet_band_powers__mutmut_47(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule l'énergie de bandes via une CWT Morlet paramétrable."""

    # Valide le nom de wavelet demandé pour éviter les comportements implicites
    _normalize_wavelet_name(config.get("wavelet", "morlet"))
    if not band_ranges:
        raise ValueError("At least one wavelet band must be provided.")
    # Configure la largeur de la wavelet pour ajuster la résolution temps-fréquence
    wavelet_cycles: float = float(config.get("wavelet_width", 6.0))
    validated_bands: List[Tuple[str, Tuple[float, float]]] = []
    for band_name, (low, high) in band_ranges.items():
        if high <= low:
            raise ValueError(
                f"Wavelet band {band_name!r} must have low < high (got {low}, {high})."
            )
        validated_bands.append((band_name, (float(low), float(high))))
    # Calcule la fréquence centrale de chaque bande pour cibler la wavelet
    central_frequencies: List[float] = [
        (low + high) / 2.0 for _, (low, high) in validated_bands
    ]
    if not central_frequencies:
        raise ValueError(
            "Wavelet central frequencies are empty. Check band configuration."
        )
    # Prépare un tableau pour stocker l'énergie par essai, canal et bande
    band_powers: np.ndarray = np.zeros(
        (data.shape[0], data.shape[1], len(validated_bands))
    )
    # Parcourt chaque essai pour éviter des allocations massives inutiles
    for epoch_index, epoch_data in enumerate(data):
        # Parcourt chaque canal pour projeter le signal sur les échelles ciblées
        for channel_index, channel_values in enumerate(epoch_data):
            # Calcule les coefficients CWT sur les échelles demandées
            coefficients = _compute_wavelet_coefficients(
                channel_values,
                central_frequencies,
                sfreq,
                wavelet_cycles,
            )
            if coefficients.size == 1:
                raise ValueError(
                    "Wavelet coefficients computation returned an empty array. "
                    "Verify band configuration."
                )
            # Calcule la puissance moyenne par bande en intégrant la magnitude
            band_energy = np.abs(coefficients) ** 2
            # Moyenne temporelle pour stabiliser l'énergie de chaque bande
            band_powers[epoch_index, channel_index, :] = band_energy.mean(axis=1)
    # Retourne le tenseur énergie pour alignement avec les étiquettes de bandes
    return band_powers


def x__compute_wavelet_band_powers__mutmut_48(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule l'énergie de bandes via une CWT Morlet paramétrable."""

    # Valide le nom de wavelet demandé pour éviter les comportements implicites
    _normalize_wavelet_name(config.get("wavelet", "morlet"))
    if not band_ranges:
        raise ValueError("At least one wavelet band must be provided.")
    # Configure la largeur de la wavelet pour ajuster la résolution temps-fréquence
    wavelet_cycles: float = float(config.get("wavelet_width", 6.0))
    validated_bands: List[Tuple[str, Tuple[float, float]]] = []
    for band_name, (low, high) in band_ranges.items():
        if high <= low:
            raise ValueError(
                f"Wavelet band {band_name!r} must have low < high (got {low}, {high})."
            )
        validated_bands.append((band_name, (float(low), float(high))))
    # Calcule la fréquence centrale de chaque bande pour cibler la wavelet
    central_frequencies: List[float] = [
        (low + high) / 2.0 for _, (low, high) in validated_bands
    ]
    if not central_frequencies:
        raise ValueError(
            "Wavelet central frequencies are empty. Check band configuration."
        )
    # Prépare un tableau pour stocker l'énergie par essai, canal et bande
    band_powers: np.ndarray = np.zeros(
        (data.shape[0], data.shape[1], len(validated_bands))
    )
    # Parcourt chaque essai pour éviter des allocations massives inutiles
    for epoch_index, epoch_data in enumerate(data):
        # Parcourt chaque canal pour projeter le signal sur les échelles ciblées
        for channel_index, channel_values in enumerate(epoch_data):
            # Calcule les coefficients CWT sur les échelles demandées
            coefficients = _compute_wavelet_coefficients(
                channel_values,
                central_frequencies,
                sfreq,
                wavelet_cycles,
            )
            if coefficients.size == 0:
                raise ValueError(
                    "Wavelet coefficients computation returned an empty array. "
                    "Verify band configuration."
                )
            # Calcule la puissance moyenne par bande en intégrant la magnitude
            band_energy = None
            # Moyenne temporelle pour stabiliser l'énergie de chaque bande
            band_powers[epoch_index, channel_index, :] = band_energy.mean(axis=1)
    # Retourne le tenseur énergie pour alignement avec les étiquettes de bandes
    return band_powers


def x__compute_wavelet_band_powers__mutmut_49(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule l'énergie de bandes via une CWT Morlet paramétrable."""

    # Valide le nom de wavelet demandé pour éviter les comportements implicites
    _normalize_wavelet_name(config.get("wavelet", "morlet"))
    if not band_ranges:
        raise ValueError("At least one wavelet band must be provided.")
    # Configure la largeur de la wavelet pour ajuster la résolution temps-fréquence
    wavelet_cycles: float = float(config.get("wavelet_width", 6.0))
    validated_bands: List[Tuple[str, Tuple[float, float]]] = []
    for band_name, (low, high) in band_ranges.items():
        if high <= low:
            raise ValueError(
                f"Wavelet band {band_name!r} must have low < high (got {low}, {high})."
            )
        validated_bands.append((band_name, (float(low), float(high))))
    # Calcule la fréquence centrale de chaque bande pour cibler la wavelet
    central_frequencies: List[float] = [
        (low + high) / 2.0 for _, (low, high) in validated_bands
    ]
    if not central_frequencies:
        raise ValueError(
            "Wavelet central frequencies are empty. Check band configuration."
        )
    # Prépare un tableau pour stocker l'énergie par essai, canal et bande
    band_powers: np.ndarray = np.zeros(
        (data.shape[0], data.shape[1], len(validated_bands))
    )
    # Parcourt chaque essai pour éviter des allocations massives inutiles
    for epoch_index, epoch_data in enumerate(data):
        # Parcourt chaque canal pour projeter le signal sur les échelles ciblées
        for channel_index, channel_values in enumerate(epoch_data):
            # Calcule les coefficients CWT sur les échelles demandées
            coefficients = _compute_wavelet_coefficients(
                channel_values,
                central_frequencies,
                sfreq,
                wavelet_cycles,
            )
            if coefficients.size == 0:
                raise ValueError(
                    "Wavelet coefficients computation returned an empty array. "
                    "Verify band configuration."
                )
            # Calcule la puissance moyenne par bande en intégrant la magnitude
            band_energy = np.abs(coefficients) * 2
            # Moyenne temporelle pour stabiliser l'énergie de chaque bande
            band_powers[epoch_index, channel_index, :] = band_energy.mean(axis=1)
    # Retourne le tenseur énergie pour alignement avec les étiquettes de bandes
    return band_powers


def x__compute_wavelet_band_powers__mutmut_50(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule l'énergie de bandes via une CWT Morlet paramétrable."""

    # Valide le nom de wavelet demandé pour éviter les comportements implicites
    _normalize_wavelet_name(config.get("wavelet", "morlet"))
    if not band_ranges:
        raise ValueError("At least one wavelet band must be provided.")
    # Configure la largeur de la wavelet pour ajuster la résolution temps-fréquence
    wavelet_cycles: float = float(config.get("wavelet_width", 6.0))
    validated_bands: List[Tuple[str, Tuple[float, float]]] = []
    for band_name, (low, high) in band_ranges.items():
        if high <= low:
            raise ValueError(
                f"Wavelet band {band_name!r} must have low < high (got {low}, {high})."
            )
        validated_bands.append((band_name, (float(low), float(high))))
    # Calcule la fréquence centrale de chaque bande pour cibler la wavelet
    central_frequencies: List[float] = [
        (low + high) / 2.0 for _, (low, high) in validated_bands
    ]
    if not central_frequencies:
        raise ValueError(
            "Wavelet central frequencies are empty. Check band configuration."
        )
    # Prépare un tableau pour stocker l'énergie par essai, canal et bande
    band_powers: np.ndarray = np.zeros(
        (data.shape[0], data.shape[1], len(validated_bands))
    )
    # Parcourt chaque essai pour éviter des allocations massives inutiles
    for epoch_index, epoch_data in enumerate(data):
        # Parcourt chaque canal pour projeter le signal sur les échelles ciblées
        for channel_index, channel_values in enumerate(epoch_data):
            # Calcule les coefficients CWT sur les échelles demandées
            coefficients = _compute_wavelet_coefficients(
                channel_values,
                central_frequencies,
                sfreq,
                wavelet_cycles,
            )
            if coefficients.size == 0:
                raise ValueError(
                    "Wavelet coefficients computation returned an empty array. "
                    "Verify band configuration."
                )
            # Calcule la puissance moyenne par bande en intégrant la magnitude
            band_energy = np.abs(None) ** 2
            # Moyenne temporelle pour stabiliser l'énergie de chaque bande
            band_powers[epoch_index, channel_index, :] = band_energy.mean(axis=1)
    # Retourne le tenseur énergie pour alignement avec les étiquettes de bandes
    return band_powers


def x__compute_wavelet_band_powers__mutmut_51(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule l'énergie de bandes via une CWT Morlet paramétrable."""

    # Valide le nom de wavelet demandé pour éviter les comportements implicites
    _normalize_wavelet_name(config.get("wavelet", "morlet"))
    if not band_ranges:
        raise ValueError("At least one wavelet band must be provided.")
    # Configure la largeur de la wavelet pour ajuster la résolution temps-fréquence
    wavelet_cycles: float = float(config.get("wavelet_width", 6.0))
    validated_bands: List[Tuple[str, Tuple[float, float]]] = []
    for band_name, (low, high) in band_ranges.items():
        if high <= low:
            raise ValueError(
                f"Wavelet band {band_name!r} must have low < high (got {low}, {high})."
            )
        validated_bands.append((band_name, (float(low), float(high))))
    # Calcule la fréquence centrale de chaque bande pour cibler la wavelet
    central_frequencies: List[float] = [
        (low + high) / 2.0 for _, (low, high) in validated_bands
    ]
    if not central_frequencies:
        raise ValueError(
            "Wavelet central frequencies are empty. Check band configuration."
        )
    # Prépare un tableau pour stocker l'énergie par essai, canal et bande
    band_powers: np.ndarray = np.zeros(
        (data.shape[0], data.shape[1], len(validated_bands))
    )
    # Parcourt chaque essai pour éviter des allocations massives inutiles
    for epoch_index, epoch_data in enumerate(data):
        # Parcourt chaque canal pour projeter le signal sur les échelles ciblées
        for channel_index, channel_values in enumerate(epoch_data):
            # Calcule les coefficients CWT sur les échelles demandées
            coefficients = _compute_wavelet_coefficients(
                channel_values,
                central_frequencies,
                sfreq,
                wavelet_cycles,
            )
            if coefficients.size == 0:
                raise ValueError(
                    "Wavelet coefficients computation returned an empty array. "
                    "Verify band configuration."
                )
            # Calcule la puissance moyenne par bande en intégrant la magnitude
            band_energy = np.abs(coefficients) ** 3
            # Moyenne temporelle pour stabiliser l'énergie de chaque bande
            band_powers[epoch_index, channel_index, :] = band_energy.mean(axis=1)
    # Retourne le tenseur énergie pour alignement avec les étiquettes de bandes
    return band_powers


def x__compute_wavelet_band_powers__mutmut_52(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule l'énergie de bandes via une CWT Morlet paramétrable."""

    # Valide le nom de wavelet demandé pour éviter les comportements implicites
    _normalize_wavelet_name(config.get("wavelet", "morlet"))
    if not band_ranges:
        raise ValueError("At least one wavelet band must be provided.")
    # Configure la largeur de la wavelet pour ajuster la résolution temps-fréquence
    wavelet_cycles: float = float(config.get("wavelet_width", 6.0))
    validated_bands: List[Tuple[str, Tuple[float, float]]] = []
    for band_name, (low, high) in band_ranges.items():
        if high <= low:
            raise ValueError(
                f"Wavelet band {band_name!r} must have low < high (got {low}, {high})."
            )
        validated_bands.append((band_name, (float(low), float(high))))
    # Calcule la fréquence centrale de chaque bande pour cibler la wavelet
    central_frequencies: List[float] = [
        (low + high) / 2.0 for _, (low, high) in validated_bands
    ]
    if not central_frequencies:
        raise ValueError(
            "Wavelet central frequencies are empty. Check band configuration."
        )
    # Prépare un tableau pour stocker l'énergie par essai, canal et bande
    band_powers: np.ndarray = np.zeros(
        (data.shape[0], data.shape[1], len(validated_bands))
    )
    # Parcourt chaque essai pour éviter des allocations massives inutiles
    for epoch_index, epoch_data in enumerate(data):
        # Parcourt chaque canal pour projeter le signal sur les échelles ciblées
        for channel_index, channel_values in enumerate(epoch_data):
            # Calcule les coefficients CWT sur les échelles demandées
            coefficients = _compute_wavelet_coefficients(
                channel_values,
                central_frequencies,
                sfreq,
                wavelet_cycles,
            )
            if coefficients.size == 0:
                raise ValueError(
                    "Wavelet coefficients computation returned an empty array. "
                    "Verify band configuration."
                )
            # Calcule la puissance moyenne par bande en intégrant la magnitude
            band_energy = np.abs(coefficients) ** 2
            # Moyenne temporelle pour stabiliser l'énergie de chaque bande
            band_powers[epoch_index, channel_index, :] = None
    # Retourne le tenseur énergie pour alignement avec les étiquettes de bandes
    return band_powers


def x__compute_wavelet_band_powers__mutmut_53(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule l'énergie de bandes via une CWT Morlet paramétrable."""

    # Valide le nom de wavelet demandé pour éviter les comportements implicites
    _normalize_wavelet_name(config.get("wavelet", "morlet"))
    if not band_ranges:
        raise ValueError("At least one wavelet band must be provided.")
    # Configure la largeur de la wavelet pour ajuster la résolution temps-fréquence
    wavelet_cycles: float = float(config.get("wavelet_width", 6.0))
    validated_bands: List[Tuple[str, Tuple[float, float]]] = []
    for band_name, (low, high) in band_ranges.items():
        if high <= low:
            raise ValueError(
                f"Wavelet band {band_name!r} must have low < high (got {low}, {high})."
            )
        validated_bands.append((band_name, (float(low), float(high))))
    # Calcule la fréquence centrale de chaque bande pour cibler la wavelet
    central_frequencies: List[float] = [
        (low + high) / 2.0 for _, (low, high) in validated_bands
    ]
    if not central_frequencies:
        raise ValueError(
            "Wavelet central frequencies are empty. Check band configuration."
        )
    # Prépare un tableau pour stocker l'énergie par essai, canal et bande
    band_powers: np.ndarray = np.zeros(
        (data.shape[0], data.shape[1], len(validated_bands))
    )
    # Parcourt chaque essai pour éviter des allocations massives inutiles
    for epoch_index, epoch_data in enumerate(data):
        # Parcourt chaque canal pour projeter le signal sur les échelles ciblées
        for channel_index, channel_values in enumerate(epoch_data):
            # Calcule les coefficients CWT sur les échelles demandées
            coefficients = _compute_wavelet_coefficients(
                channel_values,
                central_frequencies,
                sfreq,
                wavelet_cycles,
            )
            if coefficients.size == 0:
                raise ValueError(
                    "Wavelet coefficients computation returned an empty array. "
                    "Verify band configuration."
                )
            # Calcule la puissance moyenne par bande en intégrant la magnitude
            band_energy = np.abs(coefficients) ** 2
            # Moyenne temporelle pour stabiliser l'énergie de chaque bande
            band_powers[epoch_index, channel_index, :] = band_energy.mean(axis=None)
    # Retourne le tenseur énergie pour alignement avec les étiquettes de bandes
    return band_powers


def x__compute_wavelet_band_powers__mutmut_54(
    data: np.ndarray,
    sfreq: float,
    band_ranges: Mapping[str, Tuple[float, float]],
    config: Mapping[str, Any],
) -> np.ndarray:
    """Calcule l'énergie de bandes via une CWT Morlet paramétrable."""

    # Valide le nom de wavelet demandé pour éviter les comportements implicites
    _normalize_wavelet_name(config.get("wavelet", "morlet"))
    if not band_ranges:
        raise ValueError("At least one wavelet band must be provided.")
    # Configure la largeur de la wavelet pour ajuster la résolution temps-fréquence
    wavelet_cycles: float = float(config.get("wavelet_width", 6.0))
    validated_bands: List[Tuple[str, Tuple[float, float]]] = []
    for band_name, (low, high) in band_ranges.items():
        if high <= low:
            raise ValueError(
                f"Wavelet band {band_name!r} must have low < high (got {low}, {high})."
            )
        validated_bands.append((band_name, (float(low), float(high))))
    # Calcule la fréquence centrale de chaque bande pour cibler la wavelet
    central_frequencies: List[float] = [
        (low + high) / 2.0 for _, (low, high) in validated_bands
    ]
    if not central_frequencies:
        raise ValueError(
            "Wavelet central frequencies are empty. Check band configuration."
        )
    # Prépare un tableau pour stocker l'énergie par essai, canal et bande
    band_powers: np.ndarray = np.zeros(
        (data.shape[0], data.shape[1], len(validated_bands))
    )
    # Parcourt chaque essai pour éviter des allocations massives inutiles
    for epoch_index, epoch_data in enumerate(data):
        # Parcourt chaque canal pour projeter le signal sur les échelles ciblées
        for channel_index, channel_values in enumerate(epoch_data):
            # Calcule les coefficients CWT sur les échelles demandées
            coefficients = _compute_wavelet_coefficients(
                channel_values,
                central_frequencies,
                sfreq,
                wavelet_cycles,
            )
            if coefficients.size == 0:
                raise ValueError(
                    "Wavelet coefficients computation returned an empty array. "
                    "Verify band configuration."
                )
            # Calcule la puissance moyenne par bande en intégrant la magnitude
            band_energy = np.abs(coefficients) ** 2
            # Moyenne temporelle pour stabiliser l'énergie de chaque bande
            band_powers[epoch_index, channel_index, :] = band_energy.mean(axis=2)
    # Retourne le tenseur énergie pour alignement avec les étiquettes de bandes
    return band_powers

x__compute_wavelet_band_powers__mutmut_mutants : ClassVar[MutantDict] = {
'x__compute_wavelet_band_powers__mutmut_1': x__compute_wavelet_band_powers__mutmut_1, 
    'x__compute_wavelet_band_powers__mutmut_2': x__compute_wavelet_band_powers__mutmut_2, 
    'x__compute_wavelet_band_powers__mutmut_3': x__compute_wavelet_band_powers__mutmut_3, 
    'x__compute_wavelet_band_powers__mutmut_4': x__compute_wavelet_band_powers__mutmut_4, 
    'x__compute_wavelet_band_powers__mutmut_5': x__compute_wavelet_band_powers__mutmut_5, 
    'x__compute_wavelet_band_powers__mutmut_6': x__compute_wavelet_band_powers__mutmut_6, 
    'x__compute_wavelet_band_powers__mutmut_7': x__compute_wavelet_band_powers__mutmut_7, 
    'x__compute_wavelet_band_powers__mutmut_8': x__compute_wavelet_band_powers__mutmut_8, 
    'x__compute_wavelet_band_powers__mutmut_9': x__compute_wavelet_band_powers__mutmut_9, 
    'x__compute_wavelet_band_powers__mutmut_10': x__compute_wavelet_band_powers__mutmut_10, 
    'x__compute_wavelet_band_powers__mutmut_11': x__compute_wavelet_band_powers__mutmut_11, 
    'x__compute_wavelet_band_powers__mutmut_12': x__compute_wavelet_band_powers__mutmut_12, 
    'x__compute_wavelet_band_powers__mutmut_13': x__compute_wavelet_band_powers__mutmut_13, 
    'x__compute_wavelet_band_powers__mutmut_14': x__compute_wavelet_band_powers__mutmut_14, 
    'x__compute_wavelet_band_powers__mutmut_15': x__compute_wavelet_band_powers__mutmut_15, 
    'x__compute_wavelet_band_powers__mutmut_16': x__compute_wavelet_band_powers__mutmut_16, 
    'x__compute_wavelet_band_powers__mutmut_17': x__compute_wavelet_band_powers__mutmut_17, 
    'x__compute_wavelet_band_powers__mutmut_18': x__compute_wavelet_band_powers__mutmut_18, 
    'x__compute_wavelet_band_powers__mutmut_19': x__compute_wavelet_band_powers__mutmut_19, 
    'x__compute_wavelet_band_powers__mutmut_20': x__compute_wavelet_band_powers__mutmut_20, 
    'x__compute_wavelet_band_powers__mutmut_21': x__compute_wavelet_band_powers__mutmut_21, 
    'x__compute_wavelet_band_powers__mutmut_22': x__compute_wavelet_band_powers__mutmut_22, 
    'x__compute_wavelet_band_powers__mutmut_23': x__compute_wavelet_band_powers__mutmut_23, 
    'x__compute_wavelet_band_powers__mutmut_24': x__compute_wavelet_band_powers__mutmut_24, 
    'x__compute_wavelet_band_powers__mutmut_25': x__compute_wavelet_band_powers__mutmut_25, 
    'x__compute_wavelet_band_powers__mutmut_26': x__compute_wavelet_band_powers__mutmut_26, 
    'x__compute_wavelet_band_powers__mutmut_27': x__compute_wavelet_band_powers__mutmut_27, 
    'x__compute_wavelet_band_powers__mutmut_28': x__compute_wavelet_band_powers__mutmut_28, 
    'x__compute_wavelet_band_powers__mutmut_29': x__compute_wavelet_band_powers__mutmut_29, 
    'x__compute_wavelet_band_powers__mutmut_30': x__compute_wavelet_band_powers__mutmut_30, 
    'x__compute_wavelet_band_powers__mutmut_31': x__compute_wavelet_band_powers__mutmut_31, 
    'x__compute_wavelet_band_powers__mutmut_32': x__compute_wavelet_band_powers__mutmut_32, 
    'x__compute_wavelet_band_powers__mutmut_33': x__compute_wavelet_band_powers__mutmut_33, 
    'x__compute_wavelet_band_powers__mutmut_34': x__compute_wavelet_band_powers__mutmut_34, 
    'x__compute_wavelet_band_powers__mutmut_35': x__compute_wavelet_band_powers__mutmut_35, 
    'x__compute_wavelet_band_powers__mutmut_36': x__compute_wavelet_band_powers__mutmut_36, 
    'x__compute_wavelet_band_powers__mutmut_37': x__compute_wavelet_band_powers__mutmut_37, 
    'x__compute_wavelet_band_powers__mutmut_38': x__compute_wavelet_band_powers__mutmut_38, 
    'x__compute_wavelet_band_powers__mutmut_39': x__compute_wavelet_band_powers__mutmut_39, 
    'x__compute_wavelet_band_powers__mutmut_40': x__compute_wavelet_band_powers__mutmut_40, 
    'x__compute_wavelet_band_powers__mutmut_41': x__compute_wavelet_band_powers__mutmut_41, 
    'x__compute_wavelet_band_powers__mutmut_42': x__compute_wavelet_band_powers__mutmut_42, 
    'x__compute_wavelet_band_powers__mutmut_43': x__compute_wavelet_band_powers__mutmut_43, 
    'x__compute_wavelet_band_powers__mutmut_44': x__compute_wavelet_band_powers__mutmut_44, 
    'x__compute_wavelet_band_powers__mutmut_45': x__compute_wavelet_band_powers__mutmut_45, 
    'x__compute_wavelet_band_powers__mutmut_46': x__compute_wavelet_band_powers__mutmut_46, 
    'x__compute_wavelet_band_powers__mutmut_47': x__compute_wavelet_band_powers__mutmut_47, 
    'x__compute_wavelet_band_powers__mutmut_48': x__compute_wavelet_band_powers__mutmut_48, 
    'x__compute_wavelet_band_powers__mutmut_49': x__compute_wavelet_band_powers__mutmut_49, 
    'x__compute_wavelet_band_powers__mutmut_50': x__compute_wavelet_band_powers__mutmut_50, 
    'x__compute_wavelet_band_powers__mutmut_51': x__compute_wavelet_band_powers__mutmut_51, 
    'x__compute_wavelet_band_powers__mutmut_52': x__compute_wavelet_band_powers__mutmut_52, 
    'x__compute_wavelet_band_powers__mutmut_53': x__compute_wavelet_band_powers__mutmut_53, 
    'x__compute_wavelet_band_powers__mutmut_54': x__compute_wavelet_band_powers__mutmut_54
}

def _compute_wavelet_band_powers(*args, **kwargs):
    result = _mutmut_trampoline(x__compute_wavelet_band_powers__mutmut_orig, x__compute_wavelet_band_powers__mutmut_mutants, args, kwargs)
    return result 

_compute_wavelet_band_powers.__signature__ = _mutmut_signature(x__compute_wavelet_band_powers__mutmut_orig)
x__compute_wavelet_band_powers__mutmut_orig.__name__ = 'x__compute_wavelet_band_powers'


def x__build_labels__mutmut_orig(
    stacked: np.ndarray,
    band_ranges: Mapping[str, Tuple[float, float]],
    channel_names: Sequence[str],
) -> List[str]:
    """Construit des étiquettes canal_bande pour interpréter les features."""

    # Prépare les étiquettes par canal et bande pour interpréter les colonnes
    labels: List[str] = []
    # Parcourt les canaux pour associer les bandes à chaque série temporelle
    for channel_index in range(stacked.shape[1]):
        # Sélectionne un nom explicite ou construit un identifiant générique
        channel_label = (
            channel_names[channel_index] if channel_names else f"ch{channel_index}"
        )
        # Ajoute une étiquette pour chaque bande afin de suivre l'ordre des colonnes
        for band_name in band_ranges.keys():
            # Concatène le canal et la bande pour un suivi lisible
            labels.append(f"{channel_label}_{band_name}")
    # Retourne la liste d'étiquettes alignée sur la matrice aplatie
    return labels


def x__build_labels__mutmut_1(
    stacked: np.ndarray,
    band_ranges: Mapping[str, Tuple[float, float]],
    channel_names: Sequence[str],
) -> List[str]:
    """Construit des étiquettes canal_bande pour interpréter les features."""

    # Prépare les étiquettes par canal et bande pour interpréter les colonnes
    labels: List[str] = None
    # Parcourt les canaux pour associer les bandes à chaque série temporelle
    for channel_index in range(stacked.shape[1]):
        # Sélectionne un nom explicite ou construit un identifiant générique
        channel_label = (
            channel_names[channel_index] if channel_names else f"ch{channel_index}"
        )
        # Ajoute une étiquette pour chaque bande afin de suivre l'ordre des colonnes
        for band_name in band_ranges.keys():
            # Concatène le canal et la bande pour un suivi lisible
            labels.append(f"{channel_label}_{band_name}")
    # Retourne la liste d'étiquettes alignée sur la matrice aplatie
    return labels


def x__build_labels__mutmut_2(
    stacked: np.ndarray,
    band_ranges: Mapping[str, Tuple[float, float]],
    channel_names: Sequence[str],
) -> List[str]:
    """Construit des étiquettes canal_bande pour interpréter les features."""

    # Prépare les étiquettes par canal et bande pour interpréter les colonnes
    labels: List[str] = []
    # Parcourt les canaux pour associer les bandes à chaque série temporelle
    for channel_index in range(None):
        # Sélectionne un nom explicite ou construit un identifiant générique
        channel_label = (
            channel_names[channel_index] if channel_names else f"ch{channel_index}"
        )
        # Ajoute une étiquette pour chaque bande afin de suivre l'ordre des colonnes
        for band_name in band_ranges.keys():
            # Concatène le canal et la bande pour un suivi lisible
            labels.append(f"{channel_label}_{band_name}")
    # Retourne la liste d'étiquettes alignée sur la matrice aplatie
    return labels


def x__build_labels__mutmut_3(
    stacked: np.ndarray,
    band_ranges: Mapping[str, Tuple[float, float]],
    channel_names: Sequence[str],
) -> List[str]:
    """Construit des étiquettes canal_bande pour interpréter les features."""

    # Prépare les étiquettes par canal et bande pour interpréter les colonnes
    labels: List[str] = []
    # Parcourt les canaux pour associer les bandes à chaque série temporelle
    for channel_index in range(stacked.shape[2]):
        # Sélectionne un nom explicite ou construit un identifiant générique
        channel_label = (
            channel_names[channel_index] if channel_names else f"ch{channel_index}"
        )
        # Ajoute une étiquette pour chaque bande afin de suivre l'ordre des colonnes
        for band_name in band_ranges.keys():
            # Concatène le canal et la bande pour un suivi lisible
            labels.append(f"{channel_label}_{band_name}")
    # Retourne la liste d'étiquettes alignée sur la matrice aplatie
    return labels


def x__build_labels__mutmut_4(
    stacked: np.ndarray,
    band_ranges: Mapping[str, Tuple[float, float]],
    channel_names: Sequence[str],
) -> List[str]:
    """Construit des étiquettes canal_bande pour interpréter les features."""

    # Prépare les étiquettes par canal et bande pour interpréter les colonnes
    labels: List[str] = []
    # Parcourt les canaux pour associer les bandes à chaque série temporelle
    for channel_index in range(stacked.shape[1]):
        # Sélectionne un nom explicite ou construit un identifiant générique
        channel_label = None
        # Ajoute une étiquette pour chaque bande afin de suivre l'ordre des colonnes
        for band_name in band_ranges.keys():
            # Concatène le canal et la bande pour un suivi lisible
            labels.append(f"{channel_label}_{band_name}")
    # Retourne la liste d'étiquettes alignée sur la matrice aplatie
    return labels


def x__build_labels__mutmut_5(
    stacked: np.ndarray,
    band_ranges: Mapping[str, Tuple[float, float]],
    channel_names: Sequence[str],
) -> List[str]:
    """Construit des étiquettes canal_bande pour interpréter les features."""

    # Prépare les étiquettes par canal et bande pour interpréter les colonnes
    labels: List[str] = []
    # Parcourt les canaux pour associer les bandes à chaque série temporelle
    for channel_index in range(stacked.shape[1]):
        # Sélectionne un nom explicite ou construit un identifiant générique
        channel_label = (
            channel_names[channel_index] if channel_names else f"ch{channel_index}"
        )
        # Ajoute une étiquette pour chaque bande afin de suivre l'ordre des colonnes
        for band_name in band_ranges.keys():
            # Concatène le canal et la bande pour un suivi lisible
            labels.append(None)
    # Retourne la liste d'étiquettes alignée sur la matrice aplatie
    return labels

x__build_labels__mutmut_mutants : ClassVar[MutantDict] = {
'x__build_labels__mutmut_1': x__build_labels__mutmut_1, 
    'x__build_labels__mutmut_2': x__build_labels__mutmut_2, 
    'x__build_labels__mutmut_3': x__build_labels__mutmut_3, 
    'x__build_labels__mutmut_4': x__build_labels__mutmut_4, 
    'x__build_labels__mutmut_5': x__build_labels__mutmut_5
}

def _build_labels(*args, **kwargs):
    result = _mutmut_trampoline(x__build_labels__mutmut_orig, x__build_labels__mutmut_mutants, args, kwargs)
    return result 

_build_labels.__signature__ = _mutmut_signature(x__build_labels__mutmut_orig)
x__build_labels__mutmut_orig.__name__ = 'x__build_labels'


class ExtractFeatures(BaseEstimator, TransformerMixin):
    """Extract band power features from EEG recordings."""

    BAND_RANGES = {
        "theta": (4.0, 7.0),
        "alpha": (8.0, 12.0),
        "beta": (13.0, 30.0),
        "gamma": (31.0, 45.0),
    }

    EXPECTED_EEG_NDIM = 3
    NORMALIZATION_EPS = 1e-12

    def xǁExtractFeaturesǁ__init____mutmut_orig(
        self,
        sfreq: float,
        feature_strategy: str | Sequence[str] = "fft",
        normalize: bool = True,
        bands: Mapping[str, Tuple[float, float]] | None = None,
        strategy_config: Mapping[str, Any] | None = None,
    ):
        # Stocke la fréquence d'échantillonnage comme float pour la FFT
        self.sfreq = float(sfreq)
        # Sélectionne la stratégie d'extraction ("fft" ou "wavelet")
        self.feature_strategy = feature_strategy
        # Active ou non la normalisation des features
        self.normalize = normalize
        # Expose les bandes pour compatibilité scikit-learn (get_params)
        self.bands = bands
        # Stocke les bandes utilisées pour la construction des features
        ordered_band_items: List[Tuple[str, Tuple[float, float]]] = list(
            (bands or self.BAND_RANGES).items()
        )
        self._band_items: List[Tuple[str, Tuple[float, float]]] = ordered_band_items
        self.band_ranges: Dict[str, Tuple[float, float]] = dict(ordered_band_items)
        # Stocke la configuration spécifique à la stratégie (Welch, wavelet, etc.)
        self.strategy_config = strategy_config
        self._effective_strategy_config: Dict[str, Any] = dict(strategy_config or {})

    def xǁExtractFeaturesǁ__init____mutmut_1(
        self,
        sfreq: float,
        feature_strategy: str | Sequence[str] = "XXfftXX",
        normalize: bool = True,
        bands: Mapping[str, Tuple[float, float]] | None = None,
        strategy_config: Mapping[str, Any] | None = None,
    ):
        # Stocke la fréquence d'échantillonnage comme float pour la FFT
        self.sfreq = float(sfreq)
        # Sélectionne la stratégie d'extraction ("fft" ou "wavelet")
        self.feature_strategy = feature_strategy
        # Active ou non la normalisation des features
        self.normalize = normalize
        # Expose les bandes pour compatibilité scikit-learn (get_params)
        self.bands = bands
        # Stocke les bandes utilisées pour la construction des features
        ordered_band_items: List[Tuple[str, Tuple[float, float]]] = list(
            (bands or self.BAND_RANGES).items()
        )
        self._band_items: List[Tuple[str, Tuple[float, float]]] = ordered_band_items
        self.band_ranges: Dict[str, Tuple[float, float]] = dict(ordered_band_items)
        # Stocke la configuration spécifique à la stratégie (Welch, wavelet, etc.)
        self.strategy_config = strategy_config
        self._effective_strategy_config: Dict[str, Any] = dict(strategy_config or {})

    def xǁExtractFeaturesǁ__init____mutmut_2(
        self,
        sfreq: float,
        feature_strategy: str | Sequence[str] = "FFT",
        normalize: bool = True,
        bands: Mapping[str, Tuple[float, float]] | None = None,
        strategy_config: Mapping[str, Any] | None = None,
    ):
        # Stocke la fréquence d'échantillonnage comme float pour la FFT
        self.sfreq = float(sfreq)
        # Sélectionne la stratégie d'extraction ("fft" ou "wavelet")
        self.feature_strategy = feature_strategy
        # Active ou non la normalisation des features
        self.normalize = normalize
        # Expose les bandes pour compatibilité scikit-learn (get_params)
        self.bands = bands
        # Stocke les bandes utilisées pour la construction des features
        ordered_band_items: List[Tuple[str, Tuple[float, float]]] = list(
            (bands or self.BAND_RANGES).items()
        )
        self._band_items: List[Tuple[str, Tuple[float, float]]] = ordered_band_items
        self.band_ranges: Dict[str, Tuple[float, float]] = dict(ordered_band_items)
        # Stocke la configuration spécifique à la stratégie (Welch, wavelet, etc.)
        self.strategy_config = strategy_config
        self._effective_strategy_config: Dict[str, Any] = dict(strategy_config or {})

    def xǁExtractFeaturesǁ__init____mutmut_3(
        self,
        sfreq: float,
        feature_strategy: str | Sequence[str] = "fft",
        normalize: bool = False,
        bands: Mapping[str, Tuple[float, float]] | None = None,
        strategy_config: Mapping[str, Any] | None = None,
    ):
        # Stocke la fréquence d'échantillonnage comme float pour la FFT
        self.sfreq = float(sfreq)
        # Sélectionne la stratégie d'extraction ("fft" ou "wavelet")
        self.feature_strategy = feature_strategy
        # Active ou non la normalisation des features
        self.normalize = normalize
        # Expose les bandes pour compatibilité scikit-learn (get_params)
        self.bands = bands
        # Stocke les bandes utilisées pour la construction des features
        ordered_band_items: List[Tuple[str, Tuple[float, float]]] = list(
            (bands or self.BAND_RANGES).items()
        )
        self._band_items: List[Tuple[str, Tuple[float, float]]] = ordered_band_items
        self.band_ranges: Dict[str, Tuple[float, float]] = dict(ordered_band_items)
        # Stocke la configuration spécifique à la stratégie (Welch, wavelet, etc.)
        self.strategy_config = strategy_config
        self._effective_strategy_config: Dict[str, Any] = dict(strategy_config or {})

    def xǁExtractFeaturesǁ__init____mutmut_4(
        self,
        sfreq: float,
        feature_strategy: str | Sequence[str] = "fft",
        normalize: bool = True,
        bands: Mapping[str, Tuple[float, float]] | None = None,
        strategy_config: Mapping[str, Any] | None = None,
    ):
        # Stocke la fréquence d'échantillonnage comme float pour la FFT
        self.sfreq = None
        # Sélectionne la stratégie d'extraction ("fft" ou "wavelet")
        self.feature_strategy = feature_strategy
        # Active ou non la normalisation des features
        self.normalize = normalize
        # Expose les bandes pour compatibilité scikit-learn (get_params)
        self.bands = bands
        # Stocke les bandes utilisées pour la construction des features
        ordered_band_items: List[Tuple[str, Tuple[float, float]]] = list(
            (bands or self.BAND_RANGES).items()
        )
        self._band_items: List[Tuple[str, Tuple[float, float]]] = ordered_band_items
        self.band_ranges: Dict[str, Tuple[float, float]] = dict(ordered_band_items)
        # Stocke la configuration spécifique à la stratégie (Welch, wavelet, etc.)
        self.strategy_config = strategy_config
        self._effective_strategy_config: Dict[str, Any] = dict(strategy_config or {})

    def xǁExtractFeaturesǁ__init____mutmut_5(
        self,
        sfreq: float,
        feature_strategy: str | Sequence[str] = "fft",
        normalize: bool = True,
        bands: Mapping[str, Tuple[float, float]] | None = None,
        strategy_config: Mapping[str, Any] | None = None,
    ):
        # Stocke la fréquence d'échantillonnage comme float pour la FFT
        self.sfreq = float(None)
        # Sélectionne la stratégie d'extraction ("fft" ou "wavelet")
        self.feature_strategy = feature_strategy
        # Active ou non la normalisation des features
        self.normalize = normalize
        # Expose les bandes pour compatibilité scikit-learn (get_params)
        self.bands = bands
        # Stocke les bandes utilisées pour la construction des features
        ordered_band_items: List[Tuple[str, Tuple[float, float]]] = list(
            (bands or self.BAND_RANGES).items()
        )
        self._band_items: List[Tuple[str, Tuple[float, float]]] = ordered_band_items
        self.band_ranges: Dict[str, Tuple[float, float]] = dict(ordered_band_items)
        # Stocke la configuration spécifique à la stratégie (Welch, wavelet, etc.)
        self.strategy_config = strategy_config
        self._effective_strategy_config: Dict[str, Any] = dict(strategy_config or {})

    def xǁExtractFeaturesǁ__init____mutmut_6(
        self,
        sfreq: float,
        feature_strategy: str | Sequence[str] = "fft",
        normalize: bool = True,
        bands: Mapping[str, Tuple[float, float]] | None = None,
        strategy_config: Mapping[str, Any] | None = None,
    ):
        # Stocke la fréquence d'échantillonnage comme float pour la FFT
        self.sfreq = float(sfreq)
        # Sélectionne la stratégie d'extraction ("fft" ou "wavelet")
        self.feature_strategy = None
        # Active ou non la normalisation des features
        self.normalize = normalize
        # Expose les bandes pour compatibilité scikit-learn (get_params)
        self.bands = bands
        # Stocke les bandes utilisées pour la construction des features
        ordered_band_items: List[Tuple[str, Tuple[float, float]]] = list(
            (bands or self.BAND_RANGES).items()
        )
        self._band_items: List[Tuple[str, Tuple[float, float]]] = ordered_band_items
        self.band_ranges: Dict[str, Tuple[float, float]] = dict(ordered_band_items)
        # Stocke la configuration spécifique à la stratégie (Welch, wavelet, etc.)
        self.strategy_config = strategy_config
        self._effective_strategy_config: Dict[str, Any] = dict(strategy_config or {})

    def xǁExtractFeaturesǁ__init____mutmut_7(
        self,
        sfreq: float,
        feature_strategy: str | Sequence[str] = "fft",
        normalize: bool = True,
        bands: Mapping[str, Tuple[float, float]] | None = None,
        strategy_config: Mapping[str, Any] | None = None,
    ):
        # Stocke la fréquence d'échantillonnage comme float pour la FFT
        self.sfreq = float(sfreq)
        # Sélectionne la stratégie d'extraction ("fft" ou "wavelet")
        self.feature_strategy = feature_strategy
        # Active ou non la normalisation des features
        self.normalize = None
        # Expose les bandes pour compatibilité scikit-learn (get_params)
        self.bands = bands
        # Stocke les bandes utilisées pour la construction des features
        ordered_band_items: List[Tuple[str, Tuple[float, float]]] = list(
            (bands or self.BAND_RANGES).items()
        )
        self._band_items: List[Tuple[str, Tuple[float, float]]] = ordered_band_items
        self.band_ranges: Dict[str, Tuple[float, float]] = dict(ordered_band_items)
        # Stocke la configuration spécifique à la stratégie (Welch, wavelet, etc.)
        self.strategy_config = strategy_config
        self._effective_strategy_config: Dict[str, Any] = dict(strategy_config or {})

    def xǁExtractFeaturesǁ__init____mutmut_8(
        self,
        sfreq: float,
        feature_strategy: str | Sequence[str] = "fft",
        normalize: bool = True,
        bands: Mapping[str, Tuple[float, float]] | None = None,
        strategy_config: Mapping[str, Any] | None = None,
    ):
        # Stocke la fréquence d'échantillonnage comme float pour la FFT
        self.sfreq = float(sfreq)
        # Sélectionne la stratégie d'extraction ("fft" ou "wavelet")
        self.feature_strategy = feature_strategy
        # Active ou non la normalisation des features
        self.normalize = normalize
        # Expose les bandes pour compatibilité scikit-learn (get_params)
        self.bands = None
        # Stocke les bandes utilisées pour la construction des features
        ordered_band_items: List[Tuple[str, Tuple[float, float]]] = list(
            (bands or self.BAND_RANGES).items()
        )
        self._band_items: List[Tuple[str, Tuple[float, float]]] = ordered_band_items
        self.band_ranges: Dict[str, Tuple[float, float]] = dict(ordered_band_items)
        # Stocke la configuration spécifique à la stratégie (Welch, wavelet, etc.)
        self.strategy_config = strategy_config
        self._effective_strategy_config: Dict[str, Any] = dict(strategy_config or {})

    def xǁExtractFeaturesǁ__init____mutmut_9(
        self,
        sfreq: float,
        feature_strategy: str | Sequence[str] = "fft",
        normalize: bool = True,
        bands: Mapping[str, Tuple[float, float]] | None = None,
        strategy_config: Mapping[str, Any] | None = None,
    ):
        # Stocke la fréquence d'échantillonnage comme float pour la FFT
        self.sfreq = float(sfreq)
        # Sélectionne la stratégie d'extraction ("fft" ou "wavelet")
        self.feature_strategy = feature_strategy
        # Active ou non la normalisation des features
        self.normalize = normalize
        # Expose les bandes pour compatibilité scikit-learn (get_params)
        self.bands = bands
        # Stocke les bandes utilisées pour la construction des features
        ordered_band_items: List[Tuple[str, Tuple[float, float]]] = None
        self._band_items: List[Tuple[str, Tuple[float, float]]] = ordered_band_items
        self.band_ranges: Dict[str, Tuple[float, float]] = dict(ordered_band_items)
        # Stocke la configuration spécifique à la stratégie (Welch, wavelet, etc.)
        self.strategy_config = strategy_config
        self._effective_strategy_config: Dict[str, Any] = dict(strategy_config or {})

    def xǁExtractFeaturesǁ__init____mutmut_10(
        self,
        sfreq: float,
        feature_strategy: str | Sequence[str] = "fft",
        normalize: bool = True,
        bands: Mapping[str, Tuple[float, float]] | None = None,
        strategy_config: Mapping[str, Any] | None = None,
    ):
        # Stocke la fréquence d'échantillonnage comme float pour la FFT
        self.sfreq = float(sfreq)
        # Sélectionne la stratégie d'extraction ("fft" ou "wavelet")
        self.feature_strategy = feature_strategy
        # Active ou non la normalisation des features
        self.normalize = normalize
        # Expose les bandes pour compatibilité scikit-learn (get_params)
        self.bands = bands
        # Stocke les bandes utilisées pour la construction des features
        ordered_band_items: List[Tuple[str, Tuple[float, float]]] = list(
            None
        )
        self._band_items: List[Tuple[str, Tuple[float, float]]] = ordered_band_items
        self.band_ranges: Dict[str, Tuple[float, float]] = dict(ordered_band_items)
        # Stocke la configuration spécifique à la stratégie (Welch, wavelet, etc.)
        self.strategy_config = strategy_config
        self._effective_strategy_config: Dict[str, Any] = dict(strategy_config or {})

    def xǁExtractFeaturesǁ__init____mutmut_11(
        self,
        sfreq: float,
        feature_strategy: str | Sequence[str] = "fft",
        normalize: bool = True,
        bands: Mapping[str, Tuple[float, float]] | None = None,
        strategy_config: Mapping[str, Any] | None = None,
    ):
        # Stocke la fréquence d'échantillonnage comme float pour la FFT
        self.sfreq = float(sfreq)
        # Sélectionne la stratégie d'extraction ("fft" ou "wavelet")
        self.feature_strategy = feature_strategy
        # Active ou non la normalisation des features
        self.normalize = normalize
        # Expose les bandes pour compatibilité scikit-learn (get_params)
        self.bands = bands
        # Stocke les bandes utilisées pour la construction des features
        ordered_band_items: List[Tuple[str, Tuple[float, float]]] = list(
            (bands and self.BAND_RANGES).items()
        )
        self._band_items: List[Tuple[str, Tuple[float, float]]] = ordered_band_items
        self.band_ranges: Dict[str, Tuple[float, float]] = dict(ordered_band_items)
        # Stocke la configuration spécifique à la stratégie (Welch, wavelet, etc.)
        self.strategy_config = strategy_config
        self._effective_strategy_config: Dict[str, Any] = dict(strategy_config or {})

    def xǁExtractFeaturesǁ__init____mutmut_12(
        self,
        sfreq: float,
        feature_strategy: str | Sequence[str] = "fft",
        normalize: bool = True,
        bands: Mapping[str, Tuple[float, float]] | None = None,
        strategy_config: Mapping[str, Any] | None = None,
    ):
        # Stocke la fréquence d'échantillonnage comme float pour la FFT
        self.sfreq = float(sfreq)
        # Sélectionne la stratégie d'extraction ("fft" ou "wavelet")
        self.feature_strategy = feature_strategy
        # Active ou non la normalisation des features
        self.normalize = normalize
        # Expose les bandes pour compatibilité scikit-learn (get_params)
        self.bands = bands
        # Stocke les bandes utilisées pour la construction des features
        ordered_band_items: List[Tuple[str, Tuple[float, float]]] = list(
            (bands or self.BAND_RANGES).items()
        )
        self._band_items: List[Tuple[str, Tuple[float, float]]] = None
        self.band_ranges: Dict[str, Tuple[float, float]] = dict(ordered_band_items)
        # Stocke la configuration spécifique à la stratégie (Welch, wavelet, etc.)
        self.strategy_config = strategy_config
        self._effective_strategy_config: Dict[str, Any] = dict(strategy_config or {})

    def xǁExtractFeaturesǁ__init____mutmut_13(
        self,
        sfreq: float,
        feature_strategy: str | Sequence[str] = "fft",
        normalize: bool = True,
        bands: Mapping[str, Tuple[float, float]] | None = None,
        strategy_config: Mapping[str, Any] | None = None,
    ):
        # Stocke la fréquence d'échantillonnage comme float pour la FFT
        self.sfreq = float(sfreq)
        # Sélectionne la stratégie d'extraction ("fft" ou "wavelet")
        self.feature_strategy = feature_strategy
        # Active ou non la normalisation des features
        self.normalize = normalize
        # Expose les bandes pour compatibilité scikit-learn (get_params)
        self.bands = bands
        # Stocke les bandes utilisées pour la construction des features
        ordered_band_items: List[Tuple[str, Tuple[float, float]]] = list(
            (bands or self.BAND_RANGES).items()
        )
        self._band_items: List[Tuple[str, Tuple[float, float]]] = ordered_band_items
        self.band_ranges: Dict[str, Tuple[float, float]] = None
        # Stocke la configuration spécifique à la stratégie (Welch, wavelet, etc.)
        self.strategy_config = strategy_config
        self._effective_strategy_config: Dict[str, Any] = dict(strategy_config or {})

    def xǁExtractFeaturesǁ__init____mutmut_14(
        self,
        sfreq: float,
        feature_strategy: str | Sequence[str] = "fft",
        normalize: bool = True,
        bands: Mapping[str, Tuple[float, float]] | None = None,
        strategy_config: Mapping[str, Any] | None = None,
    ):
        # Stocke la fréquence d'échantillonnage comme float pour la FFT
        self.sfreq = float(sfreq)
        # Sélectionne la stratégie d'extraction ("fft" ou "wavelet")
        self.feature_strategy = feature_strategy
        # Active ou non la normalisation des features
        self.normalize = normalize
        # Expose les bandes pour compatibilité scikit-learn (get_params)
        self.bands = bands
        # Stocke les bandes utilisées pour la construction des features
        ordered_band_items: List[Tuple[str, Tuple[float, float]]] = list(
            (bands or self.BAND_RANGES).items()
        )
        self._band_items: List[Tuple[str, Tuple[float, float]]] = ordered_band_items
        self.band_ranges: Dict[str, Tuple[float, float]] = dict(None)
        # Stocke la configuration spécifique à la stratégie (Welch, wavelet, etc.)
        self.strategy_config = strategy_config
        self._effective_strategy_config: Dict[str, Any] = dict(strategy_config or {})

    def xǁExtractFeaturesǁ__init____mutmut_15(
        self,
        sfreq: float,
        feature_strategy: str | Sequence[str] = "fft",
        normalize: bool = True,
        bands: Mapping[str, Tuple[float, float]] | None = None,
        strategy_config: Mapping[str, Any] | None = None,
    ):
        # Stocke la fréquence d'échantillonnage comme float pour la FFT
        self.sfreq = float(sfreq)
        # Sélectionne la stratégie d'extraction ("fft" ou "wavelet")
        self.feature_strategy = feature_strategy
        # Active ou non la normalisation des features
        self.normalize = normalize
        # Expose les bandes pour compatibilité scikit-learn (get_params)
        self.bands = bands
        # Stocke les bandes utilisées pour la construction des features
        ordered_band_items: List[Tuple[str, Tuple[float, float]]] = list(
            (bands or self.BAND_RANGES).items()
        )
        self._band_items: List[Tuple[str, Tuple[float, float]]] = ordered_band_items
        self.band_ranges: Dict[str, Tuple[float, float]] = dict(ordered_band_items)
        # Stocke la configuration spécifique à la stratégie (Welch, wavelet, etc.)
        self.strategy_config = None
        self._effective_strategy_config: Dict[str, Any] = dict(strategy_config or {})

    def xǁExtractFeaturesǁ__init____mutmut_16(
        self,
        sfreq: float,
        feature_strategy: str | Sequence[str] = "fft",
        normalize: bool = True,
        bands: Mapping[str, Tuple[float, float]] | None = None,
        strategy_config: Mapping[str, Any] | None = None,
    ):
        # Stocke la fréquence d'échantillonnage comme float pour la FFT
        self.sfreq = float(sfreq)
        # Sélectionne la stratégie d'extraction ("fft" ou "wavelet")
        self.feature_strategy = feature_strategy
        # Active ou non la normalisation des features
        self.normalize = normalize
        # Expose les bandes pour compatibilité scikit-learn (get_params)
        self.bands = bands
        # Stocke les bandes utilisées pour la construction des features
        ordered_band_items: List[Tuple[str, Tuple[float, float]]] = list(
            (bands or self.BAND_RANGES).items()
        )
        self._band_items: List[Tuple[str, Tuple[float, float]]] = ordered_band_items
        self.band_ranges: Dict[str, Tuple[float, float]] = dict(ordered_band_items)
        # Stocke la configuration spécifique à la stratégie (Welch, wavelet, etc.)
        self.strategy_config = strategy_config
        self._effective_strategy_config: Dict[str, Any] = None

    def xǁExtractFeaturesǁ__init____mutmut_17(
        self,
        sfreq: float,
        feature_strategy: str | Sequence[str] = "fft",
        normalize: bool = True,
        bands: Mapping[str, Tuple[float, float]] | None = None,
        strategy_config: Mapping[str, Any] | None = None,
    ):
        # Stocke la fréquence d'échantillonnage comme float pour la FFT
        self.sfreq = float(sfreq)
        # Sélectionne la stratégie d'extraction ("fft" ou "wavelet")
        self.feature_strategy = feature_strategy
        # Active ou non la normalisation des features
        self.normalize = normalize
        # Expose les bandes pour compatibilité scikit-learn (get_params)
        self.bands = bands
        # Stocke les bandes utilisées pour la construction des features
        ordered_band_items: List[Tuple[str, Tuple[float, float]]] = list(
            (bands or self.BAND_RANGES).items()
        )
        self._band_items: List[Tuple[str, Tuple[float, float]]] = ordered_band_items
        self.band_ranges: Dict[str, Tuple[float, float]] = dict(ordered_band_items)
        # Stocke la configuration spécifique à la stratégie (Welch, wavelet, etc.)
        self.strategy_config = strategy_config
        self._effective_strategy_config: Dict[str, Any] = dict(None)

    def xǁExtractFeaturesǁ__init____mutmut_18(
        self,
        sfreq: float,
        feature_strategy: str | Sequence[str] = "fft",
        normalize: bool = True,
        bands: Mapping[str, Tuple[float, float]] | None = None,
        strategy_config: Mapping[str, Any] | None = None,
    ):
        # Stocke la fréquence d'échantillonnage comme float pour la FFT
        self.sfreq = float(sfreq)
        # Sélectionne la stratégie d'extraction ("fft" ou "wavelet")
        self.feature_strategy = feature_strategy
        # Active ou non la normalisation des features
        self.normalize = normalize
        # Expose les bandes pour compatibilité scikit-learn (get_params)
        self.bands = bands
        # Stocke les bandes utilisées pour la construction des features
        ordered_band_items: List[Tuple[str, Tuple[float, float]]] = list(
            (bands or self.BAND_RANGES).items()
        )
        self._band_items: List[Tuple[str, Tuple[float, float]]] = ordered_band_items
        self.band_ranges: Dict[str, Tuple[float, float]] = dict(ordered_band_items)
        # Stocke la configuration spécifique à la stratégie (Welch, wavelet, etc.)
        self.strategy_config = strategy_config
        self._effective_strategy_config: Dict[str, Any] = dict(strategy_config and {})
    
    xǁExtractFeaturesǁ__init____mutmut_mutants : ClassVar[MutantDict] = {
    'xǁExtractFeaturesǁ__init____mutmut_1': xǁExtractFeaturesǁ__init____mutmut_1, 
        'xǁExtractFeaturesǁ__init____mutmut_2': xǁExtractFeaturesǁ__init____mutmut_2, 
        'xǁExtractFeaturesǁ__init____mutmut_3': xǁExtractFeaturesǁ__init____mutmut_3, 
        'xǁExtractFeaturesǁ__init____mutmut_4': xǁExtractFeaturesǁ__init____mutmut_4, 
        'xǁExtractFeaturesǁ__init____mutmut_5': xǁExtractFeaturesǁ__init____mutmut_5, 
        'xǁExtractFeaturesǁ__init____mutmut_6': xǁExtractFeaturesǁ__init____mutmut_6, 
        'xǁExtractFeaturesǁ__init____mutmut_7': xǁExtractFeaturesǁ__init____mutmut_7, 
        'xǁExtractFeaturesǁ__init____mutmut_8': xǁExtractFeaturesǁ__init____mutmut_8, 
        'xǁExtractFeaturesǁ__init____mutmut_9': xǁExtractFeaturesǁ__init____mutmut_9, 
        'xǁExtractFeaturesǁ__init____mutmut_10': xǁExtractFeaturesǁ__init____mutmut_10, 
        'xǁExtractFeaturesǁ__init____mutmut_11': xǁExtractFeaturesǁ__init____mutmut_11, 
        'xǁExtractFeaturesǁ__init____mutmut_12': xǁExtractFeaturesǁ__init____mutmut_12, 
        'xǁExtractFeaturesǁ__init____mutmut_13': xǁExtractFeaturesǁ__init____mutmut_13, 
        'xǁExtractFeaturesǁ__init____mutmut_14': xǁExtractFeaturesǁ__init____mutmut_14, 
        'xǁExtractFeaturesǁ__init____mutmut_15': xǁExtractFeaturesǁ__init____mutmut_15, 
        'xǁExtractFeaturesǁ__init____mutmut_16': xǁExtractFeaturesǁ__init____mutmut_16, 
        'xǁExtractFeaturesǁ__init____mutmut_17': xǁExtractFeaturesǁ__init____mutmut_17, 
        'xǁExtractFeaturesǁ__init____mutmut_18': xǁExtractFeaturesǁ__init____mutmut_18
    }
    
    def __init__(self, *args, **kwargs):
        result = _mutmut_trampoline(object.__getattribute__(self, "xǁExtractFeaturesǁ__init____mutmut_orig"), object.__getattribute__(self, "xǁExtractFeaturesǁ__init____mutmut_mutants"), args, kwargs, self)
        return result 
    
    __init__.__signature__ = _mutmut_signature(xǁExtractFeaturesǁ__init____mutmut_orig)
    xǁExtractFeaturesǁ__init____mutmut_orig.__name__ = 'xǁExtractFeaturesǁ__init__'

    def fit(self, X, y=None):
        # Pas d'apprentissage de paramètres pour l'instant
        return self

    def xǁExtractFeaturesǁtransform__mutmut_orig(self, X):
        # Vérifie que X est bien (n_epochs, n_channels, n_times)
        if X.ndim != self.EXPECTED_EEG_NDIM:
            raise ValueError("X must have shape (n_samples, n_channels, n_times)")
        if X.shape[0] == 0:
            raise ValueError("X must contain at least one epoch.")

        # Calcule les features brutes selon la stratégie choisie
        raw_features = self._compute_features(X)

        # Normalise optionnellement les features bande-par-bande
        if self.normalize:
            mean = raw_features.mean(axis=1, keepdims=True)
            std = raw_features.std(axis=1, keepdims=True) + self.NORMALIZATION_EPS
            features = (raw_features - mean) / std
        else:
            features = raw_features

        # Vérifie qu'aucune valeur non finie ne subsiste
        if not np.all(np.isfinite(features)):
            raise ValueError(
                "ExtractFeatures produced non-finite values (NaN/Inf). "
                "Check band ranges and sampling frequency."
            )

        return features

    def xǁExtractFeaturesǁtransform__mutmut_1(self, X):
        # Vérifie que X est bien (n_epochs, n_channels, n_times)
        if X.ndim == self.EXPECTED_EEG_NDIM:
            raise ValueError("X must have shape (n_samples, n_channels, n_times)")
        if X.shape[0] == 0:
            raise ValueError("X must contain at least one epoch.")

        # Calcule les features brutes selon la stratégie choisie
        raw_features = self._compute_features(X)

        # Normalise optionnellement les features bande-par-bande
        if self.normalize:
            mean = raw_features.mean(axis=1, keepdims=True)
            std = raw_features.std(axis=1, keepdims=True) + self.NORMALIZATION_EPS
            features = (raw_features - mean) / std
        else:
            features = raw_features

        # Vérifie qu'aucune valeur non finie ne subsiste
        if not np.all(np.isfinite(features)):
            raise ValueError(
                "ExtractFeatures produced non-finite values (NaN/Inf). "
                "Check band ranges and sampling frequency."
            )

        return features

    def xǁExtractFeaturesǁtransform__mutmut_2(self, X):
        # Vérifie que X est bien (n_epochs, n_channels, n_times)
        if X.ndim != self.EXPECTED_EEG_NDIM:
            raise ValueError(None)
        if X.shape[0] == 0:
            raise ValueError("X must contain at least one epoch.")

        # Calcule les features brutes selon la stratégie choisie
        raw_features = self._compute_features(X)

        # Normalise optionnellement les features bande-par-bande
        if self.normalize:
            mean = raw_features.mean(axis=1, keepdims=True)
            std = raw_features.std(axis=1, keepdims=True) + self.NORMALIZATION_EPS
            features = (raw_features - mean) / std
        else:
            features = raw_features

        # Vérifie qu'aucune valeur non finie ne subsiste
        if not np.all(np.isfinite(features)):
            raise ValueError(
                "ExtractFeatures produced non-finite values (NaN/Inf). "
                "Check band ranges and sampling frequency."
            )

        return features

    def xǁExtractFeaturesǁtransform__mutmut_3(self, X):
        # Vérifie que X est bien (n_epochs, n_channels, n_times)
        if X.ndim != self.EXPECTED_EEG_NDIM:
            raise ValueError("XXX must have shape (n_samples, n_channels, n_times)XX")
        if X.shape[0] == 0:
            raise ValueError("X must contain at least one epoch.")

        # Calcule les features brutes selon la stratégie choisie
        raw_features = self._compute_features(X)

        # Normalise optionnellement les features bande-par-bande
        if self.normalize:
            mean = raw_features.mean(axis=1, keepdims=True)
            std = raw_features.std(axis=1, keepdims=True) + self.NORMALIZATION_EPS
            features = (raw_features - mean) / std
        else:
            features = raw_features

        # Vérifie qu'aucune valeur non finie ne subsiste
        if not np.all(np.isfinite(features)):
            raise ValueError(
                "ExtractFeatures produced non-finite values (NaN/Inf). "
                "Check band ranges and sampling frequency."
            )

        return features

    def xǁExtractFeaturesǁtransform__mutmut_4(self, X):
        # Vérifie que X est bien (n_epochs, n_channels, n_times)
        if X.ndim != self.EXPECTED_EEG_NDIM:
            raise ValueError("x must have shape (n_samples, n_channels, n_times)")
        if X.shape[0] == 0:
            raise ValueError("X must contain at least one epoch.")

        # Calcule les features brutes selon la stratégie choisie
        raw_features = self._compute_features(X)

        # Normalise optionnellement les features bande-par-bande
        if self.normalize:
            mean = raw_features.mean(axis=1, keepdims=True)
            std = raw_features.std(axis=1, keepdims=True) + self.NORMALIZATION_EPS
            features = (raw_features - mean) / std
        else:
            features = raw_features

        # Vérifie qu'aucune valeur non finie ne subsiste
        if not np.all(np.isfinite(features)):
            raise ValueError(
                "ExtractFeatures produced non-finite values (NaN/Inf). "
                "Check band ranges and sampling frequency."
            )

        return features

    def xǁExtractFeaturesǁtransform__mutmut_5(self, X):
        # Vérifie que X est bien (n_epochs, n_channels, n_times)
        if X.ndim != self.EXPECTED_EEG_NDIM:
            raise ValueError("X MUST HAVE SHAPE (N_SAMPLES, N_CHANNELS, N_TIMES)")
        if X.shape[0] == 0:
            raise ValueError("X must contain at least one epoch.")

        # Calcule les features brutes selon la stratégie choisie
        raw_features = self._compute_features(X)

        # Normalise optionnellement les features bande-par-bande
        if self.normalize:
            mean = raw_features.mean(axis=1, keepdims=True)
            std = raw_features.std(axis=1, keepdims=True) + self.NORMALIZATION_EPS
            features = (raw_features - mean) / std
        else:
            features = raw_features

        # Vérifie qu'aucune valeur non finie ne subsiste
        if not np.all(np.isfinite(features)):
            raise ValueError(
                "ExtractFeatures produced non-finite values (NaN/Inf). "
                "Check band ranges and sampling frequency."
            )

        return features

    def xǁExtractFeaturesǁtransform__mutmut_6(self, X):
        # Vérifie que X est bien (n_epochs, n_channels, n_times)
        if X.ndim != self.EXPECTED_EEG_NDIM:
            raise ValueError("X must have shape (n_samples, n_channels, n_times)")
        if X.shape[1] == 0:
            raise ValueError("X must contain at least one epoch.")

        # Calcule les features brutes selon la stratégie choisie
        raw_features = self._compute_features(X)

        # Normalise optionnellement les features bande-par-bande
        if self.normalize:
            mean = raw_features.mean(axis=1, keepdims=True)
            std = raw_features.std(axis=1, keepdims=True) + self.NORMALIZATION_EPS
            features = (raw_features - mean) / std
        else:
            features = raw_features

        # Vérifie qu'aucune valeur non finie ne subsiste
        if not np.all(np.isfinite(features)):
            raise ValueError(
                "ExtractFeatures produced non-finite values (NaN/Inf). "
                "Check band ranges and sampling frequency."
            )

        return features

    def xǁExtractFeaturesǁtransform__mutmut_7(self, X):
        # Vérifie que X est bien (n_epochs, n_channels, n_times)
        if X.ndim != self.EXPECTED_EEG_NDIM:
            raise ValueError("X must have shape (n_samples, n_channels, n_times)")
        if X.shape[0] != 0:
            raise ValueError("X must contain at least one epoch.")

        # Calcule les features brutes selon la stratégie choisie
        raw_features = self._compute_features(X)

        # Normalise optionnellement les features bande-par-bande
        if self.normalize:
            mean = raw_features.mean(axis=1, keepdims=True)
            std = raw_features.std(axis=1, keepdims=True) + self.NORMALIZATION_EPS
            features = (raw_features - mean) / std
        else:
            features = raw_features

        # Vérifie qu'aucune valeur non finie ne subsiste
        if not np.all(np.isfinite(features)):
            raise ValueError(
                "ExtractFeatures produced non-finite values (NaN/Inf). "
                "Check band ranges and sampling frequency."
            )

        return features

    def xǁExtractFeaturesǁtransform__mutmut_8(self, X):
        # Vérifie que X est bien (n_epochs, n_channels, n_times)
        if X.ndim != self.EXPECTED_EEG_NDIM:
            raise ValueError("X must have shape (n_samples, n_channels, n_times)")
        if X.shape[0] == 1:
            raise ValueError("X must contain at least one epoch.")

        # Calcule les features brutes selon la stratégie choisie
        raw_features = self._compute_features(X)

        # Normalise optionnellement les features bande-par-bande
        if self.normalize:
            mean = raw_features.mean(axis=1, keepdims=True)
            std = raw_features.std(axis=1, keepdims=True) + self.NORMALIZATION_EPS
            features = (raw_features - mean) / std
        else:
            features = raw_features

        # Vérifie qu'aucune valeur non finie ne subsiste
        if not np.all(np.isfinite(features)):
            raise ValueError(
                "ExtractFeatures produced non-finite values (NaN/Inf). "
                "Check band ranges and sampling frequency."
            )

        return features

    def xǁExtractFeaturesǁtransform__mutmut_9(self, X):
        # Vérifie que X est bien (n_epochs, n_channels, n_times)
        if X.ndim != self.EXPECTED_EEG_NDIM:
            raise ValueError("X must have shape (n_samples, n_channels, n_times)")
        if X.shape[0] == 0:
            raise ValueError(None)

        # Calcule les features brutes selon la stratégie choisie
        raw_features = self._compute_features(X)

        # Normalise optionnellement les features bande-par-bande
        if self.normalize:
            mean = raw_features.mean(axis=1, keepdims=True)
            std = raw_features.std(axis=1, keepdims=True) + self.NORMALIZATION_EPS
            features = (raw_features - mean) / std
        else:
            features = raw_features

        # Vérifie qu'aucune valeur non finie ne subsiste
        if not np.all(np.isfinite(features)):
            raise ValueError(
                "ExtractFeatures produced non-finite values (NaN/Inf). "
                "Check band ranges and sampling frequency."
            )

        return features

    def xǁExtractFeaturesǁtransform__mutmut_10(self, X):
        # Vérifie que X est bien (n_epochs, n_channels, n_times)
        if X.ndim != self.EXPECTED_EEG_NDIM:
            raise ValueError("X must have shape (n_samples, n_channels, n_times)")
        if X.shape[0] == 0:
            raise ValueError("XXX must contain at least one epoch.XX")

        # Calcule les features brutes selon la stratégie choisie
        raw_features = self._compute_features(X)

        # Normalise optionnellement les features bande-par-bande
        if self.normalize:
            mean = raw_features.mean(axis=1, keepdims=True)
            std = raw_features.std(axis=1, keepdims=True) + self.NORMALIZATION_EPS
            features = (raw_features - mean) / std
        else:
            features = raw_features

        # Vérifie qu'aucune valeur non finie ne subsiste
        if not np.all(np.isfinite(features)):
            raise ValueError(
                "ExtractFeatures produced non-finite values (NaN/Inf). "
                "Check band ranges and sampling frequency."
            )

        return features

    def xǁExtractFeaturesǁtransform__mutmut_11(self, X):
        # Vérifie que X est bien (n_epochs, n_channels, n_times)
        if X.ndim != self.EXPECTED_EEG_NDIM:
            raise ValueError("X must have shape (n_samples, n_channels, n_times)")
        if X.shape[0] == 0:
            raise ValueError("x must contain at least one epoch.")

        # Calcule les features brutes selon la stratégie choisie
        raw_features = self._compute_features(X)

        # Normalise optionnellement les features bande-par-bande
        if self.normalize:
            mean = raw_features.mean(axis=1, keepdims=True)
            std = raw_features.std(axis=1, keepdims=True) + self.NORMALIZATION_EPS
            features = (raw_features - mean) / std
        else:
            features = raw_features

        # Vérifie qu'aucune valeur non finie ne subsiste
        if not np.all(np.isfinite(features)):
            raise ValueError(
                "ExtractFeatures produced non-finite values (NaN/Inf). "
                "Check band ranges and sampling frequency."
            )

        return features

    def xǁExtractFeaturesǁtransform__mutmut_12(self, X):
        # Vérifie que X est bien (n_epochs, n_channels, n_times)
        if X.ndim != self.EXPECTED_EEG_NDIM:
            raise ValueError("X must have shape (n_samples, n_channels, n_times)")
        if X.shape[0] == 0:
            raise ValueError("X MUST CONTAIN AT LEAST ONE EPOCH.")

        # Calcule les features brutes selon la stratégie choisie
        raw_features = self._compute_features(X)

        # Normalise optionnellement les features bande-par-bande
        if self.normalize:
            mean = raw_features.mean(axis=1, keepdims=True)
            std = raw_features.std(axis=1, keepdims=True) + self.NORMALIZATION_EPS
            features = (raw_features - mean) / std
        else:
            features = raw_features

        # Vérifie qu'aucune valeur non finie ne subsiste
        if not np.all(np.isfinite(features)):
            raise ValueError(
                "ExtractFeatures produced non-finite values (NaN/Inf). "
                "Check band ranges and sampling frequency."
            )

        return features

    def xǁExtractFeaturesǁtransform__mutmut_13(self, X):
        # Vérifie que X est bien (n_epochs, n_channels, n_times)
        if X.ndim != self.EXPECTED_EEG_NDIM:
            raise ValueError("X must have shape (n_samples, n_channels, n_times)")
        if X.shape[0] == 0:
            raise ValueError("X must contain at least one epoch.")

        # Calcule les features brutes selon la stratégie choisie
        raw_features = None

        # Normalise optionnellement les features bande-par-bande
        if self.normalize:
            mean = raw_features.mean(axis=1, keepdims=True)
            std = raw_features.std(axis=1, keepdims=True) + self.NORMALIZATION_EPS
            features = (raw_features - mean) / std
        else:
            features = raw_features

        # Vérifie qu'aucune valeur non finie ne subsiste
        if not np.all(np.isfinite(features)):
            raise ValueError(
                "ExtractFeatures produced non-finite values (NaN/Inf). "
                "Check band ranges and sampling frequency."
            )

        return features

    def xǁExtractFeaturesǁtransform__mutmut_14(self, X):
        # Vérifie que X est bien (n_epochs, n_channels, n_times)
        if X.ndim != self.EXPECTED_EEG_NDIM:
            raise ValueError("X must have shape (n_samples, n_channels, n_times)")
        if X.shape[0] == 0:
            raise ValueError("X must contain at least one epoch.")

        # Calcule les features brutes selon la stratégie choisie
        raw_features = self._compute_features(None)

        # Normalise optionnellement les features bande-par-bande
        if self.normalize:
            mean = raw_features.mean(axis=1, keepdims=True)
            std = raw_features.std(axis=1, keepdims=True) + self.NORMALIZATION_EPS
            features = (raw_features - mean) / std
        else:
            features = raw_features

        # Vérifie qu'aucune valeur non finie ne subsiste
        if not np.all(np.isfinite(features)):
            raise ValueError(
                "ExtractFeatures produced non-finite values (NaN/Inf). "
                "Check band ranges and sampling frequency."
            )

        return features

    def xǁExtractFeaturesǁtransform__mutmut_15(self, X):
        # Vérifie que X est bien (n_epochs, n_channels, n_times)
        if X.ndim != self.EXPECTED_EEG_NDIM:
            raise ValueError("X must have shape (n_samples, n_channels, n_times)")
        if X.shape[0] == 0:
            raise ValueError("X must contain at least one epoch.")

        # Calcule les features brutes selon la stratégie choisie
        raw_features = self._compute_features(X)

        # Normalise optionnellement les features bande-par-bande
        if self.normalize:
            mean = None
            std = raw_features.std(axis=1, keepdims=True) + self.NORMALIZATION_EPS
            features = (raw_features - mean) / std
        else:
            features = raw_features

        # Vérifie qu'aucune valeur non finie ne subsiste
        if not np.all(np.isfinite(features)):
            raise ValueError(
                "ExtractFeatures produced non-finite values (NaN/Inf). "
                "Check band ranges and sampling frequency."
            )

        return features

    def xǁExtractFeaturesǁtransform__mutmut_16(self, X):
        # Vérifie que X est bien (n_epochs, n_channels, n_times)
        if X.ndim != self.EXPECTED_EEG_NDIM:
            raise ValueError("X must have shape (n_samples, n_channels, n_times)")
        if X.shape[0] == 0:
            raise ValueError("X must contain at least one epoch.")

        # Calcule les features brutes selon la stratégie choisie
        raw_features = self._compute_features(X)

        # Normalise optionnellement les features bande-par-bande
        if self.normalize:
            mean = raw_features.mean(axis=None, keepdims=True)
            std = raw_features.std(axis=1, keepdims=True) + self.NORMALIZATION_EPS
            features = (raw_features - mean) / std
        else:
            features = raw_features

        # Vérifie qu'aucune valeur non finie ne subsiste
        if not np.all(np.isfinite(features)):
            raise ValueError(
                "ExtractFeatures produced non-finite values (NaN/Inf). "
                "Check band ranges and sampling frequency."
            )

        return features

    def xǁExtractFeaturesǁtransform__mutmut_17(self, X):
        # Vérifie que X est bien (n_epochs, n_channels, n_times)
        if X.ndim != self.EXPECTED_EEG_NDIM:
            raise ValueError("X must have shape (n_samples, n_channels, n_times)")
        if X.shape[0] == 0:
            raise ValueError("X must contain at least one epoch.")

        # Calcule les features brutes selon la stratégie choisie
        raw_features = self._compute_features(X)

        # Normalise optionnellement les features bande-par-bande
        if self.normalize:
            mean = raw_features.mean(axis=1, keepdims=None)
            std = raw_features.std(axis=1, keepdims=True) + self.NORMALIZATION_EPS
            features = (raw_features - mean) / std
        else:
            features = raw_features

        # Vérifie qu'aucune valeur non finie ne subsiste
        if not np.all(np.isfinite(features)):
            raise ValueError(
                "ExtractFeatures produced non-finite values (NaN/Inf). "
                "Check band ranges and sampling frequency."
            )

        return features

    def xǁExtractFeaturesǁtransform__mutmut_18(self, X):
        # Vérifie que X est bien (n_epochs, n_channels, n_times)
        if X.ndim != self.EXPECTED_EEG_NDIM:
            raise ValueError("X must have shape (n_samples, n_channels, n_times)")
        if X.shape[0] == 0:
            raise ValueError("X must contain at least one epoch.")

        # Calcule les features brutes selon la stratégie choisie
        raw_features = self._compute_features(X)

        # Normalise optionnellement les features bande-par-bande
        if self.normalize:
            mean = raw_features.mean(keepdims=True)
            std = raw_features.std(axis=1, keepdims=True) + self.NORMALIZATION_EPS
            features = (raw_features - mean) / std
        else:
            features = raw_features

        # Vérifie qu'aucune valeur non finie ne subsiste
        if not np.all(np.isfinite(features)):
            raise ValueError(
                "ExtractFeatures produced non-finite values (NaN/Inf). "
                "Check band ranges and sampling frequency."
            )

        return features

    def xǁExtractFeaturesǁtransform__mutmut_19(self, X):
        # Vérifie que X est bien (n_epochs, n_channels, n_times)
        if X.ndim != self.EXPECTED_EEG_NDIM:
            raise ValueError("X must have shape (n_samples, n_channels, n_times)")
        if X.shape[0] == 0:
            raise ValueError("X must contain at least one epoch.")

        # Calcule les features brutes selon la stratégie choisie
        raw_features = self._compute_features(X)

        # Normalise optionnellement les features bande-par-bande
        if self.normalize:
            mean = raw_features.mean(axis=1, )
            std = raw_features.std(axis=1, keepdims=True) + self.NORMALIZATION_EPS
            features = (raw_features - mean) / std
        else:
            features = raw_features

        # Vérifie qu'aucune valeur non finie ne subsiste
        if not np.all(np.isfinite(features)):
            raise ValueError(
                "ExtractFeatures produced non-finite values (NaN/Inf). "
                "Check band ranges and sampling frequency."
            )

        return features

    def xǁExtractFeaturesǁtransform__mutmut_20(self, X):
        # Vérifie que X est bien (n_epochs, n_channels, n_times)
        if X.ndim != self.EXPECTED_EEG_NDIM:
            raise ValueError("X must have shape (n_samples, n_channels, n_times)")
        if X.shape[0] == 0:
            raise ValueError("X must contain at least one epoch.")

        # Calcule les features brutes selon la stratégie choisie
        raw_features = self._compute_features(X)

        # Normalise optionnellement les features bande-par-bande
        if self.normalize:
            mean = raw_features.mean(axis=2, keepdims=True)
            std = raw_features.std(axis=1, keepdims=True) + self.NORMALIZATION_EPS
            features = (raw_features - mean) / std
        else:
            features = raw_features

        # Vérifie qu'aucune valeur non finie ne subsiste
        if not np.all(np.isfinite(features)):
            raise ValueError(
                "ExtractFeatures produced non-finite values (NaN/Inf). "
                "Check band ranges and sampling frequency."
            )

        return features

    def xǁExtractFeaturesǁtransform__mutmut_21(self, X):
        # Vérifie que X est bien (n_epochs, n_channels, n_times)
        if X.ndim != self.EXPECTED_EEG_NDIM:
            raise ValueError("X must have shape (n_samples, n_channels, n_times)")
        if X.shape[0] == 0:
            raise ValueError("X must contain at least one epoch.")

        # Calcule les features brutes selon la stratégie choisie
        raw_features = self._compute_features(X)

        # Normalise optionnellement les features bande-par-bande
        if self.normalize:
            mean = raw_features.mean(axis=1, keepdims=False)
            std = raw_features.std(axis=1, keepdims=True) + self.NORMALIZATION_EPS
            features = (raw_features - mean) / std
        else:
            features = raw_features

        # Vérifie qu'aucune valeur non finie ne subsiste
        if not np.all(np.isfinite(features)):
            raise ValueError(
                "ExtractFeatures produced non-finite values (NaN/Inf). "
                "Check band ranges and sampling frequency."
            )

        return features

    def xǁExtractFeaturesǁtransform__mutmut_22(self, X):
        # Vérifie que X est bien (n_epochs, n_channels, n_times)
        if X.ndim != self.EXPECTED_EEG_NDIM:
            raise ValueError("X must have shape (n_samples, n_channels, n_times)")
        if X.shape[0] == 0:
            raise ValueError("X must contain at least one epoch.")

        # Calcule les features brutes selon la stratégie choisie
        raw_features = self._compute_features(X)

        # Normalise optionnellement les features bande-par-bande
        if self.normalize:
            mean = raw_features.mean(axis=1, keepdims=True)
            std = None
            features = (raw_features - mean) / std
        else:
            features = raw_features

        # Vérifie qu'aucune valeur non finie ne subsiste
        if not np.all(np.isfinite(features)):
            raise ValueError(
                "ExtractFeatures produced non-finite values (NaN/Inf). "
                "Check band ranges and sampling frequency."
            )

        return features

    def xǁExtractFeaturesǁtransform__mutmut_23(self, X):
        # Vérifie que X est bien (n_epochs, n_channels, n_times)
        if X.ndim != self.EXPECTED_EEG_NDIM:
            raise ValueError("X must have shape (n_samples, n_channels, n_times)")
        if X.shape[0] == 0:
            raise ValueError("X must contain at least one epoch.")

        # Calcule les features brutes selon la stratégie choisie
        raw_features = self._compute_features(X)

        # Normalise optionnellement les features bande-par-bande
        if self.normalize:
            mean = raw_features.mean(axis=1, keepdims=True)
            std = raw_features.std(axis=1, keepdims=True) - self.NORMALIZATION_EPS
            features = (raw_features - mean) / std
        else:
            features = raw_features

        # Vérifie qu'aucune valeur non finie ne subsiste
        if not np.all(np.isfinite(features)):
            raise ValueError(
                "ExtractFeatures produced non-finite values (NaN/Inf). "
                "Check band ranges and sampling frequency."
            )

        return features

    def xǁExtractFeaturesǁtransform__mutmut_24(self, X):
        # Vérifie que X est bien (n_epochs, n_channels, n_times)
        if X.ndim != self.EXPECTED_EEG_NDIM:
            raise ValueError("X must have shape (n_samples, n_channels, n_times)")
        if X.shape[0] == 0:
            raise ValueError("X must contain at least one epoch.")

        # Calcule les features brutes selon la stratégie choisie
        raw_features = self._compute_features(X)

        # Normalise optionnellement les features bande-par-bande
        if self.normalize:
            mean = raw_features.mean(axis=1, keepdims=True)
            std = raw_features.std(axis=None, keepdims=True) + self.NORMALIZATION_EPS
            features = (raw_features - mean) / std
        else:
            features = raw_features

        # Vérifie qu'aucune valeur non finie ne subsiste
        if not np.all(np.isfinite(features)):
            raise ValueError(
                "ExtractFeatures produced non-finite values (NaN/Inf). "
                "Check band ranges and sampling frequency."
            )

        return features

    def xǁExtractFeaturesǁtransform__mutmut_25(self, X):
        # Vérifie que X est bien (n_epochs, n_channels, n_times)
        if X.ndim != self.EXPECTED_EEG_NDIM:
            raise ValueError("X must have shape (n_samples, n_channels, n_times)")
        if X.shape[0] == 0:
            raise ValueError("X must contain at least one epoch.")

        # Calcule les features brutes selon la stratégie choisie
        raw_features = self._compute_features(X)

        # Normalise optionnellement les features bande-par-bande
        if self.normalize:
            mean = raw_features.mean(axis=1, keepdims=True)
            std = raw_features.std(axis=1, keepdims=None) + self.NORMALIZATION_EPS
            features = (raw_features - mean) / std
        else:
            features = raw_features

        # Vérifie qu'aucune valeur non finie ne subsiste
        if not np.all(np.isfinite(features)):
            raise ValueError(
                "ExtractFeatures produced non-finite values (NaN/Inf). "
                "Check band ranges and sampling frequency."
            )

        return features

    def xǁExtractFeaturesǁtransform__mutmut_26(self, X):
        # Vérifie que X est bien (n_epochs, n_channels, n_times)
        if X.ndim != self.EXPECTED_EEG_NDIM:
            raise ValueError("X must have shape (n_samples, n_channels, n_times)")
        if X.shape[0] == 0:
            raise ValueError("X must contain at least one epoch.")

        # Calcule les features brutes selon la stratégie choisie
        raw_features = self._compute_features(X)

        # Normalise optionnellement les features bande-par-bande
        if self.normalize:
            mean = raw_features.mean(axis=1, keepdims=True)
            std = raw_features.std(keepdims=True) + self.NORMALIZATION_EPS
            features = (raw_features - mean) / std
        else:
            features = raw_features

        # Vérifie qu'aucune valeur non finie ne subsiste
        if not np.all(np.isfinite(features)):
            raise ValueError(
                "ExtractFeatures produced non-finite values (NaN/Inf). "
                "Check band ranges and sampling frequency."
            )

        return features

    def xǁExtractFeaturesǁtransform__mutmut_27(self, X):
        # Vérifie que X est bien (n_epochs, n_channels, n_times)
        if X.ndim != self.EXPECTED_EEG_NDIM:
            raise ValueError("X must have shape (n_samples, n_channels, n_times)")
        if X.shape[0] == 0:
            raise ValueError("X must contain at least one epoch.")

        # Calcule les features brutes selon la stratégie choisie
        raw_features = self._compute_features(X)

        # Normalise optionnellement les features bande-par-bande
        if self.normalize:
            mean = raw_features.mean(axis=1, keepdims=True)
            std = raw_features.std(axis=1, ) + self.NORMALIZATION_EPS
            features = (raw_features - mean) / std
        else:
            features = raw_features

        # Vérifie qu'aucune valeur non finie ne subsiste
        if not np.all(np.isfinite(features)):
            raise ValueError(
                "ExtractFeatures produced non-finite values (NaN/Inf). "
                "Check band ranges and sampling frequency."
            )

        return features

    def xǁExtractFeaturesǁtransform__mutmut_28(self, X):
        # Vérifie que X est bien (n_epochs, n_channels, n_times)
        if X.ndim != self.EXPECTED_EEG_NDIM:
            raise ValueError("X must have shape (n_samples, n_channels, n_times)")
        if X.shape[0] == 0:
            raise ValueError("X must contain at least one epoch.")

        # Calcule les features brutes selon la stratégie choisie
        raw_features = self._compute_features(X)

        # Normalise optionnellement les features bande-par-bande
        if self.normalize:
            mean = raw_features.mean(axis=1, keepdims=True)
            std = raw_features.std(axis=2, keepdims=True) + self.NORMALIZATION_EPS
            features = (raw_features - mean) / std
        else:
            features = raw_features

        # Vérifie qu'aucune valeur non finie ne subsiste
        if not np.all(np.isfinite(features)):
            raise ValueError(
                "ExtractFeatures produced non-finite values (NaN/Inf). "
                "Check band ranges and sampling frequency."
            )

        return features

    def xǁExtractFeaturesǁtransform__mutmut_29(self, X):
        # Vérifie que X est bien (n_epochs, n_channels, n_times)
        if X.ndim != self.EXPECTED_EEG_NDIM:
            raise ValueError("X must have shape (n_samples, n_channels, n_times)")
        if X.shape[0] == 0:
            raise ValueError("X must contain at least one epoch.")

        # Calcule les features brutes selon la stratégie choisie
        raw_features = self._compute_features(X)

        # Normalise optionnellement les features bande-par-bande
        if self.normalize:
            mean = raw_features.mean(axis=1, keepdims=True)
            std = raw_features.std(axis=1, keepdims=False) + self.NORMALIZATION_EPS
            features = (raw_features - mean) / std
        else:
            features = raw_features

        # Vérifie qu'aucune valeur non finie ne subsiste
        if not np.all(np.isfinite(features)):
            raise ValueError(
                "ExtractFeatures produced non-finite values (NaN/Inf). "
                "Check band ranges and sampling frequency."
            )

        return features

    def xǁExtractFeaturesǁtransform__mutmut_30(self, X):
        # Vérifie que X est bien (n_epochs, n_channels, n_times)
        if X.ndim != self.EXPECTED_EEG_NDIM:
            raise ValueError("X must have shape (n_samples, n_channels, n_times)")
        if X.shape[0] == 0:
            raise ValueError("X must contain at least one epoch.")

        # Calcule les features brutes selon la stratégie choisie
        raw_features = self._compute_features(X)

        # Normalise optionnellement les features bande-par-bande
        if self.normalize:
            mean = raw_features.mean(axis=1, keepdims=True)
            std = raw_features.std(axis=1, keepdims=True) + self.NORMALIZATION_EPS
            features = None
        else:
            features = raw_features

        # Vérifie qu'aucune valeur non finie ne subsiste
        if not np.all(np.isfinite(features)):
            raise ValueError(
                "ExtractFeatures produced non-finite values (NaN/Inf). "
                "Check band ranges and sampling frequency."
            )

        return features

    def xǁExtractFeaturesǁtransform__mutmut_31(self, X):
        # Vérifie que X est bien (n_epochs, n_channels, n_times)
        if X.ndim != self.EXPECTED_EEG_NDIM:
            raise ValueError("X must have shape (n_samples, n_channels, n_times)")
        if X.shape[0] == 0:
            raise ValueError("X must contain at least one epoch.")

        # Calcule les features brutes selon la stratégie choisie
        raw_features = self._compute_features(X)

        # Normalise optionnellement les features bande-par-bande
        if self.normalize:
            mean = raw_features.mean(axis=1, keepdims=True)
            std = raw_features.std(axis=1, keepdims=True) + self.NORMALIZATION_EPS
            features = (raw_features - mean) * std
        else:
            features = raw_features

        # Vérifie qu'aucune valeur non finie ne subsiste
        if not np.all(np.isfinite(features)):
            raise ValueError(
                "ExtractFeatures produced non-finite values (NaN/Inf). "
                "Check band ranges and sampling frequency."
            )

        return features

    def xǁExtractFeaturesǁtransform__mutmut_32(self, X):
        # Vérifie que X est bien (n_epochs, n_channels, n_times)
        if X.ndim != self.EXPECTED_EEG_NDIM:
            raise ValueError("X must have shape (n_samples, n_channels, n_times)")
        if X.shape[0] == 0:
            raise ValueError("X must contain at least one epoch.")

        # Calcule les features brutes selon la stratégie choisie
        raw_features = self._compute_features(X)

        # Normalise optionnellement les features bande-par-bande
        if self.normalize:
            mean = raw_features.mean(axis=1, keepdims=True)
            std = raw_features.std(axis=1, keepdims=True) + self.NORMALIZATION_EPS
            features = (raw_features + mean) / std
        else:
            features = raw_features

        # Vérifie qu'aucune valeur non finie ne subsiste
        if not np.all(np.isfinite(features)):
            raise ValueError(
                "ExtractFeatures produced non-finite values (NaN/Inf). "
                "Check band ranges and sampling frequency."
            )

        return features

    def xǁExtractFeaturesǁtransform__mutmut_33(self, X):
        # Vérifie que X est bien (n_epochs, n_channels, n_times)
        if X.ndim != self.EXPECTED_EEG_NDIM:
            raise ValueError("X must have shape (n_samples, n_channels, n_times)")
        if X.shape[0] == 0:
            raise ValueError("X must contain at least one epoch.")

        # Calcule les features brutes selon la stratégie choisie
        raw_features = self._compute_features(X)

        # Normalise optionnellement les features bande-par-bande
        if self.normalize:
            mean = raw_features.mean(axis=1, keepdims=True)
            std = raw_features.std(axis=1, keepdims=True) + self.NORMALIZATION_EPS
            features = (raw_features - mean) / std
        else:
            features = None

        # Vérifie qu'aucune valeur non finie ne subsiste
        if not np.all(np.isfinite(features)):
            raise ValueError(
                "ExtractFeatures produced non-finite values (NaN/Inf). "
                "Check band ranges and sampling frequency."
            )

        return features

    def xǁExtractFeaturesǁtransform__mutmut_34(self, X):
        # Vérifie que X est bien (n_epochs, n_channels, n_times)
        if X.ndim != self.EXPECTED_EEG_NDIM:
            raise ValueError("X must have shape (n_samples, n_channels, n_times)")
        if X.shape[0] == 0:
            raise ValueError("X must contain at least one epoch.")

        # Calcule les features brutes selon la stratégie choisie
        raw_features = self._compute_features(X)

        # Normalise optionnellement les features bande-par-bande
        if self.normalize:
            mean = raw_features.mean(axis=1, keepdims=True)
            std = raw_features.std(axis=1, keepdims=True) + self.NORMALIZATION_EPS
            features = (raw_features - mean) / std
        else:
            features = raw_features

        # Vérifie qu'aucune valeur non finie ne subsiste
        if np.all(np.isfinite(features)):
            raise ValueError(
                "ExtractFeatures produced non-finite values (NaN/Inf). "
                "Check band ranges and sampling frequency."
            )

        return features

    def xǁExtractFeaturesǁtransform__mutmut_35(self, X):
        # Vérifie que X est bien (n_epochs, n_channels, n_times)
        if X.ndim != self.EXPECTED_EEG_NDIM:
            raise ValueError("X must have shape (n_samples, n_channels, n_times)")
        if X.shape[0] == 0:
            raise ValueError("X must contain at least one epoch.")

        # Calcule les features brutes selon la stratégie choisie
        raw_features = self._compute_features(X)

        # Normalise optionnellement les features bande-par-bande
        if self.normalize:
            mean = raw_features.mean(axis=1, keepdims=True)
            std = raw_features.std(axis=1, keepdims=True) + self.NORMALIZATION_EPS
            features = (raw_features - mean) / std
        else:
            features = raw_features

        # Vérifie qu'aucune valeur non finie ne subsiste
        if not np.all(None):
            raise ValueError(
                "ExtractFeatures produced non-finite values (NaN/Inf). "
                "Check band ranges and sampling frequency."
            )

        return features

    def xǁExtractFeaturesǁtransform__mutmut_36(self, X):
        # Vérifie que X est bien (n_epochs, n_channels, n_times)
        if X.ndim != self.EXPECTED_EEG_NDIM:
            raise ValueError("X must have shape (n_samples, n_channels, n_times)")
        if X.shape[0] == 0:
            raise ValueError("X must contain at least one epoch.")

        # Calcule les features brutes selon la stratégie choisie
        raw_features = self._compute_features(X)

        # Normalise optionnellement les features bande-par-bande
        if self.normalize:
            mean = raw_features.mean(axis=1, keepdims=True)
            std = raw_features.std(axis=1, keepdims=True) + self.NORMALIZATION_EPS
            features = (raw_features - mean) / std
        else:
            features = raw_features

        # Vérifie qu'aucune valeur non finie ne subsiste
        if not np.all(np.isfinite(None)):
            raise ValueError(
                "ExtractFeatures produced non-finite values (NaN/Inf). "
                "Check band ranges and sampling frequency."
            )

        return features
    
    xǁExtractFeaturesǁtransform__mutmut_mutants : ClassVar[MutantDict] = {
    'xǁExtractFeaturesǁtransform__mutmut_1': xǁExtractFeaturesǁtransform__mutmut_1, 
        'xǁExtractFeaturesǁtransform__mutmut_2': xǁExtractFeaturesǁtransform__mutmut_2, 
        'xǁExtractFeaturesǁtransform__mutmut_3': xǁExtractFeaturesǁtransform__mutmut_3, 
        'xǁExtractFeaturesǁtransform__mutmut_4': xǁExtractFeaturesǁtransform__mutmut_4, 
        'xǁExtractFeaturesǁtransform__mutmut_5': xǁExtractFeaturesǁtransform__mutmut_5, 
        'xǁExtractFeaturesǁtransform__mutmut_6': xǁExtractFeaturesǁtransform__mutmut_6, 
        'xǁExtractFeaturesǁtransform__mutmut_7': xǁExtractFeaturesǁtransform__mutmut_7, 
        'xǁExtractFeaturesǁtransform__mutmut_8': xǁExtractFeaturesǁtransform__mutmut_8, 
        'xǁExtractFeaturesǁtransform__mutmut_9': xǁExtractFeaturesǁtransform__mutmut_9, 
        'xǁExtractFeaturesǁtransform__mutmut_10': xǁExtractFeaturesǁtransform__mutmut_10, 
        'xǁExtractFeaturesǁtransform__mutmut_11': xǁExtractFeaturesǁtransform__mutmut_11, 
        'xǁExtractFeaturesǁtransform__mutmut_12': xǁExtractFeaturesǁtransform__mutmut_12, 
        'xǁExtractFeaturesǁtransform__mutmut_13': xǁExtractFeaturesǁtransform__mutmut_13, 
        'xǁExtractFeaturesǁtransform__mutmut_14': xǁExtractFeaturesǁtransform__mutmut_14, 
        'xǁExtractFeaturesǁtransform__mutmut_15': xǁExtractFeaturesǁtransform__mutmut_15, 
        'xǁExtractFeaturesǁtransform__mutmut_16': xǁExtractFeaturesǁtransform__mutmut_16, 
        'xǁExtractFeaturesǁtransform__mutmut_17': xǁExtractFeaturesǁtransform__mutmut_17, 
        'xǁExtractFeaturesǁtransform__mutmut_18': xǁExtractFeaturesǁtransform__mutmut_18, 
        'xǁExtractFeaturesǁtransform__mutmut_19': xǁExtractFeaturesǁtransform__mutmut_19, 
        'xǁExtractFeaturesǁtransform__mutmut_20': xǁExtractFeaturesǁtransform__mutmut_20, 
        'xǁExtractFeaturesǁtransform__mutmut_21': xǁExtractFeaturesǁtransform__mutmut_21, 
        'xǁExtractFeaturesǁtransform__mutmut_22': xǁExtractFeaturesǁtransform__mutmut_22, 
        'xǁExtractFeaturesǁtransform__mutmut_23': xǁExtractFeaturesǁtransform__mutmut_23, 
        'xǁExtractFeaturesǁtransform__mutmut_24': xǁExtractFeaturesǁtransform__mutmut_24, 
        'xǁExtractFeaturesǁtransform__mutmut_25': xǁExtractFeaturesǁtransform__mutmut_25, 
        'xǁExtractFeaturesǁtransform__mutmut_26': xǁExtractFeaturesǁtransform__mutmut_26, 
        'xǁExtractFeaturesǁtransform__mutmut_27': xǁExtractFeaturesǁtransform__mutmut_27, 
        'xǁExtractFeaturesǁtransform__mutmut_28': xǁExtractFeaturesǁtransform__mutmut_28, 
        'xǁExtractFeaturesǁtransform__mutmut_29': xǁExtractFeaturesǁtransform__mutmut_29, 
        'xǁExtractFeaturesǁtransform__mutmut_30': xǁExtractFeaturesǁtransform__mutmut_30, 
        'xǁExtractFeaturesǁtransform__mutmut_31': xǁExtractFeaturesǁtransform__mutmut_31, 
        'xǁExtractFeaturesǁtransform__mutmut_32': xǁExtractFeaturesǁtransform__mutmut_32, 
        'xǁExtractFeaturesǁtransform__mutmut_33': xǁExtractFeaturesǁtransform__mutmut_33, 
        'xǁExtractFeaturesǁtransform__mutmut_34': xǁExtractFeaturesǁtransform__mutmut_34, 
        'xǁExtractFeaturesǁtransform__mutmut_35': xǁExtractFeaturesǁtransform__mutmut_35, 
        'xǁExtractFeaturesǁtransform__mutmut_36': xǁExtractFeaturesǁtransform__mutmut_36
    }
    
    def transform(self, *args, **kwargs):
        result = _mutmut_trampoline(object.__getattribute__(self, "xǁExtractFeaturesǁtransform__mutmut_orig"), object.__getattribute__(self, "xǁExtractFeaturesǁtransform__mutmut_mutants"), args, kwargs, self)
        return result 
    
    transform.__signature__ = _mutmut_signature(xǁExtractFeaturesǁtransform__mutmut_orig)
    xǁExtractFeaturesǁtransform__mutmut_orig.__name__ = 'xǁExtractFeaturesǁtransform'

    @property
    def band_labels(self) -> List[str]:
        # Retourne les noms de bandes dans l'ordre déclaré
        return [band_name for band_name, _ in self._band_items]

    def xǁExtractFeaturesǁ_normalize_feature_families__mutmut_orig(self) -> List[Tuple[str, str]]:
        """Valide et normalise la sélection de familles de features."""

        if isinstance(self.feature_strategy, str):
            feature_families: List[str] = [self.feature_strategy]
        else:
            try:
                feature_families = list(self.feature_strategy)
            except TypeError as exc:  # pragma: no cover - defensive
                raise ValueError(
                    "feature_strategy must be a string or sequence of strings."
                ) from exc

        if not feature_families:
            raise ValueError(
                "feature_strategy must include at least one feature family."
            )

        normalized: List[Tuple[str, str]] = []
        for feature_family in feature_families:
            if not isinstance(feature_family, str):
                raise ValueError(
                    "Each feature family must be provided as a non-empty string."
                )
            cleaned = feature_family.strip().lower()
            if not cleaned:
                raise ValueError(
                    "Each feature family must be provided as a non-empty string."
                )
            normalized.append((feature_family, cleaned))

        return normalized

    def xǁExtractFeaturesǁ_normalize_feature_families__mutmut_1(self) -> List[Tuple[str, str]]:
        """Valide et normalise la sélection de familles de features."""

        if isinstance(self.feature_strategy, str):
            feature_families: List[str] = None
        else:
            try:
                feature_families = list(self.feature_strategy)
            except TypeError as exc:  # pragma: no cover - defensive
                raise ValueError(
                    "feature_strategy must be a string or sequence of strings."
                ) from exc

        if not feature_families:
            raise ValueError(
                "feature_strategy must include at least one feature family."
            )

        normalized: List[Tuple[str, str]] = []
        for feature_family in feature_families:
            if not isinstance(feature_family, str):
                raise ValueError(
                    "Each feature family must be provided as a non-empty string."
                )
            cleaned = feature_family.strip().lower()
            if not cleaned:
                raise ValueError(
                    "Each feature family must be provided as a non-empty string."
                )
            normalized.append((feature_family, cleaned))

        return normalized

    def xǁExtractFeaturesǁ_normalize_feature_families__mutmut_2(self) -> List[Tuple[str, str]]:
        """Valide et normalise la sélection de familles de features."""

        if isinstance(self.feature_strategy, str):
            feature_families: List[str] = [self.feature_strategy]
        else:
            try:
                feature_families = None
            except TypeError as exc:  # pragma: no cover - defensive
                raise ValueError(
                    "feature_strategy must be a string or sequence of strings."
                ) from exc

        if not feature_families:
            raise ValueError(
                "feature_strategy must include at least one feature family."
            )

        normalized: List[Tuple[str, str]] = []
        for feature_family in feature_families:
            if not isinstance(feature_family, str):
                raise ValueError(
                    "Each feature family must be provided as a non-empty string."
                )
            cleaned = feature_family.strip().lower()
            if not cleaned:
                raise ValueError(
                    "Each feature family must be provided as a non-empty string."
                )
            normalized.append((feature_family, cleaned))

        return normalized

    def xǁExtractFeaturesǁ_normalize_feature_families__mutmut_3(self) -> List[Tuple[str, str]]:
        """Valide et normalise la sélection de familles de features."""

        if isinstance(self.feature_strategy, str):
            feature_families: List[str] = [self.feature_strategy]
        else:
            try:
                feature_families = list(None)
            except TypeError as exc:  # pragma: no cover - defensive
                raise ValueError(
                    "feature_strategy must be a string or sequence of strings."
                ) from exc

        if not feature_families:
            raise ValueError(
                "feature_strategy must include at least one feature family."
            )

        normalized: List[Tuple[str, str]] = []
        for feature_family in feature_families:
            if not isinstance(feature_family, str):
                raise ValueError(
                    "Each feature family must be provided as a non-empty string."
                )
            cleaned = feature_family.strip().lower()
            if not cleaned:
                raise ValueError(
                    "Each feature family must be provided as a non-empty string."
                )
            normalized.append((feature_family, cleaned))

        return normalized

    def xǁExtractFeaturesǁ_normalize_feature_families__mutmut_4(self) -> List[Tuple[str, str]]:
        """Valide et normalise la sélection de familles de features."""

        if isinstance(self.feature_strategy, str):
            feature_families: List[str] = [self.feature_strategy]
        else:
            try:
                feature_families = list(self.feature_strategy)
            except TypeError as exc:  # pragma: no cover - defensive
                raise ValueError(
                    "feature_strategy must be a string or sequence of strings."
                ) from exc

        if feature_families:
            raise ValueError(
                "feature_strategy must include at least one feature family."
            )

        normalized: List[Tuple[str, str]] = []
        for feature_family in feature_families:
            if not isinstance(feature_family, str):
                raise ValueError(
                    "Each feature family must be provided as a non-empty string."
                )
            cleaned = feature_family.strip().lower()
            if not cleaned:
                raise ValueError(
                    "Each feature family must be provided as a non-empty string."
                )
            normalized.append((feature_family, cleaned))

        return normalized

    def xǁExtractFeaturesǁ_normalize_feature_families__mutmut_5(self) -> List[Tuple[str, str]]:
        """Valide et normalise la sélection de familles de features."""

        if isinstance(self.feature_strategy, str):
            feature_families: List[str] = [self.feature_strategy]
        else:
            try:
                feature_families = list(self.feature_strategy)
            except TypeError as exc:  # pragma: no cover - defensive
                raise ValueError(
                    "feature_strategy must be a string or sequence of strings."
                ) from exc

        if not feature_families:
            raise ValueError(
                None
            )

        normalized: List[Tuple[str, str]] = []
        for feature_family in feature_families:
            if not isinstance(feature_family, str):
                raise ValueError(
                    "Each feature family must be provided as a non-empty string."
                )
            cleaned = feature_family.strip().lower()
            if not cleaned:
                raise ValueError(
                    "Each feature family must be provided as a non-empty string."
                )
            normalized.append((feature_family, cleaned))

        return normalized

    def xǁExtractFeaturesǁ_normalize_feature_families__mutmut_6(self) -> List[Tuple[str, str]]:
        """Valide et normalise la sélection de familles de features."""

        if isinstance(self.feature_strategy, str):
            feature_families: List[str] = [self.feature_strategy]
        else:
            try:
                feature_families = list(self.feature_strategy)
            except TypeError as exc:  # pragma: no cover - defensive
                raise ValueError(
                    "feature_strategy must be a string or sequence of strings."
                ) from exc

        if not feature_families:
            raise ValueError(
                "XXfeature_strategy must include at least one feature family.XX"
            )

        normalized: List[Tuple[str, str]] = []
        for feature_family in feature_families:
            if not isinstance(feature_family, str):
                raise ValueError(
                    "Each feature family must be provided as a non-empty string."
                )
            cleaned = feature_family.strip().lower()
            if not cleaned:
                raise ValueError(
                    "Each feature family must be provided as a non-empty string."
                )
            normalized.append((feature_family, cleaned))

        return normalized

    def xǁExtractFeaturesǁ_normalize_feature_families__mutmut_7(self) -> List[Tuple[str, str]]:
        """Valide et normalise la sélection de familles de features."""

        if isinstance(self.feature_strategy, str):
            feature_families: List[str] = [self.feature_strategy]
        else:
            try:
                feature_families = list(self.feature_strategy)
            except TypeError as exc:  # pragma: no cover - defensive
                raise ValueError(
                    "feature_strategy must be a string or sequence of strings."
                ) from exc

        if not feature_families:
            raise ValueError(
                "FEATURE_STRATEGY MUST INCLUDE AT LEAST ONE FEATURE FAMILY."
            )

        normalized: List[Tuple[str, str]] = []
        for feature_family in feature_families:
            if not isinstance(feature_family, str):
                raise ValueError(
                    "Each feature family must be provided as a non-empty string."
                )
            cleaned = feature_family.strip().lower()
            if not cleaned:
                raise ValueError(
                    "Each feature family must be provided as a non-empty string."
                )
            normalized.append((feature_family, cleaned))

        return normalized

    def xǁExtractFeaturesǁ_normalize_feature_families__mutmut_8(self) -> List[Tuple[str, str]]:
        """Valide et normalise la sélection de familles de features."""

        if isinstance(self.feature_strategy, str):
            feature_families: List[str] = [self.feature_strategy]
        else:
            try:
                feature_families = list(self.feature_strategy)
            except TypeError as exc:  # pragma: no cover - defensive
                raise ValueError(
                    "feature_strategy must be a string or sequence of strings."
                ) from exc

        if not feature_families:
            raise ValueError(
                "feature_strategy must include at least one feature family."
            )

        normalized: List[Tuple[str, str]] = None
        for feature_family in feature_families:
            if not isinstance(feature_family, str):
                raise ValueError(
                    "Each feature family must be provided as a non-empty string."
                )
            cleaned = feature_family.strip().lower()
            if not cleaned:
                raise ValueError(
                    "Each feature family must be provided as a non-empty string."
                )
            normalized.append((feature_family, cleaned))

        return normalized

    def xǁExtractFeaturesǁ_normalize_feature_families__mutmut_9(self) -> List[Tuple[str, str]]:
        """Valide et normalise la sélection de familles de features."""

        if isinstance(self.feature_strategy, str):
            feature_families: List[str] = [self.feature_strategy]
        else:
            try:
                feature_families = list(self.feature_strategy)
            except TypeError as exc:  # pragma: no cover - defensive
                raise ValueError(
                    "feature_strategy must be a string or sequence of strings."
                ) from exc

        if not feature_families:
            raise ValueError(
                "feature_strategy must include at least one feature family."
            )

        normalized: List[Tuple[str, str]] = []
        for feature_family in feature_families:
            if isinstance(feature_family, str):
                raise ValueError(
                    "Each feature family must be provided as a non-empty string."
                )
            cleaned = feature_family.strip().lower()
            if not cleaned:
                raise ValueError(
                    "Each feature family must be provided as a non-empty string."
                )
            normalized.append((feature_family, cleaned))

        return normalized

    def xǁExtractFeaturesǁ_normalize_feature_families__mutmut_10(self) -> List[Tuple[str, str]]:
        """Valide et normalise la sélection de familles de features."""

        if isinstance(self.feature_strategy, str):
            feature_families: List[str] = [self.feature_strategy]
        else:
            try:
                feature_families = list(self.feature_strategy)
            except TypeError as exc:  # pragma: no cover - defensive
                raise ValueError(
                    "feature_strategy must be a string or sequence of strings."
                ) from exc

        if not feature_families:
            raise ValueError(
                "feature_strategy must include at least one feature family."
            )

        normalized: List[Tuple[str, str]] = []
        for feature_family in feature_families:
            if not isinstance(feature_family, str):
                raise ValueError(
                    "Each feature family must be provided as a non-empty string."
                )
            cleaned = None
            if not cleaned:
                raise ValueError(
                    "Each feature family must be provided as a non-empty string."
                )
            normalized.append((feature_family, cleaned))

        return normalized

    def xǁExtractFeaturesǁ_normalize_feature_families__mutmut_11(self) -> List[Tuple[str, str]]:
        """Valide et normalise la sélection de familles de features."""

        if isinstance(self.feature_strategy, str):
            feature_families: List[str] = [self.feature_strategy]
        else:
            try:
                feature_families = list(self.feature_strategy)
            except TypeError as exc:  # pragma: no cover - defensive
                raise ValueError(
                    "feature_strategy must be a string or sequence of strings."
                ) from exc

        if not feature_families:
            raise ValueError(
                "feature_strategy must include at least one feature family."
            )

        normalized: List[Tuple[str, str]] = []
        for feature_family in feature_families:
            if not isinstance(feature_family, str):
                raise ValueError(
                    "Each feature family must be provided as a non-empty string."
                )
            cleaned = feature_family.strip().upper()
            if not cleaned:
                raise ValueError(
                    "Each feature family must be provided as a non-empty string."
                )
            normalized.append((feature_family, cleaned))

        return normalized

    def xǁExtractFeaturesǁ_normalize_feature_families__mutmut_12(self) -> List[Tuple[str, str]]:
        """Valide et normalise la sélection de familles de features."""

        if isinstance(self.feature_strategy, str):
            feature_families: List[str] = [self.feature_strategy]
        else:
            try:
                feature_families = list(self.feature_strategy)
            except TypeError as exc:  # pragma: no cover - defensive
                raise ValueError(
                    "feature_strategy must be a string or sequence of strings."
                ) from exc

        if not feature_families:
            raise ValueError(
                "feature_strategy must include at least one feature family."
            )

        normalized: List[Tuple[str, str]] = []
        for feature_family in feature_families:
            if not isinstance(feature_family, str):
                raise ValueError(
                    "Each feature family must be provided as a non-empty string."
                )
            cleaned = feature_family.strip().lower()
            if cleaned:
                raise ValueError(
                    "Each feature family must be provided as a non-empty string."
                )
            normalized.append((feature_family, cleaned))

        return normalized

    def xǁExtractFeaturesǁ_normalize_feature_families__mutmut_13(self) -> List[Tuple[str, str]]:
        """Valide et normalise la sélection de familles de features."""

        if isinstance(self.feature_strategy, str):
            feature_families: List[str] = [self.feature_strategy]
        else:
            try:
                feature_families = list(self.feature_strategy)
            except TypeError as exc:  # pragma: no cover - defensive
                raise ValueError(
                    "feature_strategy must be a string or sequence of strings."
                ) from exc

        if not feature_families:
            raise ValueError(
                "feature_strategy must include at least one feature family."
            )

        normalized: List[Tuple[str, str]] = []
        for feature_family in feature_families:
            if not isinstance(feature_family, str):
                raise ValueError(
                    "Each feature family must be provided as a non-empty string."
                )
            cleaned = feature_family.strip().lower()
            if not cleaned:
                raise ValueError(
                    "Each feature family must be provided as a non-empty string."
                )
            normalized.append(None)

        return normalized
    
    xǁExtractFeaturesǁ_normalize_feature_families__mutmut_mutants : ClassVar[MutantDict] = {
    'xǁExtractFeaturesǁ_normalize_feature_families__mutmut_1': xǁExtractFeaturesǁ_normalize_feature_families__mutmut_1, 
        'xǁExtractFeaturesǁ_normalize_feature_families__mutmut_2': xǁExtractFeaturesǁ_normalize_feature_families__mutmut_2, 
        'xǁExtractFeaturesǁ_normalize_feature_families__mutmut_3': xǁExtractFeaturesǁ_normalize_feature_families__mutmut_3, 
        'xǁExtractFeaturesǁ_normalize_feature_families__mutmut_4': xǁExtractFeaturesǁ_normalize_feature_families__mutmut_4, 
        'xǁExtractFeaturesǁ_normalize_feature_families__mutmut_5': xǁExtractFeaturesǁ_normalize_feature_families__mutmut_5, 
        'xǁExtractFeaturesǁ_normalize_feature_families__mutmut_6': xǁExtractFeaturesǁ_normalize_feature_families__mutmut_6, 
        'xǁExtractFeaturesǁ_normalize_feature_families__mutmut_7': xǁExtractFeaturesǁ_normalize_feature_families__mutmut_7, 
        'xǁExtractFeaturesǁ_normalize_feature_families__mutmut_8': xǁExtractFeaturesǁ_normalize_feature_families__mutmut_8, 
        'xǁExtractFeaturesǁ_normalize_feature_families__mutmut_9': xǁExtractFeaturesǁ_normalize_feature_families__mutmut_9, 
        'xǁExtractFeaturesǁ_normalize_feature_families__mutmut_10': xǁExtractFeaturesǁ_normalize_feature_families__mutmut_10, 
        'xǁExtractFeaturesǁ_normalize_feature_families__mutmut_11': xǁExtractFeaturesǁ_normalize_feature_families__mutmut_11, 
        'xǁExtractFeaturesǁ_normalize_feature_families__mutmut_12': xǁExtractFeaturesǁ_normalize_feature_families__mutmut_12, 
        'xǁExtractFeaturesǁ_normalize_feature_families__mutmut_13': xǁExtractFeaturesǁ_normalize_feature_families__mutmut_13
    }
    
    def _normalize_feature_families(self, *args, **kwargs):
        result = _mutmut_trampoline(object.__getattribute__(self, "xǁExtractFeaturesǁ_normalize_feature_families__mutmut_orig"), object.__getattribute__(self, "xǁExtractFeaturesǁ_normalize_feature_families__mutmut_mutants"), args, kwargs, self)
        return result 
    
    _normalize_feature_families.__signature__ = _mutmut_signature(xǁExtractFeaturesǁ_normalize_feature_families__mutmut_orig)
    xǁExtractFeaturesǁ_normalize_feature_families__mutmut_orig.__name__ = 'xǁExtractFeaturesǁ_normalize_feature_families'

    def xǁExtractFeaturesǁ_compute_features__mutmut_orig(self, X: np.ndarray) -> np.ndarray:
        """Dispatch interne vers la ou les stratégies de features demandées."""

        strategy_handlers = {
            "fft": self._compute_fft_features,
            "wavelet": self._compute_wavelet_features,
            "welch": self._compute_welch_features,
        }

        feature_blocks: List[np.ndarray] = []
        for original_family, normalized_family in self._normalize_feature_families():
            handler = strategy_handlers.get(normalized_family)
            if handler is None:
                raise ValueError(
                    f"Unsupported feature_strategy: {original_family!r}. "
                    "Use 'fft', 'welch', or 'wavelet'."
                )
            feature_blocks.append(handler(X))

        if len(feature_blocks) == 1:
            return feature_blocks[0]

        # Concatène les blocs en conservant l'alignement des échantillons
        n_samples = feature_blocks[0].shape[0]
        for block in feature_blocks[1:]:
            if block.shape[0] != n_samples:  # pragma: no cover - cohérence interne
                raise ValueError(
                    "All feature families must yield the same sample count."
                )

        return np.concatenate(feature_blocks, axis=1)

    def xǁExtractFeaturesǁ_compute_features__mutmut_1(self, X: np.ndarray) -> np.ndarray:
        """Dispatch interne vers la ou les stratégies de features demandées."""

        strategy_handlers = None

        feature_blocks: List[np.ndarray] = []
        for original_family, normalized_family in self._normalize_feature_families():
            handler = strategy_handlers.get(normalized_family)
            if handler is None:
                raise ValueError(
                    f"Unsupported feature_strategy: {original_family!r}. "
                    "Use 'fft', 'welch', or 'wavelet'."
                )
            feature_blocks.append(handler(X))

        if len(feature_blocks) == 1:
            return feature_blocks[0]

        # Concatène les blocs en conservant l'alignement des échantillons
        n_samples = feature_blocks[0].shape[0]
        for block in feature_blocks[1:]:
            if block.shape[0] != n_samples:  # pragma: no cover - cohérence interne
                raise ValueError(
                    "All feature families must yield the same sample count."
                )

        return np.concatenate(feature_blocks, axis=1)

    def xǁExtractFeaturesǁ_compute_features__mutmut_2(self, X: np.ndarray) -> np.ndarray:
        """Dispatch interne vers la ou les stratégies de features demandées."""

        strategy_handlers = {
            "XXfftXX": self._compute_fft_features,
            "wavelet": self._compute_wavelet_features,
            "welch": self._compute_welch_features,
        }

        feature_blocks: List[np.ndarray] = []
        for original_family, normalized_family in self._normalize_feature_families():
            handler = strategy_handlers.get(normalized_family)
            if handler is None:
                raise ValueError(
                    f"Unsupported feature_strategy: {original_family!r}. "
                    "Use 'fft', 'welch', or 'wavelet'."
                )
            feature_blocks.append(handler(X))

        if len(feature_blocks) == 1:
            return feature_blocks[0]

        # Concatène les blocs en conservant l'alignement des échantillons
        n_samples = feature_blocks[0].shape[0]
        for block in feature_blocks[1:]:
            if block.shape[0] != n_samples:  # pragma: no cover - cohérence interne
                raise ValueError(
                    "All feature families must yield the same sample count."
                )

        return np.concatenate(feature_blocks, axis=1)

    def xǁExtractFeaturesǁ_compute_features__mutmut_3(self, X: np.ndarray) -> np.ndarray:
        """Dispatch interne vers la ou les stratégies de features demandées."""

        strategy_handlers = {
            "FFT": self._compute_fft_features,
            "wavelet": self._compute_wavelet_features,
            "welch": self._compute_welch_features,
        }

        feature_blocks: List[np.ndarray] = []
        for original_family, normalized_family in self._normalize_feature_families():
            handler = strategy_handlers.get(normalized_family)
            if handler is None:
                raise ValueError(
                    f"Unsupported feature_strategy: {original_family!r}. "
                    "Use 'fft', 'welch', or 'wavelet'."
                )
            feature_blocks.append(handler(X))

        if len(feature_blocks) == 1:
            return feature_blocks[0]

        # Concatène les blocs en conservant l'alignement des échantillons
        n_samples = feature_blocks[0].shape[0]
        for block in feature_blocks[1:]:
            if block.shape[0] != n_samples:  # pragma: no cover - cohérence interne
                raise ValueError(
                    "All feature families must yield the same sample count."
                )

        return np.concatenate(feature_blocks, axis=1)

    def xǁExtractFeaturesǁ_compute_features__mutmut_4(self, X: np.ndarray) -> np.ndarray:
        """Dispatch interne vers la ou les stratégies de features demandées."""

        strategy_handlers = {
            "fft": self._compute_fft_features,
            "XXwaveletXX": self._compute_wavelet_features,
            "welch": self._compute_welch_features,
        }

        feature_blocks: List[np.ndarray] = []
        for original_family, normalized_family in self._normalize_feature_families():
            handler = strategy_handlers.get(normalized_family)
            if handler is None:
                raise ValueError(
                    f"Unsupported feature_strategy: {original_family!r}. "
                    "Use 'fft', 'welch', or 'wavelet'."
                )
            feature_blocks.append(handler(X))

        if len(feature_blocks) == 1:
            return feature_blocks[0]

        # Concatène les blocs en conservant l'alignement des échantillons
        n_samples = feature_blocks[0].shape[0]
        for block in feature_blocks[1:]:
            if block.shape[0] != n_samples:  # pragma: no cover - cohérence interne
                raise ValueError(
                    "All feature families must yield the same sample count."
                )

        return np.concatenate(feature_blocks, axis=1)

    def xǁExtractFeaturesǁ_compute_features__mutmut_5(self, X: np.ndarray) -> np.ndarray:
        """Dispatch interne vers la ou les stratégies de features demandées."""

        strategy_handlers = {
            "fft": self._compute_fft_features,
            "WAVELET": self._compute_wavelet_features,
            "welch": self._compute_welch_features,
        }

        feature_blocks: List[np.ndarray] = []
        for original_family, normalized_family in self._normalize_feature_families():
            handler = strategy_handlers.get(normalized_family)
            if handler is None:
                raise ValueError(
                    f"Unsupported feature_strategy: {original_family!r}. "
                    "Use 'fft', 'welch', or 'wavelet'."
                )
            feature_blocks.append(handler(X))

        if len(feature_blocks) == 1:
            return feature_blocks[0]

        # Concatène les blocs en conservant l'alignement des échantillons
        n_samples = feature_blocks[0].shape[0]
        for block in feature_blocks[1:]:
            if block.shape[0] != n_samples:  # pragma: no cover - cohérence interne
                raise ValueError(
                    "All feature families must yield the same sample count."
                )

        return np.concatenate(feature_blocks, axis=1)

    def xǁExtractFeaturesǁ_compute_features__mutmut_6(self, X: np.ndarray) -> np.ndarray:
        """Dispatch interne vers la ou les stratégies de features demandées."""

        strategy_handlers = {
            "fft": self._compute_fft_features,
            "wavelet": self._compute_wavelet_features,
            "XXwelchXX": self._compute_welch_features,
        }

        feature_blocks: List[np.ndarray] = []
        for original_family, normalized_family in self._normalize_feature_families():
            handler = strategy_handlers.get(normalized_family)
            if handler is None:
                raise ValueError(
                    f"Unsupported feature_strategy: {original_family!r}. "
                    "Use 'fft', 'welch', or 'wavelet'."
                )
            feature_blocks.append(handler(X))

        if len(feature_blocks) == 1:
            return feature_blocks[0]

        # Concatène les blocs en conservant l'alignement des échantillons
        n_samples = feature_blocks[0].shape[0]
        for block in feature_blocks[1:]:
            if block.shape[0] != n_samples:  # pragma: no cover - cohérence interne
                raise ValueError(
                    "All feature families must yield the same sample count."
                )

        return np.concatenate(feature_blocks, axis=1)

    def xǁExtractFeaturesǁ_compute_features__mutmut_7(self, X: np.ndarray) -> np.ndarray:
        """Dispatch interne vers la ou les stratégies de features demandées."""

        strategy_handlers = {
            "fft": self._compute_fft_features,
            "wavelet": self._compute_wavelet_features,
            "WELCH": self._compute_welch_features,
        }

        feature_blocks: List[np.ndarray] = []
        for original_family, normalized_family in self._normalize_feature_families():
            handler = strategy_handlers.get(normalized_family)
            if handler is None:
                raise ValueError(
                    f"Unsupported feature_strategy: {original_family!r}. "
                    "Use 'fft', 'welch', or 'wavelet'."
                )
            feature_blocks.append(handler(X))

        if len(feature_blocks) == 1:
            return feature_blocks[0]

        # Concatène les blocs en conservant l'alignement des échantillons
        n_samples = feature_blocks[0].shape[0]
        for block in feature_blocks[1:]:
            if block.shape[0] != n_samples:  # pragma: no cover - cohérence interne
                raise ValueError(
                    "All feature families must yield the same sample count."
                )

        return np.concatenate(feature_blocks, axis=1)

    def xǁExtractFeaturesǁ_compute_features__mutmut_8(self, X: np.ndarray) -> np.ndarray:
        """Dispatch interne vers la ou les stratégies de features demandées."""

        strategy_handlers = {
            "fft": self._compute_fft_features,
            "wavelet": self._compute_wavelet_features,
            "welch": self._compute_welch_features,
        }

        feature_blocks: List[np.ndarray] = None
        for original_family, normalized_family in self._normalize_feature_families():
            handler = strategy_handlers.get(normalized_family)
            if handler is None:
                raise ValueError(
                    f"Unsupported feature_strategy: {original_family!r}. "
                    "Use 'fft', 'welch', or 'wavelet'."
                )
            feature_blocks.append(handler(X))

        if len(feature_blocks) == 1:
            return feature_blocks[0]

        # Concatène les blocs en conservant l'alignement des échantillons
        n_samples = feature_blocks[0].shape[0]
        for block in feature_blocks[1:]:
            if block.shape[0] != n_samples:  # pragma: no cover - cohérence interne
                raise ValueError(
                    "All feature families must yield the same sample count."
                )

        return np.concatenate(feature_blocks, axis=1)

    def xǁExtractFeaturesǁ_compute_features__mutmut_9(self, X: np.ndarray) -> np.ndarray:
        """Dispatch interne vers la ou les stratégies de features demandées."""

        strategy_handlers = {
            "fft": self._compute_fft_features,
            "wavelet": self._compute_wavelet_features,
            "welch": self._compute_welch_features,
        }

        feature_blocks: List[np.ndarray] = []
        for original_family, normalized_family in self._normalize_feature_families():
            handler = None
            if handler is None:
                raise ValueError(
                    f"Unsupported feature_strategy: {original_family!r}. "
                    "Use 'fft', 'welch', or 'wavelet'."
                )
            feature_blocks.append(handler(X))

        if len(feature_blocks) == 1:
            return feature_blocks[0]

        # Concatène les blocs en conservant l'alignement des échantillons
        n_samples = feature_blocks[0].shape[0]
        for block in feature_blocks[1:]:
            if block.shape[0] != n_samples:  # pragma: no cover - cohérence interne
                raise ValueError(
                    "All feature families must yield the same sample count."
                )

        return np.concatenate(feature_blocks, axis=1)

    def xǁExtractFeaturesǁ_compute_features__mutmut_10(self, X: np.ndarray) -> np.ndarray:
        """Dispatch interne vers la ou les stratégies de features demandées."""

        strategy_handlers = {
            "fft": self._compute_fft_features,
            "wavelet": self._compute_wavelet_features,
            "welch": self._compute_welch_features,
        }

        feature_blocks: List[np.ndarray] = []
        for original_family, normalized_family in self._normalize_feature_families():
            handler = strategy_handlers.get(None)
            if handler is None:
                raise ValueError(
                    f"Unsupported feature_strategy: {original_family!r}. "
                    "Use 'fft', 'welch', or 'wavelet'."
                )
            feature_blocks.append(handler(X))

        if len(feature_blocks) == 1:
            return feature_blocks[0]

        # Concatène les blocs en conservant l'alignement des échantillons
        n_samples = feature_blocks[0].shape[0]
        for block in feature_blocks[1:]:
            if block.shape[0] != n_samples:  # pragma: no cover - cohérence interne
                raise ValueError(
                    "All feature families must yield the same sample count."
                )

        return np.concatenate(feature_blocks, axis=1)

    def xǁExtractFeaturesǁ_compute_features__mutmut_11(self, X: np.ndarray) -> np.ndarray:
        """Dispatch interne vers la ou les stratégies de features demandées."""

        strategy_handlers = {
            "fft": self._compute_fft_features,
            "wavelet": self._compute_wavelet_features,
            "welch": self._compute_welch_features,
        }

        feature_blocks: List[np.ndarray] = []
        for original_family, normalized_family in self._normalize_feature_families():
            handler = strategy_handlers.get(normalized_family)
            if handler is not None:
                raise ValueError(
                    f"Unsupported feature_strategy: {original_family!r}. "
                    "Use 'fft', 'welch', or 'wavelet'."
                )
            feature_blocks.append(handler(X))

        if len(feature_blocks) == 1:
            return feature_blocks[0]

        # Concatène les blocs en conservant l'alignement des échantillons
        n_samples = feature_blocks[0].shape[0]
        for block in feature_blocks[1:]:
            if block.shape[0] != n_samples:  # pragma: no cover - cohérence interne
                raise ValueError(
                    "All feature families must yield the same sample count."
                )

        return np.concatenate(feature_blocks, axis=1)

    def xǁExtractFeaturesǁ_compute_features__mutmut_12(self, X: np.ndarray) -> np.ndarray:
        """Dispatch interne vers la ou les stratégies de features demandées."""

        strategy_handlers = {
            "fft": self._compute_fft_features,
            "wavelet": self._compute_wavelet_features,
            "welch": self._compute_welch_features,
        }

        feature_blocks: List[np.ndarray] = []
        for original_family, normalized_family in self._normalize_feature_families():
            handler = strategy_handlers.get(normalized_family)
            if handler is None:
                raise ValueError(
                    None
                )
            feature_blocks.append(handler(X))

        if len(feature_blocks) == 1:
            return feature_blocks[0]

        # Concatène les blocs en conservant l'alignement des échantillons
        n_samples = feature_blocks[0].shape[0]
        for block in feature_blocks[1:]:
            if block.shape[0] != n_samples:  # pragma: no cover - cohérence interne
                raise ValueError(
                    "All feature families must yield the same sample count."
                )

        return np.concatenate(feature_blocks, axis=1)

    def xǁExtractFeaturesǁ_compute_features__mutmut_13(self, X: np.ndarray) -> np.ndarray:
        """Dispatch interne vers la ou les stratégies de features demandées."""

        strategy_handlers = {
            "fft": self._compute_fft_features,
            "wavelet": self._compute_wavelet_features,
            "welch": self._compute_welch_features,
        }

        feature_blocks: List[np.ndarray] = []
        for original_family, normalized_family in self._normalize_feature_families():
            handler = strategy_handlers.get(normalized_family)
            if handler is None:
                raise ValueError(
                    f"Unsupported feature_strategy: {original_family!r}. "
                    "Use 'fft', 'welch', or 'wavelet'."
                )
            feature_blocks.append(None)

        if len(feature_blocks) == 1:
            return feature_blocks[0]

        # Concatène les blocs en conservant l'alignement des échantillons
        n_samples = feature_blocks[0].shape[0]
        for block in feature_blocks[1:]:
            if block.shape[0] != n_samples:  # pragma: no cover - cohérence interne
                raise ValueError(
                    "All feature families must yield the same sample count."
                )

        return np.concatenate(feature_blocks, axis=1)

    def xǁExtractFeaturesǁ_compute_features__mutmut_14(self, X: np.ndarray) -> np.ndarray:
        """Dispatch interne vers la ou les stratégies de features demandées."""

        strategy_handlers = {
            "fft": self._compute_fft_features,
            "wavelet": self._compute_wavelet_features,
            "welch": self._compute_welch_features,
        }

        feature_blocks: List[np.ndarray] = []
        for original_family, normalized_family in self._normalize_feature_families():
            handler = strategy_handlers.get(normalized_family)
            if handler is None:
                raise ValueError(
                    f"Unsupported feature_strategy: {original_family!r}. "
                    "Use 'fft', 'welch', or 'wavelet'."
                )
            feature_blocks.append(handler(None))

        if len(feature_blocks) == 1:
            return feature_blocks[0]

        # Concatène les blocs en conservant l'alignement des échantillons
        n_samples = feature_blocks[0].shape[0]
        for block in feature_blocks[1:]:
            if block.shape[0] != n_samples:  # pragma: no cover - cohérence interne
                raise ValueError(
                    "All feature families must yield the same sample count."
                )

        return np.concatenate(feature_blocks, axis=1)

    def xǁExtractFeaturesǁ_compute_features__mutmut_15(self, X: np.ndarray) -> np.ndarray:
        """Dispatch interne vers la ou les stratégies de features demandées."""

        strategy_handlers = {
            "fft": self._compute_fft_features,
            "wavelet": self._compute_wavelet_features,
            "welch": self._compute_welch_features,
        }

        feature_blocks: List[np.ndarray] = []
        for original_family, normalized_family in self._normalize_feature_families():
            handler = strategy_handlers.get(normalized_family)
            if handler is None:
                raise ValueError(
                    f"Unsupported feature_strategy: {original_family!r}. "
                    "Use 'fft', 'welch', or 'wavelet'."
                )
            feature_blocks.append(handler(X))

        if len(feature_blocks) != 1:
            return feature_blocks[0]

        # Concatène les blocs en conservant l'alignement des échantillons
        n_samples = feature_blocks[0].shape[0]
        for block in feature_blocks[1:]:
            if block.shape[0] != n_samples:  # pragma: no cover - cohérence interne
                raise ValueError(
                    "All feature families must yield the same sample count."
                )

        return np.concatenate(feature_blocks, axis=1)

    def xǁExtractFeaturesǁ_compute_features__mutmut_16(self, X: np.ndarray) -> np.ndarray:
        """Dispatch interne vers la ou les stratégies de features demandées."""

        strategy_handlers = {
            "fft": self._compute_fft_features,
            "wavelet": self._compute_wavelet_features,
            "welch": self._compute_welch_features,
        }

        feature_blocks: List[np.ndarray] = []
        for original_family, normalized_family in self._normalize_feature_families():
            handler = strategy_handlers.get(normalized_family)
            if handler is None:
                raise ValueError(
                    f"Unsupported feature_strategy: {original_family!r}. "
                    "Use 'fft', 'welch', or 'wavelet'."
                )
            feature_blocks.append(handler(X))

        if len(feature_blocks) == 2:
            return feature_blocks[0]

        # Concatène les blocs en conservant l'alignement des échantillons
        n_samples = feature_blocks[0].shape[0]
        for block in feature_blocks[1:]:
            if block.shape[0] != n_samples:  # pragma: no cover - cohérence interne
                raise ValueError(
                    "All feature families must yield the same sample count."
                )

        return np.concatenate(feature_blocks, axis=1)

    def xǁExtractFeaturesǁ_compute_features__mutmut_17(self, X: np.ndarray) -> np.ndarray:
        """Dispatch interne vers la ou les stratégies de features demandées."""

        strategy_handlers = {
            "fft": self._compute_fft_features,
            "wavelet": self._compute_wavelet_features,
            "welch": self._compute_welch_features,
        }

        feature_blocks: List[np.ndarray] = []
        for original_family, normalized_family in self._normalize_feature_families():
            handler = strategy_handlers.get(normalized_family)
            if handler is None:
                raise ValueError(
                    f"Unsupported feature_strategy: {original_family!r}. "
                    "Use 'fft', 'welch', or 'wavelet'."
                )
            feature_blocks.append(handler(X))

        if len(feature_blocks) == 1:
            return feature_blocks[1]

        # Concatène les blocs en conservant l'alignement des échantillons
        n_samples = feature_blocks[0].shape[0]
        for block in feature_blocks[1:]:
            if block.shape[0] != n_samples:  # pragma: no cover - cohérence interne
                raise ValueError(
                    "All feature families must yield the same sample count."
                )

        return np.concatenate(feature_blocks, axis=1)

    def xǁExtractFeaturesǁ_compute_features__mutmut_18(self, X: np.ndarray) -> np.ndarray:
        """Dispatch interne vers la ou les stratégies de features demandées."""

        strategy_handlers = {
            "fft": self._compute_fft_features,
            "wavelet": self._compute_wavelet_features,
            "welch": self._compute_welch_features,
        }

        feature_blocks: List[np.ndarray] = []
        for original_family, normalized_family in self._normalize_feature_families():
            handler = strategy_handlers.get(normalized_family)
            if handler is None:
                raise ValueError(
                    f"Unsupported feature_strategy: {original_family!r}. "
                    "Use 'fft', 'welch', or 'wavelet'."
                )
            feature_blocks.append(handler(X))

        if len(feature_blocks) == 1:
            return feature_blocks[0]

        # Concatène les blocs en conservant l'alignement des échantillons
        n_samples = None
        for block in feature_blocks[1:]:
            if block.shape[0] != n_samples:  # pragma: no cover - cohérence interne
                raise ValueError(
                    "All feature families must yield the same sample count."
                )

        return np.concatenate(feature_blocks, axis=1)

    def xǁExtractFeaturesǁ_compute_features__mutmut_19(self, X: np.ndarray) -> np.ndarray:
        """Dispatch interne vers la ou les stratégies de features demandées."""

        strategy_handlers = {
            "fft": self._compute_fft_features,
            "wavelet": self._compute_wavelet_features,
            "welch": self._compute_welch_features,
        }

        feature_blocks: List[np.ndarray] = []
        for original_family, normalized_family in self._normalize_feature_families():
            handler = strategy_handlers.get(normalized_family)
            if handler is None:
                raise ValueError(
                    f"Unsupported feature_strategy: {original_family!r}. "
                    "Use 'fft', 'welch', or 'wavelet'."
                )
            feature_blocks.append(handler(X))

        if len(feature_blocks) == 1:
            return feature_blocks[0]

        # Concatène les blocs en conservant l'alignement des échantillons
        n_samples = feature_blocks[1].shape[0]
        for block in feature_blocks[1:]:
            if block.shape[0] != n_samples:  # pragma: no cover - cohérence interne
                raise ValueError(
                    "All feature families must yield the same sample count."
                )

        return np.concatenate(feature_blocks, axis=1)

    def xǁExtractFeaturesǁ_compute_features__mutmut_20(self, X: np.ndarray) -> np.ndarray:
        """Dispatch interne vers la ou les stratégies de features demandées."""

        strategy_handlers = {
            "fft": self._compute_fft_features,
            "wavelet": self._compute_wavelet_features,
            "welch": self._compute_welch_features,
        }

        feature_blocks: List[np.ndarray] = []
        for original_family, normalized_family in self._normalize_feature_families():
            handler = strategy_handlers.get(normalized_family)
            if handler is None:
                raise ValueError(
                    f"Unsupported feature_strategy: {original_family!r}. "
                    "Use 'fft', 'welch', or 'wavelet'."
                )
            feature_blocks.append(handler(X))

        if len(feature_blocks) == 1:
            return feature_blocks[0]

        # Concatène les blocs en conservant l'alignement des échantillons
        n_samples = feature_blocks[0].shape[1]
        for block in feature_blocks[1:]:
            if block.shape[0] != n_samples:  # pragma: no cover - cohérence interne
                raise ValueError(
                    "All feature families must yield the same sample count."
                )

        return np.concatenate(feature_blocks, axis=1)

    def xǁExtractFeaturesǁ_compute_features__mutmut_21(self, X: np.ndarray) -> np.ndarray:
        """Dispatch interne vers la ou les stratégies de features demandées."""

        strategy_handlers = {
            "fft": self._compute_fft_features,
            "wavelet": self._compute_wavelet_features,
            "welch": self._compute_welch_features,
        }

        feature_blocks: List[np.ndarray] = []
        for original_family, normalized_family in self._normalize_feature_families():
            handler = strategy_handlers.get(normalized_family)
            if handler is None:
                raise ValueError(
                    f"Unsupported feature_strategy: {original_family!r}. "
                    "Use 'fft', 'welch', or 'wavelet'."
                )
            feature_blocks.append(handler(X))

        if len(feature_blocks) == 1:
            return feature_blocks[0]

        # Concatène les blocs en conservant l'alignement des échantillons
        n_samples = feature_blocks[0].shape[0]
        for block in feature_blocks[2:]:
            if block.shape[0] != n_samples:  # pragma: no cover - cohérence interne
                raise ValueError(
                    "All feature families must yield the same sample count."
                )

        return np.concatenate(feature_blocks, axis=1)

    def xǁExtractFeaturesǁ_compute_features__mutmut_22(self, X: np.ndarray) -> np.ndarray:
        """Dispatch interne vers la ou les stratégies de features demandées."""

        strategy_handlers = {
            "fft": self._compute_fft_features,
            "wavelet": self._compute_wavelet_features,
            "welch": self._compute_welch_features,
        }

        feature_blocks: List[np.ndarray] = []
        for original_family, normalized_family in self._normalize_feature_families():
            handler = strategy_handlers.get(normalized_family)
            if handler is None:
                raise ValueError(
                    f"Unsupported feature_strategy: {original_family!r}. "
                    "Use 'fft', 'welch', or 'wavelet'."
                )
            feature_blocks.append(handler(X))

        if len(feature_blocks) == 1:
            return feature_blocks[0]

        # Concatène les blocs en conservant l'alignement des échantillons
        n_samples = feature_blocks[0].shape[0]
        for block in feature_blocks[1:]:
            if block.shape[1] != n_samples:  # pragma: no cover - cohérence interne
                raise ValueError(
                    "All feature families must yield the same sample count."
                )

        return np.concatenate(feature_blocks, axis=1)

    def xǁExtractFeaturesǁ_compute_features__mutmut_23(self, X: np.ndarray) -> np.ndarray:
        """Dispatch interne vers la ou les stratégies de features demandées."""

        strategy_handlers = {
            "fft": self._compute_fft_features,
            "wavelet": self._compute_wavelet_features,
            "welch": self._compute_welch_features,
        }

        feature_blocks: List[np.ndarray] = []
        for original_family, normalized_family in self._normalize_feature_families():
            handler = strategy_handlers.get(normalized_family)
            if handler is None:
                raise ValueError(
                    f"Unsupported feature_strategy: {original_family!r}. "
                    "Use 'fft', 'welch', or 'wavelet'."
                )
            feature_blocks.append(handler(X))

        if len(feature_blocks) == 1:
            return feature_blocks[0]

        # Concatène les blocs en conservant l'alignement des échantillons
        n_samples = feature_blocks[0].shape[0]
        for block in feature_blocks[1:]:
            if block.shape[0] == n_samples:  # pragma: no cover - cohérence interne
                raise ValueError(
                    "All feature families must yield the same sample count."
                )

        return np.concatenate(feature_blocks, axis=1)

    def xǁExtractFeaturesǁ_compute_features__mutmut_24(self, X: np.ndarray) -> np.ndarray:
        """Dispatch interne vers la ou les stratégies de features demandées."""

        strategy_handlers = {
            "fft": self._compute_fft_features,
            "wavelet": self._compute_wavelet_features,
            "welch": self._compute_welch_features,
        }

        feature_blocks: List[np.ndarray] = []
        for original_family, normalized_family in self._normalize_feature_families():
            handler = strategy_handlers.get(normalized_family)
            if handler is None:
                raise ValueError(
                    f"Unsupported feature_strategy: {original_family!r}. "
                    "Use 'fft', 'welch', or 'wavelet'."
                )
            feature_blocks.append(handler(X))

        if len(feature_blocks) == 1:
            return feature_blocks[0]

        # Concatène les blocs en conservant l'alignement des échantillons
        n_samples = feature_blocks[0].shape[0]
        for block in feature_blocks[1:]:
            if block.shape[0] != n_samples:  # pragma: no cover - cohérence interne
                raise ValueError(
                    None
                )

        return np.concatenate(feature_blocks, axis=1)

    def xǁExtractFeaturesǁ_compute_features__mutmut_25(self, X: np.ndarray) -> np.ndarray:
        """Dispatch interne vers la ou les stratégies de features demandées."""

        strategy_handlers = {
            "fft": self._compute_fft_features,
            "wavelet": self._compute_wavelet_features,
            "welch": self._compute_welch_features,
        }

        feature_blocks: List[np.ndarray] = []
        for original_family, normalized_family in self._normalize_feature_families():
            handler = strategy_handlers.get(normalized_family)
            if handler is None:
                raise ValueError(
                    f"Unsupported feature_strategy: {original_family!r}. "
                    "Use 'fft', 'welch', or 'wavelet'."
                )
            feature_blocks.append(handler(X))

        if len(feature_blocks) == 1:
            return feature_blocks[0]

        # Concatène les blocs en conservant l'alignement des échantillons
        n_samples = feature_blocks[0].shape[0]
        for block in feature_blocks[1:]:
            if block.shape[0] != n_samples:  # pragma: no cover - cohérence interne
                raise ValueError(
                    "XXAll feature families must yield the same sample count.XX"
                )

        return np.concatenate(feature_blocks, axis=1)

    def xǁExtractFeaturesǁ_compute_features__mutmut_26(self, X: np.ndarray) -> np.ndarray:
        """Dispatch interne vers la ou les stratégies de features demandées."""

        strategy_handlers = {
            "fft": self._compute_fft_features,
            "wavelet": self._compute_wavelet_features,
            "welch": self._compute_welch_features,
        }

        feature_blocks: List[np.ndarray] = []
        for original_family, normalized_family in self._normalize_feature_families():
            handler = strategy_handlers.get(normalized_family)
            if handler is None:
                raise ValueError(
                    f"Unsupported feature_strategy: {original_family!r}. "
                    "Use 'fft', 'welch', or 'wavelet'."
                )
            feature_blocks.append(handler(X))

        if len(feature_blocks) == 1:
            return feature_blocks[0]

        # Concatène les blocs en conservant l'alignement des échantillons
        n_samples = feature_blocks[0].shape[0]
        for block in feature_blocks[1:]:
            if block.shape[0] != n_samples:  # pragma: no cover - cohérence interne
                raise ValueError(
                    "all feature families must yield the same sample count."
                )

        return np.concatenate(feature_blocks, axis=1)

    def xǁExtractFeaturesǁ_compute_features__mutmut_27(self, X: np.ndarray) -> np.ndarray:
        """Dispatch interne vers la ou les stratégies de features demandées."""

        strategy_handlers = {
            "fft": self._compute_fft_features,
            "wavelet": self._compute_wavelet_features,
            "welch": self._compute_welch_features,
        }

        feature_blocks: List[np.ndarray] = []
        for original_family, normalized_family in self._normalize_feature_families():
            handler = strategy_handlers.get(normalized_family)
            if handler is None:
                raise ValueError(
                    f"Unsupported feature_strategy: {original_family!r}. "
                    "Use 'fft', 'welch', or 'wavelet'."
                )
            feature_blocks.append(handler(X))

        if len(feature_blocks) == 1:
            return feature_blocks[0]

        # Concatène les blocs en conservant l'alignement des échantillons
        n_samples = feature_blocks[0].shape[0]
        for block in feature_blocks[1:]:
            if block.shape[0] != n_samples:  # pragma: no cover - cohérence interne
                raise ValueError(
                    "ALL FEATURE FAMILIES MUST YIELD THE SAME SAMPLE COUNT."
                )

        return np.concatenate(feature_blocks, axis=1)

    def xǁExtractFeaturesǁ_compute_features__mutmut_28(self, X: np.ndarray) -> np.ndarray:
        """Dispatch interne vers la ou les stratégies de features demandées."""

        strategy_handlers = {
            "fft": self._compute_fft_features,
            "wavelet": self._compute_wavelet_features,
            "welch": self._compute_welch_features,
        }

        feature_blocks: List[np.ndarray] = []
        for original_family, normalized_family in self._normalize_feature_families():
            handler = strategy_handlers.get(normalized_family)
            if handler is None:
                raise ValueError(
                    f"Unsupported feature_strategy: {original_family!r}. "
                    "Use 'fft', 'welch', or 'wavelet'."
                )
            feature_blocks.append(handler(X))

        if len(feature_blocks) == 1:
            return feature_blocks[0]

        # Concatène les blocs en conservant l'alignement des échantillons
        n_samples = feature_blocks[0].shape[0]
        for block in feature_blocks[1:]:
            if block.shape[0] != n_samples:  # pragma: no cover - cohérence interne
                raise ValueError(
                    "All feature families must yield the same sample count."
                )

        return np.concatenate(None, axis=1)

    def xǁExtractFeaturesǁ_compute_features__mutmut_29(self, X: np.ndarray) -> np.ndarray:
        """Dispatch interne vers la ou les stratégies de features demandées."""

        strategy_handlers = {
            "fft": self._compute_fft_features,
            "wavelet": self._compute_wavelet_features,
            "welch": self._compute_welch_features,
        }

        feature_blocks: List[np.ndarray] = []
        for original_family, normalized_family in self._normalize_feature_families():
            handler = strategy_handlers.get(normalized_family)
            if handler is None:
                raise ValueError(
                    f"Unsupported feature_strategy: {original_family!r}. "
                    "Use 'fft', 'welch', or 'wavelet'."
                )
            feature_blocks.append(handler(X))

        if len(feature_blocks) == 1:
            return feature_blocks[0]

        # Concatène les blocs en conservant l'alignement des échantillons
        n_samples = feature_blocks[0].shape[0]
        for block in feature_blocks[1:]:
            if block.shape[0] != n_samples:  # pragma: no cover - cohérence interne
                raise ValueError(
                    "All feature families must yield the same sample count."
                )

        return np.concatenate(feature_blocks, axis=None)

    def xǁExtractFeaturesǁ_compute_features__mutmut_30(self, X: np.ndarray) -> np.ndarray:
        """Dispatch interne vers la ou les stratégies de features demandées."""

        strategy_handlers = {
            "fft": self._compute_fft_features,
            "wavelet": self._compute_wavelet_features,
            "welch": self._compute_welch_features,
        }

        feature_blocks: List[np.ndarray] = []
        for original_family, normalized_family in self._normalize_feature_families():
            handler = strategy_handlers.get(normalized_family)
            if handler is None:
                raise ValueError(
                    f"Unsupported feature_strategy: {original_family!r}. "
                    "Use 'fft', 'welch', or 'wavelet'."
                )
            feature_blocks.append(handler(X))

        if len(feature_blocks) == 1:
            return feature_blocks[0]

        # Concatène les blocs en conservant l'alignement des échantillons
        n_samples = feature_blocks[0].shape[0]
        for block in feature_blocks[1:]:
            if block.shape[0] != n_samples:  # pragma: no cover - cohérence interne
                raise ValueError(
                    "All feature families must yield the same sample count."
                )

        return np.concatenate(axis=1)

    def xǁExtractFeaturesǁ_compute_features__mutmut_31(self, X: np.ndarray) -> np.ndarray:
        """Dispatch interne vers la ou les stratégies de features demandées."""

        strategy_handlers = {
            "fft": self._compute_fft_features,
            "wavelet": self._compute_wavelet_features,
            "welch": self._compute_welch_features,
        }

        feature_blocks: List[np.ndarray] = []
        for original_family, normalized_family in self._normalize_feature_families():
            handler = strategy_handlers.get(normalized_family)
            if handler is None:
                raise ValueError(
                    f"Unsupported feature_strategy: {original_family!r}. "
                    "Use 'fft', 'welch', or 'wavelet'."
                )
            feature_blocks.append(handler(X))

        if len(feature_blocks) == 1:
            return feature_blocks[0]

        # Concatène les blocs en conservant l'alignement des échantillons
        n_samples = feature_blocks[0].shape[0]
        for block in feature_blocks[1:]:
            if block.shape[0] != n_samples:  # pragma: no cover - cohérence interne
                raise ValueError(
                    "All feature families must yield the same sample count."
                )

        return np.concatenate(feature_blocks, )

    def xǁExtractFeaturesǁ_compute_features__mutmut_32(self, X: np.ndarray) -> np.ndarray:
        """Dispatch interne vers la ou les stratégies de features demandées."""

        strategy_handlers = {
            "fft": self._compute_fft_features,
            "wavelet": self._compute_wavelet_features,
            "welch": self._compute_welch_features,
        }

        feature_blocks: List[np.ndarray] = []
        for original_family, normalized_family in self._normalize_feature_families():
            handler = strategy_handlers.get(normalized_family)
            if handler is None:
                raise ValueError(
                    f"Unsupported feature_strategy: {original_family!r}. "
                    "Use 'fft', 'welch', or 'wavelet'."
                )
            feature_blocks.append(handler(X))

        if len(feature_blocks) == 1:
            return feature_blocks[0]

        # Concatène les blocs en conservant l'alignement des échantillons
        n_samples = feature_blocks[0].shape[0]
        for block in feature_blocks[1:]:
            if block.shape[0] != n_samples:  # pragma: no cover - cohérence interne
                raise ValueError(
                    "All feature families must yield the same sample count."
                )

        return np.concatenate(feature_blocks, axis=2)
    
    xǁExtractFeaturesǁ_compute_features__mutmut_mutants : ClassVar[MutantDict] = {
    'xǁExtractFeaturesǁ_compute_features__mutmut_1': xǁExtractFeaturesǁ_compute_features__mutmut_1, 
        'xǁExtractFeaturesǁ_compute_features__mutmut_2': xǁExtractFeaturesǁ_compute_features__mutmut_2, 
        'xǁExtractFeaturesǁ_compute_features__mutmut_3': xǁExtractFeaturesǁ_compute_features__mutmut_3, 
        'xǁExtractFeaturesǁ_compute_features__mutmut_4': xǁExtractFeaturesǁ_compute_features__mutmut_4, 
        'xǁExtractFeaturesǁ_compute_features__mutmut_5': xǁExtractFeaturesǁ_compute_features__mutmut_5, 
        'xǁExtractFeaturesǁ_compute_features__mutmut_6': xǁExtractFeaturesǁ_compute_features__mutmut_6, 
        'xǁExtractFeaturesǁ_compute_features__mutmut_7': xǁExtractFeaturesǁ_compute_features__mutmut_7, 
        'xǁExtractFeaturesǁ_compute_features__mutmut_8': xǁExtractFeaturesǁ_compute_features__mutmut_8, 
        'xǁExtractFeaturesǁ_compute_features__mutmut_9': xǁExtractFeaturesǁ_compute_features__mutmut_9, 
        'xǁExtractFeaturesǁ_compute_features__mutmut_10': xǁExtractFeaturesǁ_compute_features__mutmut_10, 
        'xǁExtractFeaturesǁ_compute_features__mutmut_11': xǁExtractFeaturesǁ_compute_features__mutmut_11, 
        'xǁExtractFeaturesǁ_compute_features__mutmut_12': xǁExtractFeaturesǁ_compute_features__mutmut_12, 
        'xǁExtractFeaturesǁ_compute_features__mutmut_13': xǁExtractFeaturesǁ_compute_features__mutmut_13, 
        'xǁExtractFeaturesǁ_compute_features__mutmut_14': xǁExtractFeaturesǁ_compute_features__mutmut_14, 
        'xǁExtractFeaturesǁ_compute_features__mutmut_15': xǁExtractFeaturesǁ_compute_features__mutmut_15, 
        'xǁExtractFeaturesǁ_compute_features__mutmut_16': xǁExtractFeaturesǁ_compute_features__mutmut_16, 
        'xǁExtractFeaturesǁ_compute_features__mutmut_17': xǁExtractFeaturesǁ_compute_features__mutmut_17, 
        'xǁExtractFeaturesǁ_compute_features__mutmut_18': xǁExtractFeaturesǁ_compute_features__mutmut_18, 
        'xǁExtractFeaturesǁ_compute_features__mutmut_19': xǁExtractFeaturesǁ_compute_features__mutmut_19, 
        'xǁExtractFeaturesǁ_compute_features__mutmut_20': xǁExtractFeaturesǁ_compute_features__mutmut_20, 
        'xǁExtractFeaturesǁ_compute_features__mutmut_21': xǁExtractFeaturesǁ_compute_features__mutmut_21, 
        'xǁExtractFeaturesǁ_compute_features__mutmut_22': xǁExtractFeaturesǁ_compute_features__mutmut_22, 
        'xǁExtractFeaturesǁ_compute_features__mutmut_23': xǁExtractFeaturesǁ_compute_features__mutmut_23, 
        'xǁExtractFeaturesǁ_compute_features__mutmut_24': xǁExtractFeaturesǁ_compute_features__mutmut_24, 
        'xǁExtractFeaturesǁ_compute_features__mutmut_25': xǁExtractFeaturesǁ_compute_features__mutmut_25, 
        'xǁExtractFeaturesǁ_compute_features__mutmut_26': xǁExtractFeaturesǁ_compute_features__mutmut_26, 
        'xǁExtractFeaturesǁ_compute_features__mutmut_27': xǁExtractFeaturesǁ_compute_features__mutmut_27, 
        'xǁExtractFeaturesǁ_compute_features__mutmut_28': xǁExtractFeaturesǁ_compute_features__mutmut_28, 
        'xǁExtractFeaturesǁ_compute_features__mutmut_29': xǁExtractFeaturesǁ_compute_features__mutmut_29, 
        'xǁExtractFeaturesǁ_compute_features__mutmut_30': xǁExtractFeaturesǁ_compute_features__mutmut_30, 
        'xǁExtractFeaturesǁ_compute_features__mutmut_31': xǁExtractFeaturesǁ_compute_features__mutmut_31, 
        'xǁExtractFeaturesǁ_compute_features__mutmut_32': xǁExtractFeaturesǁ_compute_features__mutmut_32
    }
    
    def _compute_features(self, *args, **kwargs):
        result = _mutmut_trampoline(object.__getattribute__(self, "xǁExtractFeaturesǁ_compute_features__mutmut_orig"), object.__getattribute__(self, "xǁExtractFeaturesǁ_compute_features__mutmut_mutants"), args, kwargs, self)
        return result 
    
    _compute_features.__signature__ = _mutmut_signature(xǁExtractFeaturesǁ_compute_features__mutmut_orig)
    xǁExtractFeaturesǁ_compute_features__mutmut_orig.__name__ = 'xǁExtractFeaturesǁ_compute_features'

    def xǁExtractFeaturesǁ_compute_fft_features__mutmut_orig(self, X: np.ndarray) -> np.ndarray:
        """Calcule les puissances de bandes à partir de la FFT."""

        n_times = X.shape[-1]
        # Centre le signal pour supprimer la composante DC avant la FFT
        centered = X - X.mean(axis=-1, keepdims=True)
        # Calcule les fréquences réelles à partir de la sfreq configurée
        freqs = np.fft.rfftfreq(n_times, d=1.0 / self.sfreq)
        # Calcule la puissance spectrale par canal et échantillon
        power = np.asarray(
            np.abs(np.fft.rfft(centered, axis=-1)) ** 2, dtype=float
        )  # pragma: no mutate
        # Restaure l'énergie des composantes symétriques manquantes pour un signal réel
        if power.shape[-1] > 1:
            power[..., 1:-1] *= 2
            # Lorsque n_times est impair, la dernière fréquence possède un symétrique
            if n_times % 2 != 0:
                power[..., -1] *= 2
        # Normalise par la longueur temporelle pour obtenir une puissance moyenne
        power = power / float(n_times**2)
        # Accumule les puissances par bande pour chaque canal
        band_powers: List[np.ndarray] = []
        # Parcourt chaque bande EEG définie dans les paramètres
        for _, (low, high) in self._band_items:
            # Construit le masque fréquentiel pour cette bande
            band_mask = (freqs >= low) & (freqs <= high)

            # Gère le cas où aucune fréquence ne tombe dans la bande
            if not np.any(band_mask):
                # Retourne un bloc de zéros pour préserver la forme
                band_power = np.zeros(power.shape[:2])
            else:
                # Moyenne la puissance sur les fréquences de la bande
                band_power = power[:, :, band_mask].mean(axis=2)

            # Ajoute la matrice (n_samples, n_channels) à la liste
            band_powers.append(band_power)

        # Empile les bandes pour retourner un tenseur cohérent canal x bande
        stacked = np.stack(band_powers, axis=2)
        # Retourne une matrice aplatie (échantillons, canaux * bandes)
        return cast(np.ndarray, stacked.reshape(stacked.shape[0], -1))

    def xǁExtractFeaturesǁ_compute_fft_features__mutmut_1(self, X: np.ndarray) -> np.ndarray:
        """Calcule les puissances de bandes à partir de la FFT."""

        n_times = None
        # Centre le signal pour supprimer la composante DC avant la FFT
        centered = X - X.mean(axis=-1, keepdims=True)
        # Calcule les fréquences réelles à partir de la sfreq configurée
        freqs = np.fft.rfftfreq(n_times, d=1.0 / self.sfreq)
        # Calcule la puissance spectrale par canal et échantillon
        power = np.asarray(
            np.abs(np.fft.rfft(centered, axis=-1)) ** 2, dtype=float
        )  # pragma: no mutate
        # Restaure l'énergie des composantes symétriques manquantes pour un signal réel
        if power.shape[-1] > 1:
            power[..., 1:-1] *= 2
            # Lorsque n_times est impair, la dernière fréquence possède un symétrique
            if n_times % 2 != 0:
                power[..., -1] *= 2
        # Normalise par la longueur temporelle pour obtenir une puissance moyenne
        power = power / float(n_times**2)
        # Accumule les puissances par bande pour chaque canal
        band_powers: List[np.ndarray] = []
        # Parcourt chaque bande EEG définie dans les paramètres
        for _, (low, high) in self._band_items:
            # Construit le masque fréquentiel pour cette bande
            band_mask = (freqs >= low) & (freqs <= high)

            # Gère le cas où aucune fréquence ne tombe dans la bande
            if not np.any(band_mask):
                # Retourne un bloc de zéros pour préserver la forme
                band_power = np.zeros(power.shape[:2])
            else:
                # Moyenne la puissance sur les fréquences de la bande
                band_power = power[:, :, band_mask].mean(axis=2)

            # Ajoute la matrice (n_samples, n_channels) à la liste
            band_powers.append(band_power)

        # Empile les bandes pour retourner un tenseur cohérent canal x bande
        stacked = np.stack(band_powers, axis=2)
        # Retourne une matrice aplatie (échantillons, canaux * bandes)
        return cast(np.ndarray, stacked.reshape(stacked.shape[0], -1))

    def xǁExtractFeaturesǁ_compute_fft_features__mutmut_2(self, X: np.ndarray) -> np.ndarray:
        """Calcule les puissances de bandes à partir de la FFT."""

        n_times = X.shape[+1]
        # Centre le signal pour supprimer la composante DC avant la FFT
        centered = X - X.mean(axis=-1, keepdims=True)
        # Calcule les fréquences réelles à partir de la sfreq configurée
        freqs = np.fft.rfftfreq(n_times, d=1.0 / self.sfreq)
        # Calcule la puissance spectrale par canal et échantillon
        power = np.asarray(
            np.abs(np.fft.rfft(centered, axis=-1)) ** 2, dtype=float
        )  # pragma: no mutate
        # Restaure l'énergie des composantes symétriques manquantes pour un signal réel
        if power.shape[-1] > 1:
            power[..., 1:-1] *= 2
            # Lorsque n_times est impair, la dernière fréquence possède un symétrique
            if n_times % 2 != 0:
                power[..., -1] *= 2
        # Normalise par la longueur temporelle pour obtenir une puissance moyenne
        power = power / float(n_times**2)
        # Accumule les puissances par bande pour chaque canal
        band_powers: List[np.ndarray] = []
        # Parcourt chaque bande EEG définie dans les paramètres
        for _, (low, high) in self._band_items:
            # Construit le masque fréquentiel pour cette bande
            band_mask = (freqs >= low) & (freqs <= high)

            # Gère le cas où aucune fréquence ne tombe dans la bande
            if not np.any(band_mask):
                # Retourne un bloc de zéros pour préserver la forme
                band_power = np.zeros(power.shape[:2])
            else:
                # Moyenne la puissance sur les fréquences de la bande
                band_power = power[:, :, band_mask].mean(axis=2)

            # Ajoute la matrice (n_samples, n_channels) à la liste
            band_powers.append(band_power)

        # Empile les bandes pour retourner un tenseur cohérent canal x bande
        stacked = np.stack(band_powers, axis=2)
        # Retourne une matrice aplatie (échantillons, canaux * bandes)
        return cast(np.ndarray, stacked.reshape(stacked.shape[0], -1))

    def xǁExtractFeaturesǁ_compute_fft_features__mutmut_3(self, X: np.ndarray) -> np.ndarray:
        """Calcule les puissances de bandes à partir de la FFT."""

        n_times = X.shape[-2]
        # Centre le signal pour supprimer la composante DC avant la FFT
        centered = X - X.mean(axis=-1, keepdims=True)
        # Calcule les fréquences réelles à partir de la sfreq configurée
        freqs = np.fft.rfftfreq(n_times, d=1.0 / self.sfreq)
        # Calcule la puissance spectrale par canal et échantillon
        power = np.asarray(
            np.abs(np.fft.rfft(centered, axis=-1)) ** 2, dtype=float
        )  # pragma: no mutate
        # Restaure l'énergie des composantes symétriques manquantes pour un signal réel
        if power.shape[-1] > 1:
            power[..., 1:-1] *= 2
            # Lorsque n_times est impair, la dernière fréquence possède un symétrique
            if n_times % 2 != 0:
                power[..., -1] *= 2
        # Normalise par la longueur temporelle pour obtenir une puissance moyenne
        power = power / float(n_times**2)
        # Accumule les puissances par bande pour chaque canal
        band_powers: List[np.ndarray] = []
        # Parcourt chaque bande EEG définie dans les paramètres
        for _, (low, high) in self._band_items:
            # Construit le masque fréquentiel pour cette bande
            band_mask = (freqs >= low) & (freqs <= high)

            # Gère le cas où aucune fréquence ne tombe dans la bande
            if not np.any(band_mask):
                # Retourne un bloc de zéros pour préserver la forme
                band_power = np.zeros(power.shape[:2])
            else:
                # Moyenne la puissance sur les fréquences de la bande
                band_power = power[:, :, band_mask].mean(axis=2)

            # Ajoute la matrice (n_samples, n_channels) à la liste
            band_powers.append(band_power)

        # Empile les bandes pour retourner un tenseur cohérent canal x bande
        stacked = np.stack(band_powers, axis=2)
        # Retourne une matrice aplatie (échantillons, canaux * bandes)
        return cast(np.ndarray, stacked.reshape(stacked.shape[0], -1))

    def xǁExtractFeaturesǁ_compute_fft_features__mutmut_4(self, X: np.ndarray) -> np.ndarray:
        """Calcule les puissances de bandes à partir de la FFT."""

        n_times = X.shape[-1]
        # Centre le signal pour supprimer la composante DC avant la FFT
        centered = None
        # Calcule les fréquences réelles à partir de la sfreq configurée
        freqs = np.fft.rfftfreq(n_times, d=1.0 / self.sfreq)
        # Calcule la puissance spectrale par canal et échantillon
        power = np.asarray(
            np.abs(np.fft.rfft(centered, axis=-1)) ** 2, dtype=float
        )  # pragma: no mutate
        # Restaure l'énergie des composantes symétriques manquantes pour un signal réel
        if power.shape[-1] > 1:
            power[..., 1:-1] *= 2
            # Lorsque n_times est impair, la dernière fréquence possède un symétrique
            if n_times % 2 != 0:
                power[..., -1] *= 2
        # Normalise par la longueur temporelle pour obtenir une puissance moyenne
        power = power / float(n_times**2)
        # Accumule les puissances par bande pour chaque canal
        band_powers: List[np.ndarray] = []
        # Parcourt chaque bande EEG définie dans les paramètres
        for _, (low, high) in self._band_items:
            # Construit le masque fréquentiel pour cette bande
            band_mask = (freqs >= low) & (freqs <= high)

            # Gère le cas où aucune fréquence ne tombe dans la bande
            if not np.any(band_mask):
                # Retourne un bloc de zéros pour préserver la forme
                band_power = np.zeros(power.shape[:2])
            else:
                # Moyenne la puissance sur les fréquences de la bande
                band_power = power[:, :, band_mask].mean(axis=2)

            # Ajoute la matrice (n_samples, n_channels) à la liste
            band_powers.append(band_power)

        # Empile les bandes pour retourner un tenseur cohérent canal x bande
        stacked = np.stack(band_powers, axis=2)
        # Retourne une matrice aplatie (échantillons, canaux * bandes)
        return cast(np.ndarray, stacked.reshape(stacked.shape[0], -1))

    def xǁExtractFeaturesǁ_compute_fft_features__mutmut_5(self, X: np.ndarray) -> np.ndarray:
        """Calcule les puissances de bandes à partir de la FFT."""

        n_times = X.shape[-1]
        # Centre le signal pour supprimer la composante DC avant la FFT
        centered = X + X.mean(axis=-1, keepdims=True)
        # Calcule les fréquences réelles à partir de la sfreq configurée
        freqs = np.fft.rfftfreq(n_times, d=1.0 / self.sfreq)
        # Calcule la puissance spectrale par canal et échantillon
        power = np.asarray(
            np.abs(np.fft.rfft(centered, axis=-1)) ** 2, dtype=float
        )  # pragma: no mutate
        # Restaure l'énergie des composantes symétriques manquantes pour un signal réel
        if power.shape[-1] > 1:
            power[..., 1:-1] *= 2
            # Lorsque n_times est impair, la dernière fréquence possède un symétrique
            if n_times % 2 != 0:
                power[..., -1] *= 2
        # Normalise par la longueur temporelle pour obtenir une puissance moyenne
        power = power / float(n_times**2)
        # Accumule les puissances par bande pour chaque canal
        band_powers: List[np.ndarray] = []
        # Parcourt chaque bande EEG définie dans les paramètres
        for _, (low, high) in self._band_items:
            # Construit le masque fréquentiel pour cette bande
            band_mask = (freqs >= low) & (freqs <= high)

            # Gère le cas où aucune fréquence ne tombe dans la bande
            if not np.any(band_mask):
                # Retourne un bloc de zéros pour préserver la forme
                band_power = np.zeros(power.shape[:2])
            else:
                # Moyenne la puissance sur les fréquences de la bande
                band_power = power[:, :, band_mask].mean(axis=2)

            # Ajoute la matrice (n_samples, n_channels) à la liste
            band_powers.append(band_power)

        # Empile les bandes pour retourner un tenseur cohérent canal x bande
        stacked = np.stack(band_powers, axis=2)
        # Retourne une matrice aplatie (échantillons, canaux * bandes)
        return cast(np.ndarray, stacked.reshape(stacked.shape[0], -1))

    def xǁExtractFeaturesǁ_compute_fft_features__mutmut_6(self, X: np.ndarray) -> np.ndarray:
        """Calcule les puissances de bandes à partir de la FFT."""

        n_times = X.shape[-1]
        # Centre le signal pour supprimer la composante DC avant la FFT
        centered = X - X.mean(axis=None, keepdims=True)
        # Calcule les fréquences réelles à partir de la sfreq configurée
        freqs = np.fft.rfftfreq(n_times, d=1.0 / self.sfreq)
        # Calcule la puissance spectrale par canal et échantillon
        power = np.asarray(
            np.abs(np.fft.rfft(centered, axis=-1)) ** 2, dtype=float
        )  # pragma: no mutate
        # Restaure l'énergie des composantes symétriques manquantes pour un signal réel
        if power.shape[-1] > 1:
            power[..., 1:-1] *= 2
            # Lorsque n_times est impair, la dernière fréquence possède un symétrique
            if n_times % 2 != 0:
                power[..., -1] *= 2
        # Normalise par la longueur temporelle pour obtenir une puissance moyenne
        power = power / float(n_times**2)
        # Accumule les puissances par bande pour chaque canal
        band_powers: List[np.ndarray] = []
        # Parcourt chaque bande EEG définie dans les paramètres
        for _, (low, high) in self._band_items:
            # Construit le masque fréquentiel pour cette bande
            band_mask = (freqs >= low) & (freqs <= high)

            # Gère le cas où aucune fréquence ne tombe dans la bande
            if not np.any(band_mask):
                # Retourne un bloc de zéros pour préserver la forme
                band_power = np.zeros(power.shape[:2])
            else:
                # Moyenne la puissance sur les fréquences de la bande
                band_power = power[:, :, band_mask].mean(axis=2)

            # Ajoute la matrice (n_samples, n_channels) à la liste
            band_powers.append(band_power)

        # Empile les bandes pour retourner un tenseur cohérent canal x bande
        stacked = np.stack(band_powers, axis=2)
        # Retourne une matrice aplatie (échantillons, canaux * bandes)
        return cast(np.ndarray, stacked.reshape(stacked.shape[0], -1))

    def xǁExtractFeaturesǁ_compute_fft_features__mutmut_7(self, X: np.ndarray) -> np.ndarray:
        """Calcule les puissances de bandes à partir de la FFT."""

        n_times = X.shape[-1]
        # Centre le signal pour supprimer la composante DC avant la FFT
        centered = X - X.mean(axis=-1, keepdims=None)
        # Calcule les fréquences réelles à partir de la sfreq configurée
        freqs = np.fft.rfftfreq(n_times, d=1.0 / self.sfreq)
        # Calcule la puissance spectrale par canal et échantillon
        power = np.asarray(
            np.abs(np.fft.rfft(centered, axis=-1)) ** 2, dtype=float
        )  # pragma: no mutate
        # Restaure l'énergie des composantes symétriques manquantes pour un signal réel
        if power.shape[-1] > 1:
            power[..., 1:-1] *= 2
            # Lorsque n_times est impair, la dernière fréquence possède un symétrique
            if n_times % 2 != 0:
                power[..., -1] *= 2
        # Normalise par la longueur temporelle pour obtenir une puissance moyenne
        power = power / float(n_times**2)
        # Accumule les puissances par bande pour chaque canal
        band_powers: List[np.ndarray] = []
        # Parcourt chaque bande EEG définie dans les paramètres
        for _, (low, high) in self._band_items:
            # Construit le masque fréquentiel pour cette bande
            band_mask = (freqs >= low) & (freqs <= high)

            # Gère le cas où aucune fréquence ne tombe dans la bande
            if not np.any(band_mask):
                # Retourne un bloc de zéros pour préserver la forme
                band_power = np.zeros(power.shape[:2])
            else:
                # Moyenne la puissance sur les fréquences de la bande
                band_power = power[:, :, band_mask].mean(axis=2)

            # Ajoute la matrice (n_samples, n_channels) à la liste
            band_powers.append(band_power)

        # Empile les bandes pour retourner un tenseur cohérent canal x bande
        stacked = np.stack(band_powers, axis=2)
        # Retourne une matrice aplatie (échantillons, canaux * bandes)
        return cast(np.ndarray, stacked.reshape(stacked.shape[0], -1))

    def xǁExtractFeaturesǁ_compute_fft_features__mutmut_8(self, X: np.ndarray) -> np.ndarray:
        """Calcule les puissances de bandes à partir de la FFT."""

        n_times = X.shape[-1]
        # Centre le signal pour supprimer la composante DC avant la FFT
        centered = X - X.mean(keepdims=True)
        # Calcule les fréquences réelles à partir de la sfreq configurée
        freqs = np.fft.rfftfreq(n_times, d=1.0 / self.sfreq)
        # Calcule la puissance spectrale par canal et échantillon
        power = np.asarray(
            np.abs(np.fft.rfft(centered, axis=-1)) ** 2, dtype=float
        )  # pragma: no mutate
        # Restaure l'énergie des composantes symétriques manquantes pour un signal réel
        if power.shape[-1] > 1:
            power[..., 1:-1] *= 2
            # Lorsque n_times est impair, la dernière fréquence possède un symétrique
            if n_times % 2 != 0:
                power[..., -1] *= 2
        # Normalise par la longueur temporelle pour obtenir une puissance moyenne
        power = power / float(n_times**2)
        # Accumule les puissances par bande pour chaque canal
        band_powers: List[np.ndarray] = []
        # Parcourt chaque bande EEG définie dans les paramètres
        for _, (low, high) in self._band_items:
            # Construit le masque fréquentiel pour cette bande
            band_mask = (freqs >= low) & (freqs <= high)

            # Gère le cas où aucune fréquence ne tombe dans la bande
            if not np.any(band_mask):
                # Retourne un bloc de zéros pour préserver la forme
                band_power = np.zeros(power.shape[:2])
            else:
                # Moyenne la puissance sur les fréquences de la bande
                band_power = power[:, :, band_mask].mean(axis=2)

            # Ajoute la matrice (n_samples, n_channels) à la liste
            band_powers.append(band_power)

        # Empile les bandes pour retourner un tenseur cohérent canal x bande
        stacked = np.stack(band_powers, axis=2)
        # Retourne une matrice aplatie (échantillons, canaux * bandes)
        return cast(np.ndarray, stacked.reshape(stacked.shape[0], -1))

    def xǁExtractFeaturesǁ_compute_fft_features__mutmut_9(self, X: np.ndarray) -> np.ndarray:
        """Calcule les puissances de bandes à partir de la FFT."""

        n_times = X.shape[-1]
        # Centre le signal pour supprimer la composante DC avant la FFT
        centered = X - X.mean(axis=-1, )
        # Calcule les fréquences réelles à partir de la sfreq configurée
        freqs = np.fft.rfftfreq(n_times, d=1.0 / self.sfreq)
        # Calcule la puissance spectrale par canal et échantillon
        power = np.asarray(
            np.abs(np.fft.rfft(centered, axis=-1)) ** 2, dtype=float
        )  # pragma: no mutate
        # Restaure l'énergie des composantes symétriques manquantes pour un signal réel
        if power.shape[-1] > 1:
            power[..., 1:-1] *= 2
            # Lorsque n_times est impair, la dernière fréquence possède un symétrique
            if n_times % 2 != 0:
                power[..., -1] *= 2
        # Normalise par la longueur temporelle pour obtenir une puissance moyenne
        power = power / float(n_times**2)
        # Accumule les puissances par bande pour chaque canal
        band_powers: List[np.ndarray] = []
        # Parcourt chaque bande EEG définie dans les paramètres
        for _, (low, high) in self._band_items:
            # Construit le masque fréquentiel pour cette bande
            band_mask = (freqs >= low) & (freqs <= high)

            # Gère le cas où aucune fréquence ne tombe dans la bande
            if not np.any(band_mask):
                # Retourne un bloc de zéros pour préserver la forme
                band_power = np.zeros(power.shape[:2])
            else:
                # Moyenne la puissance sur les fréquences de la bande
                band_power = power[:, :, band_mask].mean(axis=2)

            # Ajoute la matrice (n_samples, n_channels) à la liste
            band_powers.append(band_power)

        # Empile les bandes pour retourner un tenseur cohérent canal x bande
        stacked = np.stack(band_powers, axis=2)
        # Retourne une matrice aplatie (échantillons, canaux * bandes)
        return cast(np.ndarray, stacked.reshape(stacked.shape[0], -1))

    def xǁExtractFeaturesǁ_compute_fft_features__mutmut_10(self, X: np.ndarray) -> np.ndarray:
        """Calcule les puissances de bandes à partir de la FFT."""

        n_times = X.shape[-1]
        # Centre le signal pour supprimer la composante DC avant la FFT
        centered = X - X.mean(axis=+1, keepdims=True)
        # Calcule les fréquences réelles à partir de la sfreq configurée
        freqs = np.fft.rfftfreq(n_times, d=1.0 / self.sfreq)
        # Calcule la puissance spectrale par canal et échantillon
        power = np.asarray(
            np.abs(np.fft.rfft(centered, axis=-1)) ** 2, dtype=float
        )  # pragma: no mutate
        # Restaure l'énergie des composantes symétriques manquantes pour un signal réel
        if power.shape[-1] > 1:
            power[..., 1:-1] *= 2
            # Lorsque n_times est impair, la dernière fréquence possède un symétrique
            if n_times % 2 != 0:
                power[..., -1] *= 2
        # Normalise par la longueur temporelle pour obtenir une puissance moyenne
        power = power / float(n_times**2)
        # Accumule les puissances par bande pour chaque canal
        band_powers: List[np.ndarray] = []
        # Parcourt chaque bande EEG définie dans les paramètres
        for _, (low, high) in self._band_items:
            # Construit le masque fréquentiel pour cette bande
            band_mask = (freqs >= low) & (freqs <= high)

            # Gère le cas où aucune fréquence ne tombe dans la bande
            if not np.any(band_mask):
                # Retourne un bloc de zéros pour préserver la forme
                band_power = np.zeros(power.shape[:2])
            else:
                # Moyenne la puissance sur les fréquences de la bande
                band_power = power[:, :, band_mask].mean(axis=2)

            # Ajoute la matrice (n_samples, n_channels) à la liste
            band_powers.append(band_power)

        # Empile les bandes pour retourner un tenseur cohérent canal x bande
        stacked = np.stack(band_powers, axis=2)
        # Retourne une matrice aplatie (échantillons, canaux * bandes)
        return cast(np.ndarray, stacked.reshape(stacked.shape[0], -1))

    def xǁExtractFeaturesǁ_compute_fft_features__mutmut_11(self, X: np.ndarray) -> np.ndarray:
        """Calcule les puissances de bandes à partir de la FFT."""

        n_times = X.shape[-1]
        # Centre le signal pour supprimer la composante DC avant la FFT
        centered = X - X.mean(axis=-2, keepdims=True)
        # Calcule les fréquences réelles à partir de la sfreq configurée
        freqs = np.fft.rfftfreq(n_times, d=1.0 / self.sfreq)
        # Calcule la puissance spectrale par canal et échantillon
        power = np.asarray(
            np.abs(np.fft.rfft(centered, axis=-1)) ** 2, dtype=float
        )  # pragma: no mutate
        # Restaure l'énergie des composantes symétriques manquantes pour un signal réel
        if power.shape[-1] > 1:
            power[..., 1:-1] *= 2
            # Lorsque n_times est impair, la dernière fréquence possède un symétrique
            if n_times % 2 != 0:
                power[..., -1] *= 2
        # Normalise par la longueur temporelle pour obtenir une puissance moyenne
        power = power / float(n_times**2)
        # Accumule les puissances par bande pour chaque canal
        band_powers: List[np.ndarray] = []
        # Parcourt chaque bande EEG définie dans les paramètres
        for _, (low, high) in self._band_items:
            # Construit le masque fréquentiel pour cette bande
            band_mask = (freqs >= low) & (freqs <= high)

            # Gère le cas où aucune fréquence ne tombe dans la bande
            if not np.any(band_mask):
                # Retourne un bloc de zéros pour préserver la forme
                band_power = np.zeros(power.shape[:2])
            else:
                # Moyenne la puissance sur les fréquences de la bande
                band_power = power[:, :, band_mask].mean(axis=2)

            # Ajoute la matrice (n_samples, n_channels) à la liste
            band_powers.append(band_power)

        # Empile les bandes pour retourner un tenseur cohérent canal x bande
        stacked = np.stack(band_powers, axis=2)
        # Retourne une matrice aplatie (échantillons, canaux * bandes)
        return cast(np.ndarray, stacked.reshape(stacked.shape[0], -1))

    def xǁExtractFeaturesǁ_compute_fft_features__mutmut_12(self, X: np.ndarray) -> np.ndarray:
        """Calcule les puissances de bandes à partir de la FFT."""

        n_times = X.shape[-1]
        # Centre le signal pour supprimer la composante DC avant la FFT
        centered = X - X.mean(axis=-1, keepdims=False)
        # Calcule les fréquences réelles à partir de la sfreq configurée
        freqs = np.fft.rfftfreq(n_times, d=1.0 / self.sfreq)
        # Calcule la puissance spectrale par canal et échantillon
        power = np.asarray(
            np.abs(np.fft.rfft(centered, axis=-1)) ** 2, dtype=float
        )  # pragma: no mutate
        # Restaure l'énergie des composantes symétriques manquantes pour un signal réel
        if power.shape[-1] > 1:
            power[..., 1:-1] *= 2
            # Lorsque n_times est impair, la dernière fréquence possède un symétrique
            if n_times % 2 != 0:
                power[..., -1] *= 2
        # Normalise par la longueur temporelle pour obtenir une puissance moyenne
        power = power / float(n_times**2)
        # Accumule les puissances par bande pour chaque canal
        band_powers: List[np.ndarray] = []
        # Parcourt chaque bande EEG définie dans les paramètres
        for _, (low, high) in self._band_items:
            # Construit le masque fréquentiel pour cette bande
            band_mask = (freqs >= low) & (freqs <= high)

            # Gère le cas où aucune fréquence ne tombe dans la bande
            if not np.any(band_mask):
                # Retourne un bloc de zéros pour préserver la forme
                band_power = np.zeros(power.shape[:2])
            else:
                # Moyenne la puissance sur les fréquences de la bande
                band_power = power[:, :, band_mask].mean(axis=2)

            # Ajoute la matrice (n_samples, n_channels) à la liste
            band_powers.append(band_power)

        # Empile les bandes pour retourner un tenseur cohérent canal x bande
        stacked = np.stack(band_powers, axis=2)
        # Retourne une matrice aplatie (échantillons, canaux * bandes)
        return cast(np.ndarray, stacked.reshape(stacked.shape[0], -1))

    def xǁExtractFeaturesǁ_compute_fft_features__mutmut_13(self, X: np.ndarray) -> np.ndarray:
        """Calcule les puissances de bandes à partir de la FFT."""

        n_times = X.shape[-1]
        # Centre le signal pour supprimer la composante DC avant la FFT
        centered = X - X.mean(axis=-1, keepdims=True)
        # Calcule les fréquences réelles à partir de la sfreq configurée
        freqs = None
        # Calcule la puissance spectrale par canal et échantillon
        power = np.asarray(
            np.abs(np.fft.rfft(centered, axis=-1)) ** 2, dtype=float
        )  # pragma: no mutate
        # Restaure l'énergie des composantes symétriques manquantes pour un signal réel
        if power.shape[-1] > 1:
            power[..., 1:-1] *= 2
            # Lorsque n_times est impair, la dernière fréquence possède un symétrique
            if n_times % 2 != 0:
                power[..., -1] *= 2
        # Normalise par la longueur temporelle pour obtenir une puissance moyenne
        power = power / float(n_times**2)
        # Accumule les puissances par bande pour chaque canal
        band_powers: List[np.ndarray] = []
        # Parcourt chaque bande EEG définie dans les paramètres
        for _, (low, high) in self._band_items:
            # Construit le masque fréquentiel pour cette bande
            band_mask = (freqs >= low) & (freqs <= high)

            # Gère le cas où aucune fréquence ne tombe dans la bande
            if not np.any(band_mask):
                # Retourne un bloc de zéros pour préserver la forme
                band_power = np.zeros(power.shape[:2])
            else:
                # Moyenne la puissance sur les fréquences de la bande
                band_power = power[:, :, band_mask].mean(axis=2)

            # Ajoute la matrice (n_samples, n_channels) à la liste
            band_powers.append(band_power)

        # Empile les bandes pour retourner un tenseur cohérent canal x bande
        stacked = np.stack(band_powers, axis=2)
        # Retourne une matrice aplatie (échantillons, canaux * bandes)
        return cast(np.ndarray, stacked.reshape(stacked.shape[0], -1))

    def xǁExtractFeaturesǁ_compute_fft_features__mutmut_14(self, X: np.ndarray) -> np.ndarray:
        """Calcule les puissances de bandes à partir de la FFT."""

        n_times = X.shape[-1]
        # Centre le signal pour supprimer la composante DC avant la FFT
        centered = X - X.mean(axis=-1, keepdims=True)
        # Calcule les fréquences réelles à partir de la sfreq configurée
        freqs = np.fft.rfftfreq(None, d=1.0 / self.sfreq)
        # Calcule la puissance spectrale par canal et échantillon
        power = np.asarray(
            np.abs(np.fft.rfft(centered, axis=-1)) ** 2, dtype=float
        )  # pragma: no mutate
        # Restaure l'énergie des composantes symétriques manquantes pour un signal réel
        if power.shape[-1] > 1:
            power[..., 1:-1] *= 2
            # Lorsque n_times est impair, la dernière fréquence possède un symétrique
            if n_times % 2 != 0:
                power[..., -1] *= 2
        # Normalise par la longueur temporelle pour obtenir une puissance moyenne
        power = power / float(n_times**2)
        # Accumule les puissances par bande pour chaque canal
        band_powers: List[np.ndarray] = []
        # Parcourt chaque bande EEG définie dans les paramètres
        for _, (low, high) in self._band_items:
            # Construit le masque fréquentiel pour cette bande
            band_mask = (freqs >= low) & (freqs <= high)

            # Gère le cas où aucune fréquence ne tombe dans la bande
            if not np.any(band_mask):
                # Retourne un bloc de zéros pour préserver la forme
                band_power = np.zeros(power.shape[:2])
            else:
                # Moyenne la puissance sur les fréquences de la bande
                band_power = power[:, :, band_mask].mean(axis=2)

            # Ajoute la matrice (n_samples, n_channels) à la liste
            band_powers.append(band_power)

        # Empile les bandes pour retourner un tenseur cohérent canal x bande
        stacked = np.stack(band_powers, axis=2)
        # Retourne une matrice aplatie (échantillons, canaux * bandes)
        return cast(np.ndarray, stacked.reshape(stacked.shape[0], -1))

    def xǁExtractFeaturesǁ_compute_fft_features__mutmut_15(self, X: np.ndarray) -> np.ndarray:
        """Calcule les puissances de bandes à partir de la FFT."""

        n_times = X.shape[-1]
        # Centre le signal pour supprimer la composante DC avant la FFT
        centered = X - X.mean(axis=-1, keepdims=True)
        # Calcule les fréquences réelles à partir de la sfreq configurée
        freqs = np.fft.rfftfreq(n_times, d=None)
        # Calcule la puissance spectrale par canal et échantillon
        power = np.asarray(
            np.abs(np.fft.rfft(centered, axis=-1)) ** 2, dtype=float
        )  # pragma: no mutate
        # Restaure l'énergie des composantes symétriques manquantes pour un signal réel
        if power.shape[-1] > 1:
            power[..., 1:-1] *= 2
            # Lorsque n_times est impair, la dernière fréquence possède un symétrique
            if n_times % 2 != 0:
                power[..., -1] *= 2
        # Normalise par la longueur temporelle pour obtenir une puissance moyenne
        power = power / float(n_times**2)
        # Accumule les puissances par bande pour chaque canal
        band_powers: List[np.ndarray] = []
        # Parcourt chaque bande EEG définie dans les paramètres
        for _, (low, high) in self._band_items:
            # Construit le masque fréquentiel pour cette bande
            band_mask = (freqs >= low) & (freqs <= high)

            # Gère le cas où aucune fréquence ne tombe dans la bande
            if not np.any(band_mask):
                # Retourne un bloc de zéros pour préserver la forme
                band_power = np.zeros(power.shape[:2])
            else:
                # Moyenne la puissance sur les fréquences de la bande
                band_power = power[:, :, band_mask].mean(axis=2)

            # Ajoute la matrice (n_samples, n_channels) à la liste
            band_powers.append(band_power)

        # Empile les bandes pour retourner un tenseur cohérent canal x bande
        stacked = np.stack(band_powers, axis=2)
        # Retourne une matrice aplatie (échantillons, canaux * bandes)
        return cast(np.ndarray, stacked.reshape(stacked.shape[0], -1))

    def xǁExtractFeaturesǁ_compute_fft_features__mutmut_16(self, X: np.ndarray) -> np.ndarray:
        """Calcule les puissances de bandes à partir de la FFT."""

        n_times = X.shape[-1]
        # Centre le signal pour supprimer la composante DC avant la FFT
        centered = X - X.mean(axis=-1, keepdims=True)
        # Calcule les fréquences réelles à partir de la sfreq configurée
        freqs = np.fft.rfftfreq(d=1.0 / self.sfreq)
        # Calcule la puissance spectrale par canal et échantillon
        power = np.asarray(
            np.abs(np.fft.rfft(centered, axis=-1)) ** 2, dtype=float
        )  # pragma: no mutate
        # Restaure l'énergie des composantes symétriques manquantes pour un signal réel
        if power.shape[-1] > 1:
            power[..., 1:-1] *= 2
            # Lorsque n_times est impair, la dernière fréquence possède un symétrique
            if n_times % 2 != 0:
                power[..., -1] *= 2
        # Normalise par la longueur temporelle pour obtenir une puissance moyenne
        power = power / float(n_times**2)
        # Accumule les puissances par bande pour chaque canal
        band_powers: List[np.ndarray] = []
        # Parcourt chaque bande EEG définie dans les paramètres
        for _, (low, high) in self._band_items:
            # Construit le masque fréquentiel pour cette bande
            band_mask = (freqs >= low) & (freqs <= high)

            # Gère le cas où aucune fréquence ne tombe dans la bande
            if not np.any(band_mask):
                # Retourne un bloc de zéros pour préserver la forme
                band_power = np.zeros(power.shape[:2])
            else:
                # Moyenne la puissance sur les fréquences de la bande
                band_power = power[:, :, band_mask].mean(axis=2)

            # Ajoute la matrice (n_samples, n_channels) à la liste
            band_powers.append(band_power)

        # Empile les bandes pour retourner un tenseur cohérent canal x bande
        stacked = np.stack(band_powers, axis=2)
        # Retourne une matrice aplatie (échantillons, canaux * bandes)
        return cast(np.ndarray, stacked.reshape(stacked.shape[0], -1))

    def xǁExtractFeaturesǁ_compute_fft_features__mutmut_17(self, X: np.ndarray) -> np.ndarray:
        """Calcule les puissances de bandes à partir de la FFT."""

        n_times = X.shape[-1]
        # Centre le signal pour supprimer la composante DC avant la FFT
        centered = X - X.mean(axis=-1, keepdims=True)
        # Calcule les fréquences réelles à partir de la sfreq configurée
        freqs = np.fft.rfftfreq(n_times, )
        # Calcule la puissance spectrale par canal et échantillon
        power = np.asarray(
            np.abs(np.fft.rfft(centered, axis=-1)) ** 2, dtype=float
        )  # pragma: no mutate
        # Restaure l'énergie des composantes symétriques manquantes pour un signal réel
        if power.shape[-1] > 1:
            power[..., 1:-1] *= 2
            # Lorsque n_times est impair, la dernière fréquence possède un symétrique
            if n_times % 2 != 0:
                power[..., -1] *= 2
        # Normalise par la longueur temporelle pour obtenir une puissance moyenne
        power = power / float(n_times**2)
        # Accumule les puissances par bande pour chaque canal
        band_powers: List[np.ndarray] = []
        # Parcourt chaque bande EEG définie dans les paramètres
        for _, (low, high) in self._band_items:
            # Construit le masque fréquentiel pour cette bande
            band_mask = (freqs >= low) & (freqs <= high)

            # Gère le cas où aucune fréquence ne tombe dans la bande
            if not np.any(band_mask):
                # Retourne un bloc de zéros pour préserver la forme
                band_power = np.zeros(power.shape[:2])
            else:
                # Moyenne la puissance sur les fréquences de la bande
                band_power = power[:, :, band_mask].mean(axis=2)

            # Ajoute la matrice (n_samples, n_channels) à la liste
            band_powers.append(band_power)

        # Empile les bandes pour retourner un tenseur cohérent canal x bande
        stacked = np.stack(band_powers, axis=2)
        # Retourne une matrice aplatie (échantillons, canaux * bandes)
        return cast(np.ndarray, stacked.reshape(stacked.shape[0], -1))

    def xǁExtractFeaturesǁ_compute_fft_features__mutmut_18(self, X: np.ndarray) -> np.ndarray:
        """Calcule les puissances de bandes à partir de la FFT."""

        n_times = X.shape[-1]
        # Centre le signal pour supprimer la composante DC avant la FFT
        centered = X - X.mean(axis=-1, keepdims=True)
        # Calcule les fréquences réelles à partir de la sfreq configurée
        freqs = np.fft.rfftfreq(n_times, d=1.0 * self.sfreq)
        # Calcule la puissance spectrale par canal et échantillon
        power = np.asarray(
            np.abs(np.fft.rfft(centered, axis=-1)) ** 2, dtype=float
        )  # pragma: no mutate
        # Restaure l'énergie des composantes symétriques manquantes pour un signal réel
        if power.shape[-1] > 1:
            power[..., 1:-1] *= 2
            # Lorsque n_times est impair, la dernière fréquence possède un symétrique
            if n_times % 2 != 0:
                power[..., -1] *= 2
        # Normalise par la longueur temporelle pour obtenir une puissance moyenne
        power = power / float(n_times**2)
        # Accumule les puissances par bande pour chaque canal
        band_powers: List[np.ndarray] = []
        # Parcourt chaque bande EEG définie dans les paramètres
        for _, (low, high) in self._band_items:
            # Construit le masque fréquentiel pour cette bande
            band_mask = (freqs >= low) & (freqs <= high)

            # Gère le cas où aucune fréquence ne tombe dans la bande
            if not np.any(band_mask):
                # Retourne un bloc de zéros pour préserver la forme
                band_power = np.zeros(power.shape[:2])
            else:
                # Moyenne la puissance sur les fréquences de la bande
                band_power = power[:, :, band_mask].mean(axis=2)

            # Ajoute la matrice (n_samples, n_channels) à la liste
            band_powers.append(band_power)

        # Empile les bandes pour retourner un tenseur cohérent canal x bande
        stacked = np.stack(band_powers, axis=2)
        # Retourne une matrice aplatie (échantillons, canaux * bandes)
        return cast(np.ndarray, stacked.reshape(stacked.shape[0], -1))

    def xǁExtractFeaturesǁ_compute_fft_features__mutmut_19(self, X: np.ndarray) -> np.ndarray:
        """Calcule les puissances de bandes à partir de la FFT."""

        n_times = X.shape[-1]
        # Centre le signal pour supprimer la composante DC avant la FFT
        centered = X - X.mean(axis=-1, keepdims=True)
        # Calcule les fréquences réelles à partir de la sfreq configurée
        freqs = np.fft.rfftfreq(n_times, d=2.0 / self.sfreq)
        # Calcule la puissance spectrale par canal et échantillon
        power = np.asarray(
            np.abs(np.fft.rfft(centered, axis=-1)) ** 2, dtype=float
        )  # pragma: no mutate
        # Restaure l'énergie des composantes symétriques manquantes pour un signal réel
        if power.shape[-1] > 1:
            power[..., 1:-1] *= 2
            # Lorsque n_times est impair, la dernière fréquence possède un symétrique
            if n_times % 2 != 0:
                power[..., -1] *= 2
        # Normalise par la longueur temporelle pour obtenir une puissance moyenne
        power = power / float(n_times**2)
        # Accumule les puissances par bande pour chaque canal
        band_powers: List[np.ndarray] = []
        # Parcourt chaque bande EEG définie dans les paramètres
        for _, (low, high) in self._band_items:
            # Construit le masque fréquentiel pour cette bande
            band_mask = (freqs >= low) & (freqs <= high)

            # Gère le cas où aucune fréquence ne tombe dans la bande
            if not np.any(band_mask):
                # Retourne un bloc de zéros pour préserver la forme
                band_power = np.zeros(power.shape[:2])
            else:
                # Moyenne la puissance sur les fréquences de la bande
                band_power = power[:, :, band_mask].mean(axis=2)

            # Ajoute la matrice (n_samples, n_channels) à la liste
            band_powers.append(band_power)

        # Empile les bandes pour retourner un tenseur cohérent canal x bande
        stacked = np.stack(band_powers, axis=2)
        # Retourne une matrice aplatie (échantillons, canaux * bandes)
        return cast(np.ndarray, stacked.reshape(stacked.shape[0], -1))

    def xǁExtractFeaturesǁ_compute_fft_features__mutmut_20(self, X: np.ndarray) -> np.ndarray:
        """Calcule les puissances de bandes à partir de la FFT."""

        n_times = X.shape[-1]
        # Centre le signal pour supprimer la composante DC avant la FFT
        centered = X - X.mean(axis=-1, keepdims=True)
        # Calcule les fréquences réelles à partir de la sfreq configurée
        freqs = np.fft.rfftfreq(n_times, d=1.0 / self.sfreq)
        # Calcule la puissance spectrale par canal et échantillon
        power = None  # pragma: no mutate
        # Restaure l'énergie des composantes symétriques manquantes pour un signal réel
        if power.shape[-1] > 1:
            power[..., 1:-1] *= 2
            # Lorsque n_times est impair, la dernière fréquence possède un symétrique
            if n_times % 2 != 0:
                power[..., -1] *= 2
        # Normalise par la longueur temporelle pour obtenir une puissance moyenne
        power = power / float(n_times**2)
        # Accumule les puissances par bande pour chaque canal
        band_powers: List[np.ndarray] = []
        # Parcourt chaque bande EEG définie dans les paramètres
        for _, (low, high) in self._band_items:
            # Construit le masque fréquentiel pour cette bande
            band_mask = (freqs >= low) & (freqs <= high)

            # Gère le cas où aucune fréquence ne tombe dans la bande
            if not np.any(band_mask):
                # Retourne un bloc de zéros pour préserver la forme
                band_power = np.zeros(power.shape[:2])
            else:
                # Moyenne la puissance sur les fréquences de la bande
                band_power = power[:, :, band_mask].mean(axis=2)

            # Ajoute la matrice (n_samples, n_channels) à la liste
            band_powers.append(band_power)

        # Empile les bandes pour retourner un tenseur cohérent canal x bande
        stacked = np.stack(band_powers, axis=2)
        # Retourne une matrice aplatie (échantillons, canaux * bandes)
        return cast(np.ndarray, stacked.reshape(stacked.shape[0], -1))

    def xǁExtractFeaturesǁ_compute_fft_features__mutmut_21(self, X: np.ndarray) -> np.ndarray:
        """Calcule les puissances de bandes à partir de la FFT."""

        n_times = X.shape[-1]
        # Centre le signal pour supprimer la composante DC avant la FFT
        centered = X - X.mean(axis=-1, keepdims=True)
        # Calcule les fréquences réelles à partir de la sfreq configurée
        freqs = np.fft.rfftfreq(n_times, d=1.0 / self.sfreq)
        # Calcule la puissance spectrale par canal et échantillon
        power = np.asarray(
            None, dtype=float
        )  # pragma: no mutate
        # Restaure l'énergie des composantes symétriques manquantes pour un signal réel
        if power.shape[-1] > 1:
            power[..., 1:-1] *= 2
            # Lorsque n_times est impair, la dernière fréquence possède un symétrique
            if n_times % 2 != 0:
                power[..., -1] *= 2
        # Normalise par la longueur temporelle pour obtenir une puissance moyenne
        power = power / float(n_times**2)
        # Accumule les puissances par bande pour chaque canal
        band_powers: List[np.ndarray] = []
        # Parcourt chaque bande EEG définie dans les paramètres
        for _, (low, high) in self._band_items:
            # Construit le masque fréquentiel pour cette bande
            band_mask = (freqs >= low) & (freqs <= high)

            # Gère le cas où aucune fréquence ne tombe dans la bande
            if not np.any(band_mask):
                # Retourne un bloc de zéros pour préserver la forme
                band_power = np.zeros(power.shape[:2])
            else:
                # Moyenne la puissance sur les fréquences de la bande
                band_power = power[:, :, band_mask].mean(axis=2)

            # Ajoute la matrice (n_samples, n_channels) à la liste
            band_powers.append(band_power)

        # Empile les bandes pour retourner un tenseur cohérent canal x bande
        stacked = np.stack(band_powers, axis=2)
        # Retourne une matrice aplatie (échantillons, canaux * bandes)
        return cast(np.ndarray, stacked.reshape(stacked.shape[0], -1))

    def xǁExtractFeaturesǁ_compute_fft_features__mutmut_22(self, X: np.ndarray) -> np.ndarray:
        """Calcule les puissances de bandes à partir de la FFT."""

        n_times = X.shape[-1]
        # Centre le signal pour supprimer la composante DC avant la FFT
        centered = X - X.mean(axis=-1, keepdims=True)
        # Calcule les fréquences réelles à partir de la sfreq configurée
        freqs = np.fft.rfftfreq(n_times, d=1.0 / self.sfreq)
        # Calcule la puissance spectrale par canal et échantillon
        power = np.asarray(
            np.abs(np.fft.rfft(centered, axis=-1)) ** 2, dtype=None
        )  # pragma: no mutate
        # Restaure l'énergie des composantes symétriques manquantes pour un signal réel
        if power.shape[-1] > 1:
            power[..., 1:-1] *= 2
            # Lorsque n_times est impair, la dernière fréquence possède un symétrique
            if n_times % 2 != 0:
                power[..., -1] *= 2
        # Normalise par la longueur temporelle pour obtenir une puissance moyenne
        power = power / float(n_times**2)
        # Accumule les puissances par bande pour chaque canal
        band_powers: List[np.ndarray] = []
        # Parcourt chaque bande EEG définie dans les paramètres
        for _, (low, high) in self._band_items:
            # Construit le masque fréquentiel pour cette bande
            band_mask = (freqs >= low) & (freqs <= high)

            # Gère le cas où aucune fréquence ne tombe dans la bande
            if not np.any(band_mask):
                # Retourne un bloc de zéros pour préserver la forme
                band_power = np.zeros(power.shape[:2])
            else:
                # Moyenne la puissance sur les fréquences de la bande
                band_power = power[:, :, band_mask].mean(axis=2)

            # Ajoute la matrice (n_samples, n_channels) à la liste
            band_powers.append(band_power)

        # Empile les bandes pour retourner un tenseur cohérent canal x bande
        stacked = np.stack(band_powers, axis=2)
        # Retourne une matrice aplatie (échantillons, canaux * bandes)
        return cast(np.ndarray, stacked.reshape(stacked.shape[0], -1))

    def xǁExtractFeaturesǁ_compute_fft_features__mutmut_23(self, X: np.ndarray) -> np.ndarray:
        """Calcule les puissances de bandes à partir de la FFT."""

        n_times = X.shape[-1]
        # Centre le signal pour supprimer la composante DC avant la FFT
        centered = X - X.mean(axis=-1, keepdims=True)
        # Calcule les fréquences réelles à partir de la sfreq configurée
        freqs = np.fft.rfftfreq(n_times, d=1.0 / self.sfreq)
        # Calcule la puissance spectrale par canal et échantillon
        power = np.asarray(
            dtype=float
        )  # pragma: no mutate
        # Restaure l'énergie des composantes symétriques manquantes pour un signal réel
        if power.shape[-1] > 1:
            power[..., 1:-1] *= 2
            # Lorsque n_times est impair, la dernière fréquence possède un symétrique
            if n_times % 2 != 0:
                power[..., -1] *= 2
        # Normalise par la longueur temporelle pour obtenir une puissance moyenne
        power = power / float(n_times**2)
        # Accumule les puissances par bande pour chaque canal
        band_powers: List[np.ndarray] = []
        # Parcourt chaque bande EEG définie dans les paramètres
        for _, (low, high) in self._band_items:
            # Construit le masque fréquentiel pour cette bande
            band_mask = (freqs >= low) & (freqs <= high)

            # Gère le cas où aucune fréquence ne tombe dans la bande
            if not np.any(band_mask):
                # Retourne un bloc de zéros pour préserver la forme
                band_power = np.zeros(power.shape[:2])
            else:
                # Moyenne la puissance sur les fréquences de la bande
                band_power = power[:, :, band_mask].mean(axis=2)

            # Ajoute la matrice (n_samples, n_channels) à la liste
            band_powers.append(band_power)

        # Empile les bandes pour retourner un tenseur cohérent canal x bande
        stacked = np.stack(band_powers, axis=2)
        # Retourne une matrice aplatie (échantillons, canaux * bandes)
        return cast(np.ndarray, stacked.reshape(stacked.shape[0], -1))

    def xǁExtractFeaturesǁ_compute_fft_features__mutmut_24(self, X: np.ndarray) -> np.ndarray:
        """Calcule les puissances de bandes à partir de la FFT."""

        n_times = X.shape[-1]
        # Centre le signal pour supprimer la composante DC avant la FFT
        centered = X - X.mean(axis=-1, keepdims=True)
        # Calcule les fréquences réelles à partir de la sfreq configurée
        freqs = np.fft.rfftfreq(n_times, d=1.0 / self.sfreq)
        # Calcule la puissance spectrale par canal et échantillon
        power = np.asarray(
            np.abs(np.fft.rfft(centered, axis=-1)) ** 2, )  # pragma: no mutate
        # Restaure l'énergie des composantes symétriques manquantes pour un signal réel
        if power.shape[-1] > 1:
            power[..., 1:-1] *= 2
            # Lorsque n_times est impair, la dernière fréquence possède un symétrique
            if n_times % 2 != 0:
                power[..., -1] *= 2
        # Normalise par la longueur temporelle pour obtenir une puissance moyenne
        power = power / float(n_times**2)
        # Accumule les puissances par bande pour chaque canal
        band_powers: List[np.ndarray] = []
        # Parcourt chaque bande EEG définie dans les paramètres
        for _, (low, high) in self._band_items:
            # Construit le masque fréquentiel pour cette bande
            band_mask = (freqs >= low) & (freqs <= high)

            # Gère le cas où aucune fréquence ne tombe dans la bande
            if not np.any(band_mask):
                # Retourne un bloc de zéros pour préserver la forme
                band_power = np.zeros(power.shape[:2])
            else:
                # Moyenne la puissance sur les fréquences de la bande
                band_power = power[:, :, band_mask].mean(axis=2)

            # Ajoute la matrice (n_samples, n_channels) à la liste
            band_powers.append(band_power)

        # Empile les bandes pour retourner un tenseur cohérent canal x bande
        stacked = np.stack(band_powers, axis=2)
        # Retourne une matrice aplatie (échantillons, canaux * bandes)
        return cast(np.ndarray, stacked.reshape(stacked.shape[0], -1))

    def xǁExtractFeaturesǁ_compute_fft_features__mutmut_25(self, X: np.ndarray) -> np.ndarray:
        """Calcule les puissances de bandes à partir de la FFT."""

        n_times = X.shape[-1]
        # Centre le signal pour supprimer la composante DC avant la FFT
        centered = X - X.mean(axis=-1, keepdims=True)
        # Calcule les fréquences réelles à partir de la sfreq configurée
        freqs = np.fft.rfftfreq(n_times, d=1.0 / self.sfreq)
        # Calcule la puissance spectrale par canal et échantillon
        power = np.asarray(
            np.abs(np.fft.rfft(centered, axis=-1)) * 2, dtype=float
        )  # pragma: no mutate
        # Restaure l'énergie des composantes symétriques manquantes pour un signal réel
        if power.shape[-1] > 1:
            power[..., 1:-1] *= 2
            # Lorsque n_times est impair, la dernière fréquence possède un symétrique
            if n_times % 2 != 0:
                power[..., -1] *= 2
        # Normalise par la longueur temporelle pour obtenir une puissance moyenne
        power = power / float(n_times**2)
        # Accumule les puissances par bande pour chaque canal
        band_powers: List[np.ndarray] = []
        # Parcourt chaque bande EEG définie dans les paramètres
        for _, (low, high) in self._band_items:
            # Construit le masque fréquentiel pour cette bande
            band_mask = (freqs >= low) & (freqs <= high)

            # Gère le cas où aucune fréquence ne tombe dans la bande
            if not np.any(band_mask):
                # Retourne un bloc de zéros pour préserver la forme
                band_power = np.zeros(power.shape[:2])
            else:
                # Moyenne la puissance sur les fréquences de la bande
                band_power = power[:, :, band_mask].mean(axis=2)

            # Ajoute la matrice (n_samples, n_channels) à la liste
            band_powers.append(band_power)

        # Empile les bandes pour retourner un tenseur cohérent canal x bande
        stacked = np.stack(band_powers, axis=2)
        # Retourne une matrice aplatie (échantillons, canaux * bandes)
        return cast(np.ndarray, stacked.reshape(stacked.shape[0], -1))

    def xǁExtractFeaturesǁ_compute_fft_features__mutmut_26(self, X: np.ndarray) -> np.ndarray:
        """Calcule les puissances de bandes à partir de la FFT."""

        n_times = X.shape[-1]
        # Centre le signal pour supprimer la composante DC avant la FFT
        centered = X - X.mean(axis=-1, keepdims=True)
        # Calcule les fréquences réelles à partir de la sfreq configurée
        freqs = np.fft.rfftfreq(n_times, d=1.0 / self.sfreq)
        # Calcule la puissance spectrale par canal et échantillon
        power = np.asarray(
            np.abs(None) ** 2, dtype=float
        )  # pragma: no mutate
        # Restaure l'énergie des composantes symétriques manquantes pour un signal réel
        if power.shape[-1] > 1:
            power[..., 1:-1] *= 2
            # Lorsque n_times est impair, la dernière fréquence possède un symétrique
            if n_times % 2 != 0:
                power[..., -1] *= 2
        # Normalise par la longueur temporelle pour obtenir une puissance moyenne
        power = power / float(n_times**2)
        # Accumule les puissances par bande pour chaque canal
        band_powers: List[np.ndarray] = []
        # Parcourt chaque bande EEG définie dans les paramètres
        for _, (low, high) in self._band_items:
            # Construit le masque fréquentiel pour cette bande
            band_mask = (freqs >= low) & (freqs <= high)

            # Gère le cas où aucune fréquence ne tombe dans la bande
            if not np.any(band_mask):
                # Retourne un bloc de zéros pour préserver la forme
                band_power = np.zeros(power.shape[:2])
            else:
                # Moyenne la puissance sur les fréquences de la bande
                band_power = power[:, :, band_mask].mean(axis=2)

            # Ajoute la matrice (n_samples, n_channels) à la liste
            band_powers.append(band_power)

        # Empile les bandes pour retourner un tenseur cohérent canal x bande
        stacked = np.stack(band_powers, axis=2)
        # Retourne une matrice aplatie (échantillons, canaux * bandes)
        return cast(np.ndarray, stacked.reshape(stacked.shape[0], -1))

    def xǁExtractFeaturesǁ_compute_fft_features__mutmut_27(self, X: np.ndarray) -> np.ndarray:
        """Calcule les puissances de bandes à partir de la FFT."""

        n_times = X.shape[-1]
        # Centre le signal pour supprimer la composante DC avant la FFT
        centered = X - X.mean(axis=-1, keepdims=True)
        # Calcule les fréquences réelles à partir de la sfreq configurée
        freqs = np.fft.rfftfreq(n_times, d=1.0 / self.sfreq)
        # Calcule la puissance spectrale par canal et échantillon
        power = np.asarray(
            np.abs(np.fft.rfft(None, axis=-1)) ** 2, dtype=float
        )  # pragma: no mutate
        # Restaure l'énergie des composantes symétriques manquantes pour un signal réel
        if power.shape[-1] > 1:
            power[..., 1:-1] *= 2
            # Lorsque n_times est impair, la dernière fréquence possède un symétrique
            if n_times % 2 != 0:
                power[..., -1] *= 2
        # Normalise par la longueur temporelle pour obtenir une puissance moyenne
        power = power / float(n_times**2)
        # Accumule les puissances par bande pour chaque canal
        band_powers: List[np.ndarray] = []
        # Parcourt chaque bande EEG définie dans les paramètres
        for _, (low, high) in self._band_items:
            # Construit le masque fréquentiel pour cette bande
            band_mask = (freqs >= low) & (freqs <= high)

            # Gère le cas où aucune fréquence ne tombe dans la bande
            if not np.any(band_mask):
                # Retourne un bloc de zéros pour préserver la forme
                band_power = np.zeros(power.shape[:2])
            else:
                # Moyenne la puissance sur les fréquences de la bande
                band_power = power[:, :, band_mask].mean(axis=2)

            # Ajoute la matrice (n_samples, n_channels) à la liste
            band_powers.append(band_power)

        # Empile les bandes pour retourner un tenseur cohérent canal x bande
        stacked = np.stack(band_powers, axis=2)
        # Retourne une matrice aplatie (échantillons, canaux * bandes)
        return cast(np.ndarray, stacked.reshape(stacked.shape[0], -1))

    def xǁExtractFeaturesǁ_compute_fft_features__mutmut_28(self, X: np.ndarray) -> np.ndarray:
        """Calcule les puissances de bandes à partir de la FFT."""

        n_times = X.shape[-1]
        # Centre le signal pour supprimer la composante DC avant la FFT
        centered = X - X.mean(axis=-1, keepdims=True)
        # Calcule les fréquences réelles à partir de la sfreq configurée
        freqs = np.fft.rfftfreq(n_times, d=1.0 / self.sfreq)
        # Calcule la puissance spectrale par canal et échantillon
        power = np.asarray(
            np.abs(np.fft.rfft(centered, axis=None)) ** 2, dtype=float
        )  # pragma: no mutate
        # Restaure l'énergie des composantes symétriques manquantes pour un signal réel
        if power.shape[-1] > 1:
            power[..., 1:-1] *= 2
            # Lorsque n_times est impair, la dernière fréquence possède un symétrique
            if n_times % 2 != 0:
                power[..., -1] *= 2
        # Normalise par la longueur temporelle pour obtenir une puissance moyenne
        power = power / float(n_times**2)
        # Accumule les puissances par bande pour chaque canal
        band_powers: List[np.ndarray] = []
        # Parcourt chaque bande EEG définie dans les paramètres
        for _, (low, high) in self._band_items:
            # Construit le masque fréquentiel pour cette bande
            band_mask = (freqs >= low) & (freqs <= high)

            # Gère le cas où aucune fréquence ne tombe dans la bande
            if not np.any(band_mask):
                # Retourne un bloc de zéros pour préserver la forme
                band_power = np.zeros(power.shape[:2])
            else:
                # Moyenne la puissance sur les fréquences de la bande
                band_power = power[:, :, band_mask].mean(axis=2)

            # Ajoute la matrice (n_samples, n_channels) à la liste
            band_powers.append(band_power)

        # Empile les bandes pour retourner un tenseur cohérent canal x bande
        stacked = np.stack(band_powers, axis=2)
        # Retourne une matrice aplatie (échantillons, canaux * bandes)
        return cast(np.ndarray, stacked.reshape(stacked.shape[0], -1))

    def xǁExtractFeaturesǁ_compute_fft_features__mutmut_29(self, X: np.ndarray) -> np.ndarray:
        """Calcule les puissances de bandes à partir de la FFT."""

        n_times = X.shape[-1]
        # Centre le signal pour supprimer la composante DC avant la FFT
        centered = X - X.mean(axis=-1, keepdims=True)
        # Calcule les fréquences réelles à partir de la sfreq configurée
        freqs = np.fft.rfftfreq(n_times, d=1.0 / self.sfreq)
        # Calcule la puissance spectrale par canal et échantillon
        power = np.asarray(
            np.abs(np.fft.rfft(axis=-1)) ** 2, dtype=float
        )  # pragma: no mutate
        # Restaure l'énergie des composantes symétriques manquantes pour un signal réel
        if power.shape[-1] > 1:
            power[..., 1:-1] *= 2
            # Lorsque n_times est impair, la dernière fréquence possède un symétrique
            if n_times % 2 != 0:
                power[..., -1] *= 2
        # Normalise par la longueur temporelle pour obtenir une puissance moyenne
        power = power / float(n_times**2)
        # Accumule les puissances par bande pour chaque canal
        band_powers: List[np.ndarray] = []
        # Parcourt chaque bande EEG définie dans les paramètres
        for _, (low, high) in self._band_items:
            # Construit le masque fréquentiel pour cette bande
            band_mask = (freqs >= low) & (freqs <= high)

            # Gère le cas où aucune fréquence ne tombe dans la bande
            if not np.any(band_mask):
                # Retourne un bloc de zéros pour préserver la forme
                band_power = np.zeros(power.shape[:2])
            else:
                # Moyenne la puissance sur les fréquences de la bande
                band_power = power[:, :, band_mask].mean(axis=2)

            # Ajoute la matrice (n_samples, n_channels) à la liste
            band_powers.append(band_power)

        # Empile les bandes pour retourner un tenseur cohérent canal x bande
        stacked = np.stack(band_powers, axis=2)
        # Retourne une matrice aplatie (échantillons, canaux * bandes)
        return cast(np.ndarray, stacked.reshape(stacked.shape[0], -1))

    def xǁExtractFeaturesǁ_compute_fft_features__mutmut_30(self, X: np.ndarray) -> np.ndarray:
        """Calcule les puissances de bandes à partir de la FFT."""

        n_times = X.shape[-1]
        # Centre le signal pour supprimer la composante DC avant la FFT
        centered = X - X.mean(axis=-1, keepdims=True)
        # Calcule les fréquences réelles à partir de la sfreq configurée
        freqs = np.fft.rfftfreq(n_times, d=1.0 / self.sfreq)
        # Calcule la puissance spectrale par canal et échantillon
        power = np.asarray(
            np.abs(np.fft.rfft(centered, )) ** 2, dtype=float
        )  # pragma: no mutate
        # Restaure l'énergie des composantes symétriques manquantes pour un signal réel
        if power.shape[-1] > 1:
            power[..., 1:-1] *= 2
            # Lorsque n_times est impair, la dernière fréquence possède un symétrique
            if n_times % 2 != 0:
                power[..., -1] *= 2
        # Normalise par la longueur temporelle pour obtenir une puissance moyenne
        power = power / float(n_times**2)
        # Accumule les puissances par bande pour chaque canal
        band_powers: List[np.ndarray] = []
        # Parcourt chaque bande EEG définie dans les paramètres
        for _, (low, high) in self._band_items:
            # Construit le masque fréquentiel pour cette bande
            band_mask = (freqs >= low) & (freqs <= high)

            # Gère le cas où aucune fréquence ne tombe dans la bande
            if not np.any(band_mask):
                # Retourne un bloc de zéros pour préserver la forme
                band_power = np.zeros(power.shape[:2])
            else:
                # Moyenne la puissance sur les fréquences de la bande
                band_power = power[:, :, band_mask].mean(axis=2)

            # Ajoute la matrice (n_samples, n_channels) à la liste
            band_powers.append(band_power)

        # Empile les bandes pour retourner un tenseur cohérent canal x bande
        stacked = np.stack(band_powers, axis=2)
        # Retourne une matrice aplatie (échantillons, canaux * bandes)
        return cast(np.ndarray, stacked.reshape(stacked.shape[0], -1))

    def xǁExtractFeaturesǁ_compute_fft_features__mutmut_31(self, X: np.ndarray) -> np.ndarray:
        """Calcule les puissances de bandes à partir de la FFT."""

        n_times = X.shape[-1]
        # Centre le signal pour supprimer la composante DC avant la FFT
        centered = X - X.mean(axis=-1, keepdims=True)
        # Calcule les fréquences réelles à partir de la sfreq configurée
        freqs = np.fft.rfftfreq(n_times, d=1.0 / self.sfreq)
        # Calcule la puissance spectrale par canal et échantillon
        power = np.asarray(
            np.abs(np.fft.rfft(centered, axis=+1)) ** 2, dtype=float
        )  # pragma: no mutate
        # Restaure l'énergie des composantes symétriques manquantes pour un signal réel
        if power.shape[-1] > 1:
            power[..., 1:-1] *= 2
            # Lorsque n_times est impair, la dernière fréquence possède un symétrique
            if n_times % 2 != 0:
                power[..., -1] *= 2
        # Normalise par la longueur temporelle pour obtenir une puissance moyenne
        power = power / float(n_times**2)
        # Accumule les puissances par bande pour chaque canal
        band_powers: List[np.ndarray] = []
        # Parcourt chaque bande EEG définie dans les paramètres
        for _, (low, high) in self._band_items:
            # Construit le masque fréquentiel pour cette bande
            band_mask = (freqs >= low) & (freqs <= high)

            # Gère le cas où aucune fréquence ne tombe dans la bande
            if not np.any(band_mask):
                # Retourne un bloc de zéros pour préserver la forme
                band_power = np.zeros(power.shape[:2])
            else:
                # Moyenne la puissance sur les fréquences de la bande
                band_power = power[:, :, band_mask].mean(axis=2)

            # Ajoute la matrice (n_samples, n_channels) à la liste
            band_powers.append(band_power)

        # Empile les bandes pour retourner un tenseur cohérent canal x bande
        stacked = np.stack(band_powers, axis=2)
        # Retourne une matrice aplatie (échantillons, canaux * bandes)
        return cast(np.ndarray, stacked.reshape(stacked.shape[0], -1))

    def xǁExtractFeaturesǁ_compute_fft_features__mutmut_32(self, X: np.ndarray) -> np.ndarray:
        """Calcule les puissances de bandes à partir de la FFT."""

        n_times = X.shape[-1]
        # Centre le signal pour supprimer la composante DC avant la FFT
        centered = X - X.mean(axis=-1, keepdims=True)
        # Calcule les fréquences réelles à partir de la sfreq configurée
        freqs = np.fft.rfftfreq(n_times, d=1.0 / self.sfreq)
        # Calcule la puissance spectrale par canal et échantillon
        power = np.asarray(
            np.abs(np.fft.rfft(centered, axis=-2)) ** 2, dtype=float
        )  # pragma: no mutate
        # Restaure l'énergie des composantes symétriques manquantes pour un signal réel
        if power.shape[-1] > 1:
            power[..., 1:-1] *= 2
            # Lorsque n_times est impair, la dernière fréquence possède un symétrique
            if n_times % 2 != 0:
                power[..., -1] *= 2
        # Normalise par la longueur temporelle pour obtenir une puissance moyenne
        power = power / float(n_times**2)
        # Accumule les puissances par bande pour chaque canal
        band_powers: List[np.ndarray] = []
        # Parcourt chaque bande EEG définie dans les paramètres
        for _, (low, high) in self._band_items:
            # Construit le masque fréquentiel pour cette bande
            band_mask = (freqs >= low) & (freqs <= high)

            # Gère le cas où aucune fréquence ne tombe dans la bande
            if not np.any(band_mask):
                # Retourne un bloc de zéros pour préserver la forme
                band_power = np.zeros(power.shape[:2])
            else:
                # Moyenne la puissance sur les fréquences de la bande
                band_power = power[:, :, band_mask].mean(axis=2)

            # Ajoute la matrice (n_samples, n_channels) à la liste
            band_powers.append(band_power)

        # Empile les bandes pour retourner un tenseur cohérent canal x bande
        stacked = np.stack(band_powers, axis=2)
        # Retourne une matrice aplatie (échantillons, canaux * bandes)
        return cast(np.ndarray, stacked.reshape(stacked.shape[0], -1))

    def xǁExtractFeaturesǁ_compute_fft_features__mutmut_33(self, X: np.ndarray) -> np.ndarray:
        """Calcule les puissances de bandes à partir de la FFT."""

        n_times = X.shape[-1]
        # Centre le signal pour supprimer la composante DC avant la FFT
        centered = X - X.mean(axis=-1, keepdims=True)
        # Calcule les fréquences réelles à partir de la sfreq configurée
        freqs = np.fft.rfftfreq(n_times, d=1.0 / self.sfreq)
        # Calcule la puissance spectrale par canal et échantillon
        power = np.asarray(
            np.abs(np.fft.rfft(centered, axis=-1)) ** 3, dtype=float
        )  # pragma: no mutate
        # Restaure l'énergie des composantes symétriques manquantes pour un signal réel
        if power.shape[-1] > 1:
            power[..., 1:-1] *= 2
            # Lorsque n_times est impair, la dernière fréquence possède un symétrique
            if n_times % 2 != 0:
                power[..., -1] *= 2
        # Normalise par la longueur temporelle pour obtenir une puissance moyenne
        power = power / float(n_times**2)
        # Accumule les puissances par bande pour chaque canal
        band_powers: List[np.ndarray] = []
        # Parcourt chaque bande EEG définie dans les paramètres
        for _, (low, high) in self._band_items:
            # Construit le masque fréquentiel pour cette bande
            band_mask = (freqs >= low) & (freqs <= high)

            # Gère le cas où aucune fréquence ne tombe dans la bande
            if not np.any(band_mask):
                # Retourne un bloc de zéros pour préserver la forme
                band_power = np.zeros(power.shape[:2])
            else:
                # Moyenne la puissance sur les fréquences de la bande
                band_power = power[:, :, band_mask].mean(axis=2)

            # Ajoute la matrice (n_samples, n_channels) à la liste
            band_powers.append(band_power)

        # Empile les bandes pour retourner un tenseur cohérent canal x bande
        stacked = np.stack(band_powers, axis=2)
        # Retourne une matrice aplatie (échantillons, canaux * bandes)
        return cast(np.ndarray, stacked.reshape(stacked.shape[0], -1))

    def xǁExtractFeaturesǁ_compute_fft_features__mutmut_34(self, X: np.ndarray) -> np.ndarray:
        """Calcule les puissances de bandes à partir de la FFT."""

        n_times = X.shape[-1]
        # Centre le signal pour supprimer la composante DC avant la FFT
        centered = X - X.mean(axis=-1, keepdims=True)
        # Calcule les fréquences réelles à partir de la sfreq configurée
        freqs = np.fft.rfftfreq(n_times, d=1.0 / self.sfreq)
        # Calcule la puissance spectrale par canal et échantillon
        power = np.asarray(
            np.abs(np.fft.rfft(centered, axis=-1)) ** 2, dtype=float
        )  # pragma: no mutate
        # Restaure l'énergie des composantes symétriques manquantes pour un signal réel
        if power.shape[+1] > 1:
            power[..., 1:-1] *= 2
            # Lorsque n_times est impair, la dernière fréquence possède un symétrique
            if n_times % 2 != 0:
                power[..., -1] *= 2
        # Normalise par la longueur temporelle pour obtenir une puissance moyenne
        power = power / float(n_times**2)
        # Accumule les puissances par bande pour chaque canal
        band_powers: List[np.ndarray] = []
        # Parcourt chaque bande EEG définie dans les paramètres
        for _, (low, high) in self._band_items:
            # Construit le masque fréquentiel pour cette bande
            band_mask = (freqs >= low) & (freqs <= high)

            # Gère le cas où aucune fréquence ne tombe dans la bande
            if not np.any(band_mask):
                # Retourne un bloc de zéros pour préserver la forme
                band_power = np.zeros(power.shape[:2])
            else:
                # Moyenne la puissance sur les fréquences de la bande
                band_power = power[:, :, band_mask].mean(axis=2)

            # Ajoute la matrice (n_samples, n_channels) à la liste
            band_powers.append(band_power)

        # Empile les bandes pour retourner un tenseur cohérent canal x bande
        stacked = np.stack(band_powers, axis=2)
        # Retourne une matrice aplatie (échantillons, canaux * bandes)
        return cast(np.ndarray, stacked.reshape(stacked.shape[0], -1))

    def xǁExtractFeaturesǁ_compute_fft_features__mutmut_35(self, X: np.ndarray) -> np.ndarray:
        """Calcule les puissances de bandes à partir de la FFT."""

        n_times = X.shape[-1]
        # Centre le signal pour supprimer la composante DC avant la FFT
        centered = X - X.mean(axis=-1, keepdims=True)
        # Calcule les fréquences réelles à partir de la sfreq configurée
        freqs = np.fft.rfftfreq(n_times, d=1.0 / self.sfreq)
        # Calcule la puissance spectrale par canal et échantillon
        power = np.asarray(
            np.abs(np.fft.rfft(centered, axis=-1)) ** 2, dtype=float
        )  # pragma: no mutate
        # Restaure l'énergie des composantes symétriques manquantes pour un signal réel
        if power.shape[-2] > 1:
            power[..., 1:-1] *= 2
            # Lorsque n_times est impair, la dernière fréquence possède un symétrique
            if n_times % 2 != 0:
                power[..., -1] *= 2
        # Normalise par la longueur temporelle pour obtenir une puissance moyenne
        power = power / float(n_times**2)
        # Accumule les puissances par bande pour chaque canal
        band_powers: List[np.ndarray] = []
        # Parcourt chaque bande EEG définie dans les paramètres
        for _, (low, high) in self._band_items:
            # Construit le masque fréquentiel pour cette bande
            band_mask = (freqs >= low) & (freqs <= high)

            # Gère le cas où aucune fréquence ne tombe dans la bande
            if not np.any(band_mask):
                # Retourne un bloc de zéros pour préserver la forme
                band_power = np.zeros(power.shape[:2])
            else:
                # Moyenne la puissance sur les fréquences de la bande
                band_power = power[:, :, band_mask].mean(axis=2)

            # Ajoute la matrice (n_samples, n_channels) à la liste
            band_powers.append(band_power)

        # Empile les bandes pour retourner un tenseur cohérent canal x bande
        stacked = np.stack(band_powers, axis=2)
        # Retourne une matrice aplatie (échantillons, canaux * bandes)
        return cast(np.ndarray, stacked.reshape(stacked.shape[0], -1))

    def xǁExtractFeaturesǁ_compute_fft_features__mutmut_36(self, X: np.ndarray) -> np.ndarray:
        """Calcule les puissances de bandes à partir de la FFT."""

        n_times = X.shape[-1]
        # Centre le signal pour supprimer la composante DC avant la FFT
        centered = X - X.mean(axis=-1, keepdims=True)
        # Calcule les fréquences réelles à partir de la sfreq configurée
        freqs = np.fft.rfftfreq(n_times, d=1.0 / self.sfreq)
        # Calcule la puissance spectrale par canal et échantillon
        power = np.asarray(
            np.abs(np.fft.rfft(centered, axis=-1)) ** 2, dtype=float
        )  # pragma: no mutate
        # Restaure l'énergie des composantes symétriques manquantes pour un signal réel
        if power.shape[-1] >= 1:
            power[..., 1:-1] *= 2
            # Lorsque n_times est impair, la dernière fréquence possède un symétrique
            if n_times % 2 != 0:
                power[..., -1] *= 2
        # Normalise par la longueur temporelle pour obtenir une puissance moyenne
        power = power / float(n_times**2)
        # Accumule les puissances par bande pour chaque canal
        band_powers: List[np.ndarray] = []
        # Parcourt chaque bande EEG définie dans les paramètres
        for _, (low, high) in self._band_items:
            # Construit le masque fréquentiel pour cette bande
            band_mask = (freqs >= low) & (freqs <= high)

            # Gère le cas où aucune fréquence ne tombe dans la bande
            if not np.any(band_mask):
                # Retourne un bloc de zéros pour préserver la forme
                band_power = np.zeros(power.shape[:2])
            else:
                # Moyenne la puissance sur les fréquences de la bande
                band_power = power[:, :, band_mask].mean(axis=2)

            # Ajoute la matrice (n_samples, n_channels) à la liste
            band_powers.append(band_power)

        # Empile les bandes pour retourner un tenseur cohérent canal x bande
        stacked = np.stack(band_powers, axis=2)
        # Retourne une matrice aplatie (échantillons, canaux * bandes)
        return cast(np.ndarray, stacked.reshape(stacked.shape[0], -1))

    def xǁExtractFeaturesǁ_compute_fft_features__mutmut_37(self, X: np.ndarray) -> np.ndarray:
        """Calcule les puissances de bandes à partir de la FFT."""

        n_times = X.shape[-1]
        # Centre le signal pour supprimer la composante DC avant la FFT
        centered = X - X.mean(axis=-1, keepdims=True)
        # Calcule les fréquences réelles à partir de la sfreq configurée
        freqs = np.fft.rfftfreq(n_times, d=1.0 / self.sfreq)
        # Calcule la puissance spectrale par canal et échantillon
        power = np.asarray(
            np.abs(np.fft.rfft(centered, axis=-1)) ** 2, dtype=float
        )  # pragma: no mutate
        # Restaure l'énergie des composantes symétriques manquantes pour un signal réel
        if power.shape[-1] > 2:
            power[..., 1:-1] *= 2
            # Lorsque n_times est impair, la dernière fréquence possède un symétrique
            if n_times % 2 != 0:
                power[..., -1] *= 2
        # Normalise par la longueur temporelle pour obtenir une puissance moyenne
        power = power / float(n_times**2)
        # Accumule les puissances par bande pour chaque canal
        band_powers: List[np.ndarray] = []
        # Parcourt chaque bande EEG définie dans les paramètres
        for _, (low, high) in self._band_items:
            # Construit le masque fréquentiel pour cette bande
            band_mask = (freqs >= low) & (freqs <= high)

            # Gère le cas où aucune fréquence ne tombe dans la bande
            if not np.any(band_mask):
                # Retourne un bloc de zéros pour préserver la forme
                band_power = np.zeros(power.shape[:2])
            else:
                # Moyenne la puissance sur les fréquences de la bande
                band_power = power[:, :, band_mask].mean(axis=2)

            # Ajoute la matrice (n_samples, n_channels) à la liste
            band_powers.append(band_power)

        # Empile les bandes pour retourner un tenseur cohérent canal x bande
        stacked = np.stack(band_powers, axis=2)
        # Retourne une matrice aplatie (échantillons, canaux * bandes)
        return cast(np.ndarray, stacked.reshape(stacked.shape[0], -1))

    def xǁExtractFeaturesǁ_compute_fft_features__mutmut_38(self, X: np.ndarray) -> np.ndarray:
        """Calcule les puissances de bandes à partir de la FFT."""

        n_times = X.shape[-1]
        # Centre le signal pour supprimer la composante DC avant la FFT
        centered = X - X.mean(axis=-1, keepdims=True)
        # Calcule les fréquences réelles à partir de la sfreq configurée
        freqs = np.fft.rfftfreq(n_times, d=1.0 / self.sfreq)
        # Calcule la puissance spectrale par canal et échantillon
        power = np.asarray(
            np.abs(np.fft.rfft(centered, axis=-1)) ** 2, dtype=float
        )  # pragma: no mutate
        # Restaure l'énergie des composantes symétriques manquantes pour un signal réel
        if power.shape[-1] > 1:
            power[..., 1:-1] = 2
            # Lorsque n_times est impair, la dernière fréquence possède un symétrique
            if n_times % 2 != 0:
                power[..., -1] *= 2
        # Normalise par la longueur temporelle pour obtenir une puissance moyenne
        power = power / float(n_times**2)
        # Accumule les puissances par bande pour chaque canal
        band_powers: List[np.ndarray] = []
        # Parcourt chaque bande EEG définie dans les paramètres
        for _, (low, high) in self._band_items:
            # Construit le masque fréquentiel pour cette bande
            band_mask = (freqs >= low) & (freqs <= high)

            # Gère le cas où aucune fréquence ne tombe dans la bande
            if not np.any(band_mask):
                # Retourne un bloc de zéros pour préserver la forme
                band_power = np.zeros(power.shape[:2])
            else:
                # Moyenne la puissance sur les fréquences de la bande
                band_power = power[:, :, band_mask].mean(axis=2)

            # Ajoute la matrice (n_samples, n_channels) à la liste
            band_powers.append(band_power)

        # Empile les bandes pour retourner un tenseur cohérent canal x bande
        stacked = np.stack(band_powers, axis=2)
        # Retourne une matrice aplatie (échantillons, canaux * bandes)
        return cast(np.ndarray, stacked.reshape(stacked.shape[0], -1))

    def xǁExtractFeaturesǁ_compute_fft_features__mutmut_39(self, X: np.ndarray) -> np.ndarray:
        """Calcule les puissances de bandes à partir de la FFT."""

        n_times = X.shape[-1]
        # Centre le signal pour supprimer la composante DC avant la FFT
        centered = X - X.mean(axis=-1, keepdims=True)
        # Calcule les fréquences réelles à partir de la sfreq configurée
        freqs = np.fft.rfftfreq(n_times, d=1.0 / self.sfreq)
        # Calcule la puissance spectrale par canal et échantillon
        power = np.asarray(
            np.abs(np.fft.rfft(centered, axis=-1)) ** 2, dtype=float
        )  # pragma: no mutate
        # Restaure l'énergie des composantes symétriques manquantes pour un signal réel
        if power.shape[-1] > 1:
            power[..., 1:-1] /= 2
            # Lorsque n_times est impair, la dernière fréquence possède un symétrique
            if n_times % 2 != 0:
                power[..., -1] *= 2
        # Normalise par la longueur temporelle pour obtenir une puissance moyenne
        power = power / float(n_times**2)
        # Accumule les puissances par bande pour chaque canal
        band_powers: List[np.ndarray] = []
        # Parcourt chaque bande EEG définie dans les paramètres
        for _, (low, high) in self._band_items:
            # Construit le masque fréquentiel pour cette bande
            band_mask = (freqs >= low) & (freqs <= high)

            # Gère le cas où aucune fréquence ne tombe dans la bande
            if not np.any(band_mask):
                # Retourne un bloc de zéros pour préserver la forme
                band_power = np.zeros(power.shape[:2])
            else:
                # Moyenne la puissance sur les fréquences de la bande
                band_power = power[:, :, band_mask].mean(axis=2)

            # Ajoute la matrice (n_samples, n_channels) à la liste
            band_powers.append(band_power)

        # Empile les bandes pour retourner un tenseur cohérent canal x bande
        stacked = np.stack(band_powers, axis=2)
        # Retourne une matrice aplatie (échantillons, canaux * bandes)
        return cast(np.ndarray, stacked.reshape(stacked.shape[0], -1))

    def xǁExtractFeaturesǁ_compute_fft_features__mutmut_40(self, X: np.ndarray) -> np.ndarray:
        """Calcule les puissances de bandes à partir de la FFT."""

        n_times = X.shape[-1]
        # Centre le signal pour supprimer la composante DC avant la FFT
        centered = X - X.mean(axis=-1, keepdims=True)
        # Calcule les fréquences réelles à partir de la sfreq configurée
        freqs = np.fft.rfftfreq(n_times, d=1.0 / self.sfreq)
        # Calcule la puissance spectrale par canal et échantillon
        power = np.asarray(
            np.abs(np.fft.rfft(centered, axis=-1)) ** 2, dtype=float
        )  # pragma: no mutate
        # Restaure l'énergie des composantes symétriques manquantes pour un signal réel
        if power.shape[-1] > 1:
            power[..., 2:-1] *= 2
            # Lorsque n_times est impair, la dernière fréquence possède un symétrique
            if n_times % 2 != 0:
                power[..., -1] *= 2
        # Normalise par la longueur temporelle pour obtenir une puissance moyenne
        power = power / float(n_times**2)
        # Accumule les puissances par bande pour chaque canal
        band_powers: List[np.ndarray] = []
        # Parcourt chaque bande EEG définie dans les paramètres
        for _, (low, high) in self._band_items:
            # Construit le masque fréquentiel pour cette bande
            band_mask = (freqs >= low) & (freqs <= high)

            # Gère le cas où aucune fréquence ne tombe dans la bande
            if not np.any(band_mask):
                # Retourne un bloc de zéros pour préserver la forme
                band_power = np.zeros(power.shape[:2])
            else:
                # Moyenne la puissance sur les fréquences de la bande
                band_power = power[:, :, band_mask].mean(axis=2)

            # Ajoute la matrice (n_samples, n_channels) à la liste
            band_powers.append(band_power)

        # Empile les bandes pour retourner un tenseur cohérent canal x bande
        stacked = np.stack(band_powers, axis=2)
        # Retourne une matrice aplatie (échantillons, canaux * bandes)
        return cast(np.ndarray, stacked.reshape(stacked.shape[0], -1))

    def xǁExtractFeaturesǁ_compute_fft_features__mutmut_41(self, X: np.ndarray) -> np.ndarray:
        """Calcule les puissances de bandes à partir de la FFT."""

        n_times = X.shape[-1]
        # Centre le signal pour supprimer la composante DC avant la FFT
        centered = X - X.mean(axis=-1, keepdims=True)
        # Calcule les fréquences réelles à partir de la sfreq configurée
        freqs = np.fft.rfftfreq(n_times, d=1.0 / self.sfreq)
        # Calcule la puissance spectrale par canal et échantillon
        power = np.asarray(
            np.abs(np.fft.rfft(centered, axis=-1)) ** 2, dtype=float
        )  # pragma: no mutate
        # Restaure l'énergie des composantes symétriques manquantes pour un signal réel
        if power.shape[-1] > 1:
            power[..., 1:+1] *= 2
            # Lorsque n_times est impair, la dernière fréquence possède un symétrique
            if n_times % 2 != 0:
                power[..., -1] *= 2
        # Normalise par la longueur temporelle pour obtenir une puissance moyenne
        power = power / float(n_times**2)
        # Accumule les puissances par bande pour chaque canal
        band_powers: List[np.ndarray] = []
        # Parcourt chaque bande EEG définie dans les paramètres
        for _, (low, high) in self._band_items:
            # Construit le masque fréquentiel pour cette bande
            band_mask = (freqs >= low) & (freqs <= high)

            # Gère le cas où aucune fréquence ne tombe dans la bande
            if not np.any(band_mask):
                # Retourne un bloc de zéros pour préserver la forme
                band_power = np.zeros(power.shape[:2])
            else:
                # Moyenne la puissance sur les fréquences de la bande
                band_power = power[:, :, band_mask].mean(axis=2)

            # Ajoute la matrice (n_samples, n_channels) à la liste
            band_powers.append(band_power)

        # Empile les bandes pour retourner un tenseur cohérent canal x bande
        stacked = np.stack(band_powers, axis=2)
        # Retourne une matrice aplatie (échantillons, canaux * bandes)
        return cast(np.ndarray, stacked.reshape(stacked.shape[0], -1))

    def xǁExtractFeaturesǁ_compute_fft_features__mutmut_42(self, X: np.ndarray) -> np.ndarray:
        """Calcule les puissances de bandes à partir de la FFT."""

        n_times = X.shape[-1]
        # Centre le signal pour supprimer la composante DC avant la FFT
        centered = X - X.mean(axis=-1, keepdims=True)
        # Calcule les fréquences réelles à partir de la sfreq configurée
        freqs = np.fft.rfftfreq(n_times, d=1.0 / self.sfreq)
        # Calcule la puissance spectrale par canal et échantillon
        power = np.asarray(
            np.abs(np.fft.rfft(centered, axis=-1)) ** 2, dtype=float
        )  # pragma: no mutate
        # Restaure l'énergie des composantes symétriques manquantes pour un signal réel
        if power.shape[-1] > 1:
            power[..., 1:-2] *= 2
            # Lorsque n_times est impair, la dernière fréquence possède un symétrique
            if n_times % 2 != 0:
                power[..., -1] *= 2
        # Normalise par la longueur temporelle pour obtenir une puissance moyenne
        power = power / float(n_times**2)
        # Accumule les puissances par bande pour chaque canal
        band_powers: List[np.ndarray] = []
        # Parcourt chaque bande EEG définie dans les paramètres
        for _, (low, high) in self._band_items:
            # Construit le masque fréquentiel pour cette bande
            band_mask = (freqs >= low) & (freqs <= high)

            # Gère le cas où aucune fréquence ne tombe dans la bande
            if not np.any(band_mask):
                # Retourne un bloc de zéros pour préserver la forme
                band_power = np.zeros(power.shape[:2])
            else:
                # Moyenne la puissance sur les fréquences de la bande
                band_power = power[:, :, band_mask].mean(axis=2)

            # Ajoute la matrice (n_samples, n_channels) à la liste
            band_powers.append(band_power)

        # Empile les bandes pour retourner un tenseur cohérent canal x bande
        stacked = np.stack(band_powers, axis=2)
        # Retourne une matrice aplatie (échantillons, canaux * bandes)
        return cast(np.ndarray, stacked.reshape(stacked.shape[0], -1))

    def xǁExtractFeaturesǁ_compute_fft_features__mutmut_43(self, X: np.ndarray) -> np.ndarray:
        """Calcule les puissances de bandes à partir de la FFT."""

        n_times = X.shape[-1]
        # Centre le signal pour supprimer la composante DC avant la FFT
        centered = X - X.mean(axis=-1, keepdims=True)
        # Calcule les fréquences réelles à partir de la sfreq configurée
        freqs = np.fft.rfftfreq(n_times, d=1.0 / self.sfreq)
        # Calcule la puissance spectrale par canal et échantillon
        power = np.asarray(
            np.abs(np.fft.rfft(centered, axis=-1)) ** 2, dtype=float
        )  # pragma: no mutate
        # Restaure l'énergie des composantes symétriques manquantes pour un signal réel
        if power.shape[-1] > 1:
            power[..., 1:-1] *= 3
            # Lorsque n_times est impair, la dernière fréquence possède un symétrique
            if n_times % 2 != 0:
                power[..., -1] *= 2
        # Normalise par la longueur temporelle pour obtenir une puissance moyenne
        power = power / float(n_times**2)
        # Accumule les puissances par bande pour chaque canal
        band_powers: List[np.ndarray] = []
        # Parcourt chaque bande EEG définie dans les paramètres
        for _, (low, high) in self._band_items:
            # Construit le masque fréquentiel pour cette bande
            band_mask = (freqs >= low) & (freqs <= high)

            # Gère le cas où aucune fréquence ne tombe dans la bande
            if not np.any(band_mask):
                # Retourne un bloc de zéros pour préserver la forme
                band_power = np.zeros(power.shape[:2])
            else:
                # Moyenne la puissance sur les fréquences de la bande
                band_power = power[:, :, band_mask].mean(axis=2)

            # Ajoute la matrice (n_samples, n_channels) à la liste
            band_powers.append(band_power)

        # Empile les bandes pour retourner un tenseur cohérent canal x bande
        stacked = np.stack(band_powers, axis=2)
        # Retourne une matrice aplatie (échantillons, canaux * bandes)
        return cast(np.ndarray, stacked.reshape(stacked.shape[0], -1))

    def xǁExtractFeaturesǁ_compute_fft_features__mutmut_44(self, X: np.ndarray) -> np.ndarray:
        """Calcule les puissances de bandes à partir de la FFT."""

        n_times = X.shape[-1]
        # Centre le signal pour supprimer la composante DC avant la FFT
        centered = X - X.mean(axis=-1, keepdims=True)
        # Calcule les fréquences réelles à partir de la sfreq configurée
        freqs = np.fft.rfftfreq(n_times, d=1.0 / self.sfreq)
        # Calcule la puissance spectrale par canal et échantillon
        power = np.asarray(
            np.abs(np.fft.rfft(centered, axis=-1)) ** 2, dtype=float
        )  # pragma: no mutate
        # Restaure l'énergie des composantes symétriques manquantes pour un signal réel
        if power.shape[-1] > 1:
            power[..., 1:-1] *= 2
            # Lorsque n_times est impair, la dernière fréquence possède un symétrique
            if n_times / 2 != 0:
                power[..., -1] *= 2
        # Normalise par la longueur temporelle pour obtenir une puissance moyenne
        power = power / float(n_times**2)
        # Accumule les puissances par bande pour chaque canal
        band_powers: List[np.ndarray] = []
        # Parcourt chaque bande EEG définie dans les paramètres
        for _, (low, high) in self._band_items:
            # Construit le masque fréquentiel pour cette bande
            band_mask = (freqs >= low) & (freqs <= high)

            # Gère le cas où aucune fréquence ne tombe dans la bande
            if not np.any(band_mask):
                # Retourne un bloc de zéros pour préserver la forme
                band_power = np.zeros(power.shape[:2])
            else:
                # Moyenne la puissance sur les fréquences de la bande
                band_power = power[:, :, band_mask].mean(axis=2)

            # Ajoute la matrice (n_samples, n_channels) à la liste
            band_powers.append(band_power)

        # Empile les bandes pour retourner un tenseur cohérent canal x bande
        stacked = np.stack(band_powers, axis=2)
        # Retourne une matrice aplatie (échantillons, canaux * bandes)
        return cast(np.ndarray, stacked.reshape(stacked.shape[0], -1))

    def xǁExtractFeaturesǁ_compute_fft_features__mutmut_45(self, X: np.ndarray) -> np.ndarray:
        """Calcule les puissances de bandes à partir de la FFT."""

        n_times = X.shape[-1]
        # Centre le signal pour supprimer la composante DC avant la FFT
        centered = X - X.mean(axis=-1, keepdims=True)
        # Calcule les fréquences réelles à partir de la sfreq configurée
        freqs = np.fft.rfftfreq(n_times, d=1.0 / self.sfreq)
        # Calcule la puissance spectrale par canal et échantillon
        power = np.asarray(
            np.abs(np.fft.rfft(centered, axis=-1)) ** 2, dtype=float
        )  # pragma: no mutate
        # Restaure l'énergie des composantes symétriques manquantes pour un signal réel
        if power.shape[-1] > 1:
            power[..., 1:-1] *= 2
            # Lorsque n_times est impair, la dernière fréquence possède un symétrique
            if n_times % 3 != 0:
                power[..., -1] *= 2
        # Normalise par la longueur temporelle pour obtenir une puissance moyenne
        power = power / float(n_times**2)
        # Accumule les puissances par bande pour chaque canal
        band_powers: List[np.ndarray] = []
        # Parcourt chaque bande EEG définie dans les paramètres
        for _, (low, high) in self._band_items:
            # Construit le masque fréquentiel pour cette bande
            band_mask = (freqs >= low) & (freqs <= high)

            # Gère le cas où aucune fréquence ne tombe dans la bande
            if not np.any(band_mask):
                # Retourne un bloc de zéros pour préserver la forme
                band_power = np.zeros(power.shape[:2])
            else:
                # Moyenne la puissance sur les fréquences de la bande
                band_power = power[:, :, band_mask].mean(axis=2)

            # Ajoute la matrice (n_samples, n_channels) à la liste
            band_powers.append(band_power)

        # Empile les bandes pour retourner un tenseur cohérent canal x bande
        stacked = np.stack(band_powers, axis=2)
        # Retourne une matrice aplatie (échantillons, canaux * bandes)
        return cast(np.ndarray, stacked.reshape(stacked.shape[0], -1))

    def xǁExtractFeaturesǁ_compute_fft_features__mutmut_46(self, X: np.ndarray) -> np.ndarray:
        """Calcule les puissances de bandes à partir de la FFT."""

        n_times = X.shape[-1]
        # Centre le signal pour supprimer la composante DC avant la FFT
        centered = X - X.mean(axis=-1, keepdims=True)
        # Calcule les fréquences réelles à partir de la sfreq configurée
        freqs = np.fft.rfftfreq(n_times, d=1.0 / self.sfreq)
        # Calcule la puissance spectrale par canal et échantillon
        power = np.asarray(
            np.abs(np.fft.rfft(centered, axis=-1)) ** 2, dtype=float
        )  # pragma: no mutate
        # Restaure l'énergie des composantes symétriques manquantes pour un signal réel
        if power.shape[-1] > 1:
            power[..., 1:-1] *= 2
            # Lorsque n_times est impair, la dernière fréquence possède un symétrique
            if n_times % 2 == 0:
                power[..., -1] *= 2
        # Normalise par la longueur temporelle pour obtenir une puissance moyenne
        power = power / float(n_times**2)
        # Accumule les puissances par bande pour chaque canal
        band_powers: List[np.ndarray] = []
        # Parcourt chaque bande EEG définie dans les paramètres
        for _, (low, high) in self._band_items:
            # Construit le masque fréquentiel pour cette bande
            band_mask = (freqs >= low) & (freqs <= high)

            # Gère le cas où aucune fréquence ne tombe dans la bande
            if not np.any(band_mask):
                # Retourne un bloc de zéros pour préserver la forme
                band_power = np.zeros(power.shape[:2])
            else:
                # Moyenne la puissance sur les fréquences de la bande
                band_power = power[:, :, band_mask].mean(axis=2)

            # Ajoute la matrice (n_samples, n_channels) à la liste
            band_powers.append(band_power)

        # Empile les bandes pour retourner un tenseur cohérent canal x bande
        stacked = np.stack(band_powers, axis=2)
        # Retourne une matrice aplatie (échantillons, canaux * bandes)
        return cast(np.ndarray, stacked.reshape(stacked.shape[0], -1))

    def xǁExtractFeaturesǁ_compute_fft_features__mutmut_47(self, X: np.ndarray) -> np.ndarray:
        """Calcule les puissances de bandes à partir de la FFT."""

        n_times = X.shape[-1]
        # Centre le signal pour supprimer la composante DC avant la FFT
        centered = X - X.mean(axis=-1, keepdims=True)
        # Calcule les fréquences réelles à partir de la sfreq configurée
        freqs = np.fft.rfftfreq(n_times, d=1.0 / self.sfreq)
        # Calcule la puissance spectrale par canal et échantillon
        power = np.asarray(
            np.abs(np.fft.rfft(centered, axis=-1)) ** 2, dtype=float
        )  # pragma: no mutate
        # Restaure l'énergie des composantes symétriques manquantes pour un signal réel
        if power.shape[-1] > 1:
            power[..., 1:-1] *= 2
            # Lorsque n_times est impair, la dernière fréquence possède un symétrique
            if n_times % 2 != 1:
                power[..., -1] *= 2
        # Normalise par la longueur temporelle pour obtenir une puissance moyenne
        power = power / float(n_times**2)
        # Accumule les puissances par bande pour chaque canal
        band_powers: List[np.ndarray] = []
        # Parcourt chaque bande EEG définie dans les paramètres
        for _, (low, high) in self._band_items:
            # Construit le masque fréquentiel pour cette bande
            band_mask = (freqs >= low) & (freqs <= high)

            # Gère le cas où aucune fréquence ne tombe dans la bande
            if not np.any(band_mask):
                # Retourne un bloc de zéros pour préserver la forme
                band_power = np.zeros(power.shape[:2])
            else:
                # Moyenne la puissance sur les fréquences de la bande
                band_power = power[:, :, band_mask].mean(axis=2)

            # Ajoute la matrice (n_samples, n_channels) à la liste
            band_powers.append(band_power)

        # Empile les bandes pour retourner un tenseur cohérent canal x bande
        stacked = np.stack(band_powers, axis=2)
        # Retourne une matrice aplatie (échantillons, canaux * bandes)
        return cast(np.ndarray, stacked.reshape(stacked.shape[0], -1))

    def xǁExtractFeaturesǁ_compute_fft_features__mutmut_48(self, X: np.ndarray) -> np.ndarray:
        """Calcule les puissances de bandes à partir de la FFT."""

        n_times = X.shape[-1]
        # Centre le signal pour supprimer la composante DC avant la FFT
        centered = X - X.mean(axis=-1, keepdims=True)
        # Calcule les fréquences réelles à partir de la sfreq configurée
        freqs = np.fft.rfftfreq(n_times, d=1.0 / self.sfreq)
        # Calcule la puissance spectrale par canal et échantillon
        power = np.asarray(
            np.abs(np.fft.rfft(centered, axis=-1)) ** 2, dtype=float
        )  # pragma: no mutate
        # Restaure l'énergie des composantes symétriques manquantes pour un signal réel
        if power.shape[-1] > 1:
            power[..., 1:-1] *= 2
            # Lorsque n_times est impair, la dernière fréquence possède un symétrique
            if n_times % 2 != 0:
                power[..., -1] = 2
        # Normalise par la longueur temporelle pour obtenir une puissance moyenne
        power = power / float(n_times**2)
        # Accumule les puissances par bande pour chaque canal
        band_powers: List[np.ndarray] = []
        # Parcourt chaque bande EEG définie dans les paramètres
        for _, (low, high) in self._band_items:
            # Construit le masque fréquentiel pour cette bande
            band_mask = (freqs >= low) & (freqs <= high)

            # Gère le cas où aucune fréquence ne tombe dans la bande
            if not np.any(band_mask):
                # Retourne un bloc de zéros pour préserver la forme
                band_power = np.zeros(power.shape[:2])
            else:
                # Moyenne la puissance sur les fréquences de la bande
                band_power = power[:, :, band_mask].mean(axis=2)

            # Ajoute la matrice (n_samples, n_channels) à la liste
            band_powers.append(band_power)

        # Empile les bandes pour retourner un tenseur cohérent canal x bande
        stacked = np.stack(band_powers, axis=2)
        # Retourne une matrice aplatie (échantillons, canaux * bandes)
        return cast(np.ndarray, stacked.reshape(stacked.shape[0], -1))

    def xǁExtractFeaturesǁ_compute_fft_features__mutmut_49(self, X: np.ndarray) -> np.ndarray:
        """Calcule les puissances de bandes à partir de la FFT."""

        n_times = X.shape[-1]
        # Centre le signal pour supprimer la composante DC avant la FFT
        centered = X - X.mean(axis=-1, keepdims=True)
        # Calcule les fréquences réelles à partir de la sfreq configurée
        freqs = np.fft.rfftfreq(n_times, d=1.0 / self.sfreq)
        # Calcule la puissance spectrale par canal et échantillon
        power = np.asarray(
            np.abs(np.fft.rfft(centered, axis=-1)) ** 2, dtype=float
        )  # pragma: no mutate
        # Restaure l'énergie des composantes symétriques manquantes pour un signal réel
        if power.shape[-1] > 1:
            power[..., 1:-1] *= 2
            # Lorsque n_times est impair, la dernière fréquence possède un symétrique
            if n_times % 2 != 0:
                power[..., -1] /= 2
        # Normalise par la longueur temporelle pour obtenir une puissance moyenne
        power = power / float(n_times**2)
        # Accumule les puissances par bande pour chaque canal
        band_powers: List[np.ndarray] = []
        # Parcourt chaque bande EEG définie dans les paramètres
        for _, (low, high) in self._band_items:
            # Construit le masque fréquentiel pour cette bande
            band_mask = (freqs >= low) & (freqs <= high)

            # Gère le cas où aucune fréquence ne tombe dans la bande
            if not np.any(band_mask):
                # Retourne un bloc de zéros pour préserver la forme
                band_power = np.zeros(power.shape[:2])
            else:
                # Moyenne la puissance sur les fréquences de la bande
                band_power = power[:, :, band_mask].mean(axis=2)

            # Ajoute la matrice (n_samples, n_channels) à la liste
            band_powers.append(band_power)

        # Empile les bandes pour retourner un tenseur cohérent canal x bande
        stacked = np.stack(band_powers, axis=2)
        # Retourne une matrice aplatie (échantillons, canaux * bandes)
        return cast(np.ndarray, stacked.reshape(stacked.shape[0], -1))

    def xǁExtractFeaturesǁ_compute_fft_features__mutmut_50(self, X: np.ndarray) -> np.ndarray:
        """Calcule les puissances de bandes à partir de la FFT."""

        n_times = X.shape[-1]
        # Centre le signal pour supprimer la composante DC avant la FFT
        centered = X - X.mean(axis=-1, keepdims=True)
        # Calcule les fréquences réelles à partir de la sfreq configurée
        freqs = np.fft.rfftfreq(n_times, d=1.0 / self.sfreq)
        # Calcule la puissance spectrale par canal et échantillon
        power = np.asarray(
            np.abs(np.fft.rfft(centered, axis=-1)) ** 2, dtype=float
        )  # pragma: no mutate
        # Restaure l'énergie des composantes symétriques manquantes pour un signal réel
        if power.shape[-1] > 1:
            power[..., 1:-1] *= 2
            # Lorsque n_times est impair, la dernière fréquence possède un symétrique
            if n_times % 2 != 0:
                power[..., +1] *= 2
        # Normalise par la longueur temporelle pour obtenir une puissance moyenne
        power = power / float(n_times**2)
        # Accumule les puissances par bande pour chaque canal
        band_powers: List[np.ndarray] = []
        # Parcourt chaque bande EEG définie dans les paramètres
        for _, (low, high) in self._band_items:
            # Construit le masque fréquentiel pour cette bande
            band_mask = (freqs >= low) & (freqs <= high)

            # Gère le cas où aucune fréquence ne tombe dans la bande
            if not np.any(band_mask):
                # Retourne un bloc de zéros pour préserver la forme
                band_power = np.zeros(power.shape[:2])
            else:
                # Moyenne la puissance sur les fréquences de la bande
                band_power = power[:, :, band_mask].mean(axis=2)

            # Ajoute la matrice (n_samples, n_channels) à la liste
            band_powers.append(band_power)

        # Empile les bandes pour retourner un tenseur cohérent canal x bande
        stacked = np.stack(band_powers, axis=2)
        # Retourne une matrice aplatie (échantillons, canaux * bandes)
        return cast(np.ndarray, stacked.reshape(stacked.shape[0], -1))

    def xǁExtractFeaturesǁ_compute_fft_features__mutmut_51(self, X: np.ndarray) -> np.ndarray:
        """Calcule les puissances de bandes à partir de la FFT."""

        n_times = X.shape[-1]
        # Centre le signal pour supprimer la composante DC avant la FFT
        centered = X - X.mean(axis=-1, keepdims=True)
        # Calcule les fréquences réelles à partir de la sfreq configurée
        freqs = np.fft.rfftfreq(n_times, d=1.0 / self.sfreq)
        # Calcule la puissance spectrale par canal et échantillon
        power = np.asarray(
            np.abs(np.fft.rfft(centered, axis=-1)) ** 2, dtype=float
        )  # pragma: no mutate
        # Restaure l'énergie des composantes symétriques manquantes pour un signal réel
        if power.shape[-1] > 1:
            power[..., 1:-1] *= 2
            # Lorsque n_times est impair, la dernière fréquence possède un symétrique
            if n_times % 2 != 0:
                power[..., -2] *= 2
        # Normalise par la longueur temporelle pour obtenir une puissance moyenne
        power = power / float(n_times**2)
        # Accumule les puissances par bande pour chaque canal
        band_powers: List[np.ndarray] = []
        # Parcourt chaque bande EEG définie dans les paramètres
        for _, (low, high) in self._band_items:
            # Construit le masque fréquentiel pour cette bande
            band_mask = (freqs >= low) & (freqs <= high)

            # Gère le cas où aucune fréquence ne tombe dans la bande
            if not np.any(band_mask):
                # Retourne un bloc de zéros pour préserver la forme
                band_power = np.zeros(power.shape[:2])
            else:
                # Moyenne la puissance sur les fréquences de la bande
                band_power = power[:, :, band_mask].mean(axis=2)

            # Ajoute la matrice (n_samples, n_channels) à la liste
            band_powers.append(band_power)

        # Empile les bandes pour retourner un tenseur cohérent canal x bande
        stacked = np.stack(band_powers, axis=2)
        # Retourne une matrice aplatie (échantillons, canaux * bandes)
        return cast(np.ndarray, stacked.reshape(stacked.shape[0], -1))

    def xǁExtractFeaturesǁ_compute_fft_features__mutmut_52(self, X: np.ndarray) -> np.ndarray:
        """Calcule les puissances de bandes à partir de la FFT."""

        n_times = X.shape[-1]
        # Centre le signal pour supprimer la composante DC avant la FFT
        centered = X - X.mean(axis=-1, keepdims=True)
        # Calcule les fréquences réelles à partir de la sfreq configurée
        freqs = np.fft.rfftfreq(n_times, d=1.0 / self.sfreq)
        # Calcule la puissance spectrale par canal et échantillon
        power = np.asarray(
            np.abs(np.fft.rfft(centered, axis=-1)) ** 2, dtype=float
        )  # pragma: no mutate
        # Restaure l'énergie des composantes symétriques manquantes pour un signal réel
        if power.shape[-1] > 1:
            power[..., 1:-1] *= 2
            # Lorsque n_times est impair, la dernière fréquence possède un symétrique
            if n_times % 2 != 0:
                power[..., -1] *= 3
        # Normalise par la longueur temporelle pour obtenir une puissance moyenne
        power = power / float(n_times**2)
        # Accumule les puissances par bande pour chaque canal
        band_powers: List[np.ndarray] = []
        # Parcourt chaque bande EEG définie dans les paramètres
        for _, (low, high) in self._band_items:
            # Construit le masque fréquentiel pour cette bande
            band_mask = (freqs >= low) & (freqs <= high)

            # Gère le cas où aucune fréquence ne tombe dans la bande
            if not np.any(band_mask):
                # Retourne un bloc de zéros pour préserver la forme
                band_power = np.zeros(power.shape[:2])
            else:
                # Moyenne la puissance sur les fréquences de la bande
                band_power = power[:, :, band_mask].mean(axis=2)

            # Ajoute la matrice (n_samples, n_channels) à la liste
            band_powers.append(band_power)

        # Empile les bandes pour retourner un tenseur cohérent canal x bande
        stacked = np.stack(band_powers, axis=2)
        # Retourne une matrice aplatie (échantillons, canaux * bandes)
        return cast(np.ndarray, stacked.reshape(stacked.shape[0], -1))

    def xǁExtractFeaturesǁ_compute_fft_features__mutmut_53(self, X: np.ndarray) -> np.ndarray:
        """Calcule les puissances de bandes à partir de la FFT."""

        n_times = X.shape[-1]
        # Centre le signal pour supprimer la composante DC avant la FFT
        centered = X - X.mean(axis=-1, keepdims=True)
        # Calcule les fréquences réelles à partir de la sfreq configurée
        freqs = np.fft.rfftfreq(n_times, d=1.0 / self.sfreq)
        # Calcule la puissance spectrale par canal et échantillon
        power = np.asarray(
            np.abs(np.fft.rfft(centered, axis=-1)) ** 2, dtype=float
        )  # pragma: no mutate
        # Restaure l'énergie des composantes symétriques manquantes pour un signal réel
        if power.shape[-1] > 1:
            power[..., 1:-1] *= 2
            # Lorsque n_times est impair, la dernière fréquence possède un symétrique
            if n_times % 2 != 0:
                power[..., -1] *= 2
        # Normalise par la longueur temporelle pour obtenir une puissance moyenne
        power = None
        # Accumule les puissances par bande pour chaque canal
        band_powers: List[np.ndarray] = []
        # Parcourt chaque bande EEG définie dans les paramètres
        for _, (low, high) in self._band_items:
            # Construit le masque fréquentiel pour cette bande
            band_mask = (freqs >= low) & (freqs <= high)

            # Gère le cas où aucune fréquence ne tombe dans la bande
            if not np.any(band_mask):
                # Retourne un bloc de zéros pour préserver la forme
                band_power = np.zeros(power.shape[:2])
            else:
                # Moyenne la puissance sur les fréquences de la bande
                band_power = power[:, :, band_mask].mean(axis=2)

            # Ajoute la matrice (n_samples, n_channels) à la liste
            band_powers.append(band_power)

        # Empile les bandes pour retourner un tenseur cohérent canal x bande
        stacked = np.stack(band_powers, axis=2)
        # Retourne une matrice aplatie (échantillons, canaux * bandes)
        return cast(np.ndarray, stacked.reshape(stacked.shape[0], -1))

    def xǁExtractFeaturesǁ_compute_fft_features__mutmut_54(self, X: np.ndarray) -> np.ndarray:
        """Calcule les puissances de bandes à partir de la FFT."""

        n_times = X.shape[-1]
        # Centre le signal pour supprimer la composante DC avant la FFT
        centered = X - X.mean(axis=-1, keepdims=True)
        # Calcule les fréquences réelles à partir de la sfreq configurée
        freqs = np.fft.rfftfreq(n_times, d=1.0 / self.sfreq)
        # Calcule la puissance spectrale par canal et échantillon
        power = np.asarray(
            np.abs(np.fft.rfft(centered, axis=-1)) ** 2, dtype=float
        )  # pragma: no mutate
        # Restaure l'énergie des composantes symétriques manquantes pour un signal réel
        if power.shape[-1] > 1:
            power[..., 1:-1] *= 2
            # Lorsque n_times est impair, la dernière fréquence possède un symétrique
            if n_times % 2 != 0:
                power[..., -1] *= 2
        # Normalise par la longueur temporelle pour obtenir une puissance moyenne
        power = power * float(n_times**2)
        # Accumule les puissances par bande pour chaque canal
        band_powers: List[np.ndarray] = []
        # Parcourt chaque bande EEG définie dans les paramètres
        for _, (low, high) in self._band_items:
            # Construit le masque fréquentiel pour cette bande
            band_mask = (freqs >= low) & (freqs <= high)

            # Gère le cas où aucune fréquence ne tombe dans la bande
            if not np.any(band_mask):
                # Retourne un bloc de zéros pour préserver la forme
                band_power = np.zeros(power.shape[:2])
            else:
                # Moyenne la puissance sur les fréquences de la bande
                band_power = power[:, :, band_mask].mean(axis=2)

            # Ajoute la matrice (n_samples, n_channels) à la liste
            band_powers.append(band_power)

        # Empile les bandes pour retourner un tenseur cohérent canal x bande
        stacked = np.stack(band_powers, axis=2)
        # Retourne une matrice aplatie (échantillons, canaux * bandes)
        return cast(np.ndarray, stacked.reshape(stacked.shape[0], -1))

    def xǁExtractFeaturesǁ_compute_fft_features__mutmut_55(self, X: np.ndarray) -> np.ndarray:
        """Calcule les puissances de bandes à partir de la FFT."""

        n_times = X.shape[-1]
        # Centre le signal pour supprimer la composante DC avant la FFT
        centered = X - X.mean(axis=-1, keepdims=True)
        # Calcule les fréquences réelles à partir de la sfreq configurée
        freqs = np.fft.rfftfreq(n_times, d=1.0 / self.sfreq)
        # Calcule la puissance spectrale par canal et échantillon
        power = np.asarray(
            np.abs(np.fft.rfft(centered, axis=-1)) ** 2, dtype=float
        )  # pragma: no mutate
        # Restaure l'énergie des composantes symétriques manquantes pour un signal réel
        if power.shape[-1] > 1:
            power[..., 1:-1] *= 2
            # Lorsque n_times est impair, la dernière fréquence possède un symétrique
            if n_times % 2 != 0:
                power[..., -1] *= 2
        # Normalise par la longueur temporelle pour obtenir une puissance moyenne
        power = power / float(None)
        # Accumule les puissances par bande pour chaque canal
        band_powers: List[np.ndarray] = []
        # Parcourt chaque bande EEG définie dans les paramètres
        for _, (low, high) in self._band_items:
            # Construit le masque fréquentiel pour cette bande
            band_mask = (freqs >= low) & (freqs <= high)

            # Gère le cas où aucune fréquence ne tombe dans la bande
            if not np.any(band_mask):
                # Retourne un bloc de zéros pour préserver la forme
                band_power = np.zeros(power.shape[:2])
            else:
                # Moyenne la puissance sur les fréquences de la bande
                band_power = power[:, :, band_mask].mean(axis=2)

            # Ajoute la matrice (n_samples, n_channels) à la liste
            band_powers.append(band_power)

        # Empile les bandes pour retourner un tenseur cohérent canal x bande
        stacked = np.stack(band_powers, axis=2)
        # Retourne une matrice aplatie (échantillons, canaux * bandes)
        return cast(np.ndarray, stacked.reshape(stacked.shape[0], -1))

    def xǁExtractFeaturesǁ_compute_fft_features__mutmut_56(self, X: np.ndarray) -> np.ndarray:
        """Calcule les puissances de bandes à partir de la FFT."""

        n_times = X.shape[-1]
        # Centre le signal pour supprimer la composante DC avant la FFT
        centered = X - X.mean(axis=-1, keepdims=True)
        # Calcule les fréquences réelles à partir de la sfreq configurée
        freqs = np.fft.rfftfreq(n_times, d=1.0 / self.sfreq)
        # Calcule la puissance spectrale par canal et échantillon
        power = np.asarray(
            np.abs(np.fft.rfft(centered, axis=-1)) ** 2, dtype=float
        )  # pragma: no mutate
        # Restaure l'énergie des composantes symétriques manquantes pour un signal réel
        if power.shape[-1] > 1:
            power[..., 1:-1] *= 2
            # Lorsque n_times est impair, la dernière fréquence possède un symétrique
            if n_times % 2 != 0:
                power[..., -1] *= 2
        # Normalise par la longueur temporelle pour obtenir une puissance moyenne
        power = power / float(n_times * 2)
        # Accumule les puissances par bande pour chaque canal
        band_powers: List[np.ndarray] = []
        # Parcourt chaque bande EEG définie dans les paramètres
        for _, (low, high) in self._band_items:
            # Construit le masque fréquentiel pour cette bande
            band_mask = (freqs >= low) & (freqs <= high)

            # Gère le cas où aucune fréquence ne tombe dans la bande
            if not np.any(band_mask):
                # Retourne un bloc de zéros pour préserver la forme
                band_power = np.zeros(power.shape[:2])
            else:
                # Moyenne la puissance sur les fréquences de la bande
                band_power = power[:, :, band_mask].mean(axis=2)

            # Ajoute la matrice (n_samples, n_channels) à la liste
            band_powers.append(band_power)

        # Empile les bandes pour retourner un tenseur cohérent canal x bande
        stacked = np.stack(band_powers, axis=2)
        # Retourne une matrice aplatie (échantillons, canaux * bandes)
        return cast(np.ndarray, stacked.reshape(stacked.shape[0], -1))

    def xǁExtractFeaturesǁ_compute_fft_features__mutmut_57(self, X: np.ndarray) -> np.ndarray:
        """Calcule les puissances de bandes à partir de la FFT."""

        n_times = X.shape[-1]
        # Centre le signal pour supprimer la composante DC avant la FFT
        centered = X - X.mean(axis=-1, keepdims=True)
        # Calcule les fréquences réelles à partir de la sfreq configurée
        freqs = np.fft.rfftfreq(n_times, d=1.0 / self.sfreq)
        # Calcule la puissance spectrale par canal et échantillon
        power = np.asarray(
            np.abs(np.fft.rfft(centered, axis=-1)) ** 2, dtype=float
        )  # pragma: no mutate
        # Restaure l'énergie des composantes symétriques manquantes pour un signal réel
        if power.shape[-1] > 1:
            power[..., 1:-1] *= 2
            # Lorsque n_times est impair, la dernière fréquence possède un symétrique
            if n_times % 2 != 0:
                power[..., -1] *= 2
        # Normalise par la longueur temporelle pour obtenir une puissance moyenne
        power = power / float(n_times**3)
        # Accumule les puissances par bande pour chaque canal
        band_powers: List[np.ndarray] = []
        # Parcourt chaque bande EEG définie dans les paramètres
        for _, (low, high) in self._band_items:
            # Construit le masque fréquentiel pour cette bande
            band_mask = (freqs >= low) & (freqs <= high)

            # Gère le cas où aucune fréquence ne tombe dans la bande
            if not np.any(band_mask):
                # Retourne un bloc de zéros pour préserver la forme
                band_power = np.zeros(power.shape[:2])
            else:
                # Moyenne la puissance sur les fréquences de la bande
                band_power = power[:, :, band_mask].mean(axis=2)

            # Ajoute la matrice (n_samples, n_channels) à la liste
            band_powers.append(band_power)

        # Empile les bandes pour retourner un tenseur cohérent canal x bande
        stacked = np.stack(band_powers, axis=2)
        # Retourne une matrice aplatie (échantillons, canaux * bandes)
        return cast(np.ndarray, stacked.reshape(stacked.shape[0], -1))

    def xǁExtractFeaturesǁ_compute_fft_features__mutmut_58(self, X: np.ndarray) -> np.ndarray:
        """Calcule les puissances de bandes à partir de la FFT."""

        n_times = X.shape[-1]
        # Centre le signal pour supprimer la composante DC avant la FFT
        centered = X - X.mean(axis=-1, keepdims=True)
        # Calcule les fréquences réelles à partir de la sfreq configurée
        freqs = np.fft.rfftfreq(n_times, d=1.0 / self.sfreq)
        # Calcule la puissance spectrale par canal et échantillon
        power = np.asarray(
            np.abs(np.fft.rfft(centered, axis=-1)) ** 2, dtype=float
        )  # pragma: no mutate
        # Restaure l'énergie des composantes symétriques manquantes pour un signal réel
        if power.shape[-1] > 1:
            power[..., 1:-1] *= 2
            # Lorsque n_times est impair, la dernière fréquence possède un symétrique
            if n_times % 2 != 0:
                power[..., -1] *= 2
        # Normalise par la longueur temporelle pour obtenir une puissance moyenne
        power = power / float(n_times**2)
        # Accumule les puissances par bande pour chaque canal
        band_powers: List[np.ndarray] = None
        # Parcourt chaque bande EEG définie dans les paramètres
        for _, (low, high) in self._band_items:
            # Construit le masque fréquentiel pour cette bande
            band_mask = (freqs >= low) & (freqs <= high)

            # Gère le cas où aucune fréquence ne tombe dans la bande
            if not np.any(band_mask):
                # Retourne un bloc de zéros pour préserver la forme
                band_power = np.zeros(power.shape[:2])
            else:
                # Moyenne la puissance sur les fréquences de la bande
                band_power = power[:, :, band_mask].mean(axis=2)

            # Ajoute la matrice (n_samples, n_channels) à la liste
            band_powers.append(band_power)

        # Empile les bandes pour retourner un tenseur cohérent canal x bande
        stacked = np.stack(band_powers, axis=2)
        # Retourne une matrice aplatie (échantillons, canaux * bandes)
        return cast(np.ndarray, stacked.reshape(stacked.shape[0], -1))

    def xǁExtractFeaturesǁ_compute_fft_features__mutmut_59(self, X: np.ndarray) -> np.ndarray:
        """Calcule les puissances de bandes à partir de la FFT."""

        n_times = X.shape[-1]
        # Centre le signal pour supprimer la composante DC avant la FFT
        centered = X - X.mean(axis=-1, keepdims=True)
        # Calcule les fréquences réelles à partir de la sfreq configurée
        freqs = np.fft.rfftfreq(n_times, d=1.0 / self.sfreq)
        # Calcule la puissance spectrale par canal et échantillon
        power = np.asarray(
            np.abs(np.fft.rfft(centered, axis=-1)) ** 2, dtype=float
        )  # pragma: no mutate
        # Restaure l'énergie des composantes symétriques manquantes pour un signal réel
        if power.shape[-1] > 1:
            power[..., 1:-1] *= 2
            # Lorsque n_times est impair, la dernière fréquence possède un symétrique
            if n_times % 2 != 0:
                power[..., -1] *= 2
        # Normalise par la longueur temporelle pour obtenir une puissance moyenne
        power = power / float(n_times**2)
        # Accumule les puissances par bande pour chaque canal
        band_powers: List[np.ndarray] = []
        # Parcourt chaque bande EEG définie dans les paramètres
        for _, (low, high) in self._band_items:
            # Construit le masque fréquentiel pour cette bande
            band_mask = None

            # Gère le cas où aucune fréquence ne tombe dans la bande
            if not np.any(band_mask):
                # Retourne un bloc de zéros pour préserver la forme
                band_power = np.zeros(power.shape[:2])
            else:
                # Moyenne la puissance sur les fréquences de la bande
                band_power = power[:, :, band_mask].mean(axis=2)

            # Ajoute la matrice (n_samples, n_channels) à la liste
            band_powers.append(band_power)

        # Empile les bandes pour retourner un tenseur cohérent canal x bande
        stacked = np.stack(band_powers, axis=2)
        # Retourne une matrice aplatie (échantillons, canaux * bandes)
        return cast(np.ndarray, stacked.reshape(stacked.shape[0], -1))

    def xǁExtractFeaturesǁ_compute_fft_features__mutmut_60(self, X: np.ndarray) -> np.ndarray:
        """Calcule les puissances de bandes à partir de la FFT."""

        n_times = X.shape[-1]
        # Centre le signal pour supprimer la composante DC avant la FFT
        centered = X - X.mean(axis=-1, keepdims=True)
        # Calcule les fréquences réelles à partir de la sfreq configurée
        freqs = np.fft.rfftfreq(n_times, d=1.0 / self.sfreq)
        # Calcule la puissance spectrale par canal et échantillon
        power = np.asarray(
            np.abs(np.fft.rfft(centered, axis=-1)) ** 2, dtype=float
        )  # pragma: no mutate
        # Restaure l'énergie des composantes symétriques manquantes pour un signal réel
        if power.shape[-1] > 1:
            power[..., 1:-1] *= 2
            # Lorsque n_times est impair, la dernière fréquence possède un symétrique
            if n_times % 2 != 0:
                power[..., -1] *= 2
        # Normalise par la longueur temporelle pour obtenir une puissance moyenne
        power = power / float(n_times**2)
        # Accumule les puissances par bande pour chaque canal
        band_powers: List[np.ndarray] = []
        # Parcourt chaque bande EEG définie dans les paramètres
        for _, (low, high) in self._band_items:
            # Construit le masque fréquentiel pour cette bande
            band_mask = (freqs >= low) | (freqs <= high)

            # Gère le cas où aucune fréquence ne tombe dans la bande
            if not np.any(band_mask):
                # Retourne un bloc de zéros pour préserver la forme
                band_power = np.zeros(power.shape[:2])
            else:
                # Moyenne la puissance sur les fréquences de la bande
                band_power = power[:, :, band_mask].mean(axis=2)

            # Ajoute la matrice (n_samples, n_channels) à la liste
            band_powers.append(band_power)

        # Empile les bandes pour retourner un tenseur cohérent canal x bande
        stacked = np.stack(band_powers, axis=2)
        # Retourne une matrice aplatie (échantillons, canaux * bandes)
        return cast(np.ndarray, stacked.reshape(stacked.shape[0], -1))

    def xǁExtractFeaturesǁ_compute_fft_features__mutmut_61(self, X: np.ndarray) -> np.ndarray:
        """Calcule les puissances de bandes à partir de la FFT."""

        n_times = X.shape[-1]
        # Centre le signal pour supprimer la composante DC avant la FFT
        centered = X - X.mean(axis=-1, keepdims=True)
        # Calcule les fréquences réelles à partir de la sfreq configurée
        freqs = np.fft.rfftfreq(n_times, d=1.0 / self.sfreq)
        # Calcule la puissance spectrale par canal et échantillon
        power = np.asarray(
            np.abs(np.fft.rfft(centered, axis=-1)) ** 2, dtype=float
        )  # pragma: no mutate
        # Restaure l'énergie des composantes symétriques manquantes pour un signal réel
        if power.shape[-1] > 1:
            power[..., 1:-1] *= 2
            # Lorsque n_times est impair, la dernière fréquence possède un symétrique
            if n_times % 2 != 0:
                power[..., -1] *= 2
        # Normalise par la longueur temporelle pour obtenir une puissance moyenne
        power = power / float(n_times**2)
        # Accumule les puissances par bande pour chaque canal
        band_powers: List[np.ndarray] = []
        # Parcourt chaque bande EEG définie dans les paramètres
        for _, (low, high) in self._band_items:
            # Construit le masque fréquentiel pour cette bande
            band_mask = (freqs > low) & (freqs <= high)

            # Gère le cas où aucune fréquence ne tombe dans la bande
            if not np.any(band_mask):
                # Retourne un bloc de zéros pour préserver la forme
                band_power = np.zeros(power.shape[:2])
            else:
                # Moyenne la puissance sur les fréquences de la bande
                band_power = power[:, :, band_mask].mean(axis=2)

            # Ajoute la matrice (n_samples, n_channels) à la liste
            band_powers.append(band_power)

        # Empile les bandes pour retourner un tenseur cohérent canal x bande
        stacked = np.stack(band_powers, axis=2)
        # Retourne une matrice aplatie (échantillons, canaux * bandes)
        return cast(np.ndarray, stacked.reshape(stacked.shape[0], -1))

    def xǁExtractFeaturesǁ_compute_fft_features__mutmut_62(self, X: np.ndarray) -> np.ndarray:
        """Calcule les puissances de bandes à partir de la FFT."""

        n_times = X.shape[-1]
        # Centre le signal pour supprimer la composante DC avant la FFT
        centered = X - X.mean(axis=-1, keepdims=True)
        # Calcule les fréquences réelles à partir de la sfreq configurée
        freqs = np.fft.rfftfreq(n_times, d=1.0 / self.sfreq)
        # Calcule la puissance spectrale par canal et échantillon
        power = np.asarray(
            np.abs(np.fft.rfft(centered, axis=-1)) ** 2, dtype=float
        )  # pragma: no mutate
        # Restaure l'énergie des composantes symétriques manquantes pour un signal réel
        if power.shape[-1] > 1:
            power[..., 1:-1] *= 2
            # Lorsque n_times est impair, la dernière fréquence possède un symétrique
            if n_times % 2 != 0:
                power[..., -1] *= 2
        # Normalise par la longueur temporelle pour obtenir une puissance moyenne
        power = power / float(n_times**2)
        # Accumule les puissances par bande pour chaque canal
        band_powers: List[np.ndarray] = []
        # Parcourt chaque bande EEG définie dans les paramètres
        for _, (low, high) in self._band_items:
            # Construit le masque fréquentiel pour cette bande
            band_mask = (freqs >= low) & (freqs < high)

            # Gère le cas où aucune fréquence ne tombe dans la bande
            if not np.any(band_mask):
                # Retourne un bloc de zéros pour préserver la forme
                band_power = np.zeros(power.shape[:2])
            else:
                # Moyenne la puissance sur les fréquences de la bande
                band_power = power[:, :, band_mask].mean(axis=2)

            # Ajoute la matrice (n_samples, n_channels) à la liste
            band_powers.append(band_power)

        # Empile les bandes pour retourner un tenseur cohérent canal x bande
        stacked = np.stack(band_powers, axis=2)
        # Retourne une matrice aplatie (échantillons, canaux * bandes)
        return cast(np.ndarray, stacked.reshape(stacked.shape[0], -1))

    def xǁExtractFeaturesǁ_compute_fft_features__mutmut_63(self, X: np.ndarray) -> np.ndarray:
        """Calcule les puissances de bandes à partir de la FFT."""

        n_times = X.shape[-1]
        # Centre le signal pour supprimer la composante DC avant la FFT
        centered = X - X.mean(axis=-1, keepdims=True)
        # Calcule les fréquences réelles à partir de la sfreq configurée
        freqs = np.fft.rfftfreq(n_times, d=1.0 / self.sfreq)
        # Calcule la puissance spectrale par canal et échantillon
        power = np.asarray(
            np.abs(np.fft.rfft(centered, axis=-1)) ** 2, dtype=float
        )  # pragma: no mutate
        # Restaure l'énergie des composantes symétriques manquantes pour un signal réel
        if power.shape[-1] > 1:
            power[..., 1:-1] *= 2
            # Lorsque n_times est impair, la dernière fréquence possède un symétrique
            if n_times % 2 != 0:
                power[..., -1] *= 2
        # Normalise par la longueur temporelle pour obtenir une puissance moyenne
        power = power / float(n_times**2)
        # Accumule les puissances par bande pour chaque canal
        band_powers: List[np.ndarray] = []
        # Parcourt chaque bande EEG définie dans les paramètres
        for _, (low, high) in self._band_items:
            # Construit le masque fréquentiel pour cette bande
            band_mask = (freqs >= low) & (freqs <= high)

            # Gère le cas où aucune fréquence ne tombe dans la bande
            if np.any(band_mask):
                # Retourne un bloc de zéros pour préserver la forme
                band_power = np.zeros(power.shape[:2])
            else:
                # Moyenne la puissance sur les fréquences de la bande
                band_power = power[:, :, band_mask].mean(axis=2)

            # Ajoute la matrice (n_samples, n_channels) à la liste
            band_powers.append(band_power)

        # Empile les bandes pour retourner un tenseur cohérent canal x bande
        stacked = np.stack(band_powers, axis=2)
        # Retourne une matrice aplatie (échantillons, canaux * bandes)
        return cast(np.ndarray, stacked.reshape(stacked.shape[0], -1))

    def xǁExtractFeaturesǁ_compute_fft_features__mutmut_64(self, X: np.ndarray) -> np.ndarray:
        """Calcule les puissances de bandes à partir de la FFT."""

        n_times = X.shape[-1]
        # Centre le signal pour supprimer la composante DC avant la FFT
        centered = X - X.mean(axis=-1, keepdims=True)
        # Calcule les fréquences réelles à partir de la sfreq configurée
        freqs = np.fft.rfftfreq(n_times, d=1.0 / self.sfreq)
        # Calcule la puissance spectrale par canal et échantillon
        power = np.asarray(
            np.abs(np.fft.rfft(centered, axis=-1)) ** 2, dtype=float
        )  # pragma: no mutate
        # Restaure l'énergie des composantes symétriques manquantes pour un signal réel
        if power.shape[-1] > 1:
            power[..., 1:-1] *= 2
            # Lorsque n_times est impair, la dernière fréquence possède un symétrique
            if n_times % 2 != 0:
                power[..., -1] *= 2
        # Normalise par la longueur temporelle pour obtenir une puissance moyenne
        power = power / float(n_times**2)
        # Accumule les puissances par bande pour chaque canal
        band_powers: List[np.ndarray] = []
        # Parcourt chaque bande EEG définie dans les paramètres
        for _, (low, high) in self._band_items:
            # Construit le masque fréquentiel pour cette bande
            band_mask = (freqs >= low) & (freqs <= high)

            # Gère le cas où aucune fréquence ne tombe dans la bande
            if not np.any(None):
                # Retourne un bloc de zéros pour préserver la forme
                band_power = np.zeros(power.shape[:2])
            else:
                # Moyenne la puissance sur les fréquences de la bande
                band_power = power[:, :, band_mask].mean(axis=2)

            # Ajoute la matrice (n_samples, n_channels) à la liste
            band_powers.append(band_power)

        # Empile les bandes pour retourner un tenseur cohérent canal x bande
        stacked = np.stack(band_powers, axis=2)
        # Retourne une matrice aplatie (échantillons, canaux * bandes)
        return cast(np.ndarray, stacked.reshape(stacked.shape[0], -1))

    def xǁExtractFeaturesǁ_compute_fft_features__mutmut_65(self, X: np.ndarray) -> np.ndarray:
        """Calcule les puissances de bandes à partir de la FFT."""

        n_times = X.shape[-1]
        # Centre le signal pour supprimer la composante DC avant la FFT
        centered = X - X.mean(axis=-1, keepdims=True)
        # Calcule les fréquences réelles à partir de la sfreq configurée
        freqs = np.fft.rfftfreq(n_times, d=1.0 / self.sfreq)
        # Calcule la puissance spectrale par canal et échantillon
        power = np.asarray(
            np.abs(np.fft.rfft(centered, axis=-1)) ** 2, dtype=float
        )  # pragma: no mutate
        # Restaure l'énergie des composantes symétriques manquantes pour un signal réel
        if power.shape[-1] > 1:
            power[..., 1:-1] *= 2
            # Lorsque n_times est impair, la dernière fréquence possède un symétrique
            if n_times % 2 != 0:
                power[..., -1] *= 2
        # Normalise par la longueur temporelle pour obtenir une puissance moyenne
        power = power / float(n_times**2)
        # Accumule les puissances par bande pour chaque canal
        band_powers: List[np.ndarray] = []
        # Parcourt chaque bande EEG définie dans les paramètres
        for _, (low, high) in self._band_items:
            # Construit le masque fréquentiel pour cette bande
            band_mask = (freqs >= low) & (freqs <= high)

            # Gère le cas où aucune fréquence ne tombe dans la bande
            if not np.any(band_mask):
                # Retourne un bloc de zéros pour préserver la forme
                band_power = None
            else:
                # Moyenne la puissance sur les fréquences de la bande
                band_power = power[:, :, band_mask].mean(axis=2)

            # Ajoute la matrice (n_samples, n_channels) à la liste
            band_powers.append(band_power)

        # Empile les bandes pour retourner un tenseur cohérent canal x bande
        stacked = np.stack(band_powers, axis=2)
        # Retourne une matrice aplatie (échantillons, canaux * bandes)
        return cast(np.ndarray, stacked.reshape(stacked.shape[0], -1))

    def xǁExtractFeaturesǁ_compute_fft_features__mutmut_66(self, X: np.ndarray) -> np.ndarray:
        """Calcule les puissances de bandes à partir de la FFT."""

        n_times = X.shape[-1]
        # Centre le signal pour supprimer la composante DC avant la FFT
        centered = X - X.mean(axis=-1, keepdims=True)
        # Calcule les fréquences réelles à partir de la sfreq configurée
        freqs = np.fft.rfftfreq(n_times, d=1.0 / self.sfreq)
        # Calcule la puissance spectrale par canal et échantillon
        power = np.asarray(
            np.abs(np.fft.rfft(centered, axis=-1)) ** 2, dtype=float
        )  # pragma: no mutate
        # Restaure l'énergie des composantes symétriques manquantes pour un signal réel
        if power.shape[-1] > 1:
            power[..., 1:-1] *= 2
            # Lorsque n_times est impair, la dernière fréquence possède un symétrique
            if n_times % 2 != 0:
                power[..., -1] *= 2
        # Normalise par la longueur temporelle pour obtenir une puissance moyenne
        power = power / float(n_times**2)
        # Accumule les puissances par bande pour chaque canal
        band_powers: List[np.ndarray] = []
        # Parcourt chaque bande EEG définie dans les paramètres
        for _, (low, high) in self._band_items:
            # Construit le masque fréquentiel pour cette bande
            band_mask = (freqs >= low) & (freqs <= high)

            # Gère le cas où aucune fréquence ne tombe dans la bande
            if not np.any(band_mask):
                # Retourne un bloc de zéros pour préserver la forme
                band_power = np.zeros(None)
            else:
                # Moyenne la puissance sur les fréquences de la bande
                band_power = power[:, :, band_mask].mean(axis=2)

            # Ajoute la matrice (n_samples, n_channels) à la liste
            band_powers.append(band_power)

        # Empile les bandes pour retourner un tenseur cohérent canal x bande
        stacked = np.stack(band_powers, axis=2)
        # Retourne une matrice aplatie (échantillons, canaux * bandes)
        return cast(np.ndarray, stacked.reshape(stacked.shape[0], -1))

    def xǁExtractFeaturesǁ_compute_fft_features__mutmut_67(self, X: np.ndarray) -> np.ndarray:
        """Calcule les puissances de bandes à partir de la FFT."""

        n_times = X.shape[-1]
        # Centre le signal pour supprimer la composante DC avant la FFT
        centered = X - X.mean(axis=-1, keepdims=True)
        # Calcule les fréquences réelles à partir de la sfreq configurée
        freqs = np.fft.rfftfreq(n_times, d=1.0 / self.sfreq)
        # Calcule la puissance spectrale par canal et échantillon
        power = np.asarray(
            np.abs(np.fft.rfft(centered, axis=-1)) ** 2, dtype=float
        )  # pragma: no mutate
        # Restaure l'énergie des composantes symétriques manquantes pour un signal réel
        if power.shape[-1] > 1:
            power[..., 1:-1] *= 2
            # Lorsque n_times est impair, la dernière fréquence possède un symétrique
            if n_times % 2 != 0:
                power[..., -1] *= 2
        # Normalise par la longueur temporelle pour obtenir une puissance moyenne
        power = power / float(n_times**2)
        # Accumule les puissances par bande pour chaque canal
        band_powers: List[np.ndarray] = []
        # Parcourt chaque bande EEG définie dans les paramètres
        for _, (low, high) in self._band_items:
            # Construit le masque fréquentiel pour cette bande
            band_mask = (freqs >= low) & (freqs <= high)

            # Gère le cas où aucune fréquence ne tombe dans la bande
            if not np.any(band_mask):
                # Retourne un bloc de zéros pour préserver la forme
                band_power = np.zeros(power.shape[:3])
            else:
                # Moyenne la puissance sur les fréquences de la bande
                band_power = power[:, :, band_mask].mean(axis=2)

            # Ajoute la matrice (n_samples, n_channels) à la liste
            band_powers.append(band_power)

        # Empile les bandes pour retourner un tenseur cohérent canal x bande
        stacked = np.stack(band_powers, axis=2)
        # Retourne une matrice aplatie (échantillons, canaux * bandes)
        return cast(np.ndarray, stacked.reshape(stacked.shape[0], -1))

    def xǁExtractFeaturesǁ_compute_fft_features__mutmut_68(self, X: np.ndarray) -> np.ndarray:
        """Calcule les puissances de bandes à partir de la FFT."""

        n_times = X.shape[-1]
        # Centre le signal pour supprimer la composante DC avant la FFT
        centered = X - X.mean(axis=-1, keepdims=True)
        # Calcule les fréquences réelles à partir de la sfreq configurée
        freqs = np.fft.rfftfreq(n_times, d=1.0 / self.sfreq)
        # Calcule la puissance spectrale par canal et échantillon
        power = np.asarray(
            np.abs(np.fft.rfft(centered, axis=-1)) ** 2, dtype=float
        )  # pragma: no mutate
        # Restaure l'énergie des composantes symétriques manquantes pour un signal réel
        if power.shape[-1] > 1:
            power[..., 1:-1] *= 2
            # Lorsque n_times est impair, la dernière fréquence possède un symétrique
            if n_times % 2 != 0:
                power[..., -1] *= 2
        # Normalise par la longueur temporelle pour obtenir une puissance moyenne
        power = power / float(n_times**2)
        # Accumule les puissances par bande pour chaque canal
        band_powers: List[np.ndarray] = []
        # Parcourt chaque bande EEG définie dans les paramètres
        for _, (low, high) in self._band_items:
            # Construit le masque fréquentiel pour cette bande
            band_mask = (freqs >= low) & (freqs <= high)

            # Gère le cas où aucune fréquence ne tombe dans la bande
            if not np.any(band_mask):
                # Retourne un bloc de zéros pour préserver la forme
                band_power = np.zeros(power.shape[:2])
            else:
                # Moyenne la puissance sur les fréquences de la bande
                band_power = None

            # Ajoute la matrice (n_samples, n_channels) à la liste
            band_powers.append(band_power)

        # Empile les bandes pour retourner un tenseur cohérent canal x bande
        stacked = np.stack(band_powers, axis=2)
        # Retourne une matrice aplatie (échantillons, canaux * bandes)
        return cast(np.ndarray, stacked.reshape(stacked.shape[0], -1))

    def xǁExtractFeaturesǁ_compute_fft_features__mutmut_69(self, X: np.ndarray) -> np.ndarray:
        """Calcule les puissances de bandes à partir de la FFT."""

        n_times = X.shape[-1]
        # Centre le signal pour supprimer la composante DC avant la FFT
        centered = X - X.mean(axis=-1, keepdims=True)
        # Calcule les fréquences réelles à partir de la sfreq configurée
        freqs = np.fft.rfftfreq(n_times, d=1.0 / self.sfreq)
        # Calcule la puissance spectrale par canal et échantillon
        power = np.asarray(
            np.abs(np.fft.rfft(centered, axis=-1)) ** 2, dtype=float
        )  # pragma: no mutate
        # Restaure l'énergie des composantes symétriques manquantes pour un signal réel
        if power.shape[-1] > 1:
            power[..., 1:-1] *= 2
            # Lorsque n_times est impair, la dernière fréquence possède un symétrique
            if n_times % 2 != 0:
                power[..., -1] *= 2
        # Normalise par la longueur temporelle pour obtenir une puissance moyenne
        power = power / float(n_times**2)
        # Accumule les puissances par bande pour chaque canal
        band_powers: List[np.ndarray] = []
        # Parcourt chaque bande EEG définie dans les paramètres
        for _, (low, high) in self._band_items:
            # Construit le masque fréquentiel pour cette bande
            band_mask = (freqs >= low) & (freqs <= high)

            # Gère le cas où aucune fréquence ne tombe dans la bande
            if not np.any(band_mask):
                # Retourne un bloc de zéros pour préserver la forme
                band_power = np.zeros(power.shape[:2])
            else:
                # Moyenne la puissance sur les fréquences de la bande
                band_power = power[:, :, band_mask].mean(axis=None)

            # Ajoute la matrice (n_samples, n_channels) à la liste
            band_powers.append(band_power)

        # Empile les bandes pour retourner un tenseur cohérent canal x bande
        stacked = np.stack(band_powers, axis=2)
        # Retourne une matrice aplatie (échantillons, canaux * bandes)
        return cast(np.ndarray, stacked.reshape(stacked.shape[0], -1))

    def xǁExtractFeaturesǁ_compute_fft_features__mutmut_70(self, X: np.ndarray) -> np.ndarray:
        """Calcule les puissances de bandes à partir de la FFT."""

        n_times = X.shape[-1]
        # Centre le signal pour supprimer la composante DC avant la FFT
        centered = X - X.mean(axis=-1, keepdims=True)
        # Calcule les fréquences réelles à partir de la sfreq configurée
        freqs = np.fft.rfftfreq(n_times, d=1.0 / self.sfreq)
        # Calcule la puissance spectrale par canal et échantillon
        power = np.asarray(
            np.abs(np.fft.rfft(centered, axis=-1)) ** 2, dtype=float
        )  # pragma: no mutate
        # Restaure l'énergie des composantes symétriques manquantes pour un signal réel
        if power.shape[-1] > 1:
            power[..., 1:-1] *= 2
            # Lorsque n_times est impair, la dernière fréquence possède un symétrique
            if n_times % 2 != 0:
                power[..., -1] *= 2
        # Normalise par la longueur temporelle pour obtenir une puissance moyenne
        power = power / float(n_times**2)
        # Accumule les puissances par bande pour chaque canal
        band_powers: List[np.ndarray] = []
        # Parcourt chaque bande EEG définie dans les paramètres
        for _, (low, high) in self._band_items:
            # Construit le masque fréquentiel pour cette bande
            band_mask = (freqs >= low) & (freqs <= high)

            # Gère le cas où aucune fréquence ne tombe dans la bande
            if not np.any(band_mask):
                # Retourne un bloc de zéros pour préserver la forme
                band_power = np.zeros(power.shape[:2])
            else:
                # Moyenne la puissance sur les fréquences de la bande
                band_power = power[:, :, band_mask].mean(axis=3)

            # Ajoute la matrice (n_samples, n_channels) à la liste
            band_powers.append(band_power)

        # Empile les bandes pour retourner un tenseur cohérent canal x bande
        stacked = np.stack(band_powers, axis=2)
        # Retourne une matrice aplatie (échantillons, canaux * bandes)
        return cast(np.ndarray, stacked.reshape(stacked.shape[0], -1))

    def xǁExtractFeaturesǁ_compute_fft_features__mutmut_71(self, X: np.ndarray) -> np.ndarray:
        """Calcule les puissances de bandes à partir de la FFT."""

        n_times = X.shape[-1]
        # Centre le signal pour supprimer la composante DC avant la FFT
        centered = X - X.mean(axis=-1, keepdims=True)
        # Calcule les fréquences réelles à partir de la sfreq configurée
        freqs = np.fft.rfftfreq(n_times, d=1.0 / self.sfreq)
        # Calcule la puissance spectrale par canal et échantillon
        power = np.asarray(
            np.abs(np.fft.rfft(centered, axis=-1)) ** 2, dtype=float
        )  # pragma: no mutate
        # Restaure l'énergie des composantes symétriques manquantes pour un signal réel
        if power.shape[-1] > 1:
            power[..., 1:-1] *= 2
            # Lorsque n_times est impair, la dernière fréquence possède un symétrique
            if n_times % 2 != 0:
                power[..., -1] *= 2
        # Normalise par la longueur temporelle pour obtenir une puissance moyenne
        power = power / float(n_times**2)
        # Accumule les puissances par bande pour chaque canal
        band_powers: List[np.ndarray] = []
        # Parcourt chaque bande EEG définie dans les paramètres
        for _, (low, high) in self._band_items:
            # Construit le masque fréquentiel pour cette bande
            band_mask = (freqs >= low) & (freqs <= high)

            # Gère le cas où aucune fréquence ne tombe dans la bande
            if not np.any(band_mask):
                # Retourne un bloc de zéros pour préserver la forme
                band_power = np.zeros(power.shape[:2])
            else:
                # Moyenne la puissance sur les fréquences de la bande
                band_power = power[:, :, band_mask].mean(axis=2)

            # Ajoute la matrice (n_samples, n_channels) à la liste
            band_powers.append(None)

        # Empile les bandes pour retourner un tenseur cohérent canal x bande
        stacked = np.stack(band_powers, axis=2)
        # Retourne une matrice aplatie (échantillons, canaux * bandes)
        return cast(np.ndarray, stacked.reshape(stacked.shape[0], -1))

    def xǁExtractFeaturesǁ_compute_fft_features__mutmut_72(self, X: np.ndarray) -> np.ndarray:
        """Calcule les puissances de bandes à partir de la FFT."""

        n_times = X.shape[-1]
        # Centre le signal pour supprimer la composante DC avant la FFT
        centered = X - X.mean(axis=-1, keepdims=True)
        # Calcule les fréquences réelles à partir de la sfreq configurée
        freqs = np.fft.rfftfreq(n_times, d=1.0 / self.sfreq)
        # Calcule la puissance spectrale par canal et échantillon
        power = np.asarray(
            np.abs(np.fft.rfft(centered, axis=-1)) ** 2, dtype=float
        )  # pragma: no mutate
        # Restaure l'énergie des composantes symétriques manquantes pour un signal réel
        if power.shape[-1] > 1:
            power[..., 1:-1] *= 2
            # Lorsque n_times est impair, la dernière fréquence possède un symétrique
            if n_times % 2 != 0:
                power[..., -1] *= 2
        # Normalise par la longueur temporelle pour obtenir une puissance moyenne
        power = power / float(n_times**2)
        # Accumule les puissances par bande pour chaque canal
        band_powers: List[np.ndarray] = []
        # Parcourt chaque bande EEG définie dans les paramètres
        for _, (low, high) in self._band_items:
            # Construit le masque fréquentiel pour cette bande
            band_mask = (freqs >= low) & (freqs <= high)

            # Gère le cas où aucune fréquence ne tombe dans la bande
            if not np.any(band_mask):
                # Retourne un bloc de zéros pour préserver la forme
                band_power = np.zeros(power.shape[:2])
            else:
                # Moyenne la puissance sur les fréquences de la bande
                band_power = power[:, :, band_mask].mean(axis=2)

            # Ajoute la matrice (n_samples, n_channels) à la liste
            band_powers.append(band_power)

        # Empile les bandes pour retourner un tenseur cohérent canal x bande
        stacked = None
        # Retourne une matrice aplatie (échantillons, canaux * bandes)
        return cast(np.ndarray, stacked.reshape(stacked.shape[0], -1))

    def xǁExtractFeaturesǁ_compute_fft_features__mutmut_73(self, X: np.ndarray) -> np.ndarray:
        """Calcule les puissances de bandes à partir de la FFT."""

        n_times = X.shape[-1]
        # Centre le signal pour supprimer la composante DC avant la FFT
        centered = X - X.mean(axis=-1, keepdims=True)
        # Calcule les fréquences réelles à partir de la sfreq configurée
        freqs = np.fft.rfftfreq(n_times, d=1.0 / self.sfreq)
        # Calcule la puissance spectrale par canal et échantillon
        power = np.asarray(
            np.abs(np.fft.rfft(centered, axis=-1)) ** 2, dtype=float
        )  # pragma: no mutate
        # Restaure l'énergie des composantes symétriques manquantes pour un signal réel
        if power.shape[-1] > 1:
            power[..., 1:-1] *= 2
            # Lorsque n_times est impair, la dernière fréquence possède un symétrique
            if n_times % 2 != 0:
                power[..., -1] *= 2
        # Normalise par la longueur temporelle pour obtenir une puissance moyenne
        power = power / float(n_times**2)
        # Accumule les puissances par bande pour chaque canal
        band_powers: List[np.ndarray] = []
        # Parcourt chaque bande EEG définie dans les paramètres
        for _, (low, high) in self._band_items:
            # Construit le masque fréquentiel pour cette bande
            band_mask = (freqs >= low) & (freqs <= high)

            # Gère le cas où aucune fréquence ne tombe dans la bande
            if not np.any(band_mask):
                # Retourne un bloc de zéros pour préserver la forme
                band_power = np.zeros(power.shape[:2])
            else:
                # Moyenne la puissance sur les fréquences de la bande
                band_power = power[:, :, band_mask].mean(axis=2)

            # Ajoute la matrice (n_samples, n_channels) à la liste
            band_powers.append(band_power)

        # Empile les bandes pour retourner un tenseur cohérent canal x bande
        stacked = np.stack(None, axis=2)
        # Retourne une matrice aplatie (échantillons, canaux * bandes)
        return cast(np.ndarray, stacked.reshape(stacked.shape[0], -1))

    def xǁExtractFeaturesǁ_compute_fft_features__mutmut_74(self, X: np.ndarray) -> np.ndarray:
        """Calcule les puissances de bandes à partir de la FFT."""

        n_times = X.shape[-1]
        # Centre le signal pour supprimer la composante DC avant la FFT
        centered = X - X.mean(axis=-1, keepdims=True)
        # Calcule les fréquences réelles à partir de la sfreq configurée
        freqs = np.fft.rfftfreq(n_times, d=1.0 / self.sfreq)
        # Calcule la puissance spectrale par canal et échantillon
        power = np.asarray(
            np.abs(np.fft.rfft(centered, axis=-1)) ** 2, dtype=float
        )  # pragma: no mutate
        # Restaure l'énergie des composantes symétriques manquantes pour un signal réel
        if power.shape[-1] > 1:
            power[..., 1:-1] *= 2
            # Lorsque n_times est impair, la dernière fréquence possède un symétrique
            if n_times % 2 != 0:
                power[..., -1] *= 2
        # Normalise par la longueur temporelle pour obtenir une puissance moyenne
        power = power / float(n_times**2)
        # Accumule les puissances par bande pour chaque canal
        band_powers: List[np.ndarray] = []
        # Parcourt chaque bande EEG définie dans les paramètres
        for _, (low, high) in self._band_items:
            # Construit le masque fréquentiel pour cette bande
            band_mask = (freqs >= low) & (freqs <= high)

            # Gère le cas où aucune fréquence ne tombe dans la bande
            if not np.any(band_mask):
                # Retourne un bloc de zéros pour préserver la forme
                band_power = np.zeros(power.shape[:2])
            else:
                # Moyenne la puissance sur les fréquences de la bande
                band_power = power[:, :, band_mask].mean(axis=2)

            # Ajoute la matrice (n_samples, n_channels) à la liste
            band_powers.append(band_power)

        # Empile les bandes pour retourner un tenseur cohérent canal x bande
        stacked = np.stack(band_powers, axis=None)
        # Retourne une matrice aplatie (échantillons, canaux * bandes)
        return cast(np.ndarray, stacked.reshape(stacked.shape[0], -1))

    def xǁExtractFeaturesǁ_compute_fft_features__mutmut_75(self, X: np.ndarray) -> np.ndarray:
        """Calcule les puissances de bandes à partir de la FFT."""

        n_times = X.shape[-1]
        # Centre le signal pour supprimer la composante DC avant la FFT
        centered = X - X.mean(axis=-1, keepdims=True)
        # Calcule les fréquences réelles à partir de la sfreq configurée
        freqs = np.fft.rfftfreq(n_times, d=1.0 / self.sfreq)
        # Calcule la puissance spectrale par canal et échantillon
        power = np.asarray(
            np.abs(np.fft.rfft(centered, axis=-1)) ** 2, dtype=float
        )  # pragma: no mutate
        # Restaure l'énergie des composantes symétriques manquantes pour un signal réel
        if power.shape[-1] > 1:
            power[..., 1:-1] *= 2
            # Lorsque n_times est impair, la dernière fréquence possède un symétrique
            if n_times % 2 != 0:
                power[..., -1] *= 2
        # Normalise par la longueur temporelle pour obtenir une puissance moyenne
        power = power / float(n_times**2)
        # Accumule les puissances par bande pour chaque canal
        band_powers: List[np.ndarray] = []
        # Parcourt chaque bande EEG définie dans les paramètres
        for _, (low, high) in self._band_items:
            # Construit le masque fréquentiel pour cette bande
            band_mask = (freqs >= low) & (freqs <= high)

            # Gère le cas où aucune fréquence ne tombe dans la bande
            if not np.any(band_mask):
                # Retourne un bloc de zéros pour préserver la forme
                band_power = np.zeros(power.shape[:2])
            else:
                # Moyenne la puissance sur les fréquences de la bande
                band_power = power[:, :, band_mask].mean(axis=2)

            # Ajoute la matrice (n_samples, n_channels) à la liste
            band_powers.append(band_power)

        # Empile les bandes pour retourner un tenseur cohérent canal x bande
        stacked = np.stack(axis=2)
        # Retourne une matrice aplatie (échantillons, canaux * bandes)
        return cast(np.ndarray, stacked.reshape(stacked.shape[0], -1))

    def xǁExtractFeaturesǁ_compute_fft_features__mutmut_76(self, X: np.ndarray) -> np.ndarray:
        """Calcule les puissances de bandes à partir de la FFT."""

        n_times = X.shape[-1]
        # Centre le signal pour supprimer la composante DC avant la FFT
        centered = X - X.mean(axis=-1, keepdims=True)
        # Calcule les fréquences réelles à partir de la sfreq configurée
        freqs = np.fft.rfftfreq(n_times, d=1.0 / self.sfreq)
        # Calcule la puissance spectrale par canal et échantillon
        power = np.asarray(
            np.abs(np.fft.rfft(centered, axis=-1)) ** 2, dtype=float
        )  # pragma: no mutate
        # Restaure l'énergie des composantes symétriques manquantes pour un signal réel
        if power.shape[-1] > 1:
            power[..., 1:-1] *= 2
            # Lorsque n_times est impair, la dernière fréquence possède un symétrique
            if n_times % 2 != 0:
                power[..., -1] *= 2
        # Normalise par la longueur temporelle pour obtenir une puissance moyenne
        power = power / float(n_times**2)
        # Accumule les puissances par bande pour chaque canal
        band_powers: List[np.ndarray] = []
        # Parcourt chaque bande EEG définie dans les paramètres
        for _, (low, high) in self._band_items:
            # Construit le masque fréquentiel pour cette bande
            band_mask = (freqs >= low) & (freqs <= high)

            # Gère le cas où aucune fréquence ne tombe dans la bande
            if not np.any(band_mask):
                # Retourne un bloc de zéros pour préserver la forme
                band_power = np.zeros(power.shape[:2])
            else:
                # Moyenne la puissance sur les fréquences de la bande
                band_power = power[:, :, band_mask].mean(axis=2)

            # Ajoute la matrice (n_samples, n_channels) à la liste
            band_powers.append(band_power)

        # Empile les bandes pour retourner un tenseur cohérent canal x bande
        stacked = np.stack(band_powers, )
        # Retourne une matrice aplatie (échantillons, canaux * bandes)
        return cast(np.ndarray, stacked.reshape(stacked.shape[0], -1))

    def xǁExtractFeaturesǁ_compute_fft_features__mutmut_77(self, X: np.ndarray) -> np.ndarray:
        """Calcule les puissances de bandes à partir de la FFT."""

        n_times = X.shape[-1]
        # Centre le signal pour supprimer la composante DC avant la FFT
        centered = X - X.mean(axis=-1, keepdims=True)
        # Calcule les fréquences réelles à partir de la sfreq configurée
        freqs = np.fft.rfftfreq(n_times, d=1.0 / self.sfreq)
        # Calcule la puissance spectrale par canal et échantillon
        power = np.asarray(
            np.abs(np.fft.rfft(centered, axis=-1)) ** 2, dtype=float
        )  # pragma: no mutate
        # Restaure l'énergie des composantes symétriques manquantes pour un signal réel
        if power.shape[-1] > 1:
            power[..., 1:-1] *= 2
            # Lorsque n_times est impair, la dernière fréquence possède un symétrique
            if n_times % 2 != 0:
                power[..., -1] *= 2
        # Normalise par la longueur temporelle pour obtenir une puissance moyenne
        power = power / float(n_times**2)
        # Accumule les puissances par bande pour chaque canal
        band_powers: List[np.ndarray] = []
        # Parcourt chaque bande EEG définie dans les paramètres
        for _, (low, high) in self._band_items:
            # Construit le masque fréquentiel pour cette bande
            band_mask = (freqs >= low) & (freqs <= high)

            # Gère le cas où aucune fréquence ne tombe dans la bande
            if not np.any(band_mask):
                # Retourne un bloc de zéros pour préserver la forme
                band_power = np.zeros(power.shape[:2])
            else:
                # Moyenne la puissance sur les fréquences de la bande
                band_power = power[:, :, band_mask].mean(axis=2)

            # Ajoute la matrice (n_samples, n_channels) à la liste
            band_powers.append(band_power)

        # Empile les bandes pour retourner un tenseur cohérent canal x bande
        stacked = np.stack(band_powers, axis=3)
        # Retourne une matrice aplatie (échantillons, canaux * bandes)
        return cast(np.ndarray, stacked.reshape(stacked.shape[0], -1))

    def xǁExtractFeaturesǁ_compute_fft_features__mutmut_78(self, X: np.ndarray) -> np.ndarray:
        """Calcule les puissances de bandes à partir de la FFT."""

        n_times = X.shape[-1]
        # Centre le signal pour supprimer la composante DC avant la FFT
        centered = X - X.mean(axis=-1, keepdims=True)
        # Calcule les fréquences réelles à partir de la sfreq configurée
        freqs = np.fft.rfftfreq(n_times, d=1.0 / self.sfreq)
        # Calcule la puissance spectrale par canal et échantillon
        power = np.asarray(
            np.abs(np.fft.rfft(centered, axis=-1)) ** 2, dtype=float
        )  # pragma: no mutate
        # Restaure l'énergie des composantes symétriques manquantes pour un signal réel
        if power.shape[-1] > 1:
            power[..., 1:-1] *= 2
            # Lorsque n_times est impair, la dernière fréquence possède un symétrique
            if n_times % 2 != 0:
                power[..., -1] *= 2
        # Normalise par la longueur temporelle pour obtenir une puissance moyenne
        power = power / float(n_times**2)
        # Accumule les puissances par bande pour chaque canal
        band_powers: List[np.ndarray] = []
        # Parcourt chaque bande EEG définie dans les paramètres
        for _, (low, high) in self._band_items:
            # Construit le masque fréquentiel pour cette bande
            band_mask = (freqs >= low) & (freqs <= high)

            # Gère le cas où aucune fréquence ne tombe dans la bande
            if not np.any(band_mask):
                # Retourne un bloc de zéros pour préserver la forme
                band_power = np.zeros(power.shape[:2])
            else:
                # Moyenne la puissance sur les fréquences de la bande
                band_power = power[:, :, band_mask].mean(axis=2)

            # Ajoute la matrice (n_samples, n_channels) à la liste
            band_powers.append(band_power)

        # Empile les bandes pour retourner un tenseur cohérent canal x bande
        stacked = np.stack(band_powers, axis=2)
        # Retourne une matrice aplatie (échantillons, canaux * bandes)
        return cast(None, stacked.reshape(stacked.shape[0], -1))

    def xǁExtractFeaturesǁ_compute_fft_features__mutmut_79(self, X: np.ndarray) -> np.ndarray:
        """Calcule les puissances de bandes à partir de la FFT."""

        n_times = X.shape[-1]
        # Centre le signal pour supprimer la composante DC avant la FFT
        centered = X - X.mean(axis=-1, keepdims=True)
        # Calcule les fréquences réelles à partir de la sfreq configurée
        freqs = np.fft.rfftfreq(n_times, d=1.0 / self.sfreq)
        # Calcule la puissance spectrale par canal et échantillon
        power = np.asarray(
            np.abs(np.fft.rfft(centered, axis=-1)) ** 2, dtype=float
        )  # pragma: no mutate
        # Restaure l'énergie des composantes symétriques manquantes pour un signal réel
        if power.shape[-1] > 1:
            power[..., 1:-1] *= 2
            # Lorsque n_times est impair, la dernière fréquence possède un symétrique
            if n_times % 2 != 0:
                power[..., -1] *= 2
        # Normalise par la longueur temporelle pour obtenir une puissance moyenne
        power = power / float(n_times**2)
        # Accumule les puissances par bande pour chaque canal
        band_powers: List[np.ndarray] = []
        # Parcourt chaque bande EEG définie dans les paramètres
        for _, (low, high) in self._band_items:
            # Construit le masque fréquentiel pour cette bande
            band_mask = (freqs >= low) & (freqs <= high)

            # Gère le cas où aucune fréquence ne tombe dans la bande
            if not np.any(band_mask):
                # Retourne un bloc de zéros pour préserver la forme
                band_power = np.zeros(power.shape[:2])
            else:
                # Moyenne la puissance sur les fréquences de la bande
                band_power = power[:, :, band_mask].mean(axis=2)

            # Ajoute la matrice (n_samples, n_channels) à la liste
            band_powers.append(band_power)

        # Empile les bandes pour retourner un tenseur cohérent canal x bande
        stacked = np.stack(band_powers, axis=2)
        # Retourne une matrice aplatie (échantillons, canaux * bandes)
        return cast(np.ndarray, None)

    def xǁExtractFeaturesǁ_compute_fft_features__mutmut_80(self, X: np.ndarray) -> np.ndarray:
        """Calcule les puissances de bandes à partir de la FFT."""

        n_times = X.shape[-1]
        # Centre le signal pour supprimer la composante DC avant la FFT
        centered = X - X.mean(axis=-1, keepdims=True)
        # Calcule les fréquences réelles à partir de la sfreq configurée
        freqs = np.fft.rfftfreq(n_times, d=1.0 / self.sfreq)
        # Calcule la puissance spectrale par canal et échantillon
        power = np.asarray(
            np.abs(np.fft.rfft(centered, axis=-1)) ** 2, dtype=float
        )  # pragma: no mutate
        # Restaure l'énergie des composantes symétriques manquantes pour un signal réel
        if power.shape[-1] > 1:
            power[..., 1:-1] *= 2
            # Lorsque n_times est impair, la dernière fréquence possède un symétrique
            if n_times % 2 != 0:
                power[..., -1] *= 2
        # Normalise par la longueur temporelle pour obtenir une puissance moyenne
        power = power / float(n_times**2)
        # Accumule les puissances par bande pour chaque canal
        band_powers: List[np.ndarray] = []
        # Parcourt chaque bande EEG définie dans les paramètres
        for _, (low, high) in self._band_items:
            # Construit le masque fréquentiel pour cette bande
            band_mask = (freqs >= low) & (freqs <= high)

            # Gère le cas où aucune fréquence ne tombe dans la bande
            if not np.any(band_mask):
                # Retourne un bloc de zéros pour préserver la forme
                band_power = np.zeros(power.shape[:2])
            else:
                # Moyenne la puissance sur les fréquences de la bande
                band_power = power[:, :, band_mask].mean(axis=2)

            # Ajoute la matrice (n_samples, n_channels) à la liste
            band_powers.append(band_power)

        # Empile les bandes pour retourner un tenseur cohérent canal x bande
        stacked = np.stack(band_powers, axis=2)
        # Retourne une matrice aplatie (échantillons, canaux * bandes)
        return cast(stacked.reshape(stacked.shape[0], -1))

    def xǁExtractFeaturesǁ_compute_fft_features__mutmut_81(self, X: np.ndarray) -> np.ndarray:
        """Calcule les puissances de bandes à partir de la FFT."""

        n_times = X.shape[-1]
        # Centre le signal pour supprimer la composante DC avant la FFT
        centered = X - X.mean(axis=-1, keepdims=True)
        # Calcule les fréquences réelles à partir de la sfreq configurée
        freqs = np.fft.rfftfreq(n_times, d=1.0 / self.sfreq)
        # Calcule la puissance spectrale par canal et échantillon
        power = np.asarray(
            np.abs(np.fft.rfft(centered, axis=-1)) ** 2, dtype=float
        )  # pragma: no mutate
        # Restaure l'énergie des composantes symétriques manquantes pour un signal réel
        if power.shape[-1] > 1:
            power[..., 1:-1] *= 2
            # Lorsque n_times est impair, la dernière fréquence possède un symétrique
            if n_times % 2 != 0:
                power[..., -1] *= 2
        # Normalise par la longueur temporelle pour obtenir une puissance moyenne
        power = power / float(n_times**2)
        # Accumule les puissances par bande pour chaque canal
        band_powers: List[np.ndarray] = []
        # Parcourt chaque bande EEG définie dans les paramètres
        for _, (low, high) in self._band_items:
            # Construit le masque fréquentiel pour cette bande
            band_mask = (freqs >= low) & (freqs <= high)

            # Gère le cas où aucune fréquence ne tombe dans la bande
            if not np.any(band_mask):
                # Retourne un bloc de zéros pour préserver la forme
                band_power = np.zeros(power.shape[:2])
            else:
                # Moyenne la puissance sur les fréquences de la bande
                band_power = power[:, :, band_mask].mean(axis=2)

            # Ajoute la matrice (n_samples, n_channels) à la liste
            band_powers.append(band_power)

        # Empile les bandes pour retourner un tenseur cohérent canal x bande
        stacked = np.stack(band_powers, axis=2)
        # Retourne une matrice aplatie (échantillons, canaux * bandes)
        return cast(np.ndarray, )

    def xǁExtractFeaturesǁ_compute_fft_features__mutmut_82(self, X: np.ndarray) -> np.ndarray:
        """Calcule les puissances de bandes à partir de la FFT."""

        n_times = X.shape[-1]
        # Centre le signal pour supprimer la composante DC avant la FFT
        centered = X - X.mean(axis=-1, keepdims=True)
        # Calcule les fréquences réelles à partir de la sfreq configurée
        freqs = np.fft.rfftfreq(n_times, d=1.0 / self.sfreq)
        # Calcule la puissance spectrale par canal et échantillon
        power = np.asarray(
            np.abs(np.fft.rfft(centered, axis=-1)) ** 2, dtype=float
        )  # pragma: no mutate
        # Restaure l'énergie des composantes symétriques manquantes pour un signal réel
        if power.shape[-1] > 1:
            power[..., 1:-1] *= 2
            # Lorsque n_times est impair, la dernière fréquence possède un symétrique
            if n_times % 2 != 0:
                power[..., -1] *= 2
        # Normalise par la longueur temporelle pour obtenir une puissance moyenne
        power = power / float(n_times**2)
        # Accumule les puissances par bande pour chaque canal
        band_powers: List[np.ndarray] = []
        # Parcourt chaque bande EEG définie dans les paramètres
        for _, (low, high) in self._band_items:
            # Construit le masque fréquentiel pour cette bande
            band_mask = (freqs >= low) & (freqs <= high)

            # Gère le cas où aucune fréquence ne tombe dans la bande
            if not np.any(band_mask):
                # Retourne un bloc de zéros pour préserver la forme
                band_power = np.zeros(power.shape[:2])
            else:
                # Moyenne la puissance sur les fréquences de la bande
                band_power = power[:, :, band_mask].mean(axis=2)

            # Ajoute la matrice (n_samples, n_channels) à la liste
            band_powers.append(band_power)

        # Empile les bandes pour retourner un tenseur cohérent canal x bande
        stacked = np.stack(band_powers, axis=2)
        # Retourne une matrice aplatie (échantillons, canaux * bandes)
        return cast(np.ndarray, stacked.reshape(None, -1))

    def xǁExtractFeaturesǁ_compute_fft_features__mutmut_83(self, X: np.ndarray) -> np.ndarray:
        """Calcule les puissances de bandes à partir de la FFT."""

        n_times = X.shape[-1]
        # Centre le signal pour supprimer la composante DC avant la FFT
        centered = X - X.mean(axis=-1, keepdims=True)
        # Calcule les fréquences réelles à partir de la sfreq configurée
        freqs = np.fft.rfftfreq(n_times, d=1.0 / self.sfreq)
        # Calcule la puissance spectrale par canal et échantillon
        power = np.asarray(
            np.abs(np.fft.rfft(centered, axis=-1)) ** 2, dtype=float
        )  # pragma: no mutate
        # Restaure l'énergie des composantes symétriques manquantes pour un signal réel
        if power.shape[-1] > 1:
            power[..., 1:-1] *= 2
            # Lorsque n_times est impair, la dernière fréquence possède un symétrique
            if n_times % 2 != 0:
                power[..., -1] *= 2
        # Normalise par la longueur temporelle pour obtenir une puissance moyenne
        power = power / float(n_times**2)
        # Accumule les puissances par bande pour chaque canal
        band_powers: List[np.ndarray] = []
        # Parcourt chaque bande EEG définie dans les paramètres
        for _, (low, high) in self._band_items:
            # Construit le masque fréquentiel pour cette bande
            band_mask = (freqs >= low) & (freqs <= high)

            # Gère le cas où aucune fréquence ne tombe dans la bande
            if not np.any(band_mask):
                # Retourne un bloc de zéros pour préserver la forme
                band_power = np.zeros(power.shape[:2])
            else:
                # Moyenne la puissance sur les fréquences de la bande
                band_power = power[:, :, band_mask].mean(axis=2)

            # Ajoute la matrice (n_samples, n_channels) à la liste
            band_powers.append(band_power)

        # Empile les bandes pour retourner un tenseur cohérent canal x bande
        stacked = np.stack(band_powers, axis=2)
        # Retourne une matrice aplatie (échantillons, canaux * bandes)
        return cast(np.ndarray, stacked.reshape(stacked.shape[0], None))

    def xǁExtractFeaturesǁ_compute_fft_features__mutmut_84(self, X: np.ndarray) -> np.ndarray:
        """Calcule les puissances de bandes à partir de la FFT."""

        n_times = X.shape[-1]
        # Centre le signal pour supprimer la composante DC avant la FFT
        centered = X - X.mean(axis=-1, keepdims=True)
        # Calcule les fréquences réelles à partir de la sfreq configurée
        freqs = np.fft.rfftfreq(n_times, d=1.0 / self.sfreq)
        # Calcule la puissance spectrale par canal et échantillon
        power = np.asarray(
            np.abs(np.fft.rfft(centered, axis=-1)) ** 2, dtype=float
        )  # pragma: no mutate
        # Restaure l'énergie des composantes symétriques manquantes pour un signal réel
        if power.shape[-1] > 1:
            power[..., 1:-1] *= 2
            # Lorsque n_times est impair, la dernière fréquence possède un symétrique
            if n_times % 2 != 0:
                power[..., -1] *= 2
        # Normalise par la longueur temporelle pour obtenir une puissance moyenne
        power = power / float(n_times**2)
        # Accumule les puissances par bande pour chaque canal
        band_powers: List[np.ndarray] = []
        # Parcourt chaque bande EEG définie dans les paramètres
        for _, (low, high) in self._band_items:
            # Construit le masque fréquentiel pour cette bande
            band_mask = (freqs >= low) & (freqs <= high)

            # Gère le cas où aucune fréquence ne tombe dans la bande
            if not np.any(band_mask):
                # Retourne un bloc de zéros pour préserver la forme
                band_power = np.zeros(power.shape[:2])
            else:
                # Moyenne la puissance sur les fréquences de la bande
                band_power = power[:, :, band_mask].mean(axis=2)

            # Ajoute la matrice (n_samples, n_channels) à la liste
            band_powers.append(band_power)

        # Empile les bandes pour retourner un tenseur cohérent canal x bande
        stacked = np.stack(band_powers, axis=2)
        # Retourne une matrice aplatie (échantillons, canaux * bandes)
        return cast(np.ndarray, stacked.reshape(-1))

    def xǁExtractFeaturesǁ_compute_fft_features__mutmut_85(self, X: np.ndarray) -> np.ndarray:
        """Calcule les puissances de bandes à partir de la FFT."""

        n_times = X.shape[-1]
        # Centre le signal pour supprimer la composante DC avant la FFT
        centered = X - X.mean(axis=-1, keepdims=True)
        # Calcule les fréquences réelles à partir de la sfreq configurée
        freqs = np.fft.rfftfreq(n_times, d=1.0 / self.sfreq)
        # Calcule la puissance spectrale par canal et échantillon
        power = np.asarray(
            np.abs(np.fft.rfft(centered, axis=-1)) ** 2, dtype=float
        )  # pragma: no mutate
        # Restaure l'énergie des composantes symétriques manquantes pour un signal réel
        if power.shape[-1] > 1:
            power[..., 1:-1] *= 2
            # Lorsque n_times est impair, la dernière fréquence possède un symétrique
            if n_times % 2 != 0:
                power[..., -1] *= 2
        # Normalise par la longueur temporelle pour obtenir une puissance moyenne
        power = power / float(n_times**2)
        # Accumule les puissances par bande pour chaque canal
        band_powers: List[np.ndarray] = []
        # Parcourt chaque bande EEG définie dans les paramètres
        for _, (low, high) in self._band_items:
            # Construit le masque fréquentiel pour cette bande
            band_mask = (freqs >= low) & (freqs <= high)

            # Gère le cas où aucune fréquence ne tombe dans la bande
            if not np.any(band_mask):
                # Retourne un bloc de zéros pour préserver la forme
                band_power = np.zeros(power.shape[:2])
            else:
                # Moyenne la puissance sur les fréquences de la bande
                band_power = power[:, :, band_mask].mean(axis=2)

            # Ajoute la matrice (n_samples, n_channels) à la liste
            band_powers.append(band_power)

        # Empile les bandes pour retourner un tenseur cohérent canal x bande
        stacked = np.stack(band_powers, axis=2)
        # Retourne une matrice aplatie (échantillons, canaux * bandes)
        return cast(np.ndarray, stacked.reshape(stacked.shape[0], ))

    def xǁExtractFeaturesǁ_compute_fft_features__mutmut_86(self, X: np.ndarray) -> np.ndarray:
        """Calcule les puissances de bandes à partir de la FFT."""

        n_times = X.shape[-1]
        # Centre le signal pour supprimer la composante DC avant la FFT
        centered = X - X.mean(axis=-1, keepdims=True)
        # Calcule les fréquences réelles à partir de la sfreq configurée
        freqs = np.fft.rfftfreq(n_times, d=1.0 / self.sfreq)
        # Calcule la puissance spectrale par canal et échantillon
        power = np.asarray(
            np.abs(np.fft.rfft(centered, axis=-1)) ** 2, dtype=float
        )  # pragma: no mutate
        # Restaure l'énergie des composantes symétriques manquantes pour un signal réel
        if power.shape[-1] > 1:
            power[..., 1:-1] *= 2
            # Lorsque n_times est impair, la dernière fréquence possède un symétrique
            if n_times % 2 != 0:
                power[..., -1] *= 2
        # Normalise par la longueur temporelle pour obtenir une puissance moyenne
        power = power / float(n_times**2)
        # Accumule les puissances par bande pour chaque canal
        band_powers: List[np.ndarray] = []
        # Parcourt chaque bande EEG définie dans les paramètres
        for _, (low, high) in self._band_items:
            # Construit le masque fréquentiel pour cette bande
            band_mask = (freqs >= low) & (freqs <= high)

            # Gère le cas où aucune fréquence ne tombe dans la bande
            if not np.any(band_mask):
                # Retourne un bloc de zéros pour préserver la forme
                band_power = np.zeros(power.shape[:2])
            else:
                # Moyenne la puissance sur les fréquences de la bande
                band_power = power[:, :, band_mask].mean(axis=2)

            # Ajoute la matrice (n_samples, n_channels) à la liste
            band_powers.append(band_power)

        # Empile les bandes pour retourner un tenseur cohérent canal x bande
        stacked = np.stack(band_powers, axis=2)
        # Retourne une matrice aplatie (échantillons, canaux * bandes)
        return cast(np.ndarray, stacked.reshape(stacked.shape[1], -1))

    def xǁExtractFeaturesǁ_compute_fft_features__mutmut_87(self, X: np.ndarray) -> np.ndarray:
        """Calcule les puissances de bandes à partir de la FFT."""

        n_times = X.shape[-1]
        # Centre le signal pour supprimer la composante DC avant la FFT
        centered = X - X.mean(axis=-1, keepdims=True)
        # Calcule les fréquences réelles à partir de la sfreq configurée
        freqs = np.fft.rfftfreq(n_times, d=1.0 / self.sfreq)
        # Calcule la puissance spectrale par canal et échantillon
        power = np.asarray(
            np.abs(np.fft.rfft(centered, axis=-1)) ** 2, dtype=float
        )  # pragma: no mutate
        # Restaure l'énergie des composantes symétriques manquantes pour un signal réel
        if power.shape[-1] > 1:
            power[..., 1:-1] *= 2
            # Lorsque n_times est impair, la dernière fréquence possède un symétrique
            if n_times % 2 != 0:
                power[..., -1] *= 2
        # Normalise par la longueur temporelle pour obtenir une puissance moyenne
        power = power / float(n_times**2)
        # Accumule les puissances par bande pour chaque canal
        band_powers: List[np.ndarray] = []
        # Parcourt chaque bande EEG définie dans les paramètres
        for _, (low, high) in self._band_items:
            # Construit le masque fréquentiel pour cette bande
            band_mask = (freqs >= low) & (freqs <= high)

            # Gère le cas où aucune fréquence ne tombe dans la bande
            if not np.any(band_mask):
                # Retourne un bloc de zéros pour préserver la forme
                band_power = np.zeros(power.shape[:2])
            else:
                # Moyenne la puissance sur les fréquences de la bande
                band_power = power[:, :, band_mask].mean(axis=2)

            # Ajoute la matrice (n_samples, n_channels) à la liste
            band_powers.append(band_power)

        # Empile les bandes pour retourner un tenseur cohérent canal x bande
        stacked = np.stack(band_powers, axis=2)
        # Retourne une matrice aplatie (échantillons, canaux * bandes)
        return cast(np.ndarray, stacked.reshape(stacked.shape[0], +1))

    def xǁExtractFeaturesǁ_compute_fft_features__mutmut_88(self, X: np.ndarray) -> np.ndarray:
        """Calcule les puissances de bandes à partir de la FFT."""

        n_times = X.shape[-1]
        # Centre le signal pour supprimer la composante DC avant la FFT
        centered = X - X.mean(axis=-1, keepdims=True)
        # Calcule les fréquences réelles à partir de la sfreq configurée
        freqs = np.fft.rfftfreq(n_times, d=1.0 / self.sfreq)
        # Calcule la puissance spectrale par canal et échantillon
        power = np.asarray(
            np.abs(np.fft.rfft(centered, axis=-1)) ** 2, dtype=float
        )  # pragma: no mutate
        # Restaure l'énergie des composantes symétriques manquantes pour un signal réel
        if power.shape[-1] > 1:
            power[..., 1:-1] *= 2
            # Lorsque n_times est impair, la dernière fréquence possède un symétrique
            if n_times % 2 != 0:
                power[..., -1] *= 2
        # Normalise par la longueur temporelle pour obtenir une puissance moyenne
        power = power / float(n_times**2)
        # Accumule les puissances par bande pour chaque canal
        band_powers: List[np.ndarray] = []
        # Parcourt chaque bande EEG définie dans les paramètres
        for _, (low, high) in self._band_items:
            # Construit le masque fréquentiel pour cette bande
            band_mask = (freqs >= low) & (freqs <= high)

            # Gère le cas où aucune fréquence ne tombe dans la bande
            if not np.any(band_mask):
                # Retourne un bloc de zéros pour préserver la forme
                band_power = np.zeros(power.shape[:2])
            else:
                # Moyenne la puissance sur les fréquences de la bande
                band_power = power[:, :, band_mask].mean(axis=2)

            # Ajoute la matrice (n_samples, n_channels) à la liste
            band_powers.append(band_power)

        # Empile les bandes pour retourner un tenseur cohérent canal x bande
        stacked = np.stack(band_powers, axis=2)
        # Retourne une matrice aplatie (échantillons, canaux * bandes)
        return cast(np.ndarray, stacked.reshape(stacked.shape[0], -2))
    
    xǁExtractFeaturesǁ_compute_fft_features__mutmut_mutants : ClassVar[MutantDict] = {
    'xǁExtractFeaturesǁ_compute_fft_features__mutmut_1': xǁExtractFeaturesǁ_compute_fft_features__mutmut_1, 
        'xǁExtractFeaturesǁ_compute_fft_features__mutmut_2': xǁExtractFeaturesǁ_compute_fft_features__mutmut_2, 
        'xǁExtractFeaturesǁ_compute_fft_features__mutmut_3': xǁExtractFeaturesǁ_compute_fft_features__mutmut_3, 
        'xǁExtractFeaturesǁ_compute_fft_features__mutmut_4': xǁExtractFeaturesǁ_compute_fft_features__mutmut_4, 
        'xǁExtractFeaturesǁ_compute_fft_features__mutmut_5': xǁExtractFeaturesǁ_compute_fft_features__mutmut_5, 
        'xǁExtractFeaturesǁ_compute_fft_features__mutmut_6': xǁExtractFeaturesǁ_compute_fft_features__mutmut_6, 
        'xǁExtractFeaturesǁ_compute_fft_features__mutmut_7': xǁExtractFeaturesǁ_compute_fft_features__mutmut_7, 
        'xǁExtractFeaturesǁ_compute_fft_features__mutmut_8': xǁExtractFeaturesǁ_compute_fft_features__mutmut_8, 
        'xǁExtractFeaturesǁ_compute_fft_features__mutmut_9': xǁExtractFeaturesǁ_compute_fft_features__mutmut_9, 
        'xǁExtractFeaturesǁ_compute_fft_features__mutmut_10': xǁExtractFeaturesǁ_compute_fft_features__mutmut_10, 
        'xǁExtractFeaturesǁ_compute_fft_features__mutmut_11': xǁExtractFeaturesǁ_compute_fft_features__mutmut_11, 
        'xǁExtractFeaturesǁ_compute_fft_features__mutmut_12': xǁExtractFeaturesǁ_compute_fft_features__mutmut_12, 
        'xǁExtractFeaturesǁ_compute_fft_features__mutmut_13': xǁExtractFeaturesǁ_compute_fft_features__mutmut_13, 
        'xǁExtractFeaturesǁ_compute_fft_features__mutmut_14': xǁExtractFeaturesǁ_compute_fft_features__mutmut_14, 
        'xǁExtractFeaturesǁ_compute_fft_features__mutmut_15': xǁExtractFeaturesǁ_compute_fft_features__mutmut_15, 
        'xǁExtractFeaturesǁ_compute_fft_features__mutmut_16': xǁExtractFeaturesǁ_compute_fft_features__mutmut_16, 
        'xǁExtractFeaturesǁ_compute_fft_features__mutmut_17': xǁExtractFeaturesǁ_compute_fft_features__mutmut_17, 
        'xǁExtractFeaturesǁ_compute_fft_features__mutmut_18': xǁExtractFeaturesǁ_compute_fft_features__mutmut_18, 
        'xǁExtractFeaturesǁ_compute_fft_features__mutmut_19': xǁExtractFeaturesǁ_compute_fft_features__mutmut_19, 
        'xǁExtractFeaturesǁ_compute_fft_features__mutmut_20': xǁExtractFeaturesǁ_compute_fft_features__mutmut_20, 
        'xǁExtractFeaturesǁ_compute_fft_features__mutmut_21': xǁExtractFeaturesǁ_compute_fft_features__mutmut_21, 
        'xǁExtractFeaturesǁ_compute_fft_features__mutmut_22': xǁExtractFeaturesǁ_compute_fft_features__mutmut_22, 
        'xǁExtractFeaturesǁ_compute_fft_features__mutmut_23': xǁExtractFeaturesǁ_compute_fft_features__mutmut_23, 
        'xǁExtractFeaturesǁ_compute_fft_features__mutmut_24': xǁExtractFeaturesǁ_compute_fft_features__mutmut_24, 
        'xǁExtractFeaturesǁ_compute_fft_features__mutmut_25': xǁExtractFeaturesǁ_compute_fft_features__mutmut_25, 
        'xǁExtractFeaturesǁ_compute_fft_features__mutmut_26': xǁExtractFeaturesǁ_compute_fft_features__mutmut_26, 
        'xǁExtractFeaturesǁ_compute_fft_features__mutmut_27': xǁExtractFeaturesǁ_compute_fft_features__mutmut_27, 
        'xǁExtractFeaturesǁ_compute_fft_features__mutmut_28': xǁExtractFeaturesǁ_compute_fft_features__mutmut_28, 
        'xǁExtractFeaturesǁ_compute_fft_features__mutmut_29': xǁExtractFeaturesǁ_compute_fft_features__mutmut_29, 
        'xǁExtractFeaturesǁ_compute_fft_features__mutmut_30': xǁExtractFeaturesǁ_compute_fft_features__mutmut_30, 
        'xǁExtractFeaturesǁ_compute_fft_features__mutmut_31': xǁExtractFeaturesǁ_compute_fft_features__mutmut_31, 
        'xǁExtractFeaturesǁ_compute_fft_features__mutmut_32': xǁExtractFeaturesǁ_compute_fft_features__mutmut_32, 
        'xǁExtractFeaturesǁ_compute_fft_features__mutmut_33': xǁExtractFeaturesǁ_compute_fft_features__mutmut_33, 
        'xǁExtractFeaturesǁ_compute_fft_features__mutmut_34': xǁExtractFeaturesǁ_compute_fft_features__mutmut_34, 
        'xǁExtractFeaturesǁ_compute_fft_features__mutmut_35': xǁExtractFeaturesǁ_compute_fft_features__mutmut_35, 
        'xǁExtractFeaturesǁ_compute_fft_features__mutmut_36': xǁExtractFeaturesǁ_compute_fft_features__mutmut_36, 
        'xǁExtractFeaturesǁ_compute_fft_features__mutmut_37': xǁExtractFeaturesǁ_compute_fft_features__mutmut_37, 
        'xǁExtractFeaturesǁ_compute_fft_features__mutmut_38': xǁExtractFeaturesǁ_compute_fft_features__mutmut_38, 
        'xǁExtractFeaturesǁ_compute_fft_features__mutmut_39': xǁExtractFeaturesǁ_compute_fft_features__mutmut_39, 
        'xǁExtractFeaturesǁ_compute_fft_features__mutmut_40': xǁExtractFeaturesǁ_compute_fft_features__mutmut_40, 
        'xǁExtractFeaturesǁ_compute_fft_features__mutmut_41': xǁExtractFeaturesǁ_compute_fft_features__mutmut_41, 
        'xǁExtractFeaturesǁ_compute_fft_features__mutmut_42': xǁExtractFeaturesǁ_compute_fft_features__mutmut_42, 
        'xǁExtractFeaturesǁ_compute_fft_features__mutmut_43': xǁExtractFeaturesǁ_compute_fft_features__mutmut_43, 
        'xǁExtractFeaturesǁ_compute_fft_features__mutmut_44': xǁExtractFeaturesǁ_compute_fft_features__mutmut_44, 
        'xǁExtractFeaturesǁ_compute_fft_features__mutmut_45': xǁExtractFeaturesǁ_compute_fft_features__mutmut_45, 
        'xǁExtractFeaturesǁ_compute_fft_features__mutmut_46': xǁExtractFeaturesǁ_compute_fft_features__mutmut_46, 
        'xǁExtractFeaturesǁ_compute_fft_features__mutmut_47': xǁExtractFeaturesǁ_compute_fft_features__mutmut_47, 
        'xǁExtractFeaturesǁ_compute_fft_features__mutmut_48': xǁExtractFeaturesǁ_compute_fft_features__mutmut_48, 
        'xǁExtractFeaturesǁ_compute_fft_features__mutmut_49': xǁExtractFeaturesǁ_compute_fft_features__mutmut_49, 
        'xǁExtractFeaturesǁ_compute_fft_features__mutmut_50': xǁExtractFeaturesǁ_compute_fft_features__mutmut_50, 
        'xǁExtractFeaturesǁ_compute_fft_features__mutmut_51': xǁExtractFeaturesǁ_compute_fft_features__mutmut_51, 
        'xǁExtractFeaturesǁ_compute_fft_features__mutmut_52': xǁExtractFeaturesǁ_compute_fft_features__mutmut_52, 
        'xǁExtractFeaturesǁ_compute_fft_features__mutmut_53': xǁExtractFeaturesǁ_compute_fft_features__mutmut_53, 
        'xǁExtractFeaturesǁ_compute_fft_features__mutmut_54': xǁExtractFeaturesǁ_compute_fft_features__mutmut_54, 
        'xǁExtractFeaturesǁ_compute_fft_features__mutmut_55': xǁExtractFeaturesǁ_compute_fft_features__mutmut_55, 
        'xǁExtractFeaturesǁ_compute_fft_features__mutmut_56': xǁExtractFeaturesǁ_compute_fft_features__mutmut_56, 
        'xǁExtractFeaturesǁ_compute_fft_features__mutmut_57': xǁExtractFeaturesǁ_compute_fft_features__mutmut_57, 
        'xǁExtractFeaturesǁ_compute_fft_features__mutmut_58': xǁExtractFeaturesǁ_compute_fft_features__mutmut_58, 
        'xǁExtractFeaturesǁ_compute_fft_features__mutmut_59': xǁExtractFeaturesǁ_compute_fft_features__mutmut_59, 
        'xǁExtractFeaturesǁ_compute_fft_features__mutmut_60': xǁExtractFeaturesǁ_compute_fft_features__mutmut_60, 
        'xǁExtractFeaturesǁ_compute_fft_features__mutmut_61': xǁExtractFeaturesǁ_compute_fft_features__mutmut_61, 
        'xǁExtractFeaturesǁ_compute_fft_features__mutmut_62': xǁExtractFeaturesǁ_compute_fft_features__mutmut_62, 
        'xǁExtractFeaturesǁ_compute_fft_features__mutmut_63': xǁExtractFeaturesǁ_compute_fft_features__mutmut_63, 
        'xǁExtractFeaturesǁ_compute_fft_features__mutmut_64': xǁExtractFeaturesǁ_compute_fft_features__mutmut_64, 
        'xǁExtractFeaturesǁ_compute_fft_features__mutmut_65': xǁExtractFeaturesǁ_compute_fft_features__mutmut_65, 
        'xǁExtractFeaturesǁ_compute_fft_features__mutmut_66': xǁExtractFeaturesǁ_compute_fft_features__mutmut_66, 
        'xǁExtractFeaturesǁ_compute_fft_features__mutmut_67': xǁExtractFeaturesǁ_compute_fft_features__mutmut_67, 
        'xǁExtractFeaturesǁ_compute_fft_features__mutmut_68': xǁExtractFeaturesǁ_compute_fft_features__mutmut_68, 
        'xǁExtractFeaturesǁ_compute_fft_features__mutmut_69': xǁExtractFeaturesǁ_compute_fft_features__mutmut_69, 
        'xǁExtractFeaturesǁ_compute_fft_features__mutmut_70': xǁExtractFeaturesǁ_compute_fft_features__mutmut_70, 
        'xǁExtractFeaturesǁ_compute_fft_features__mutmut_71': xǁExtractFeaturesǁ_compute_fft_features__mutmut_71, 
        'xǁExtractFeaturesǁ_compute_fft_features__mutmut_72': xǁExtractFeaturesǁ_compute_fft_features__mutmut_72, 
        'xǁExtractFeaturesǁ_compute_fft_features__mutmut_73': xǁExtractFeaturesǁ_compute_fft_features__mutmut_73, 
        'xǁExtractFeaturesǁ_compute_fft_features__mutmut_74': xǁExtractFeaturesǁ_compute_fft_features__mutmut_74, 
        'xǁExtractFeaturesǁ_compute_fft_features__mutmut_75': xǁExtractFeaturesǁ_compute_fft_features__mutmut_75, 
        'xǁExtractFeaturesǁ_compute_fft_features__mutmut_76': xǁExtractFeaturesǁ_compute_fft_features__mutmut_76, 
        'xǁExtractFeaturesǁ_compute_fft_features__mutmut_77': xǁExtractFeaturesǁ_compute_fft_features__mutmut_77, 
        'xǁExtractFeaturesǁ_compute_fft_features__mutmut_78': xǁExtractFeaturesǁ_compute_fft_features__mutmut_78, 
        'xǁExtractFeaturesǁ_compute_fft_features__mutmut_79': xǁExtractFeaturesǁ_compute_fft_features__mutmut_79, 
        'xǁExtractFeaturesǁ_compute_fft_features__mutmut_80': xǁExtractFeaturesǁ_compute_fft_features__mutmut_80, 
        'xǁExtractFeaturesǁ_compute_fft_features__mutmut_81': xǁExtractFeaturesǁ_compute_fft_features__mutmut_81, 
        'xǁExtractFeaturesǁ_compute_fft_features__mutmut_82': xǁExtractFeaturesǁ_compute_fft_features__mutmut_82, 
        'xǁExtractFeaturesǁ_compute_fft_features__mutmut_83': xǁExtractFeaturesǁ_compute_fft_features__mutmut_83, 
        'xǁExtractFeaturesǁ_compute_fft_features__mutmut_84': xǁExtractFeaturesǁ_compute_fft_features__mutmut_84, 
        'xǁExtractFeaturesǁ_compute_fft_features__mutmut_85': xǁExtractFeaturesǁ_compute_fft_features__mutmut_85, 
        'xǁExtractFeaturesǁ_compute_fft_features__mutmut_86': xǁExtractFeaturesǁ_compute_fft_features__mutmut_86, 
        'xǁExtractFeaturesǁ_compute_fft_features__mutmut_87': xǁExtractFeaturesǁ_compute_fft_features__mutmut_87, 
        'xǁExtractFeaturesǁ_compute_fft_features__mutmut_88': xǁExtractFeaturesǁ_compute_fft_features__mutmut_88
    }
    
    def _compute_fft_features(self, *args, **kwargs):
        result = _mutmut_trampoline(object.__getattribute__(self, "xǁExtractFeaturesǁ_compute_fft_features__mutmut_orig"), object.__getattribute__(self, "xǁExtractFeaturesǁ_compute_fft_features__mutmut_mutants"), args, kwargs, self)
        return result 
    
    _compute_fft_features.__signature__ = _mutmut_signature(xǁExtractFeaturesǁ_compute_fft_features__mutmut_orig)
    xǁExtractFeaturesǁ_compute_fft_features__mutmut_orig.__name__ = 'xǁExtractFeaturesǁ_compute_fft_features'

    def xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_orig(self, X: np.ndarray) -> np.ndarray:
        """Calcule des features à partir de la CWT wavelet."""

        expected_bands = len(self._band_items)
        if expected_bands == 0:  # pragma: no cover - defensive
            raise ValueError("Wavelet features require at least one configured band.")
        config = dict(self._effective_strategy_config)
        _normalize_wavelet_name(config.get("wavelet", "morlet"))
        expected_ndim = 3
        # Calcule les coefficients puis la puissance de bande via la fonction dédiée
        stacked = _compute_wavelet_band_powers(
            X,
            self.sfreq,
            self.band_ranges,
            config,
        )
        if stacked.ndim != expected_ndim:
            raise ValueError(
                "Wavelet band powers must return a 3D array "
                "(epochs, channels, bands) to preserve feature naming."
            )
        if stacked.shape[2] != expected_bands:
            raise ValueError(
                "Wavelet band powers shape mismatch: "
                f"expected {expected_bands} bands but received {stacked.shape[2]}. "
                "Check the number of central frequencies and band definitions."
            )
        if stacked.shape[0] != X.shape[0] or stacked.shape[1] != X.shape[1]:
            raise ValueError(
                "Wavelet band powers must preserve epoch and channel dimensions."
            )

        # Retourne la matrice tabulaire prête pour un classifieur scikit-learn
        return stacked.reshape(stacked.shape[0], -1)

    def xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_1(self, X: np.ndarray) -> np.ndarray:
        """Calcule des features à partir de la CWT wavelet."""

        expected_bands = None
        if expected_bands == 0:  # pragma: no cover - defensive
            raise ValueError("Wavelet features require at least one configured band.")
        config = dict(self._effective_strategy_config)
        _normalize_wavelet_name(config.get("wavelet", "morlet"))
        expected_ndim = 3
        # Calcule les coefficients puis la puissance de bande via la fonction dédiée
        stacked = _compute_wavelet_band_powers(
            X,
            self.sfreq,
            self.band_ranges,
            config,
        )
        if stacked.ndim != expected_ndim:
            raise ValueError(
                "Wavelet band powers must return a 3D array "
                "(epochs, channels, bands) to preserve feature naming."
            )
        if stacked.shape[2] != expected_bands:
            raise ValueError(
                "Wavelet band powers shape mismatch: "
                f"expected {expected_bands} bands but received {stacked.shape[2]}. "
                "Check the number of central frequencies and band definitions."
            )
        if stacked.shape[0] != X.shape[0] or stacked.shape[1] != X.shape[1]:
            raise ValueError(
                "Wavelet band powers must preserve epoch and channel dimensions."
            )

        # Retourne la matrice tabulaire prête pour un classifieur scikit-learn
        return stacked.reshape(stacked.shape[0], -1)

    def xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_2(self, X: np.ndarray) -> np.ndarray:
        """Calcule des features à partir de la CWT wavelet."""

        expected_bands = len(self._band_items)
        if expected_bands != 0:  # pragma: no cover - defensive
            raise ValueError("Wavelet features require at least one configured band.")
        config = dict(self._effective_strategy_config)
        _normalize_wavelet_name(config.get("wavelet", "morlet"))
        expected_ndim = 3
        # Calcule les coefficients puis la puissance de bande via la fonction dédiée
        stacked = _compute_wavelet_band_powers(
            X,
            self.sfreq,
            self.band_ranges,
            config,
        )
        if stacked.ndim != expected_ndim:
            raise ValueError(
                "Wavelet band powers must return a 3D array "
                "(epochs, channels, bands) to preserve feature naming."
            )
        if stacked.shape[2] != expected_bands:
            raise ValueError(
                "Wavelet band powers shape mismatch: "
                f"expected {expected_bands} bands but received {stacked.shape[2]}. "
                "Check the number of central frequencies and band definitions."
            )
        if stacked.shape[0] != X.shape[0] or stacked.shape[1] != X.shape[1]:
            raise ValueError(
                "Wavelet band powers must preserve epoch and channel dimensions."
            )

        # Retourne la matrice tabulaire prête pour un classifieur scikit-learn
        return stacked.reshape(stacked.shape[0], -1)

    def xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_3(self, X: np.ndarray) -> np.ndarray:
        """Calcule des features à partir de la CWT wavelet."""

        expected_bands = len(self._band_items)
        if expected_bands == 1:  # pragma: no cover - defensive
            raise ValueError("Wavelet features require at least one configured band.")
        config = dict(self._effective_strategy_config)
        _normalize_wavelet_name(config.get("wavelet", "morlet"))
        expected_ndim = 3
        # Calcule les coefficients puis la puissance de bande via la fonction dédiée
        stacked = _compute_wavelet_band_powers(
            X,
            self.sfreq,
            self.band_ranges,
            config,
        )
        if stacked.ndim != expected_ndim:
            raise ValueError(
                "Wavelet band powers must return a 3D array "
                "(epochs, channels, bands) to preserve feature naming."
            )
        if stacked.shape[2] != expected_bands:
            raise ValueError(
                "Wavelet band powers shape mismatch: "
                f"expected {expected_bands} bands but received {stacked.shape[2]}. "
                "Check the number of central frequencies and band definitions."
            )
        if stacked.shape[0] != X.shape[0] or stacked.shape[1] != X.shape[1]:
            raise ValueError(
                "Wavelet band powers must preserve epoch and channel dimensions."
            )

        # Retourne la matrice tabulaire prête pour un classifieur scikit-learn
        return stacked.reshape(stacked.shape[0], -1)

    def xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_4(self, X: np.ndarray) -> np.ndarray:
        """Calcule des features à partir de la CWT wavelet."""

        expected_bands = len(self._band_items)
        if expected_bands == 0:  # pragma: no cover - defensive
            raise ValueError("Wavelet features require at least one configured band.")
        config = None
        _normalize_wavelet_name(config.get("wavelet", "morlet"))
        expected_ndim = 3
        # Calcule les coefficients puis la puissance de bande via la fonction dédiée
        stacked = _compute_wavelet_band_powers(
            X,
            self.sfreq,
            self.band_ranges,
            config,
        )
        if stacked.ndim != expected_ndim:
            raise ValueError(
                "Wavelet band powers must return a 3D array "
                "(epochs, channels, bands) to preserve feature naming."
            )
        if stacked.shape[2] != expected_bands:
            raise ValueError(
                "Wavelet band powers shape mismatch: "
                f"expected {expected_bands} bands but received {stacked.shape[2]}. "
                "Check the number of central frequencies and band definitions."
            )
        if stacked.shape[0] != X.shape[0] or stacked.shape[1] != X.shape[1]:
            raise ValueError(
                "Wavelet band powers must preserve epoch and channel dimensions."
            )

        # Retourne la matrice tabulaire prête pour un classifieur scikit-learn
        return stacked.reshape(stacked.shape[0], -1)

    def xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_5(self, X: np.ndarray) -> np.ndarray:
        """Calcule des features à partir de la CWT wavelet."""

        expected_bands = len(self._band_items)
        if expected_bands == 0:  # pragma: no cover - defensive
            raise ValueError("Wavelet features require at least one configured band.")
        config = dict(None)
        _normalize_wavelet_name(config.get("wavelet", "morlet"))
        expected_ndim = 3
        # Calcule les coefficients puis la puissance de bande via la fonction dédiée
        stacked = _compute_wavelet_band_powers(
            X,
            self.sfreq,
            self.band_ranges,
            config,
        )
        if stacked.ndim != expected_ndim:
            raise ValueError(
                "Wavelet band powers must return a 3D array "
                "(epochs, channels, bands) to preserve feature naming."
            )
        if stacked.shape[2] != expected_bands:
            raise ValueError(
                "Wavelet band powers shape mismatch: "
                f"expected {expected_bands} bands but received {stacked.shape[2]}. "
                "Check the number of central frequencies and band definitions."
            )
        if stacked.shape[0] != X.shape[0] or stacked.shape[1] != X.shape[1]:
            raise ValueError(
                "Wavelet band powers must preserve epoch and channel dimensions."
            )

        # Retourne la matrice tabulaire prête pour un classifieur scikit-learn
        return stacked.reshape(stacked.shape[0], -1)

    def xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_6(self, X: np.ndarray) -> np.ndarray:
        """Calcule des features à partir de la CWT wavelet."""

        expected_bands = len(self._band_items)
        if expected_bands == 0:  # pragma: no cover - defensive
            raise ValueError("Wavelet features require at least one configured band.")
        config = dict(self._effective_strategy_config)
        _normalize_wavelet_name(None)
        expected_ndim = 3
        # Calcule les coefficients puis la puissance de bande via la fonction dédiée
        stacked = _compute_wavelet_band_powers(
            X,
            self.sfreq,
            self.band_ranges,
            config,
        )
        if stacked.ndim != expected_ndim:
            raise ValueError(
                "Wavelet band powers must return a 3D array "
                "(epochs, channels, bands) to preserve feature naming."
            )
        if stacked.shape[2] != expected_bands:
            raise ValueError(
                "Wavelet band powers shape mismatch: "
                f"expected {expected_bands} bands but received {stacked.shape[2]}. "
                "Check the number of central frequencies and band definitions."
            )
        if stacked.shape[0] != X.shape[0] or stacked.shape[1] != X.shape[1]:
            raise ValueError(
                "Wavelet band powers must preserve epoch and channel dimensions."
            )

        # Retourne la matrice tabulaire prête pour un classifieur scikit-learn
        return stacked.reshape(stacked.shape[0], -1)

    def xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_7(self, X: np.ndarray) -> np.ndarray:
        """Calcule des features à partir de la CWT wavelet."""

        expected_bands = len(self._band_items)
        if expected_bands == 0:  # pragma: no cover - defensive
            raise ValueError("Wavelet features require at least one configured band.")
        config = dict(self._effective_strategy_config)
        _normalize_wavelet_name(config.get(None, "morlet"))
        expected_ndim = 3
        # Calcule les coefficients puis la puissance de bande via la fonction dédiée
        stacked = _compute_wavelet_band_powers(
            X,
            self.sfreq,
            self.band_ranges,
            config,
        )
        if stacked.ndim != expected_ndim:
            raise ValueError(
                "Wavelet band powers must return a 3D array "
                "(epochs, channels, bands) to preserve feature naming."
            )
        if stacked.shape[2] != expected_bands:
            raise ValueError(
                "Wavelet band powers shape mismatch: "
                f"expected {expected_bands} bands but received {stacked.shape[2]}. "
                "Check the number of central frequencies and band definitions."
            )
        if stacked.shape[0] != X.shape[0] or stacked.shape[1] != X.shape[1]:
            raise ValueError(
                "Wavelet band powers must preserve epoch and channel dimensions."
            )

        # Retourne la matrice tabulaire prête pour un classifieur scikit-learn
        return stacked.reshape(stacked.shape[0], -1)

    def xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_8(self, X: np.ndarray) -> np.ndarray:
        """Calcule des features à partir de la CWT wavelet."""

        expected_bands = len(self._band_items)
        if expected_bands == 0:  # pragma: no cover - defensive
            raise ValueError("Wavelet features require at least one configured band.")
        config = dict(self._effective_strategy_config)
        _normalize_wavelet_name(config.get("wavelet", None))
        expected_ndim = 3
        # Calcule les coefficients puis la puissance de bande via la fonction dédiée
        stacked = _compute_wavelet_band_powers(
            X,
            self.sfreq,
            self.band_ranges,
            config,
        )
        if stacked.ndim != expected_ndim:
            raise ValueError(
                "Wavelet band powers must return a 3D array "
                "(epochs, channels, bands) to preserve feature naming."
            )
        if stacked.shape[2] != expected_bands:
            raise ValueError(
                "Wavelet band powers shape mismatch: "
                f"expected {expected_bands} bands but received {stacked.shape[2]}. "
                "Check the number of central frequencies and band definitions."
            )
        if stacked.shape[0] != X.shape[0] or stacked.shape[1] != X.shape[1]:
            raise ValueError(
                "Wavelet band powers must preserve epoch and channel dimensions."
            )

        # Retourne la matrice tabulaire prête pour un classifieur scikit-learn
        return stacked.reshape(stacked.shape[0], -1)

    def xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_9(self, X: np.ndarray) -> np.ndarray:
        """Calcule des features à partir de la CWT wavelet."""

        expected_bands = len(self._band_items)
        if expected_bands == 0:  # pragma: no cover - defensive
            raise ValueError("Wavelet features require at least one configured band.")
        config = dict(self._effective_strategy_config)
        _normalize_wavelet_name(config.get("morlet"))
        expected_ndim = 3
        # Calcule les coefficients puis la puissance de bande via la fonction dédiée
        stacked = _compute_wavelet_band_powers(
            X,
            self.sfreq,
            self.band_ranges,
            config,
        )
        if stacked.ndim != expected_ndim:
            raise ValueError(
                "Wavelet band powers must return a 3D array "
                "(epochs, channels, bands) to preserve feature naming."
            )
        if stacked.shape[2] != expected_bands:
            raise ValueError(
                "Wavelet band powers shape mismatch: "
                f"expected {expected_bands} bands but received {stacked.shape[2]}. "
                "Check the number of central frequencies and band definitions."
            )
        if stacked.shape[0] != X.shape[0] or stacked.shape[1] != X.shape[1]:
            raise ValueError(
                "Wavelet band powers must preserve epoch and channel dimensions."
            )

        # Retourne la matrice tabulaire prête pour un classifieur scikit-learn
        return stacked.reshape(stacked.shape[0], -1)

    def xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_10(self, X: np.ndarray) -> np.ndarray:
        """Calcule des features à partir de la CWT wavelet."""

        expected_bands = len(self._band_items)
        if expected_bands == 0:  # pragma: no cover - defensive
            raise ValueError("Wavelet features require at least one configured band.")
        config = dict(self._effective_strategy_config)
        _normalize_wavelet_name(config.get("wavelet", ))
        expected_ndim = 3
        # Calcule les coefficients puis la puissance de bande via la fonction dédiée
        stacked = _compute_wavelet_band_powers(
            X,
            self.sfreq,
            self.band_ranges,
            config,
        )
        if stacked.ndim != expected_ndim:
            raise ValueError(
                "Wavelet band powers must return a 3D array "
                "(epochs, channels, bands) to preserve feature naming."
            )
        if stacked.shape[2] != expected_bands:
            raise ValueError(
                "Wavelet band powers shape mismatch: "
                f"expected {expected_bands} bands but received {stacked.shape[2]}. "
                "Check the number of central frequencies and band definitions."
            )
        if stacked.shape[0] != X.shape[0] or stacked.shape[1] != X.shape[1]:
            raise ValueError(
                "Wavelet band powers must preserve epoch and channel dimensions."
            )

        # Retourne la matrice tabulaire prête pour un classifieur scikit-learn
        return stacked.reshape(stacked.shape[0], -1)

    def xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_11(self, X: np.ndarray) -> np.ndarray:
        """Calcule des features à partir de la CWT wavelet."""

        expected_bands = len(self._band_items)
        if expected_bands == 0:  # pragma: no cover - defensive
            raise ValueError("Wavelet features require at least one configured band.")
        config = dict(self._effective_strategy_config)
        _normalize_wavelet_name(config.get("XXwaveletXX", "morlet"))
        expected_ndim = 3
        # Calcule les coefficients puis la puissance de bande via la fonction dédiée
        stacked = _compute_wavelet_band_powers(
            X,
            self.sfreq,
            self.band_ranges,
            config,
        )
        if stacked.ndim != expected_ndim:
            raise ValueError(
                "Wavelet band powers must return a 3D array "
                "(epochs, channels, bands) to preserve feature naming."
            )
        if stacked.shape[2] != expected_bands:
            raise ValueError(
                "Wavelet band powers shape mismatch: "
                f"expected {expected_bands} bands but received {stacked.shape[2]}. "
                "Check the number of central frequencies and band definitions."
            )
        if stacked.shape[0] != X.shape[0] or stacked.shape[1] != X.shape[1]:
            raise ValueError(
                "Wavelet band powers must preserve epoch and channel dimensions."
            )

        # Retourne la matrice tabulaire prête pour un classifieur scikit-learn
        return stacked.reshape(stacked.shape[0], -1)

    def xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_12(self, X: np.ndarray) -> np.ndarray:
        """Calcule des features à partir de la CWT wavelet."""

        expected_bands = len(self._band_items)
        if expected_bands == 0:  # pragma: no cover - defensive
            raise ValueError("Wavelet features require at least one configured band.")
        config = dict(self._effective_strategy_config)
        _normalize_wavelet_name(config.get("WAVELET", "morlet"))
        expected_ndim = 3
        # Calcule les coefficients puis la puissance de bande via la fonction dédiée
        stacked = _compute_wavelet_band_powers(
            X,
            self.sfreq,
            self.band_ranges,
            config,
        )
        if stacked.ndim != expected_ndim:
            raise ValueError(
                "Wavelet band powers must return a 3D array "
                "(epochs, channels, bands) to preserve feature naming."
            )
        if stacked.shape[2] != expected_bands:
            raise ValueError(
                "Wavelet band powers shape mismatch: "
                f"expected {expected_bands} bands but received {stacked.shape[2]}. "
                "Check the number of central frequencies and band definitions."
            )
        if stacked.shape[0] != X.shape[0] or stacked.shape[1] != X.shape[1]:
            raise ValueError(
                "Wavelet band powers must preserve epoch and channel dimensions."
            )

        # Retourne la matrice tabulaire prête pour un classifieur scikit-learn
        return stacked.reshape(stacked.shape[0], -1)

    def xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_13(self, X: np.ndarray) -> np.ndarray:
        """Calcule des features à partir de la CWT wavelet."""

        expected_bands = len(self._band_items)
        if expected_bands == 0:  # pragma: no cover - defensive
            raise ValueError("Wavelet features require at least one configured band.")
        config = dict(self._effective_strategy_config)
        _normalize_wavelet_name(config.get("wavelet", "XXmorletXX"))
        expected_ndim = 3
        # Calcule les coefficients puis la puissance de bande via la fonction dédiée
        stacked = _compute_wavelet_band_powers(
            X,
            self.sfreq,
            self.band_ranges,
            config,
        )
        if stacked.ndim != expected_ndim:
            raise ValueError(
                "Wavelet band powers must return a 3D array "
                "(epochs, channels, bands) to preserve feature naming."
            )
        if stacked.shape[2] != expected_bands:
            raise ValueError(
                "Wavelet band powers shape mismatch: "
                f"expected {expected_bands} bands but received {stacked.shape[2]}. "
                "Check the number of central frequencies and band definitions."
            )
        if stacked.shape[0] != X.shape[0] or stacked.shape[1] != X.shape[1]:
            raise ValueError(
                "Wavelet band powers must preserve epoch and channel dimensions."
            )

        # Retourne la matrice tabulaire prête pour un classifieur scikit-learn
        return stacked.reshape(stacked.shape[0], -1)

    def xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_14(self, X: np.ndarray) -> np.ndarray:
        """Calcule des features à partir de la CWT wavelet."""

        expected_bands = len(self._band_items)
        if expected_bands == 0:  # pragma: no cover - defensive
            raise ValueError("Wavelet features require at least one configured band.")
        config = dict(self._effective_strategy_config)
        _normalize_wavelet_name(config.get("wavelet", "MORLET"))
        expected_ndim = 3
        # Calcule les coefficients puis la puissance de bande via la fonction dédiée
        stacked = _compute_wavelet_band_powers(
            X,
            self.sfreq,
            self.band_ranges,
            config,
        )
        if stacked.ndim != expected_ndim:
            raise ValueError(
                "Wavelet band powers must return a 3D array "
                "(epochs, channels, bands) to preserve feature naming."
            )
        if stacked.shape[2] != expected_bands:
            raise ValueError(
                "Wavelet band powers shape mismatch: "
                f"expected {expected_bands} bands but received {stacked.shape[2]}. "
                "Check the number of central frequencies and band definitions."
            )
        if stacked.shape[0] != X.shape[0] or stacked.shape[1] != X.shape[1]:
            raise ValueError(
                "Wavelet band powers must preserve epoch and channel dimensions."
            )

        # Retourne la matrice tabulaire prête pour un classifieur scikit-learn
        return stacked.reshape(stacked.shape[0], -1)

    def xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_15(self, X: np.ndarray) -> np.ndarray:
        """Calcule des features à partir de la CWT wavelet."""

        expected_bands = len(self._band_items)
        if expected_bands == 0:  # pragma: no cover - defensive
            raise ValueError("Wavelet features require at least one configured band.")
        config = dict(self._effective_strategy_config)
        _normalize_wavelet_name(config.get("wavelet", "morlet"))
        expected_ndim = None
        # Calcule les coefficients puis la puissance de bande via la fonction dédiée
        stacked = _compute_wavelet_band_powers(
            X,
            self.sfreq,
            self.band_ranges,
            config,
        )
        if stacked.ndim != expected_ndim:
            raise ValueError(
                "Wavelet band powers must return a 3D array "
                "(epochs, channels, bands) to preserve feature naming."
            )
        if stacked.shape[2] != expected_bands:
            raise ValueError(
                "Wavelet band powers shape mismatch: "
                f"expected {expected_bands} bands but received {stacked.shape[2]}. "
                "Check the number of central frequencies and band definitions."
            )
        if stacked.shape[0] != X.shape[0] or stacked.shape[1] != X.shape[1]:
            raise ValueError(
                "Wavelet band powers must preserve epoch and channel dimensions."
            )

        # Retourne la matrice tabulaire prête pour un classifieur scikit-learn
        return stacked.reshape(stacked.shape[0], -1)

    def xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_16(self, X: np.ndarray) -> np.ndarray:
        """Calcule des features à partir de la CWT wavelet."""

        expected_bands = len(self._band_items)
        if expected_bands == 0:  # pragma: no cover - defensive
            raise ValueError("Wavelet features require at least one configured band.")
        config = dict(self._effective_strategy_config)
        _normalize_wavelet_name(config.get("wavelet", "morlet"))
        expected_ndim = 4
        # Calcule les coefficients puis la puissance de bande via la fonction dédiée
        stacked = _compute_wavelet_band_powers(
            X,
            self.sfreq,
            self.band_ranges,
            config,
        )
        if stacked.ndim != expected_ndim:
            raise ValueError(
                "Wavelet band powers must return a 3D array "
                "(epochs, channels, bands) to preserve feature naming."
            )
        if stacked.shape[2] != expected_bands:
            raise ValueError(
                "Wavelet band powers shape mismatch: "
                f"expected {expected_bands} bands but received {stacked.shape[2]}. "
                "Check the number of central frequencies and band definitions."
            )
        if stacked.shape[0] != X.shape[0] or stacked.shape[1] != X.shape[1]:
            raise ValueError(
                "Wavelet band powers must preserve epoch and channel dimensions."
            )

        # Retourne la matrice tabulaire prête pour un classifieur scikit-learn
        return stacked.reshape(stacked.shape[0], -1)

    def xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_17(self, X: np.ndarray) -> np.ndarray:
        """Calcule des features à partir de la CWT wavelet."""

        expected_bands = len(self._band_items)
        if expected_bands == 0:  # pragma: no cover - defensive
            raise ValueError("Wavelet features require at least one configured band.")
        config = dict(self._effective_strategy_config)
        _normalize_wavelet_name(config.get("wavelet", "morlet"))
        expected_ndim = 3
        # Calcule les coefficients puis la puissance de bande via la fonction dédiée
        stacked = None
        if stacked.ndim != expected_ndim:
            raise ValueError(
                "Wavelet band powers must return a 3D array "
                "(epochs, channels, bands) to preserve feature naming."
            )
        if stacked.shape[2] != expected_bands:
            raise ValueError(
                "Wavelet band powers shape mismatch: "
                f"expected {expected_bands} bands but received {stacked.shape[2]}. "
                "Check the number of central frequencies and band definitions."
            )
        if stacked.shape[0] != X.shape[0] or stacked.shape[1] != X.shape[1]:
            raise ValueError(
                "Wavelet band powers must preserve epoch and channel dimensions."
            )

        # Retourne la matrice tabulaire prête pour un classifieur scikit-learn
        return stacked.reshape(stacked.shape[0], -1)

    def xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_18(self, X: np.ndarray) -> np.ndarray:
        """Calcule des features à partir de la CWT wavelet."""

        expected_bands = len(self._band_items)
        if expected_bands == 0:  # pragma: no cover - defensive
            raise ValueError("Wavelet features require at least one configured band.")
        config = dict(self._effective_strategy_config)
        _normalize_wavelet_name(config.get("wavelet", "morlet"))
        expected_ndim = 3
        # Calcule les coefficients puis la puissance de bande via la fonction dédiée
        stacked = _compute_wavelet_band_powers(
            None,
            self.sfreq,
            self.band_ranges,
            config,
        )
        if stacked.ndim != expected_ndim:
            raise ValueError(
                "Wavelet band powers must return a 3D array "
                "(epochs, channels, bands) to preserve feature naming."
            )
        if stacked.shape[2] != expected_bands:
            raise ValueError(
                "Wavelet band powers shape mismatch: "
                f"expected {expected_bands} bands but received {stacked.shape[2]}. "
                "Check the number of central frequencies and band definitions."
            )
        if stacked.shape[0] != X.shape[0] or stacked.shape[1] != X.shape[1]:
            raise ValueError(
                "Wavelet band powers must preserve epoch and channel dimensions."
            )

        # Retourne la matrice tabulaire prête pour un classifieur scikit-learn
        return stacked.reshape(stacked.shape[0], -1)

    def xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_19(self, X: np.ndarray) -> np.ndarray:
        """Calcule des features à partir de la CWT wavelet."""

        expected_bands = len(self._band_items)
        if expected_bands == 0:  # pragma: no cover - defensive
            raise ValueError("Wavelet features require at least one configured band.")
        config = dict(self._effective_strategy_config)
        _normalize_wavelet_name(config.get("wavelet", "morlet"))
        expected_ndim = 3
        # Calcule les coefficients puis la puissance de bande via la fonction dédiée
        stacked = _compute_wavelet_band_powers(
            X,
            None,
            self.band_ranges,
            config,
        )
        if stacked.ndim != expected_ndim:
            raise ValueError(
                "Wavelet band powers must return a 3D array "
                "(epochs, channels, bands) to preserve feature naming."
            )
        if stacked.shape[2] != expected_bands:
            raise ValueError(
                "Wavelet band powers shape mismatch: "
                f"expected {expected_bands} bands but received {stacked.shape[2]}. "
                "Check the number of central frequencies and band definitions."
            )
        if stacked.shape[0] != X.shape[0] or stacked.shape[1] != X.shape[1]:
            raise ValueError(
                "Wavelet band powers must preserve epoch and channel dimensions."
            )

        # Retourne la matrice tabulaire prête pour un classifieur scikit-learn
        return stacked.reshape(stacked.shape[0], -1)

    def xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_20(self, X: np.ndarray) -> np.ndarray:
        """Calcule des features à partir de la CWT wavelet."""

        expected_bands = len(self._band_items)
        if expected_bands == 0:  # pragma: no cover - defensive
            raise ValueError("Wavelet features require at least one configured band.")
        config = dict(self._effective_strategy_config)
        _normalize_wavelet_name(config.get("wavelet", "morlet"))
        expected_ndim = 3
        # Calcule les coefficients puis la puissance de bande via la fonction dédiée
        stacked = _compute_wavelet_band_powers(
            X,
            self.sfreq,
            None,
            config,
        )
        if stacked.ndim != expected_ndim:
            raise ValueError(
                "Wavelet band powers must return a 3D array "
                "(epochs, channels, bands) to preserve feature naming."
            )
        if stacked.shape[2] != expected_bands:
            raise ValueError(
                "Wavelet band powers shape mismatch: "
                f"expected {expected_bands} bands but received {stacked.shape[2]}. "
                "Check the number of central frequencies and band definitions."
            )
        if stacked.shape[0] != X.shape[0] or stacked.shape[1] != X.shape[1]:
            raise ValueError(
                "Wavelet band powers must preserve epoch and channel dimensions."
            )

        # Retourne la matrice tabulaire prête pour un classifieur scikit-learn
        return stacked.reshape(stacked.shape[0], -1)

    def xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_21(self, X: np.ndarray) -> np.ndarray:
        """Calcule des features à partir de la CWT wavelet."""

        expected_bands = len(self._band_items)
        if expected_bands == 0:  # pragma: no cover - defensive
            raise ValueError("Wavelet features require at least one configured band.")
        config = dict(self._effective_strategy_config)
        _normalize_wavelet_name(config.get("wavelet", "morlet"))
        expected_ndim = 3
        # Calcule les coefficients puis la puissance de bande via la fonction dédiée
        stacked = _compute_wavelet_band_powers(
            X,
            self.sfreq,
            self.band_ranges,
            None,
        )
        if stacked.ndim != expected_ndim:
            raise ValueError(
                "Wavelet band powers must return a 3D array "
                "(epochs, channels, bands) to preserve feature naming."
            )
        if stacked.shape[2] != expected_bands:
            raise ValueError(
                "Wavelet band powers shape mismatch: "
                f"expected {expected_bands} bands but received {stacked.shape[2]}. "
                "Check the number of central frequencies and band definitions."
            )
        if stacked.shape[0] != X.shape[0] or stacked.shape[1] != X.shape[1]:
            raise ValueError(
                "Wavelet band powers must preserve epoch and channel dimensions."
            )

        # Retourne la matrice tabulaire prête pour un classifieur scikit-learn
        return stacked.reshape(stacked.shape[0], -1)

    def xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_22(self, X: np.ndarray) -> np.ndarray:
        """Calcule des features à partir de la CWT wavelet."""

        expected_bands = len(self._band_items)
        if expected_bands == 0:  # pragma: no cover - defensive
            raise ValueError("Wavelet features require at least one configured band.")
        config = dict(self._effective_strategy_config)
        _normalize_wavelet_name(config.get("wavelet", "morlet"))
        expected_ndim = 3
        # Calcule les coefficients puis la puissance de bande via la fonction dédiée
        stacked = _compute_wavelet_band_powers(
            self.sfreq,
            self.band_ranges,
            config,
        )
        if stacked.ndim != expected_ndim:
            raise ValueError(
                "Wavelet band powers must return a 3D array "
                "(epochs, channels, bands) to preserve feature naming."
            )
        if stacked.shape[2] != expected_bands:
            raise ValueError(
                "Wavelet band powers shape mismatch: "
                f"expected {expected_bands} bands but received {stacked.shape[2]}. "
                "Check the number of central frequencies and band definitions."
            )
        if stacked.shape[0] != X.shape[0] or stacked.shape[1] != X.shape[1]:
            raise ValueError(
                "Wavelet band powers must preserve epoch and channel dimensions."
            )

        # Retourne la matrice tabulaire prête pour un classifieur scikit-learn
        return stacked.reshape(stacked.shape[0], -1)

    def xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_23(self, X: np.ndarray) -> np.ndarray:
        """Calcule des features à partir de la CWT wavelet."""

        expected_bands = len(self._band_items)
        if expected_bands == 0:  # pragma: no cover - defensive
            raise ValueError("Wavelet features require at least one configured band.")
        config = dict(self._effective_strategy_config)
        _normalize_wavelet_name(config.get("wavelet", "morlet"))
        expected_ndim = 3
        # Calcule les coefficients puis la puissance de bande via la fonction dédiée
        stacked = _compute_wavelet_band_powers(
            X,
            self.band_ranges,
            config,
        )
        if stacked.ndim != expected_ndim:
            raise ValueError(
                "Wavelet band powers must return a 3D array "
                "(epochs, channels, bands) to preserve feature naming."
            )
        if stacked.shape[2] != expected_bands:
            raise ValueError(
                "Wavelet band powers shape mismatch: "
                f"expected {expected_bands} bands but received {stacked.shape[2]}. "
                "Check the number of central frequencies and band definitions."
            )
        if stacked.shape[0] != X.shape[0] or stacked.shape[1] != X.shape[1]:
            raise ValueError(
                "Wavelet band powers must preserve epoch and channel dimensions."
            )

        # Retourne la matrice tabulaire prête pour un classifieur scikit-learn
        return stacked.reshape(stacked.shape[0], -1)

    def xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_24(self, X: np.ndarray) -> np.ndarray:
        """Calcule des features à partir de la CWT wavelet."""

        expected_bands = len(self._band_items)
        if expected_bands == 0:  # pragma: no cover - defensive
            raise ValueError("Wavelet features require at least one configured band.")
        config = dict(self._effective_strategy_config)
        _normalize_wavelet_name(config.get("wavelet", "morlet"))
        expected_ndim = 3
        # Calcule les coefficients puis la puissance de bande via la fonction dédiée
        stacked = _compute_wavelet_band_powers(
            X,
            self.sfreq,
            config,
        )
        if stacked.ndim != expected_ndim:
            raise ValueError(
                "Wavelet band powers must return a 3D array "
                "(epochs, channels, bands) to preserve feature naming."
            )
        if stacked.shape[2] != expected_bands:
            raise ValueError(
                "Wavelet band powers shape mismatch: "
                f"expected {expected_bands} bands but received {stacked.shape[2]}. "
                "Check the number of central frequencies and band definitions."
            )
        if stacked.shape[0] != X.shape[0] or stacked.shape[1] != X.shape[1]:
            raise ValueError(
                "Wavelet band powers must preserve epoch and channel dimensions."
            )

        # Retourne la matrice tabulaire prête pour un classifieur scikit-learn
        return stacked.reshape(stacked.shape[0], -1)

    def xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_25(self, X: np.ndarray) -> np.ndarray:
        """Calcule des features à partir de la CWT wavelet."""

        expected_bands = len(self._band_items)
        if expected_bands == 0:  # pragma: no cover - defensive
            raise ValueError("Wavelet features require at least one configured band.")
        config = dict(self._effective_strategy_config)
        _normalize_wavelet_name(config.get("wavelet", "morlet"))
        expected_ndim = 3
        # Calcule les coefficients puis la puissance de bande via la fonction dédiée
        stacked = _compute_wavelet_band_powers(
            X,
            self.sfreq,
            self.band_ranges,
            )
        if stacked.ndim != expected_ndim:
            raise ValueError(
                "Wavelet band powers must return a 3D array "
                "(epochs, channels, bands) to preserve feature naming."
            )
        if stacked.shape[2] != expected_bands:
            raise ValueError(
                "Wavelet band powers shape mismatch: "
                f"expected {expected_bands} bands but received {stacked.shape[2]}. "
                "Check the number of central frequencies and band definitions."
            )
        if stacked.shape[0] != X.shape[0] or stacked.shape[1] != X.shape[1]:
            raise ValueError(
                "Wavelet band powers must preserve epoch and channel dimensions."
            )

        # Retourne la matrice tabulaire prête pour un classifieur scikit-learn
        return stacked.reshape(stacked.shape[0], -1)

    def xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_26(self, X: np.ndarray) -> np.ndarray:
        """Calcule des features à partir de la CWT wavelet."""

        expected_bands = len(self._band_items)
        if expected_bands == 0:  # pragma: no cover - defensive
            raise ValueError("Wavelet features require at least one configured band.")
        config = dict(self._effective_strategy_config)
        _normalize_wavelet_name(config.get("wavelet", "morlet"))
        expected_ndim = 3
        # Calcule les coefficients puis la puissance de bande via la fonction dédiée
        stacked = _compute_wavelet_band_powers(
            X,
            self.sfreq,
            self.band_ranges,
            config,
        )
        if stacked.ndim == expected_ndim:
            raise ValueError(
                "Wavelet band powers must return a 3D array "
                "(epochs, channels, bands) to preserve feature naming."
            )
        if stacked.shape[2] != expected_bands:
            raise ValueError(
                "Wavelet band powers shape mismatch: "
                f"expected {expected_bands} bands but received {stacked.shape[2]}. "
                "Check the number of central frequencies and band definitions."
            )
        if stacked.shape[0] != X.shape[0] or stacked.shape[1] != X.shape[1]:
            raise ValueError(
                "Wavelet band powers must preserve epoch and channel dimensions."
            )

        # Retourne la matrice tabulaire prête pour un classifieur scikit-learn
        return stacked.reshape(stacked.shape[0], -1)

    def xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_27(self, X: np.ndarray) -> np.ndarray:
        """Calcule des features à partir de la CWT wavelet."""

        expected_bands = len(self._band_items)
        if expected_bands == 0:  # pragma: no cover - defensive
            raise ValueError("Wavelet features require at least one configured band.")
        config = dict(self._effective_strategy_config)
        _normalize_wavelet_name(config.get("wavelet", "morlet"))
        expected_ndim = 3
        # Calcule les coefficients puis la puissance de bande via la fonction dédiée
        stacked = _compute_wavelet_band_powers(
            X,
            self.sfreq,
            self.band_ranges,
            config,
        )
        if stacked.ndim != expected_ndim:
            raise ValueError(
                None
            )
        if stacked.shape[2] != expected_bands:
            raise ValueError(
                "Wavelet band powers shape mismatch: "
                f"expected {expected_bands} bands but received {stacked.shape[2]}. "
                "Check the number of central frequencies and band definitions."
            )
        if stacked.shape[0] != X.shape[0] or stacked.shape[1] != X.shape[1]:
            raise ValueError(
                "Wavelet band powers must preserve epoch and channel dimensions."
            )

        # Retourne la matrice tabulaire prête pour un classifieur scikit-learn
        return stacked.reshape(stacked.shape[0], -1)

    def xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_28(self, X: np.ndarray) -> np.ndarray:
        """Calcule des features à partir de la CWT wavelet."""

        expected_bands = len(self._band_items)
        if expected_bands == 0:  # pragma: no cover - defensive
            raise ValueError("Wavelet features require at least one configured band.")
        config = dict(self._effective_strategy_config)
        _normalize_wavelet_name(config.get("wavelet", "morlet"))
        expected_ndim = 3
        # Calcule les coefficients puis la puissance de bande via la fonction dédiée
        stacked = _compute_wavelet_band_powers(
            X,
            self.sfreq,
            self.band_ranges,
            config,
        )
        if stacked.ndim != expected_ndim:
            raise ValueError(
                "XXWavelet band powers must return a 3D array XX"
                "(epochs, channels, bands) to preserve feature naming."
            )
        if stacked.shape[2] != expected_bands:
            raise ValueError(
                "Wavelet band powers shape mismatch: "
                f"expected {expected_bands} bands but received {stacked.shape[2]}. "
                "Check the number of central frequencies and band definitions."
            )
        if stacked.shape[0] != X.shape[0] or stacked.shape[1] != X.shape[1]:
            raise ValueError(
                "Wavelet band powers must preserve epoch and channel dimensions."
            )

        # Retourne la matrice tabulaire prête pour un classifieur scikit-learn
        return stacked.reshape(stacked.shape[0], -1)

    def xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_29(self, X: np.ndarray) -> np.ndarray:
        """Calcule des features à partir de la CWT wavelet."""

        expected_bands = len(self._band_items)
        if expected_bands == 0:  # pragma: no cover - defensive
            raise ValueError("Wavelet features require at least one configured band.")
        config = dict(self._effective_strategy_config)
        _normalize_wavelet_name(config.get("wavelet", "morlet"))
        expected_ndim = 3
        # Calcule les coefficients puis la puissance de bande via la fonction dédiée
        stacked = _compute_wavelet_band_powers(
            X,
            self.sfreq,
            self.band_ranges,
            config,
        )
        if stacked.ndim != expected_ndim:
            raise ValueError(
                "wavelet band powers must return a 3d array "
                "(epochs, channels, bands) to preserve feature naming."
            )
        if stacked.shape[2] != expected_bands:
            raise ValueError(
                "Wavelet band powers shape mismatch: "
                f"expected {expected_bands} bands but received {stacked.shape[2]}. "
                "Check the number of central frequencies and band definitions."
            )
        if stacked.shape[0] != X.shape[0] or stacked.shape[1] != X.shape[1]:
            raise ValueError(
                "Wavelet band powers must preserve epoch and channel dimensions."
            )

        # Retourne la matrice tabulaire prête pour un classifieur scikit-learn
        return stacked.reshape(stacked.shape[0], -1)

    def xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_30(self, X: np.ndarray) -> np.ndarray:
        """Calcule des features à partir de la CWT wavelet."""

        expected_bands = len(self._band_items)
        if expected_bands == 0:  # pragma: no cover - defensive
            raise ValueError("Wavelet features require at least one configured band.")
        config = dict(self._effective_strategy_config)
        _normalize_wavelet_name(config.get("wavelet", "morlet"))
        expected_ndim = 3
        # Calcule les coefficients puis la puissance de bande via la fonction dédiée
        stacked = _compute_wavelet_band_powers(
            X,
            self.sfreq,
            self.band_ranges,
            config,
        )
        if stacked.ndim != expected_ndim:
            raise ValueError(
                "WAVELET BAND POWERS MUST RETURN A 3D ARRAY "
                "(epochs, channels, bands) to preserve feature naming."
            )
        if stacked.shape[2] != expected_bands:
            raise ValueError(
                "Wavelet band powers shape mismatch: "
                f"expected {expected_bands} bands but received {stacked.shape[2]}. "
                "Check the number of central frequencies and band definitions."
            )
        if stacked.shape[0] != X.shape[0] or stacked.shape[1] != X.shape[1]:
            raise ValueError(
                "Wavelet band powers must preserve epoch and channel dimensions."
            )

        # Retourne la matrice tabulaire prête pour un classifieur scikit-learn
        return stacked.reshape(stacked.shape[0], -1)

    def xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_31(self, X: np.ndarray) -> np.ndarray:
        """Calcule des features à partir de la CWT wavelet."""

        expected_bands = len(self._band_items)
        if expected_bands == 0:  # pragma: no cover - defensive
            raise ValueError("Wavelet features require at least one configured band.")
        config = dict(self._effective_strategy_config)
        _normalize_wavelet_name(config.get("wavelet", "morlet"))
        expected_ndim = 3
        # Calcule les coefficients puis la puissance de bande via la fonction dédiée
        stacked = _compute_wavelet_band_powers(
            X,
            self.sfreq,
            self.band_ranges,
            config,
        )
        if stacked.ndim != expected_ndim:
            raise ValueError(
                "Wavelet band powers must return a 3D array "
                "(epochs, channels, bands) to preserve feature naming."
            )
        if stacked.shape[3] != expected_bands:
            raise ValueError(
                "Wavelet band powers shape mismatch: "
                f"expected {expected_bands} bands but received {stacked.shape[2]}. "
                "Check the number of central frequencies and band definitions."
            )
        if stacked.shape[0] != X.shape[0] or stacked.shape[1] != X.shape[1]:
            raise ValueError(
                "Wavelet band powers must preserve epoch and channel dimensions."
            )

        # Retourne la matrice tabulaire prête pour un classifieur scikit-learn
        return stacked.reshape(stacked.shape[0], -1)

    def xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_32(self, X: np.ndarray) -> np.ndarray:
        """Calcule des features à partir de la CWT wavelet."""

        expected_bands = len(self._band_items)
        if expected_bands == 0:  # pragma: no cover - defensive
            raise ValueError("Wavelet features require at least one configured band.")
        config = dict(self._effective_strategy_config)
        _normalize_wavelet_name(config.get("wavelet", "morlet"))
        expected_ndim = 3
        # Calcule les coefficients puis la puissance de bande via la fonction dédiée
        stacked = _compute_wavelet_band_powers(
            X,
            self.sfreq,
            self.band_ranges,
            config,
        )
        if stacked.ndim != expected_ndim:
            raise ValueError(
                "Wavelet band powers must return a 3D array "
                "(epochs, channels, bands) to preserve feature naming."
            )
        if stacked.shape[2] == expected_bands:
            raise ValueError(
                "Wavelet band powers shape mismatch: "
                f"expected {expected_bands} bands but received {stacked.shape[2]}. "
                "Check the number of central frequencies and band definitions."
            )
        if stacked.shape[0] != X.shape[0] or stacked.shape[1] != X.shape[1]:
            raise ValueError(
                "Wavelet band powers must preserve epoch and channel dimensions."
            )

        # Retourne la matrice tabulaire prête pour un classifieur scikit-learn
        return stacked.reshape(stacked.shape[0], -1)

    def xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_33(self, X: np.ndarray) -> np.ndarray:
        """Calcule des features à partir de la CWT wavelet."""

        expected_bands = len(self._band_items)
        if expected_bands == 0:  # pragma: no cover - defensive
            raise ValueError("Wavelet features require at least one configured band.")
        config = dict(self._effective_strategy_config)
        _normalize_wavelet_name(config.get("wavelet", "morlet"))
        expected_ndim = 3
        # Calcule les coefficients puis la puissance de bande via la fonction dédiée
        stacked = _compute_wavelet_band_powers(
            X,
            self.sfreq,
            self.band_ranges,
            config,
        )
        if stacked.ndim != expected_ndim:
            raise ValueError(
                "Wavelet band powers must return a 3D array "
                "(epochs, channels, bands) to preserve feature naming."
            )
        if stacked.shape[2] != expected_bands:
            raise ValueError(
                None
            )
        if stacked.shape[0] != X.shape[0] or stacked.shape[1] != X.shape[1]:
            raise ValueError(
                "Wavelet band powers must preserve epoch and channel dimensions."
            )

        # Retourne la matrice tabulaire prête pour un classifieur scikit-learn
        return stacked.reshape(stacked.shape[0], -1)

    def xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_34(self, X: np.ndarray) -> np.ndarray:
        """Calcule des features à partir de la CWT wavelet."""

        expected_bands = len(self._band_items)
        if expected_bands == 0:  # pragma: no cover - defensive
            raise ValueError("Wavelet features require at least one configured band.")
        config = dict(self._effective_strategy_config)
        _normalize_wavelet_name(config.get("wavelet", "morlet"))
        expected_ndim = 3
        # Calcule les coefficients puis la puissance de bande via la fonction dédiée
        stacked = _compute_wavelet_band_powers(
            X,
            self.sfreq,
            self.band_ranges,
            config,
        )
        if stacked.ndim != expected_ndim:
            raise ValueError(
                "Wavelet band powers must return a 3D array "
                "(epochs, channels, bands) to preserve feature naming."
            )
        if stacked.shape[2] != expected_bands:
            raise ValueError(
                "XXWavelet band powers shape mismatch: XX"
                f"expected {expected_bands} bands but received {stacked.shape[2]}. "
                "Check the number of central frequencies and band definitions."
            )
        if stacked.shape[0] != X.shape[0] or stacked.shape[1] != X.shape[1]:
            raise ValueError(
                "Wavelet band powers must preserve epoch and channel dimensions."
            )

        # Retourne la matrice tabulaire prête pour un classifieur scikit-learn
        return stacked.reshape(stacked.shape[0], -1)

    def xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_35(self, X: np.ndarray) -> np.ndarray:
        """Calcule des features à partir de la CWT wavelet."""

        expected_bands = len(self._band_items)
        if expected_bands == 0:  # pragma: no cover - defensive
            raise ValueError("Wavelet features require at least one configured band.")
        config = dict(self._effective_strategy_config)
        _normalize_wavelet_name(config.get("wavelet", "morlet"))
        expected_ndim = 3
        # Calcule les coefficients puis la puissance de bande via la fonction dédiée
        stacked = _compute_wavelet_band_powers(
            X,
            self.sfreq,
            self.band_ranges,
            config,
        )
        if stacked.ndim != expected_ndim:
            raise ValueError(
                "Wavelet band powers must return a 3D array "
                "(epochs, channels, bands) to preserve feature naming."
            )
        if stacked.shape[2] != expected_bands:
            raise ValueError(
                "wavelet band powers shape mismatch: "
                f"expected {expected_bands} bands but received {stacked.shape[2]}. "
                "Check the number of central frequencies and band definitions."
            )
        if stacked.shape[0] != X.shape[0] or stacked.shape[1] != X.shape[1]:
            raise ValueError(
                "Wavelet band powers must preserve epoch and channel dimensions."
            )

        # Retourne la matrice tabulaire prête pour un classifieur scikit-learn
        return stacked.reshape(stacked.shape[0], -1)

    def xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_36(self, X: np.ndarray) -> np.ndarray:
        """Calcule des features à partir de la CWT wavelet."""

        expected_bands = len(self._band_items)
        if expected_bands == 0:  # pragma: no cover - defensive
            raise ValueError("Wavelet features require at least one configured band.")
        config = dict(self._effective_strategy_config)
        _normalize_wavelet_name(config.get("wavelet", "morlet"))
        expected_ndim = 3
        # Calcule les coefficients puis la puissance de bande via la fonction dédiée
        stacked = _compute_wavelet_band_powers(
            X,
            self.sfreq,
            self.band_ranges,
            config,
        )
        if stacked.ndim != expected_ndim:
            raise ValueError(
                "Wavelet band powers must return a 3D array "
                "(epochs, channels, bands) to preserve feature naming."
            )
        if stacked.shape[2] != expected_bands:
            raise ValueError(
                "WAVELET BAND POWERS SHAPE MISMATCH: "
                f"expected {expected_bands} bands but received {stacked.shape[2]}. "
                "Check the number of central frequencies and band definitions."
            )
        if stacked.shape[0] != X.shape[0] or stacked.shape[1] != X.shape[1]:
            raise ValueError(
                "Wavelet band powers must preserve epoch and channel dimensions."
            )

        # Retourne la matrice tabulaire prête pour un classifieur scikit-learn
        return stacked.reshape(stacked.shape[0], -1)

    def xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_37(self, X: np.ndarray) -> np.ndarray:
        """Calcule des features à partir de la CWT wavelet."""

        expected_bands = len(self._band_items)
        if expected_bands == 0:  # pragma: no cover - defensive
            raise ValueError("Wavelet features require at least one configured band.")
        config = dict(self._effective_strategy_config)
        _normalize_wavelet_name(config.get("wavelet", "morlet"))
        expected_ndim = 3
        # Calcule les coefficients puis la puissance de bande via la fonction dédiée
        stacked = _compute_wavelet_band_powers(
            X,
            self.sfreq,
            self.band_ranges,
            config,
        )
        if stacked.ndim != expected_ndim:
            raise ValueError(
                "Wavelet band powers must return a 3D array "
                "(epochs, channels, bands) to preserve feature naming."
            )
        if stacked.shape[2] != expected_bands:
            raise ValueError(
                "Wavelet band powers shape mismatch: "
                f"expected {expected_bands} bands but received {stacked.shape[3]}. "
                "Check the number of central frequencies and band definitions."
            )
        if stacked.shape[0] != X.shape[0] or stacked.shape[1] != X.shape[1]:
            raise ValueError(
                "Wavelet band powers must preserve epoch and channel dimensions."
            )

        # Retourne la matrice tabulaire prête pour un classifieur scikit-learn
        return stacked.reshape(stacked.shape[0], -1)

    def xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_38(self, X: np.ndarray) -> np.ndarray:
        """Calcule des features à partir de la CWT wavelet."""

        expected_bands = len(self._band_items)
        if expected_bands == 0:  # pragma: no cover - defensive
            raise ValueError("Wavelet features require at least one configured band.")
        config = dict(self._effective_strategy_config)
        _normalize_wavelet_name(config.get("wavelet", "morlet"))
        expected_ndim = 3
        # Calcule les coefficients puis la puissance de bande via la fonction dédiée
        stacked = _compute_wavelet_band_powers(
            X,
            self.sfreq,
            self.band_ranges,
            config,
        )
        if stacked.ndim != expected_ndim:
            raise ValueError(
                "Wavelet band powers must return a 3D array "
                "(epochs, channels, bands) to preserve feature naming."
            )
        if stacked.shape[2] != expected_bands:
            raise ValueError(
                "Wavelet band powers shape mismatch: "
                f"expected {expected_bands} bands but received {stacked.shape[2]}. "
                "Check the number of central frequencies and band definitions."
            )
        if stacked.shape[0] != X.shape[0] and stacked.shape[1] != X.shape[1]:
            raise ValueError(
                "Wavelet band powers must preserve epoch and channel dimensions."
            )

        # Retourne la matrice tabulaire prête pour un classifieur scikit-learn
        return stacked.reshape(stacked.shape[0], -1)

    def xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_39(self, X: np.ndarray) -> np.ndarray:
        """Calcule des features à partir de la CWT wavelet."""

        expected_bands = len(self._band_items)
        if expected_bands == 0:  # pragma: no cover - defensive
            raise ValueError("Wavelet features require at least one configured band.")
        config = dict(self._effective_strategy_config)
        _normalize_wavelet_name(config.get("wavelet", "morlet"))
        expected_ndim = 3
        # Calcule les coefficients puis la puissance de bande via la fonction dédiée
        stacked = _compute_wavelet_band_powers(
            X,
            self.sfreq,
            self.band_ranges,
            config,
        )
        if stacked.ndim != expected_ndim:
            raise ValueError(
                "Wavelet band powers must return a 3D array "
                "(epochs, channels, bands) to preserve feature naming."
            )
        if stacked.shape[2] != expected_bands:
            raise ValueError(
                "Wavelet band powers shape mismatch: "
                f"expected {expected_bands} bands but received {stacked.shape[2]}. "
                "Check the number of central frequencies and band definitions."
            )
        if stacked.shape[1] != X.shape[0] or stacked.shape[1] != X.shape[1]:
            raise ValueError(
                "Wavelet band powers must preserve epoch and channel dimensions."
            )

        # Retourne la matrice tabulaire prête pour un classifieur scikit-learn
        return stacked.reshape(stacked.shape[0], -1)

    def xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_40(self, X: np.ndarray) -> np.ndarray:
        """Calcule des features à partir de la CWT wavelet."""

        expected_bands = len(self._band_items)
        if expected_bands == 0:  # pragma: no cover - defensive
            raise ValueError("Wavelet features require at least one configured band.")
        config = dict(self._effective_strategy_config)
        _normalize_wavelet_name(config.get("wavelet", "morlet"))
        expected_ndim = 3
        # Calcule les coefficients puis la puissance de bande via la fonction dédiée
        stacked = _compute_wavelet_band_powers(
            X,
            self.sfreq,
            self.band_ranges,
            config,
        )
        if stacked.ndim != expected_ndim:
            raise ValueError(
                "Wavelet band powers must return a 3D array "
                "(epochs, channels, bands) to preserve feature naming."
            )
        if stacked.shape[2] != expected_bands:
            raise ValueError(
                "Wavelet band powers shape mismatch: "
                f"expected {expected_bands} bands but received {stacked.shape[2]}. "
                "Check the number of central frequencies and band definitions."
            )
        if stacked.shape[0] == X.shape[0] or stacked.shape[1] != X.shape[1]:
            raise ValueError(
                "Wavelet band powers must preserve epoch and channel dimensions."
            )

        # Retourne la matrice tabulaire prête pour un classifieur scikit-learn
        return stacked.reshape(stacked.shape[0], -1)

    def xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_41(self, X: np.ndarray) -> np.ndarray:
        """Calcule des features à partir de la CWT wavelet."""

        expected_bands = len(self._band_items)
        if expected_bands == 0:  # pragma: no cover - defensive
            raise ValueError("Wavelet features require at least one configured band.")
        config = dict(self._effective_strategy_config)
        _normalize_wavelet_name(config.get("wavelet", "morlet"))
        expected_ndim = 3
        # Calcule les coefficients puis la puissance de bande via la fonction dédiée
        stacked = _compute_wavelet_band_powers(
            X,
            self.sfreq,
            self.band_ranges,
            config,
        )
        if stacked.ndim != expected_ndim:
            raise ValueError(
                "Wavelet band powers must return a 3D array "
                "(epochs, channels, bands) to preserve feature naming."
            )
        if stacked.shape[2] != expected_bands:
            raise ValueError(
                "Wavelet band powers shape mismatch: "
                f"expected {expected_bands} bands but received {stacked.shape[2]}. "
                "Check the number of central frequencies and band definitions."
            )
        if stacked.shape[0] != X.shape[1] or stacked.shape[1] != X.shape[1]:
            raise ValueError(
                "Wavelet band powers must preserve epoch and channel dimensions."
            )

        # Retourne la matrice tabulaire prête pour un classifieur scikit-learn
        return stacked.reshape(stacked.shape[0], -1)

    def xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_42(self, X: np.ndarray) -> np.ndarray:
        """Calcule des features à partir de la CWT wavelet."""

        expected_bands = len(self._band_items)
        if expected_bands == 0:  # pragma: no cover - defensive
            raise ValueError("Wavelet features require at least one configured band.")
        config = dict(self._effective_strategy_config)
        _normalize_wavelet_name(config.get("wavelet", "morlet"))
        expected_ndim = 3
        # Calcule les coefficients puis la puissance de bande via la fonction dédiée
        stacked = _compute_wavelet_band_powers(
            X,
            self.sfreq,
            self.band_ranges,
            config,
        )
        if stacked.ndim != expected_ndim:
            raise ValueError(
                "Wavelet band powers must return a 3D array "
                "(epochs, channels, bands) to preserve feature naming."
            )
        if stacked.shape[2] != expected_bands:
            raise ValueError(
                "Wavelet band powers shape mismatch: "
                f"expected {expected_bands} bands but received {stacked.shape[2]}. "
                "Check the number of central frequencies and band definitions."
            )
        if stacked.shape[0] != X.shape[0] or stacked.shape[2] != X.shape[1]:
            raise ValueError(
                "Wavelet band powers must preserve epoch and channel dimensions."
            )

        # Retourne la matrice tabulaire prête pour un classifieur scikit-learn
        return stacked.reshape(stacked.shape[0], -1)

    def xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_43(self, X: np.ndarray) -> np.ndarray:
        """Calcule des features à partir de la CWT wavelet."""

        expected_bands = len(self._band_items)
        if expected_bands == 0:  # pragma: no cover - defensive
            raise ValueError("Wavelet features require at least one configured band.")
        config = dict(self._effective_strategy_config)
        _normalize_wavelet_name(config.get("wavelet", "morlet"))
        expected_ndim = 3
        # Calcule les coefficients puis la puissance de bande via la fonction dédiée
        stacked = _compute_wavelet_band_powers(
            X,
            self.sfreq,
            self.band_ranges,
            config,
        )
        if stacked.ndim != expected_ndim:
            raise ValueError(
                "Wavelet band powers must return a 3D array "
                "(epochs, channels, bands) to preserve feature naming."
            )
        if stacked.shape[2] != expected_bands:
            raise ValueError(
                "Wavelet band powers shape mismatch: "
                f"expected {expected_bands} bands but received {stacked.shape[2]}. "
                "Check the number of central frequencies and band definitions."
            )
        if stacked.shape[0] != X.shape[0] or stacked.shape[1] == X.shape[1]:
            raise ValueError(
                "Wavelet band powers must preserve epoch and channel dimensions."
            )

        # Retourne la matrice tabulaire prête pour un classifieur scikit-learn
        return stacked.reshape(stacked.shape[0], -1)

    def xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_44(self, X: np.ndarray) -> np.ndarray:
        """Calcule des features à partir de la CWT wavelet."""

        expected_bands = len(self._band_items)
        if expected_bands == 0:  # pragma: no cover - defensive
            raise ValueError("Wavelet features require at least one configured band.")
        config = dict(self._effective_strategy_config)
        _normalize_wavelet_name(config.get("wavelet", "morlet"))
        expected_ndim = 3
        # Calcule les coefficients puis la puissance de bande via la fonction dédiée
        stacked = _compute_wavelet_band_powers(
            X,
            self.sfreq,
            self.band_ranges,
            config,
        )
        if stacked.ndim != expected_ndim:
            raise ValueError(
                "Wavelet band powers must return a 3D array "
                "(epochs, channels, bands) to preserve feature naming."
            )
        if stacked.shape[2] != expected_bands:
            raise ValueError(
                "Wavelet band powers shape mismatch: "
                f"expected {expected_bands} bands but received {stacked.shape[2]}. "
                "Check the number of central frequencies and band definitions."
            )
        if stacked.shape[0] != X.shape[0] or stacked.shape[1] != X.shape[2]:
            raise ValueError(
                "Wavelet band powers must preserve epoch and channel dimensions."
            )

        # Retourne la matrice tabulaire prête pour un classifieur scikit-learn
        return stacked.reshape(stacked.shape[0], -1)

    def xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_45(self, X: np.ndarray) -> np.ndarray:
        """Calcule des features à partir de la CWT wavelet."""

        expected_bands = len(self._band_items)
        if expected_bands == 0:  # pragma: no cover - defensive
            raise ValueError("Wavelet features require at least one configured band.")
        config = dict(self._effective_strategy_config)
        _normalize_wavelet_name(config.get("wavelet", "morlet"))
        expected_ndim = 3
        # Calcule les coefficients puis la puissance de bande via la fonction dédiée
        stacked = _compute_wavelet_band_powers(
            X,
            self.sfreq,
            self.band_ranges,
            config,
        )
        if stacked.ndim != expected_ndim:
            raise ValueError(
                "Wavelet band powers must return a 3D array "
                "(epochs, channels, bands) to preserve feature naming."
            )
        if stacked.shape[2] != expected_bands:
            raise ValueError(
                "Wavelet band powers shape mismatch: "
                f"expected {expected_bands} bands but received {stacked.shape[2]}. "
                "Check the number of central frequencies and band definitions."
            )
        if stacked.shape[0] != X.shape[0] or stacked.shape[1] != X.shape[1]:
            raise ValueError(
                None
            )

        # Retourne la matrice tabulaire prête pour un classifieur scikit-learn
        return stacked.reshape(stacked.shape[0], -1)

    def xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_46(self, X: np.ndarray) -> np.ndarray:
        """Calcule des features à partir de la CWT wavelet."""

        expected_bands = len(self._band_items)
        if expected_bands == 0:  # pragma: no cover - defensive
            raise ValueError("Wavelet features require at least one configured band.")
        config = dict(self._effective_strategy_config)
        _normalize_wavelet_name(config.get("wavelet", "morlet"))
        expected_ndim = 3
        # Calcule les coefficients puis la puissance de bande via la fonction dédiée
        stacked = _compute_wavelet_band_powers(
            X,
            self.sfreq,
            self.band_ranges,
            config,
        )
        if stacked.ndim != expected_ndim:
            raise ValueError(
                "Wavelet band powers must return a 3D array "
                "(epochs, channels, bands) to preserve feature naming."
            )
        if stacked.shape[2] != expected_bands:
            raise ValueError(
                "Wavelet band powers shape mismatch: "
                f"expected {expected_bands} bands but received {stacked.shape[2]}. "
                "Check the number of central frequencies and band definitions."
            )
        if stacked.shape[0] != X.shape[0] or stacked.shape[1] != X.shape[1]:
            raise ValueError(
                "XXWavelet band powers must preserve epoch and channel dimensions.XX"
            )

        # Retourne la matrice tabulaire prête pour un classifieur scikit-learn
        return stacked.reshape(stacked.shape[0], -1)

    def xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_47(self, X: np.ndarray) -> np.ndarray:
        """Calcule des features à partir de la CWT wavelet."""

        expected_bands = len(self._band_items)
        if expected_bands == 0:  # pragma: no cover - defensive
            raise ValueError("Wavelet features require at least one configured band.")
        config = dict(self._effective_strategy_config)
        _normalize_wavelet_name(config.get("wavelet", "morlet"))
        expected_ndim = 3
        # Calcule les coefficients puis la puissance de bande via la fonction dédiée
        stacked = _compute_wavelet_band_powers(
            X,
            self.sfreq,
            self.band_ranges,
            config,
        )
        if stacked.ndim != expected_ndim:
            raise ValueError(
                "Wavelet band powers must return a 3D array "
                "(epochs, channels, bands) to preserve feature naming."
            )
        if stacked.shape[2] != expected_bands:
            raise ValueError(
                "Wavelet band powers shape mismatch: "
                f"expected {expected_bands} bands but received {stacked.shape[2]}. "
                "Check the number of central frequencies and band definitions."
            )
        if stacked.shape[0] != X.shape[0] or stacked.shape[1] != X.shape[1]:
            raise ValueError(
                "wavelet band powers must preserve epoch and channel dimensions."
            )

        # Retourne la matrice tabulaire prête pour un classifieur scikit-learn
        return stacked.reshape(stacked.shape[0], -1)

    def xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_48(self, X: np.ndarray) -> np.ndarray:
        """Calcule des features à partir de la CWT wavelet."""

        expected_bands = len(self._band_items)
        if expected_bands == 0:  # pragma: no cover - defensive
            raise ValueError("Wavelet features require at least one configured band.")
        config = dict(self._effective_strategy_config)
        _normalize_wavelet_name(config.get("wavelet", "morlet"))
        expected_ndim = 3
        # Calcule les coefficients puis la puissance de bande via la fonction dédiée
        stacked = _compute_wavelet_band_powers(
            X,
            self.sfreq,
            self.band_ranges,
            config,
        )
        if stacked.ndim != expected_ndim:
            raise ValueError(
                "Wavelet band powers must return a 3D array "
                "(epochs, channels, bands) to preserve feature naming."
            )
        if stacked.shape[2] != expected_bands:
            raise ValueError(
                "Wavelet band powers shape mismatch: "
                f"expected {expected_bands} bands but received {stacked.shape[2]}. "
                "Check the number of central frequencies and band definitions."
            )
        if stacked.shape[0] != X.shape[0] or stacked.shape[1] != X.shape[1]:
            raise ValueError(
                "WAVELET BAND POWERS MUST PRESERVE EPOCH AND CHANNEL DIMENSIONS."
            )

        # Retourne la matrice tabulaire prête pour un classifieur scikit-learn
        return stacked.reshape(stacked.shape[0], -1)

    def xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_49(self, X: np.ndarray) -> np.ndarray:
        """Calcule des features à partir de la CWT wavelet."""

        expected_bands = len(self._band_items)
        if expected_bands == 0:  # pragma: no cover - defensive
            raise ValueError("Wavelet features require at least one configured band.")
        config = dict(self._effective_strategy_config)
        _normalize_wavelet_name(config.get("wavelet", "morlet"))
        expected_ndim = 3
        # Calcule les coefficients puis la puissance de bande via la fonction dédiée
        stacked = _compute_wavelet_band_powers(
            X,
            self.sfreq,
            self.band_ranges,
            config,
        )
        if stacked.ndim != expected_ndim:
            raise ValueError(
                "Wavelet band powers must return a 3D array "
                "(epochs, channels, bands) to preserve feature naming."
            )
        if stacked.shape[2] != expected_bands:
            raise ValueError(
                "Wavelet band powers shape mismatch: "
                f"expected {expected_bands} bands but received {stacked.shape[2]}. "
                "Check the number of central frequencies and band definitions."
            )
        if stacked.shape[0] != X.shape[0] or stacked.shape[1] != X.shape[1]:
            raise ValueError(
                "Wavelet band powers must preserve epoch and channel dimensions."
            )

        # Retourne la matrice tabulaire prête pour un classifieur scikit-learn
        return stacked.reshape(None, -1)

    def xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_50(self, X: np.ndarray) -> np.ndarray:
        """Calcule des features à partir de la CWT wavelet."""

        expected_bands = len(self._band_items)
        if expected_bands == 0:  # pragma: no cover - defensive
            raise ValueError("Wavelet features require at least one configured band.")
        config = dict(self._effective_strategy_config)
        _normalize_wavelet_name(config.get("wavelet", "morlet"))
        expected_ndim = 3
        # Calcule les coefficients puis la puissance de bande via la fonction dédiée
        stacked = _compute_wavelet_band_powers(
            X,
            self.sfreq,
            self.band_ranges,
            config,
        )
        if stacked.ndim != expected_ndim:
            raise ValueError(
                "Wavelet band powers must return a 3D array "
                "(epochs, channels, bands) to preserve feature naming."
            )
        if stacked.shape[2] != expected_bands:
            raise ValueError(
                "Wavelet band powers shape mismatch: "
                f"expected {expected_bands} bands but received {stacked.shape[2]}. "
                "Check the number of central frequencies and band definitions."
            )
        if stacked.shape[0] != X.shape[0] or stacked.shape[1] != X.shape[1]:
            raise ValueError(
                "Wavelet band powers must preserve epoch and channel dimensions."
            )

        # Retourne la matrice tabulaire prête pour un classifieur scikit-learn
        return stacked.reshape(stacked.shape[0], None)

    def xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_51(self, X: np.ndarray) -> np.ndarray:
        """Calcule des features à partir de la CWT wavelet."""

        expected_bands = len(self._band_items)
        if expected_bands == 0:  # pragma: no cover - defensive
            raise ValueError("Wavelet features require at least one configured band.")
        config = dict(self._effective_strategy_config)
        _normalize_wavelet_name(config.get("wavelet", "morlet"))
        expected_ndim = 3
        # Calcule les coefficients puis la puissance de bande via la fonction dédiée
        stacked = _compute_wavelet_band_powers(
            X,
            self.sfreq,
            self.band_ranges,
            config,
        )
        if stacked.ndim != expected_ndim:
            raise ValueError(
                "Wavelet band powers must return a 3D array "
                "(epochs, channels, bands) to preserve feature naming."
            )
        if stacked.shape[2] != expected_bands:
            raise ValueError(
                "Wavelet band powers shape mismatch: "
                f"expected {expected_bands} bands but received {stacked.shape[2]}. "
                "Check the number of central frequencies and band definitions."
            )
        if stacked.shape[0] != X.shape[0] or stacked.shape[1] != X.shape[1]:
            raise ValueError(
                "Wavelet band powers must preserve epoch and channel dimensions."
            )

        # Retourne la matrice tabulaire prête pour un classifieur scikit-learn
        return stacked.reshape(-1)

    def xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_52(self, X: np.ndarray) -> np.ndarray:
        """Calcule des features à partir de la CWT wavelet."""

        expected_bands = len(self._band_items)
        if expected_bands == 0:  # pragma: no cover - defensive
            raise ValueError("Wavelet features require at least one configured band.")
        config = dict(self._effective_strategy_config)
        _normalize_wavelet_name(config.get("wavelet", "morlet"))
        expected_ndim = 3
        # Calcule les coefficients puis la puissance de bande via la fonction dédiée
        stacked = _compute_wavelet_band_powers(
            X,
            self.sfreq,
            self.band_ranges,
            config,
        )
        if stacked.ndim != expected_ndim:
            raise ValueError(
                "Wavelet band powers must return a 3D array "
                "(epochs, channels, bands) to preserve feature naming."
            )
        if stacked.shape[2] != expected_bands:
            raise ValueError(
                "Wavelet band powers shape mismatch: "
                f"expected {expected_bands} bands but received {stacked.shape[2]}. "
                "Check the number of central frequencies and band definitions."
            )
        if stacked.shape[0] != X.shape[0] or stacked.shape[1] != X.shape[1]:
            raise ValueError(
                "Wavelet band powers must preserve epoch and channel dimensions."
            )

        # Retourne la matrice tabulaire prête pour un classifieur scikit-learn
        return stacked.reshape(stacked.shape[0], )

    def xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_53(self, X: np.ndarray) -> np.ndarray:
        """Calcule des features à partir de la CWT wavelet."""

        expected_bands = len(self._band_items)
        if expected_bands == 0:  # pragma: no cover - defensive
            raise ValueError("Wavelet features require at least one configured band.")
        config = dict(self._effective_strategy_config)
        _normalize_wavelet_name(config.get("wavelet", "morlet"))
        expected_ndim = 3
        # Calcule les coefficients puis la puissance de bande via la fonction dédiée
        stacked = _compute_wavelet_band_powers(
            X,
            self.sfreq,
            self.band_ranges,
            config,
        )
        if stacked.ndim != expected_ndim:
            raise ValueError(
                "Wavelet band powers must return a 3D array "
                "(epochs, channels, bands) to preserve feature naming."
            )
        if stacked.shape[2] != expected_bands:
            raise ValueError(
                "Wavelet band powers shape mismatch: "
                f"expected {expected_bands} bands but received {stacked.shape[2]}. "
                "Check the number of central frequencies and band definitions."
            )
        if stacked.shape[0] != X.shape[0] or stacked.shape[1] != X.shape[1]:
            raise ValueError(
                "Wavelet band powers must preserve epoch and channel dimensions."
            )

        # Retourne la matrice tabulaire prête pour un classifieur scikit-learn
        return stacked.reshape(stacked.shape[1], -1)

    def xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_54(self, X: np.ndarray) -> np.ndarray:
        """Calcule des features à partir de la CWT wavelet."""

        expected_bands = len(self._band_items)
        if expected_bands == 0:  # pragma: no cover - defensive
            raise ValueError("Wavelet features require at least one configured band.")
        config = dict(self._effective_strategy_config)
        _normalize_wavelet_name(config.get("wavelet", "morlet"))
        expected_ndim = 3
        # Calcule les coefficients puis la puissance de bande via la fonction dédiée
        stacked = _compute_wavelet_band_powers(
            X,
            self.sfreq,
            self.band_ranges,
            config,
        )
        if stacked.ndim != expected_ndim:
            raise ValueError(
                "Wavelet band powers must return a 3D array "
                "(epochs, channels, bands) to preserve feature naming."
            )
        if stacked.shape[2] != expected_bands:
            raise ValueError(
                "Wavelet band powers shape mismatch: "
                f"expected {expected_bands} bands but received {stacked.shape[2]}. "
                "Check the number of central frequencies and band definitions."
            )
        if stacked.shape[0] != X.shape[0] or stacked.shape[1] != X.shape[1]:
            raise ValueError(
                "Wavelet band powers must preserve epoch and channel dimensions."
            )

        # Retourne la matrice tabulaire prête pour un classifieur scikit-learn
        return stacked.reshape(stacked.shape[0], +1)

    def xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_55(self, X: np.ndarray) -> np.ndarray:
        """Calcule des features à partir de la CWT wavelet."""

        expected_bands = len(self._band_items)
        if expected_bands == 0:  # pragma: no cover - defensive
            raise ValueError("Wavelet features require at least one configured band.")
        config = dict(self._effective_strategy_config)
        _normalize_wavelet_name(config.get("wavelet", "morlet"))
        expected_ndim = 3
        # Calcule les coefficients puis la puissance de bande via la fonction dédiée
        stacked = _compute_wavelet_band_powers(
            X,
            self.sfreq,
            self.band_ranges,
            config,
        )
        if stacked.ndim != expected_ndim:
            raise ValueError(
                "Wavelet band powers must return a 3D array "
                "(epochs, channels, bands) to preserve feature naming."
            )
        if stacked.shape[2] != expected_bands:
            raise ValueError(
                "Wavelet band powers shape mismatch: "
                f"expected {expected_bands} bands but received {stacked.shape[2]}. "
                "Check the number of central frequencies and band definitions."
            )
        if stacked.shape[0] != X.shape[0] or stacked.shape[1] != X.shape[1]:
            raise ValueError(
                "Wavelet band powers must preserve epoch and channel dimensions."
            )

        # Retourne la matrice tabulaire prête pour un classifieur scikit-learn
        return stacked.reshape(stacked.shape[0], -2)
    
    xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_mutants : ClassVar[MutantDict] = {
    'xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_1': xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_1, 
        'xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_2': xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_2, 
        'xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_3': xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_3, 
        'xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_4': xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_4, 
        'xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_5': xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_5, 
        'xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_6': xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_6, 
        'xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_7': xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_7, 
        'xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_8': xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_8, 
        'xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_9': xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_9, 
        'xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_10': xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_10, 
        'xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_11': xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_11, 
        'xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_12': xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_12, 
        'xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_13': xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_13, 
        'xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_14': xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_14, 
        'xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_15': xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_15, 
        'xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_16': xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_16, 
        'xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_17': xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_17, 
        'xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_18': xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_18, 
        'xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_19': xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_19, 
        'xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_20': xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_20, 
        'xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_21': xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_21, 
        'xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_22': xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_22, 
        'xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_23': xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_23, 
        'xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_24': xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_24, 
        'xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_25': xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_25, 
        'xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_26': xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_26, 
        'xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_27': xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_27, 
        'xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_28': xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_28, 
        'xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_29': xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_29, 
        'xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_30': xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_30, 
        'xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_31': xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_31, 
        'xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_32': xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_32, 
        'xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_33': xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_33, 
        'xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_34': xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_34, 
        'xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_35': xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_35, 
        'xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_36': xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_36, 
        'xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_37': xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_37, 
        'xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_38': xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_38, 
        'xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_39': xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_39, 
        'xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_40': xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_40, 
        'xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_41': xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_41, 
        'xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_42': xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_42, 
        'xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_43': xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_43, 
        'xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_44': xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_44, 
        'xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_45': xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_45, 
        'xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_46': xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_46, 
        'xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_47': xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_47, 
        'xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_48': xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_48, 
        'xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_49': xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_49, 
        'xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_50': xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_50, 
        'xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_51': xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_51, 
        'xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_52': xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_52, 
        'xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_53': xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_53, 
        'xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_54': xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_54, 
        'xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_55': xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_55
    }
    
    def _compute_wavelet_features(self, *args, **kwargs):
        result = _mutmut_trampoline(object.__getattribute__(self, "xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_orig"), object.__getattribute__(self, "xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_mutants"), args, kwargs, self)
        return result 
    
    _compute_wavelet_features.__signature__ = _mutmut_signature(xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_orig)
    xǁExtractFeaturesǁ_compute_wavelet_features__mutmut_orig.__name__ = 'xǁExtractFeaturesǁ_compute_wavelet_features'

    def xǁExtractFeaturesǁ_compute_welch_features__mutmut_orig(self, X: np.ndarray) -> np.ndarray:
        """Calcule des features à partir de la méthode de Welch."""

        stacked = _compute_welch_band_powers(
            X,
            self.sfreq,
            self.band_ranges,
            self._effective_strategy_config,
        )
        return stacked.reshape(stacked.shape[0], -1)

    def xǁExtractFeaturesǁ_compute_welch_features__mutmut_1(self, X: np.ndarray) -> np.ndarray:
        """Calcule des features à partir de la méthode de Welch."""

        stacked = None
        return stacked.reshape(stacked.shape[0], -1)

    def xǁExtractFeaturesǁ_compute_welch_features__mutmut_2(self, X: np.ndarray) -> np.ndarray:
        """Calcule des features à partir de la méthode de Welch."""

        stacked = _compute_welch_band_powers(
            None,
            self.sfreq,
            self.band_ranges,
            self._effective_strategy_config,
        )
        return stacked.reshape(stacked.shape[0], -1)

    def xǁExtractFeaturesǁ_compute_welch_features__mutmut_3(self, X: np.ndarray) -> np.ndarray:
        """Calcule des features à partir de la méthode de Welch."""

        stacked = _compute_welch_band_powers(
            X,
            None,
            self.band_ranges,
            self._effective_strategy_config,
        )
        return stacked.reshape(stacked.shape[0], -1)

    def xǁExtractFeaturesǁ_compute_welch_features__mutmut_4(self, X: np.ndarray) -> np.ndarray:
        """Calcule des features à partir de la méthode de Welch."""

        stacked = _compute_welch_band_powers(
            X,
            self.sfreq,
            None,
            self._effective_strategy_config,
        )
        return stacked.reshape(stacked.shape[0], -1)

    def xǁExtractFeaturesǁ_compute_welch_features__mutmut_5(self, X: np.ndarray) -> np.ndarray:
        """Calcule des features à partir de la méthode de Welch."""

        stacked = _compute_welch_band_powers(
            X,
            self.sfreq,
            self.band_ranges,
            None,
        )
        return stacked.reshape(stacked.shape[0], -1)

    def xǁExtractFeaturesǁ_compute_welch_features__mutmut_6(self, X: np.ndarray) -> np.ndarray:
        """Calcule des features à partir de la méthode de Welch."""

        stacked = _compute_welch_band_powers(
            self.sfreq,
            self.band_ranges,
            self._effective_strategy_config,
        )
        return stacked.reshape(stacked.shape[0], -1)

    def xǁExtractFeaturesǁ_compute_welch_features__mutmut_7(self, X: np.ndarray) -> np.ndarray:
        """Calcule des features à partir de la méthode de Welch."""

        stacked = _compute_welch_band_powers(
            X,
            self.band_ranges,
            self._effective_strategy_config,
        )
        return stacked.reshape(stacked.shape[0], -1)

    def xǁExtractFeaturesǁ_compute_welch_features__mutmut_8(self, X: np.ndarray) -> np.ndarray:
        """Calcule des features à partir de la méthode de Welch."""

        stacked = _compute_welch_band_powers(
            X,
            self.sfreq,
            self._effective_strategy_config,
        )
        return stacked.reshape(stacked.shape[0], -1)

    def xǁExtractFeaturesǁ_compute_welch_features__mutmut_9(self, X: np.ndarray) -> np.ndarray:
        """Calcule des features à partir de la méthode de Welch."""

        stacked = _compute_welch_band_powers(
            X,
            self.sfreq,
            self.band_ranges,
            )
        return stacked.reshape(stacked.shape[0], -1)

    def xǁExtractFeaturesǁ_compute_welch_features__mutmut_10(self, X: np.ndarray) -> np.ndarray:
        """Calcule des features à partir de la méthode de Welch."""

        stacked = _compute_welch_band_powers(
            X,
            self.sfreq,
            self.band_ranges,
            self._effective_strategy_config,
        )
        return stacked.reshape(None, -1)

    def xǁExtractFeaturesǁ_compute_welch_features__mutmut_11(self, X: np.ndarray) -> np.ndarray:
        """Calcule des features à partir de la méthode de Welch."""

        stacked = _compute_welch_band_powers(
            X,
            self.sfreq,
            self.band_ranges,
            self._effective_strategy_config,
        )
        return stacked.reshape(stacked.shape[0], None)

    def xǁExtractFeaturesǁ_compute_welch_features__mutmut_12(self, X: np.ndarray) -> np.ndarray:
        """Calcule des features à partir de la méthode de Welch."""

        stacked = _compute_welch_band_powers(
            X,
            self.sfreq,
            self.band_ranges,
            self._effective_strategy_config,
        )
        return stacked.reshape(-1)

    def xǁExtractFeaturesǁ_compute_welch_features__mutmut_13(self, X: np.ndarray) -> np.ndarray:
        """Calcule des features à partir de la méthode de Welch."""

        stacked = _compute_welch_band_powers(
            X,
            self.sfreq,
            self.band_ranges,
            self._effective_strategy_config,
        )
        return stacked.reshape(stacked.shape[0], )

    def xǁExtractFeaturesǁ_compute_welch_features__mutmut_14(self, X: np.ndarray) -> np.ndarray:
        """Calcule des features à partir de la méthode de Welch."""

        stacked = _compute_welch_band_powers(
            X,
            self.sfreq,
            self.band_ranges,
            self._effective_strategy_config,
        )
        return stacked.reshape(stacked.shape[1], -1)

    def xǁExtractFeaturesǁ_compute_welch_features__mutmut_15(self, X: np.ndarray) -> np.ndarray:
        """Calcule des features à partir de la méthode de Welch."""

        stacked = _compute_welch_band_powers(
            X,
            self.sfreq,
            self.band_ranges,
            self._effective_strategy_config,
        )
        return stacked.reshape(stacked.shape[0], +1)

    def xǁExtractFeaturesǁ_compute_welch_features__mutmut_16(self, X: np.ndarray) -> np.ndarray:
        """Calcule des features à partir de la méthode de Welch."""

        stacked = _compute_welch_band_powers(
            X,
            self.sfreq,
            self.band_ranges,
            self._effective_strategy_config,
        )
        return stacked.reshape(stacked.shape[0], -2)
    
    xǁExtractFeaturesǁ_compute_welch_features__mutmut_mutants : ClassVar[MutantDict] = {
    'xǁExtractFeaturesǁ_compute_welch_features__mutmut_1': xǁExtractFeaturesǁ_compute_welch_features__mutmut_1, 
        'xǁExtractFeaturesǁ_compute_welch_features__mutmut_2': xǁExtractFeaturesǁ_compute_welch_features__mutmut_2, 
        'xǁExtractFeaturesǁ_compute_welch_features__mutmut_3': xǁExtractFeaturesǁ_compute_welch_features__mutmut_3, 
        'xǁExtractFeaturesǁ_compute_welch_features__mutmut_4': xǁExtractFeaturesǁ_compute_welch_features__mutmut_4, 
        'xǁExtractFeaturesǁ_compute_welch_features__mutmut_5': xǁExtractFeaturesǁ_compute_welch_features__mutmut_5, 
        'xǁExtractFeaturesǁ_compute_welch_features__mutmut_6': xǁExtractFeaturesǁ_compute_welch_features__mutmut_6, 
        'xǁExtractFeaturesǁ_compute_welch_features__mutmut_7': xǁExtractFeaturesǁ_compute_welch_features__mutmut_7, 
        'xǁExtractFeaturesǁ_compute_welch_features__mutmut_8': xǁExtractFeaturesǁ_compute_welch_features__mutmut_8, 
        'xǁExtractFeaturesǁ_compute_welch_features__mutmut_9': xǁExtractFeaturesǁ_compute_welch_features__mutmut_9, 
        'xǁExtractFeaturesǁ_compute_welch_features__mutmut_10': xǁExtractFeaturesǁ_compute_welch_features__mutmut_10, 
        'xǁExtractFeaturesǁ_compute_welch_features__mutmut_11': xǁExtractFeaturesǁ_compute_welch_features__mutmut_11, 
        'xǁExtractFeaturesǁ_compute_welch_features__mutmut_12': xǁExtractFeaturesǁ_compute_welch_features__mutmut_12, 
        'xǁExtractFeaturesǁ_compute_welch_features__mutmut_13': xǁExtractFeaturesǁ_compute_welch_features__mutmut_13, 
        'xǁExtractFeaturesǁ_compute_welch_features__mutmut_14': xǁExtractFeaturesǁ_compute_welch_features__mutmut_14, 
        'xǁExtractFeaturesǁ_compute_welch_features__mutmut_15': xǁExtractFeaturesǁ_compute_welch_features__mutmut_15, 
        'xǁExtractFeaturesǁ_compute_welch_features__mutmut_16': xǁExtractFeaturesǁ_compute_welch_features__mutmut_16
    }
    
    def _compute_welch_features(self, *args, **kwargs):
        result = _mutmut_trampoline(object.__getattribute__(self, "xǁExtractFeaturesǁ_compute_welch_features__mutmut_orig"), object.__getattribute__(self, "xǁExtractFeaturesǁ_compute_welch_features__mutmut_mutants"), args, kwargs, self)
        return result 
    
    _compute_welch_features.__signature__ = _mutmut_signature(xǁExtractFeaturesǁ_compute_welch_features__mutmut_orig)
    xǁExtractFeaturesǁ_compute_welch_features__mutmut_orig.__name__ = 'xǁExtractFeaturesǁ_compute_welch_features'


def x_extract_features__mutmut_orig(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = dict(config or {})
    # Déclare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = {
        "theta": (4.0, 7.0),
        "alpha": (8.0, 12.0),
        "beta": (13.0, 30.0),
        "gamma": (31.0, 45.0),
    }
    # Fusionne les bandes personnalisées en conservant l'ordre demandé
    band_ranges: Dict[str, Tuple[float, float]] = _resolve_band_ranges(
        effective_config, default_bands
    )
    # Refuse une configuration vide pour éviter un empilement sans bandes
    if not band_ranges:
        raise ValueError("At least one frequency band must be provided.")
    # Récupère la méthode pour aiguiller la stratégie d'extraction
    method: str = effective_config.pop("method", "welch")
    # Permet de contrôler l'activation de la normalisation via la configuration
    normalize = bool(effective_config.pop("normalize", False))
    # Supprime la configuration des bandes pour ne pas dupliquer l'information
    effective_config.pop("bands", None)
    # Capture les noms de canaux pour aligner les étiquettes de features
    channel_names: Sequence[str] = getattr(epochs.info, "ch_names", [])
    # Extrait les données temporelles pour calculer les caractéristiques spectrales
    data: np.ndarray = epochs.get_data()
    # Récupère la fréquence d'échantillonnage indispensable au calcul fréquentiel
    sfreq: float = float(epochs.info["sfreq"])
    # Construit un extracteur scikit-learn pour déléguer le calcul
    estimator = ExtractFeatures(
        sfreq=sfreq,
        feature_strategy=method,
        normalize=normalize,
        bands=band_ranges,
        strategy_config=effective_config,
    )
    # Calcule les features en déléguant à l'extracteur scikit-learn
    features = estimator.transform(data)
    # Détermine le nombre de bandes pour reconstruire les étiquettes
    n_bands = len(band_ranges)
    # Recompose un tenseur factice pour générer les étiquettes canal/bande
    stacked = features.reshape(features.shape[0], data.shape[1], n_bands)
    # Construit des étiquettes canal_bande pour interpréter les features
    labels: List[str] = _build_labels(stacked, band_ranges, channel_names)
    # Retourne les features tabulaires accompagnés de leurs étiquettes
    return features, labels


def x_extract_features__mutmut_1(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = None
    # Déclare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = {
        "theta": (4.0, 7.0),
        "alpha": (8.0, 12.0),
        "beta": (13.0, 30.0),
        "gamma": (31.0, 45.0),
    }
    # Fusionne les bandes personnalisées en conservant l'ordre demandé
    band_ranges: Dict[str, Tuple[float, float]] = _resolve_band_ranges(
        effective_config, default_bands
    )
    # Refuse une configuration vide pour éviter un empilement sans bandes
    if not band_ranges:
        raise ValueError("At least one frequency band must be provided.")
    # Récupère la méthode pour aiguiller la stratégie d'extraction
    method: str = effective_config.pop("method", "welch")
    # Permet de contrôler l'activation de la normalisation via la configuration
    normalize = bool(effective_config.pop("normalize", False))
    # Supprime la configuration des bandes pour ne pas dupliquer l'information
    effective_config.pop("bands", None)
    # Capture les noms de canaux pour aligner les étiquettes de features
    channel_names: Sequence[str] = getattr(epochs.info, "ch_names", [])
    # Extrait les données temporelles pour calculer les caractéristiques spectrales
    data: np.ndarray = epochs.get_data()
    # Récupère la fréquence d'échantillonnage indispensable au calcul fréquentiel
    sfreq: float = float(epochs.info["sfreq"])
    # Construit un extracteur scikit-learn pour déléguer le calcul
    estimator = ExtractFeatures(
        sfreq=sfreq,
        feature_strategy=method,
        normalize=normalize,
        bands=band_ranges,
        strategy_config=effective_config,
    )
    # Calcule les features en déléguant à l'extracteur scikit-learn
    features = estimator.transform(data)
    # Détermine le nombre de bandes pour reconstruire les étiquettes
    n_bands = len(band_ranges)
    # Recompose un tenseur factice pour générer les étiquettes canal/bande
    stacked = features.reshape(features.shape[0], data.shape[1], n_bands)
    # Construit des étiquettes canal_bande pour interpréter les features
    labels: List[str] = _build_labels(stacked, band_ranges, channel_names)
    # Retourne les features tabulaires accompagnés de leurs étiquettes
    return features, labels


def x_extract_features__mutmut_2(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = dict(None)
    # Déclare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = {
        "theta": (4.0, 7.0),
        "alpha": (8.0, 12.0),
        "beta": (13.0, 30.0),
        "gamma": (31.0, 45.0),
    }
    # Fusionne les bandes personnalisées en conservant l'ordre demandé
    band_ranges: Dict[str, Tuple[float, float]] = _resolve_band_ranges(
        effective_config, default_bands
    )
    # Refuse une configuration vide pour éviter un empilement sans bandes
    if not band_ranges:
        raise ValueError("At least one frequency band must be provided.")
    # Récupère la méthode pour aiguiller la stratégie d'extraction
    method: str = effective_config.pop("method", "welch")
    # Permet de contrôler l'activation de la normalisation via la configuration
    normalize = bool(effective_config.pop("normalize", False))
    # Supprime la configuration des bandes pour ne pas dupliquer l'information
    effective_config.pop("bands", None)
    # Capture les noms de canaux pour aligner les étiquettes de features
    channel_names: Sequence[str] = getattr(epochs.info, "ch_names", [])
    # Extrait les données temporelles pour calculer les caractéristiques spectrales
    data: np.ndarray = epochs.get_data()
    # Récupère la fréquence d'échantillonnage indispensable au calcul fréquentiel
    sfreq: float = float(epochs.info["sfreq"])
    # Construit un extracteur scikit-learn pour déléguer le calcul
    estimator = ExtractFeatures(
        sfreq=sfreq,
        feature_strategy=method,
        normalize=normalize,
        bands=band_ranges,
        strategy_config=effective_config,
    )
    # Calcule les features en déléguant à l'extracteur scikit-learn
    features = estimator.transform(data)
    # Détermine le nombre de bandes pour reconstruire les étiquettes
    n_bands = len(band_ranges)
    # Recompose un tenseur factice pour générer les étiquettes canal/bande
    stacked = features.reshape(features.shape[0], data.shape[1], n_bands)
    # Construit des étiquettes canal_bande pour interpréter les features
    labels: List[str] = _build_labels(stacked, band_ranges, channel_names)
    # Retourne les features tabulaires accompagnés de leurs étiquettes
    return features, labels


def x_extract_features__mutmut_3(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = dict(config and {})
    # Déclare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = {
        "theta": (4.0, 7.0),
        "alpha": (8.0, 12.0),
        "beta": (13.0, 30.0),
        "gamma": (31.0, 45.0),
    }
    # Fusionne les bandes personnalisées en conservant l'ordre demandé
    band_ranges: Dict[str, Tuple[float, float]] = _resolve_band_ranges(
        effective_config, default_bands
    )
    # Refuse une configuration vide pour éviter un empilement sans bandes
    if not band_ranges:
        raise ValueError("At least one frequency band must be provided.")
    # Récupère la méthode pour aiguiller la stratégie d'extraction
    method: str = effective_config.pop("method", "welch")
    # Permet de contrôler l'activation de la normalisation via la configuration
    normalize = bool(effective_config.pop("normalize", False))
    # Supprime la configuration des bandes pour ne pas dupliquer l'information
    effective_config.pop("bands", None)
    # Capture les noms de canaux pour aligner les étiquettes de features
    channel_names: Sequence[str] = getattr(epochs.info, "ch_names", [])
    # Extrait les données temporelles pour calculer les caractéristiques spectrales
    data: np.ndarray = epochs.get_data()
    # Récupère la fréquence d'échantillonnage indispensable au calcul fréquentiel
    sfreq: float = float(epochs.info["sfreq"])
    # Construit un extracteur scikit-learn pour déléguer le calcul
    estimator = ExtractFeatures(
        sfreq=sfreq,
        feature_strategy=method,
        normalize=normalize,
        bands=band_ranges,
        strategy_config=effective_config,
    )
    # Calcule les features en déléguant à l'extracteur scikit-learn
    features = estimator.transform(data)
    # Détermine le nombre de bandes pour reconstruire les étiquettes
    n_bands = len(band_ranges)
    # Recompose un tenseur factice pour générer les étiquettes canal/bande
    stacked = features.reshape(features.shape[0], data.shape[1], n_bands)
    # Construit des étiquettes canal_bande pour interpréter les features
    labels: List[str] = _build_labels(stacked, band_ranges, channel_names)
    # Retourne les features tabulaires accompagnés de leurs étiquettes
    return features, labels


def x_extract_features__mutmut_4(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = dict(config or {})
    # Déclare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = None
    # Fusionne les bandes personnalisées en conservant l'ordre demandé
    band_ranges: Dict[str, Tuple[float, float]] = _resolve_band_ranges(
        effective_config, default_bands
    )
    # Refuse une configuration vide pour éviter un empilement sans bandes
    if not band_ranges:
        raise ValueError("At least one frequency band must be provided.")
    # Récupère la méthode pour aiguiller la stratégie d'extraction
    method: str = effective_config.pop("method", "welch")
    # Permet de contrôler l'activation de la normalisation via la configuration
    normalize = bool(effective_config.pop("normalize", False))
    # Supprime la configuration des bandes pour ne pas dupliquer l'information
    effective_config.pop("bands", None)
    # Capture les noms de canaux pour aligner les étiquettes de features
    channel_names: Sequence[str] = getattr(epochs.info, "ch_names", [])
    # Extrait les données temporelles pour calculer les caractéristiques spectrales
    data: np.ndarray = epochs.get_data()
    # Récupère la fréquence d'échantillonnage indispensable au calcul fréquentiel
    sfreq: float = float(epochs.info["sfreq"])
    # Construit un extracteur scikit-learn pour déléguer le calcul
    estimator = ExtractFeatures(
        sfreq=sfreq,
        feature_strategy=method,
        normalize=normalize,
        bands=band_ranges,
        strategy_config=effective_config,
    )
    # Calcule les features en déléguant à l'extracteur scikit-learn
    features = estimator.transform(data)
    # Détermine le nombre de bandes pour reconstruire les étiquettes
    n_bands = len(band_ranges)
    # Recompose un tenseur factice pour générer les étiquettes canal/bande
    stacked = features.reshape(features.shape[0], data.shape[1], n_bands)
    # Construit des étiquettes canal_bande pour interpréter les features
    labels: List[str] = _build_labels(stacked, band_ranges, channel_names)
    # Retourne les features tabulaires accompagnés de leurs étiquettes
    return features, labels


def x_extract_features__mutmut_5(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = dict(config or {})
    # Déclare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = {
        "XXthetaXX": (4.0, 7.0),
        "alpha": (8.0, 12.0),
        "beta": (13.0, 30.0),
        "gamma": (31.0, 45.0),
    }
    # Fusionne les bandes personnalisées en conservant l'ordre demandé
    band_ranges: Dict[str, Tuple[float, float]] = _resolve_band_ranges(
        effective_config, default_bands
    )
    # Refuse une configuration vide pour éviter un empilement sans bandes
    if not band_ranges:
        raise ValueError("At least one frequency band must be provided.")
    # Récupère la méthode pour aiguiller la stratégie d'extraction
    method: str = effective_config.pop("method", "welch")
    # Permet de contrôler l'activation de la normalisation via la configuration
    normalize = bool(effective_config.pop("normalize", False))
    # Supprime la configuration des bandes pour ne pas dupliquer l'information
    effective_config.pop("bands", None)
    # Capture les noms de canaux pour aligner les étiquettes de features
    channel_names: Sequence[str] = getattr(epochs.info, "ch_names", [])
    # Extrait les données temporelles pour calculer les caractéristiques spectrales
    data: np.ndarray = epochs.get_data()
    # Récupère la fréquence d'échantillonnage indispensable au calcul fréquentiel
    sfreq: float = float(epochs.info["sfreq"])
    # Construit un extracteur scikit-learn pour déléguer le calcul
    estimator = ExtractFeatures(
        sfreq=sfreq,
        feature_strategy=method,
        normalize=normalize,
        bands=band_ranges,
        strategy_config=effective_config,
    )
    # Calcule les features en déléguant à l'extracteur scikit-learn
    features = estimator.transform(data)
    # Détermine le nombre de bandes pour reconstruire les étiquettes
    n_bands = len(band_ranges)
    # Recompose un tenseur factice pour générer les étiquettes canal/bande
    stacked = features.reshape(features.shape[0], data.shape[1], n_bands)
    # Construit des étiquettes canal_bande pour interpréter les features
    labels: List[str] = _build_labels(stacked, band_ranges, channel_names)
    # Retourne les features tabulaires accompagnés de leurs étiquettes
    return features, labels


def x_extract_features__mutmut_6(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = dict(config or {})
    # Déclare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = {
        "THETA": (4.0, 7.0),
        "alpha": (8.0, 12.0),
        "beta": (13.0, 30.0),
        "gamma": (31.0, 45.0),
    }
    # Fusionne les bandes personnalisées en conservant l'ordre demandé
    band_ranges: Dict[str, Tuple[float, float]] = _resolve_band_ranges(
        effective_config, default_bands
    )
    # Refuse une configuration vide pour éviter un empilement sans bandes
    if not band_ranges:
        raise ValueError("At least one frequency band must be provided.")
    # Récupère la méthode pour aiguiller la stratégie d'extraction
    method: str = effective_config.pop("method", "welch")
    # Permet de contrôler l'activation de la normalisation via la configuration
    normalize = bool(effective_config.pop("normalize", False))
    # Supprime la configuration des bandes pour ne pas dupliquer l'information
    effective_config.pop("bands", None)
    # Capture les noms de canaux pour aligner les étiquettes de features
    channel_names: Sequence[str] = getattr(epochs.info, "ch_names", [])
    # Extrait les données temporelles pour calculer les caractéristiques spectrales
    data: np.ndarray = epochs.get_data()
    # Récupère la fréquence d'échantillonnage indispensable au calcul fréquentiel
    sfreq: float = float(epochs.info["sfreq"])
    # Construit un extracteur scikit-learn pour déléguer le calcul
    estimator = ExtractFeatures(
        sfreq=sfreq,
        feature_strategy=method,
        normalize=normalize,
        bands=band_ranges,
        strategy_config=effective_config,
    )
    # Calcule les features en déléguant à l'extracteur scikit-learn
    features = estimator.transform(data)
    # Détermine le nombre de bandes pour reconstruire les étiquettes
    n_bands = len(band_ranges)
    # Recompose un tenseur factice pour générer les étiquettes canal/bande
    stacked = features.reshape(features.shape[0], data.shape[1], n_bands)
    # Construit des étiquettes canal_bande pour interpréter les features
    labels: List[str] = _build_labels(stacked, band_ranges, channel_names)
    # Retourne les features tabulaires accompagnés de leurs étiquettes
    return features, labels


def x_extract_features__mutmut_7(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = dict(config or {})
    # Déclare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = {
        "theta": (5.0, 7.0),
        "alpha": (8.0, 12.0),
        "beta": (13.0, 30.0),
        "gamma": (31.0, 45.0),
    }
    # Fusionne les bandes personnalisées en conservant l'ordre demandé
    band_ranges: Dict[str, Tuple[float, float]] = _resolve_band_ranges(
        effective_config, default_bands
    )
    # Refuse une configuration vide pour éviter un empilement sans bandes
    if not band_ranges:
        raise ValueError("At least one frequency band must be provided.")
    # Récupère la méthode pour aiguiller la stratégie d'extraction
    method: str = effective_config.pop("method", "welch")
    # Permet de contrôler l'activation de la normalisation via la configuration
    normalize = bool(effective_config.pop("normalize", False))
    # Supprime la configuration des bandes pour ne pas dupliquer l'information
    effective_config.pop("bands", None)
    # Capture les noms de canaux pour aligner les étiquettes de features
    channel_names: Sequence[str] = getattr(epochs.info, "ch_names", [])
    # Extrait les données temporelles pour calculer les caractéristiques spectrales
    data: np.ndarray = epochs.get_data()
    # Récupère la fréquence d'échantillonnage indispensable au calcul fréquentiel
    sfreq: float = float(epochs.info["sfreq"])
    # Construit un extracteur scikit-learn pour déléguer le calcul
    estimator = ExtractFeatures(
        sfreq=sfreq,
        feature_strategy=method,
        normalize=normalize,
        bands=band_ranges,
        strategy_config=effective_config,
    )
    # Calcule les features en déléguant à l'extracteur scikit-learn
    features = estimator.transform(data)
    # Détermine le nombre de bandes pour reconstruire les étiquettes
    n_bands = len(band_ranges)
    # Recompose un tenseur factice pour générer les étiquettes canal/bande
    stacked = features.reshape(features.shape[0], data.shape[1], n_bands)
    # Construit des étiquettes canal_bande pour interpréter les features
    labels: List[str] = _build_labels(stacked, band_ranges, channel_names)
    # Retourne les features tabulaires accompagnés de leurs étiquettes
    return features, labels


def x_extract_features__mutmut_8(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = dict(config or {})
    # Déclare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = {
        "theta": (4.0, 8.0),
        "alpha": (8.0, 12.0),
        "beta": (13.0, 30.0),
        "gamma": (31.0, 45.0),
    }
    # Fusionne les bandes personnalisées en conservant l'ordre demandé
    band_ranges: Dict[str, Tuple[float, float]] = _resolve_band_ranges(
        effective_config, default_bands
    )
    # Refuse une configuration vide pour éviter un empilement sans bandes
    if not band_ranges:
        raise ValueError("At least one frequency band must be provided.")
    # Récupère la méthode pour aiguiller la stratégie d'extraction
    method: str = effective_config.pop("method", "welch")
    # Permet de contrôler l'activation de la normalisation via la configuration
    normalize = bool(effective_config.pop("normalize", False))
    # Supprime la configuration des bandes pour ne pas dupliquer l'information
    effective_config.pop("bands", None)
    # Capture les noms de canaux pour aligner les étiquettes de features
    channel_names: Sequence[str] = getattr(epochs.info, "ch_names", [])
    # Extrait les données temporelles pour calculer les caractéristiques spectrales
    data: np.ndarray = epochs.get_data()
    # Récupère la fréquence d'échantillonnage indispensable au calcul fréquentiel
    sfreq: float = float(epochs.info["sfreq"])
    # Construit un extracteur scikit-learn pour déléguer le calcul
    estimator = ExtractFeatures(
        sfreq=sfreq,
        feature_strategy=method,
        normalize=normalize,
        bands=band_ranges,
        strategy_config=effective_config,
    )
    # Calcule les features en déléguant à l'extracteur scikit-learn
    features = estimator.transform(data)
    # Détermine le nombre de bandes pour reconstruire les étiquettes
    n_bands = len(band_ranges)
    # Recompose un tenseur factice pour générer les étiquettes canal/bande
    stacked = features.reshape(features.shape[0], data.shape[1], n_bands)
    # Construit des étiquettes canal_bande pour interpréter les features
    labels: List[str] = _build_labels(stacked, band_ranges, channel_names)
    # Retourne les features tabulaires accompagnés de leurs étiquettes
    return features, labels


def x_extract_features__mutmut_9(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = dict(config or {})
    # Déclare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = {
        "theta": (4.0, 7.0),
        "XXalphaXX": (8.0, 12.0),
        "beta": (13.0, 30.0),
        "gamma": (31.0, 45.0),
    }
    # Fusionne les bandes personnalisées en conservant l'ordre demandé
    band_ranges: Dict[str, Tuple[float, float]] = _resolve_band_ranges(
        effective_config, default_bands
    )
    # Refuse une configuration vide pour éviter un empilement sans bandes
    if not band_ranges:
        raise ValueError("At least one frequency band must be provided.")
    # Récupère la méthode pour aiguiller la stratégie d'extraction
    method: str = effective_config.pop("method", "welch")
    # Permet de contrôler l'activation de la normalisation via la configuration
    normalize = bool(effective_config.pop("normalize", False))
    # Supprime la configuration des bandes pour ne pas dupliquer l'information
    effective_config.pop("bands", None)
    # Capture les noms de canaux pour aligner les étiquettes de features
    channel_names: Sequence[str] = getattr(epochs.info, "ch_names", [])
    # Extrait les données temporelles pour calculer les caractéristiques spectrales
    data: np.ndarray = epochs.get_data()
    # Récupère la fréquence d'échantillonnage indispensable au calcul fréquentiel
    sfreq: float = float(epochs.info["sfreq"])
    # Construit un extracteur scikit-learn pour déléguer le calcul
    estimator = ExtractFeatures(
        sfreq=sfreq,
        feature_strategy=method,
        normalize=normalize,
        bands=band_ranges,
        strategy_config=effective_config,
    )
    # Calcule les features en déléguant à l'extracteur scikit-learn
    features = estimator.transform(data)
    # Détermine le nombre de bandes pour reconstruire les étiquettes
    n_bands = len(band_ranges)
    # Recompose un tenseur factice pour générer les étiquettes canal/bande
    stacked = features.reshape(features.shape[0], data.shape[1], n_bands)
    # Construit des étiquettes canal_bande pour interpréter les features
    labels: List[str] = _build_labels(stacked, band_ranges, channel_names)
    # Retourne les features tabulaires accompagnés de leurs étiquettes
    return features, labels


def x_extract_features__mutmut_10(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = dict(config or {})
    # Déclare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = {
        "theta": (4.0, 7.0),
        "ALPHA": (8.0, 12.0),
        "beta": (13.0, 30.0),
        "gamma": (31.0, 45.0),
    }
    # Fusionne les bandes personnalisées en conservant l'ordre demandé
    band_ranges: Dict[str, Tuple[float, float]] = _resolve_band_ranges(
        effective_config, default_bands
    )
    # Refuse une configuration vide pour éviter un empilement sans bandes
    if not band_ranges:
        raise ValueError("At least one frequency band must be provided.")
    # Récupère la méthode pour aiguiller la stratégie d'extraction
    method: str = effective_config.pop("method", "welch")
    # Permet de contrôler l'activation de la normalisation via la configuration
    normalize = bool(effective_config.pop("normalize", False))
    # Supprime la configuration des bandes pour ne pas dupliquer l'information
    effective_config.pop("bands", None)
    # Capture les noms de canaux pour aligner les étiquettes de features
    channel_names: Sequence[str] = getattr(epochs.info, "ch_names", [])
    # Extrait les données temporelles pour calculer les caractéristiques spectrales
    data: np.ndarray = epochs.get_data()
    # Récupère la fréquence d'échantillonnage indispensable au calcul fréquentiel
    sfreq: float = float(epochs.info["sfreq"])
    # Construit un extracteur scikit-learn pour déléguer le calcul
    estimator = ExtractFeatures(
        sfreq=sfreq,
        feature_strategy=method,
        normalize=normalize,
        bands=band_ranges,
        strategy_config=effective_config,
    )
    # Calcule les features en déléguant à l'extracteur scikit-learn
    features = estimator.transform(data)
    # Détermine le nombre de bandes pour reconstruire les étiquettes
    n_bands = len(band_ranges)
    # Recompose un tenseur factice pour générer les étiquettes canal/bande
    stacked = features.reshape(features.shape[0], data.shape[1], n_bands)
    # Construit des étiquettes canal_bande pour interpréter les features
    labels: List[str] = _build_labels(stacked, band_ranges, channel_names)
    # Retourne les features tabulaires accompagnés de leurs étiquettes
    return features, labels


def x_extract_features__mutmut_11(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = dict(config or {})
    # Déclare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = {
        "theta": (4.0, 7.0),
        "alpha": (9.0, 12.0),
        "beta": (13.0, 30.0),
        "gamma": (31.0, 45.0),
    }
    # Fusionne les bandes personnalisées en conservant l'ordre demandé
    band_ranges: Dict[str, Tuple[float, float]] = _resolve_band_ranges(
        effective_config, default_bands
    )
    # Refuse une configuration vide pour éviter un empilement sans bandes
    if not band_ranges:
        raise ValueError("At least one frequency band must be provided.")
    # Récupère la méthode pour aiguiller la stratégie d'extraction
    method: str = effective_config.pop("method", "welch")
    # Permet de contrôler l'activation de la normalisation via la configuration
    normalize = bool(effective_config.pop("normalize", False))
    # Supprime la configuration des bandes pour ne pas dupliquer l'information
    effective_config.pop("bands", None)
    # Capture les noms de canaux pour aligner les étiquettes de features
    channel_names: Sequence[str] = getattr(epochs.info, "ch_names", [])
    # Extrait les données temporelles pour calculer les caractéristiques spectrales
    data: np.ndarray = epochs.get_data()
    # Récupère la fréquence d'échantillonnage indispensable au calcul fréquentiel
    sfreq: float = float(epochs.info["sfreq"])
    # Construit un extracteur scikit-learn pour déléguer le calcul
    estimator = ExtractFeatures(
        sfreq=sfreq,
        feature_strategy=method,
        normalize=normalize,
        bands=band_ranges,
        strategy_config=effective_config,
    )
    # Calcule les features en déléguant à l'extracteur scikit-learn
    features = estimator.transform(data)
    # Détermine le nombre de bandes pour reconstruire les étiquettes
    n_bands = len(band_ranges)
    # Recompose un tenseur factice pour générer les étiquettes canal/bande
    stacked = features.reshape(features.shape[0], data.shape[1], n_bands)
    # Construit des étiquettes canal_bande pour interpréter les features
    labels: List[str] = _build_labels(stacked, band_ranges, channel_names)
    # Retourne les features tabulaires accompagnés de leurs étiquettes
    return features, labels


def x_extract_features__mutmut_12(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = dict(config or {})
    # Déclare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = {
        "theta": (4.0, 7.0),
        "alpha": (8.0, 13.0),
        "beta": (13.0, 30.0),
        "gamma": (31.0, 45.0),
    }
    # Fusionne les bandes personnalisées en conservant l'ordre demandé
    band_ranges: Dict[str, Tuple[float, float]] = _resolve_band_ranges(
        effective_config, default_bands
    )
    # Refuse une configuration vide pour éviter un empilement sans bandes
    if not band_ranges:
        raise ValueError("At least one frequency band must be provided.")
    # Récupère la méthode pour aiguiller la stratégie d'extraction
    method: str = effective_config.pop("method", "welch")
    # Permet de contrôler l'activation de la normalisation via la configuration
    normalize = bool(effective_config.pop("normalize", False))
    # Supprime la configuration des bandes pour ne pas dupliquer l'information
    effective_config.pop("bands", None)
    # Capture les noms de canaux pour aligner les étiquettes de features
    channel_names: Sequence[str] = getattr(epochs.info, "ch_names", [])
    # Extrait les données temporelles pour calculer les caractéristiques spectrales
    data: np.ndarray = epochs.get_data()
    # Récupère la fréquence d'échantillonnage indispensable au calcul fréquentiel
    sfreq: float = float(epochs.info["sfreq"])
    # Construit un extracteur scikit-learn pour déléguer le calcul
    estimator = ExtractFeatures(
        sfreq=sfreq,
        feature_strategy=method,
        normalize=normalize,
        bands=band_ranges,
        strategy_config=effective_config,
    )
    # Calcule les features en déléguant à l'extracteur scikit-learn
    features = estimator.transform(data)
    # Détermine le nombre de bandes pour reconstruire les étiquettes
    n_bands = len(band_ranges)
    # Recompose un tenseur factice pour générer les étiquettes canal/bande
    stacked = features.reshape(features.shape[0], data.shape[1], n_bands)
    # Construit des étiquettes canal_bande pour interpréter les features
    labels: List[str] = _build_labels(stacked, band_ranges, channel_names)
    # Retourne les features tabulaires accompagnés de leurs étiquettes
    return features, labels


def x_extract_features__mutmut_13(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = dict(config or {})
    # Déclare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = {
        "theta": (4.0, 7.0),
        "alpha": (8.0, 12.0),
        "XXbetaXX": (13.0, 30.0),
        "gamma": (31.0, 45.0),
    }
    # Fusionne les bandes personnalisées en conservant l'ordre demandé
    band_ranges: Dict[str, Tuple[float, float]] = _resolve_band_ranges(
        effective_config, default_bands
    )
    # Refuse une configuration vide pour éviter un empilement sans bandes
    if not band_ranges:
        raise ValueError("At least one frequency band must be provided.")
    # Récupère la méthode pour aiguiller la stratégie d'extraction
    method: str = effective_config.pop("method", "welch")
    # Permet de contrôler l'activation de la normalisation via la configuration
    normalize = bool(effective_config.pop("normalize", False))
    # Supprime la configuration des bandes pour ne pas dupliquer l'information
    effective_config.pop("bands", None)
    # Capture les noms de canaux pour aligner les étiquettes de features
    channel_names: Sequence[str] = getattr(epochs.info, "ch_names", [])
    # Extrait les données temporelles pour calculer les caractéristiques spectrales
    data: np.ndarray = epochs.get_data()
    # Récupère la fréquence d'échantillonnage indispensable au calcul fréquentiel
    sfreq: float = float(epochs.info["sfreq"])
    # Construit un extracteur scikit-learn pour déléguer le calcul
    estimator = ExtractFeatures(
        sfreq=sfreq,
        feature_strategy=method,
        normalize=normalize,
        bands=band_ranges,
        strategy_config=effective_config,
    )
    # Calcule les features en déléguant à l'extracteur scikit-learn
    features = estimator.transform(data)
    # Détermine le nombre de bandes pour reconstruire les étiquettes
    n_bands = len(band_ranges)
    # Recompose un tenseur factice pour générer les étiquettes canal/bande
    stacked = features.reshape(features.shape[0], data.shape[1], n_bands)
    # Construit des étiquettes canal_bande pour interpréter les features
    labels: List[str] = _build_labels(stacked, band_ranges, channel_names)
    # Retourne les features tabulaires accompagnés de leurs étiquettes
    return features, labels


def x_extract_features__mutmut_14(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = dict(config or {})
    # Déclare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = {
        "theta": (4.0, 7.0),
        "alpha": (8.0, 12.0),
        "BETA": (13.0, 30.0),
        "gamma": (31.0, 45.0),
    }
    # Fusionne les bandes personnalisées en conservant l'ordre demandé
    band_ranges: Dict[str, Tuple[float, float]] = _resolve_band_ranges(
        effective_config, default_bands
    )
    # Refuse une configuration vide pour éviter un empilement sans bandes
    if not band_ranges:
        raise ValueError("At least one frequency band must be provided.")
    # Récupère la méthode pour aiguiller la stratégie d'extraction
    method: str = effective_config.pop("method", "welch")
    # Permet de contrôler l'activation de la normalisation via la configuration
    normalize = bool(effective_config.pop("normalize", False))
    # Supprime la configuration des bandes pour ne pas dupliquer l'information
    effective_config.pop("bands", None)
    # Capture les noms de canaux pour aligner les étiquettes de features
    channel_names: Sequence[str] = getattr(epochs.info, "ch_names", [])
    # Extrait les données temporelles pour calculer les caractéristiques spectrales
    data: np.ndarray = epochs.get_data()
    # Récupère la fréquence d'échantillonnage indispensable au calcul fréquentiel
    sfreq: float = float(epochs.info["sfreq"])
    # Construit un extracteur scikit-learn pour déléguer le calcul
    estimator = ExtractFeatures(
        sfreq=sfreq,
        feature_strategy=method,
        normalize=normalize,
        bands=band_ranges,
        strategy_config=effective_config,
    )
    # Calcule les features en déléguant à l'extracteur scikit-learn
    features = estimator.transform(data)
    # Détermine le nombre de bandes pour reconstruire les étiquettes
    n_bands = len(band_ranges)
    # Recompose un tenseur factice pour générer les étiquettes canal/bande
    stacked = features.reshape(features.shape[0], data.shape[1], n_bands)
    # Construit des étiquettes canal_bande pour interpréter les features
    labels: List[str] = _build_labels(stacked, band_ranges, channel_names)
    # Retourne les features tabulaires accompagnés de leurs étiquettes
    return features, labels


def x_extract_features__mutmut_15(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = dict(config or {})
    # Déclare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = {
        "theta": (4.0, 7.0),
        "alpha": (8.0, 12.0),
        "beta": (14.0, 30.0),
        "gamma": (31.0, 45.0),
    }
    # Fusionne les bandes personnalisées en conservant l'ordre demandé
    band_ranges: Dict[str, Tuple[float, float]] = _resolve_band_ranges(
        effective_config, default_bands
    )
    # Refuse une configuration vide pour éviter un empilement sans bandes
    if not band_ranges:
        raise ValueError("At least one frequency band must be provided.")
    # Récupère la méthode pour aiguiller la stratégie d'extraction
    method: str = effective_config.pop("method", "welch")
    # Permet de contrôler l'activation de la normalisation via la configuration
    normalize = bool(effective_config.pop("normalize", False))
    # Supprime la configuration des bandes pour ne pas dupliquer l'information
    effective_config.pop("bands", None)
    # Capture les noms de canaux pour aligner les étiquettes de features
    channel_names: Sequence[str] = getattr(epochs.info, "ch_names", [])
    # Extrait les données temporelles pour calculer les caractéristiques spectrales
    data: np.ndarray = epochs.get_data()
    # Récupère la fréquence d'échantillonnage indispensable au calcul fréquentiel
    sfreq: float = float(epochs.info["sfreq"])
    # Construit un extracteur scikit-learn pour déléguer le calcul
    estimator = ExtractFeatures(
        sfreq=sfreq,
        feature_strategy=method,
        normalize=normalize,
        bands=band_ranges,
        strategy_config=effective_config,
    )
    # Calcule les features en déléguant à l'extracteur scikit-learn
    features = estimator.transform(data)
    # Détermine le nombre de bandes pour reconstruire les étiquettes
    n_bands = len(band_ranges)
    # Recompose un tenseur factice pour générer les étiquettes canal/bande
    stacked = features.reshape(features.shape[0], data.shape[1], n_bands)
    # Construit des étiquettes canal_bande pour interpréter les features
    labels: List[str] = _build_labels(stacked, band_ranges, channel_names)
    # Retourne les features tabulaires accompagnés de leurs étiquettes
    return features, labels


def x_extract_features__mutmut_16(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = dict(config or {})
    # Déclare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = {
        "theta": (4.0, 7.0),
        "alpha": (8.0, 12.0),
        "beta": (13.0, 31.0),
        "gamma": (31.0, 45.0),
    }
    # Fusionne les bandes personnalisées en conservant l'ordre demandé
    band_ranges: Dict[str, Tuple[float, float]] = _resolve_band_ranges(
        effective_config, default_bands
    )
    # Refuse une configuration vide pour éviter un empilement sans bandes
    if not band_ranges:
        raise ValueError("At least one frequency band must be provided.")
    # Récupère la méthode pour aiguiller la stratégie d'extraction
    method: str = effective_config.pop("method", "welch")
    # Permet de contrôler l'activation de la normalisation via la configuration
    normalize = bool(effective_config.pop("normalize", False))
    # Supprime la configuration des bandes pour ne pas dupliquer l'information
    effective_config.pop("bands", None)
    # Capture les noms de canaux pour aligner les étiquettes de features
    channel_names: Sequence[str] = getattr(epochs.info, "ch_names", [])
    # Extrait les données temporelles pour calculer les caractéristiques spectrales
    data: np.ndarray = epochs.get_data()
    # Récupère la fréquence d'échantillonnage indispensable au calcul fréquentiel
    sfreq: float = float(epochs.info["sfreq"])
    # Construit un extracteur scikit-learn pour déléguer le calcul
    estimator = ExtractFeatures(
        sfreq=sfreq,
        feature_strategy=method,
        normalize=normalize,
        bands=band_ranges,
        strategy_config=effective_config,
    )
    # Calcule les features en déléguant à l'extracteur scikit-learn
    features = estimator.transform(data)
    # Détermine le nombre de bandes pour reconstruire les étiquettes
    n_bands = len(band_ranges)
    # Recompose un tenseur factice pour générer les étiquettes canal/bande
    stacked = features.reshape(features.shape[0], data.shape[1], n_bands)
    # Construit des étiquettes canal_bande pour interpréter les features
    labels: List[str] = _build_labels(stacked, band_ranges, channel_names)
    # Retourne les features tabulaires accompagnés de leurs étiquettes
    return features, labels


def x_extract_features__mutmut_17(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = dict(config or {})
    # Déclare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = {
        "theta": (4.0, 7.0),
        "alpha": (8.0, 12.0),
        "beta": (13.0, 30.0),
        "XXgammaXX": (31.0, 45.0),
    }
    # Fusionne les bandes personnalisées en conservant l'ordre demandé
    band_ranges: Dict[str, Tuple[float, float]] = _resolve_band_ranges(
        effective_config, default_bands
    )
    # Refuse une configuration vide pour éviter un empilement sans bandes
    if not band_ranges:
        raise ValueError("At least one frequency band must be provided.")
    # Récupère la méthode pour aiguiller la stratégie d'extraction
    method: str = effective_config.pop("method", "welch")
    # Permet de contrôler l'activation de la normalisation via la configuration
    normalize = bool(effective_config.pop("normalize", False))
    # Supprime la configuration des bandes pour ne pas dupliquer l'information
    effective_config.pop("bands", None)
    # Capture les noms de canaux pour aligner les étiquettes de features
    channel_names: Sequence[str] = getattr(epochs.info, "ch_names", [])
    # Extrait les données temporelles pour calculer les caractéristiques spectrales
    data: np.ndarray = epochs.get_data()
    # Récupère la fréquence d'échantillonnage indispensable au calcul fréquentiel
    sfreq: float = float(epochs.info["sfreq"])
    # Construit un extracteur scikit-learn pour déléguer le calcul
    estimator = ExtractFeatures(
        sfreq=sfreq,
        feature_strategy=method,
        normalize=normalize,
        bands=band_ranges,
        strategy_config=effective_config,
    )
    # Calcule les features en déléguant à l'extracteur scikit-learn
    features = estimator.transform(data)
    # Détermine le nombre de bandes pour reconstruire les étiquettes
    n_bands = len(band_ranges)
    # Recompose un tenseur factice pour générer les étiquettes canal/bande
    stacked = features.reshape(features.shape[0], data.shape[1], n_bands)
    # Construit des étiquettes canal_bande pour interpréter les features
    labels: List[str] = _build_labels(stacked, band_ranges, channel_names)
    # Retourne les features tabulaires accompagnés de leurs étiquettes
    return features, labels


def x_extract_features__mutmut_18(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = dict(config or {})
    # Déclare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = {
        "theta": (4.0, 7.0),
        "alpha": (8.0, 12.0),
        "beta": (13.0, 30.0),
        "GAMMA": (31.0, 45.0),
    }
    # Fusionne les bandes personnalisées en conservant l'ordre demandé
    band_ranges: Dict[str, Tuple[float, float]] = _resolve_band_ranges(
        effective_config, default_bands
    )
    # Refuse une configuration vide pour éviter un empilement sans bandes
    if not band_ranges:
        raise ValueError("At least one frequency band must be provided.")
    # Récupère la méthode pour aiguiller la stratégie d'extraction
    method: str = effective_config.pop("method", "welch")
    # Permet de contrôler l'activation de la normalisation via la configuration
    normalize = bool(effective_config.pop("normalize", False))
    # Supprime la configuration des bandes pour ne pas dupliquer l'information
    effective_config.pop("bands", None)
    # Capture les noms de canaux pour aligner les étiquettes de features
    channel_names: Sequence[str] = getattr(epochs.info, "ch_names", [])
    # Extrait les données temporelles pour calculer les caractéristiques spectrales
    data: np.ndarray = epochs.get_data()
    # Récupère la fréquence d'échantillonnage indispensable au calcul fréquentiel
    sfreq: float = float(epochs.info["sfreq"])
    # Construit un extracteur scikit-learn pour déléguer le calcul
    estimator = ExtractFeatures(
        sfreq=sfreq,
        feature_strategy=method,
        normalize=normalize,
        bands=band_ranges,
        strategy_config=effective_config,
    )
    # Calcule les features en déléguant à l'extracteur scikit-learn
    features = estimator.transform(data)
    # Détermine le nombre de bandes pour reconstruire les étiquettes
    n_bands = len(band_ranges)
    # Recompose un tenseur factice pour générer les étiquettes canal/bande
    stacked = features.reshape(features.shape[0], data.shape[1], n_bands)
    # Construit des étiquettes canal_bande pour interpréter les features
    labels: List[str] = _build_labels(stacked, band_ranges, channel_names)
    # Retourne les features tabulaires accompagnés de leurs étiquettes
    return features, labels


def x_extract_features__mutmut_19(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = dict(config or {})
    # Déclare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = {
        "theta": (4.0, 7.0),
        "alpha": (8.0, 12.0),
        "beta": (13.0, 30.0),
        "gamma": (32.0, 45.0),
    }
    # Fusionne les bandes personnalisées en conservant l'ordre demandé
    band_ranges: Dict[str, Tuple[float, float]] = _resolve_band_ranges(
        effective_config, default_bands
    )
    # Refuse une configuration vide pour éviter un empilement sans bandes
    if not band_ranges:
        raise ValueError("At least one frequency band must be provided.")
    # Récupère la méthode pour aiguiller la stratégie d'extraction
    method: str = effective_config.pop("method", "welch")
    # Permet de contrôler l'activation de la normalisation via la configuration
    normalize = bool(effective_config.pop("normalize", False))
    # Supprime la configuration des bandes pour ne pas dupliquer l'information
    effective_config.pop("bands", None)
    # Capture les noms de canaux pour aligner les étiquettes de features
    channel_names: Sequence[str] = getattr(epochs.info, "ch_names", [])
    # Extrait les données temporelles pour calculer les caractéristiques spectrales
    data: np.ndarray = epochs.get_data()
    # Récupère la fréquence d'échantillonnage indispensable au calcul fréquentiel
    sfreq: float = float(epochs.info["sfreq"])
    # Construit un extracteur scikit-learn pour déléguer le calcul
    estimator = ExtractFeatures(
        sfreq=sfreq,
        feature_strategy=method,
        normalize=normalize,
        bands=band_ranges,
        strategy_config=effective_config,
    )
    # Calcule les features en déléguant à l'extracteur scikit-learn
    features = estimator.transform(data)
    # Détermine le nombre de bandes pour reconstruire les étiquettes
    n_bands = len(band_ranges)
    # Recompose un tenseur factice pour générer les étiquettes canal/bande
    stacked = features.reshape(features.shape[0], data.shape[1], n_bands)
    # Construit des étiquettes canal_bande pour interpréter les features
    labels: List[str] = _build_labels(stacked, band_ranges, channel_names)
    # Retourne les features tabulaires accompagnés de leurs étiquettes
    return features, labels


def x_extract_features__mutmut_20(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = dict(config or {})
    # Déclare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = {
        "theta": (4.0, 7.0),
        "alpha": (8.0, 12.0),
        "beta": (13.0, 30.0),
        "gamma": (31.0, 46.0),
    }
    # Fusionne les bandes personnalisées en conservant l'ordre demandé
    band_ranges: Dict[str, Tuple[float, float]] = _resolve_band_ranges(
        effective_config, default_bands
    )
    # Refuse une configuration vide pour éviter un empilement sans bandes
    if not band_ranges:
        raise ValueError("At least one frequency band must be provided.")
    # Récupère la méthode pour aiguiller la stratégie d'extraction
    method: str = effective_config.pop("method", "welch")
    # Permet de contrôler l'activation de la normalisation via la configuration
    normalize = bool(effective_config.pop("normalize", False))
    # Supprime la configuration des bandes pour ne pas dupliquer l'information
    effective_config.pop("bands", None)
    # Capture les noms de canaux pour aligner les étiquettes de features
    channel_names: Sequence[str] = getattr(epochs.info, "ch_names", [])
    # Extrait les données temporelles pour calculer les caractéristiques spectrales
    data: np.ndarray = epochs.get_data()
    # Récupère la fréquence d'échantillonnage indispensable au calcul fréquentiel
    sfreq: float = float(epochs.info["sfreq"])
    # Construit un extracteur scikit-learn pour déléguer le calcul
    estimator = ExtractFeatures(
        sfreq=sfreq,
        feature_strategy=method,
        normalize=normalize,
        bands=band_ranges,
        strategy_config=effective_config,
    )
    # Calcule les features en déléguant à l'extracteur scikit-learn
    features = estimator.transform(data)
    # Détermine le nombre de bandes pour reconstruire les étiquettes
    n_bands = len(band_ranges)
    # Recompose un tenseur factice pour générer les étiquettes canal/bande
    stacked = features.reshape(features.shape[0], data.shape[1], n_bands)
    # Construit des étiquettes canal_bande pour interpréter les features
    labels: List[str] = _build_labels(stacked, band_ranges, channel_names)
    # Retourne les features tabulaires accompagnés de leurs étiquettes
    return features, labels


def x_extract_features__mutmut_21(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = dict(config or {})
    # Déclare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = {
        "theta": (4.0, 7.0),
        "alpha": (8.0, 12.0),
        "beta": (13.0, 30.0),
        "gamma": (31.0, 45.0),
    }
    # Fusionne les bandes personnalisées en conservant l'ordre demandé
    band_ranges: Dict[str, Tuple[float, float]] = None
    # Refuse une configuration vide pour éviter un empilement sans bandes
    if not band_ranges:
        raise ValueError("At least one frequency band must be provided.")
    # Récupère la méthode pour aiguiller la stratégie d'extraction
    method: str = effective_config.pop("method", "welch")
    # Permet de contrôler l'activation de la normalisation via la configuration
    normalize = bool(effective_config.pop("normalize", False))
    # Supprime la configuration des bandes pour ne pas dupliquer l'information
    effective_config.pop("bands", None)
    # Capture les noms de canaux pour aligner les étiquettes de features
    channel_names: Sequence[str] = getattr(epochs.info, "ch_names", [])
    # Extrait les données temporelles pour calculer les caractéristiques spectrales
    data: np.ndarray = epochs.get_data()
    # Récupère la fréquence d'échantillonnage indispensable au calcul fréquentiel
    sfreq: float = float(epochs.info["sfreq"])
    # Construit un extracteur scikit-learn pour déléguer le calcul
    estimator = ExtractFeatures(
        sfreq=sfreq,
        feature_strategy=method,
        normalize=normalize,
        bands=band_ranges,
        strategy_config=effective_config,
    )
    # Calcule les features en déléguant à l'extracteur scikit-learn
    features = estimator.transform(data)
    # Détermine le nombre de bandes pour reconstruire les étiquettes
    n_bands = len(band_ranges)
    # Recompose un tenseur factice pour générer les étiquettes canal/bande
    stacked = features.reshape(features.shape[0], data.shape[1], n_bands)
    # Construit des étiquettes canal_bande pour interpréter les features
    labels: List[str] = _build_labels(stacked, band_ranges, channel_names)
    # Retourne les features tabulaires accompagnés de leurs étiquettes
    return features, labels


def x_extract_features__mutmut_22(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = dict(config or {})
    # Déclare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = {
        "theta": (4.0, 7.0),
        "alpha": (8.0, 12.0),
        "beta": (13.0, 30.0),
        "gamma": (31.0, 45.0),
    }
    # Fusionne les bandes personnalisées en conservant l'ordre demandé
    band_ranges: Dict[str, Tuple[float, float]] = _resolve_band_ranges(
        None, default_bands
    )
    # Refuse une configuration vide pour éviter un empilement sans bandes
    if not band_ranges:
        raise ValueError("At least one frequency band must be provided.")
    # Récupère la méthode pour aiguiller la stratégie d'extraction
    method: str = effective_config.pop("method", "welch")
    # Permet de contrôler l'activation de la normalisation via la configuration
    normalize = bool(effective_config.pop("normalize", False))
    # Supprime la configuration des bandes pour ne pas dupliquer l'information
    effective_config.pop("bands", None)
    # Capture les noms de canaux pour aligner les étiquettes de features
    channel_names: Sequence[str] = getattr(epochs.info, "ch_names", [])
    # Extrait les données temporelles pour calculer les caractéristiques spectrales
    data: np.ndarray = epochs.get_data()
    # Récupère la fréquence d'échantillonnage indispensable au calcul fréquentiel
    sfreq: float = float(epochs.info["sfreq"])
    # Construit un extracteur scikit-learn pour déléguer le calcul
    estimator = ExtractFeatures(
        sfreq=sfreq,
        feature_strategy=method,
        normalize=normalize,
        bands=band_ranges,
        strategy_config=effective_config,
    )
    # Calcule les features en déléguant à l'extracteur scikit-learn
    features = estimator.transform(data)
    # Détermine le nombre de bandes pour reconstruire les étiquettes
    n_bands = len(band_ranges)
    # Recompose un tenseur factice pour générer les étiquettes canal/bande
    stacked = features.reshape(features.shape[0], data.shape[1], n_bands)
    # Construit des étiquettes canal_bande pour interpréter les features
    labels: List[str] = _build_labels(stacked, band_ranges, channel_names)
    # Retourne les features tabulaires accompagnés de leurs étiquettes
    return features, labels


def x_extract_features__mutmut_23(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = dict(config or {})
    # Déclare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = {
        "theta": (4.0, 7.0),
        "alpha": (8.0, 12.0),
        "beta": (13.0, 30.0),
        "gamma": (31.0, 45.0),
    }
    # Fusionne les bandes personnalisées en conservant l'ordre demandé
    band_ranges: Dict[str, Tuple[float, float]] = _resolve_band_ranges(
        effective_config, None
    )
    # Refuse une configuration vide pour éviter un empilement sans bandes
    if not band_ranges:
        raise ValueError("At least one frequency band must be provided.")
    # Récupère la méthode pour aiguiller la stratégie d'extraction
    method: str = effective_config.pop("method", "welch")
    # Permet de contrôler l'activation de la normalisation via la configuration
    normalize = bool(effective_config.pop("normalize", False))
    # Supprime la configuration des bandes pour ne pas dupliquer l'information
    effective_config.pop("bands", None)
    # Capture les noms de canaux pour aligner les étiquettes de features
    channel_names: Sequence[str] = getattr(epochs.info, "ch_names", [])
    # Extrait les données temporelles pour calculer les caractéristiques spectrales
    data: np.ndarray = epochs.get_data()
    # Récupère la fréquence d'échantillonnage indispensable au calcul fréquentiel
    sfreq: float = float(epochs.info["sfreq"])
    # Construit un extracteur scikit-learn pour déléguer le calcul
    estimator = ExtractFeatures(
        sfreq=sfreq,
        feature_strategy=method,
        normalize=normalize,
        bands=band_ranges,
        strategy_config=effective_config,
    )
    # Calcule les features en déléguant à l'extracteur scikit-learn
    features = estimator.transform(data)
    # Détermine le nombre de bandes pour reconstruire les étiquettes
    n_bands = len(band_ranges)
    # Recompose un tenseur factice pour générer les étiquettes canal/bande
    stacked = features.reshape(features.shape[0], data.shape[1], n_bands)
    # Construit des étiquettes canal_bande pour interpréter les features
    labels: List[str] = _build_labels(stacked, band_ranges, channel_names)
    # Retourne les features tabulaires accompagnés de leurs étiquettes
    return features, labels


def x_extract_features__mutmut_24(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = dict(config or {})
    # Déclare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = {
        "theta": (4.0, 7.0),
        "alpha": (8.0, 12.0),
        "beta": (13.0, 30.0),
        "gamma": (31.0, 45.0),
    }
    # Fusionne les bandes personnalisées en conservant l'ordre demandé
    band_ranges: Dict[str, Tuple[float, float]] = _resolve_band_ranges(
        default_bands
    )
    # Refuse une configuration vide pour éviter un empilement sans bandes
    if not band_ranges:
        raise ValueError("At least one frequency band must be provided.")
    # Récupère la méthode pour aiguiller la stratégie d'extraction
    method: str = effective_config.pop("method", "welch")
    # Permet de contrôler l'activation de la normalisation via la configuration
    normalize = bool(effective_config.pop("normalize", False))
    # Supprime la configuration des bandes pour ne pas dupliquer l'information
    effective_config.pop("bands", None)
    # Capture les noms de canaux pour aligner les étiquettes de features
    channel_names: Sequence[str] = getattr(epochs.info, "ch_names", [])
    # Extrait les données temporelles pour calculer les caractéristiques spectrales
    data: np.ndarray = epochs.get_data()
    # Récupère la fréquence d'échantillonnage indispensable au calcul fréquentiel
    sfreq: float = float(epochs.info["sfreq"])
    # Construit un extracteur scikit-learn pour déléguer le calcul
    estimator = ExtractFeatures(
        sfreq=sfreq,
        feature_strategy=method,
        normalize=normalize,
        bands=band_ranges,
        strategy_config=effective_config,
    )
    # Calcule les features en déléguant à l'extracteur scikit-learn
    features = estimator.transform(data)
    # Détermine le nombre de bandes pour reconstruire les étiquettes
    n_bands = len(band_ranges)
    # Recompose un tenseur factice pour générer les étiquettes canal/bande
    stacked = features.reshape(features.shape[0], data.shape[1], n_bands)
    # Construit des étiquettes canal_bande pour interpréter les features
    labels: List[str] = _build_labels(stacked, band_ranges, channel_names)
    # Retourne les features tabulaires accompagnés de leurs étiquettes
    return features, labels


def x_extract_features__mutmut_25(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = dict(config or {})
    # Déclare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = {
        "theta": (4.0, 7.0),
        "alpha": (8.0, 12.0),
        "beta": (13.0, 30.0),
        "gamma": (31.0, 45.0),
    }
    # Fusionne les bandes personnalisées en conservant l'ordre demandé
    band_ranges: Dict[str, Tuple[float, float]] = _resolve_band_ranges(
        effective_config, )
    # Refuse une configuration vide pour éviter un empilement sans bandes
    if not band_ranges:
        raise ValueError("At least one frequency band must be provided.")
    # Récupère la méthode pour aiguiller la stratégie d'extraction
    method: str = effective_config.pop("method", "welch")
    # Permet de contrôler l'activation de la normalisation via la configuration
    normalize = bool(effective_config.pop("normalize", False))
    # Supprime la configuration des bandes pour ne pas dupliquer l'information
    effective_config.pop("bands", None)
    # Capture les noms de canaux pour aligner les étiquettes de features
    channel_names: Sequence[str] = getattr(epochs.info, "ch_names", [])
    # Extrait les données temporelles pour calculer les caractéristiques spectrales
    data: np.ndarray = epochs.get_data()
    # Récupère la fréquence d'échantillonnage indispensable au calcul fréquentiel
    sfreq: float = float(epochs.info["sfreq"])
    # Construit un extracteur scikit-learn pour déléguer le calcul
    estimator = ExtractFeatures(
        sfreq=sfreq,
        feature_strategy=method,
        normalize=normalize,
        bands=band_ranges,
        strategy_config=effective_config,
    )
    # Calcule les features en déléguant à l'extracteur scikit-learn
    features = estimator.transform(data)
    # Détermine le nombre de bandes pour reconstruire les étiquettes
    n_bands = len(band_ranges)
    # Recompose un tenseur factice pour générer les étiquettes canal/bande
    stacked = features.reshape(features.shape[0], data.shape[1], n_bands)
    # Construit des étiquettes canal_bande pour interpréter les features
    labels: List[str] = _build_labels(stacked, band_ranges, channel_names)
    # Retourne les features tabulaires accompagnés de leurs étiquettes
    return features, labels


def x_extract_features__mutmut_26(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = dict(config or {})
    # Déclare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = {
        "theta": (4.0, 7.0),
        "alpha": (8.0, 12.0),
        "beta": (13.0, 30.0),
        "gamma": (31.0, 45.0),
    }
    # Fusionne les bandes personnalisées en conservant l'ordre demandé
    band_ranges: Dict[str, Tuple[float, float]] = _resolve_band_ranges(
        effective_config, default_bands
    )
    # Refuse une configuration vide pour éviter un empilement sans bandes
    if band_ranges:
        raise ValueError("At least one frequency band must be provided.")
    # Récupère la méthode pour aiguiller la stratégie d'extraction
    method: str = effective_config.pop("method", "welch")
    # Permet de contrôler l'activation de la normalisation via la configuration
    normalize = bool(effective_config.pop("normalize", False))
    # Supprime la configuration des bandes pour ne pas dupliquer l'information
    effective_config.pop("bands", None)
    # Capture les noms de canaux pour aligner les étiquettes de features
    channel_names: Sequence[str] = getattr(epochs.info, "ch_names", [])
    # Extrait les données temporelles pour calculer les caractéristiques spectrales
    data: np.ndarray = epochs.get_data()
    # Récupère la fréquence d'échantillonnage indispensable au calcul fréquentiel
    sfreq: float = float(epochs.info["sfreq"])
    # Construit un extracteur scikit-learn pour déléguer le calcul
    estimator = ExtractFeatures(
        sfreq=sfreq,
        feature_strategy=method,
        normalize=normalize,
        bands=band_ranges,
        strategy_config=effective_config,
    )
    # Calcule les features en déléguant à l'extracteur scikit-learn
    features = estimator.transform(data)
    # Détermine le nombre de bandes pour reconstruire les étiquettes
    n_bands = len(band_ranges)
    # Recompose un tenseur factice pour générer les étiquettes canal/bande
    stacked = features.reshape(features.shape[0], data.shape[1], n_bands)
    # Construit des étiquettes canal_bande pour interpréter les features
    labels: List[str] = _build_labels(stacked, band_ranges, channel_names)
    # Retourne les features tabulaires accompagnés de leurs étiquettes
    return features, labels


def x_extract_features__mutmut_27(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = dict(config or {})
    # Déclare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = {
        "theta": (4.0, 7.0),
        "alpha": (8.0, 12.0),
        "beta": (13.0, 30.0),
        "gamma": (31.0, 45.0),
    }
    # Fusionne les bandes personnalisées en conservant l'ordre demandé
    band_ranges: Dict[str, Tuple[float, float]] = _resolve_band_ranges(
        effective_config, default_bands
    )
    # Refuse une configuration vide pour éviter un empilement sans bandes
    if not band_ranges:
        raise ValueError(None)
    # Récupère la méthode pour aiguiller la stratégie d'extraction
    method: str = effective_config.pop("method", "welch")
    # Permet de contrôler l'activation de la normalisation via la configuration
    normalize = bool(effective_config.pop("normalize", False))
    # Supprime la configuration des bandes pour ne pas dupliquer l'information
    effective_config.pop("bands", None)
    # Capture les noms de canaux pour aligner les étiquettes de features
    channel_names: Sequence[str] = getattr(epochs.info, "ch_names", [])
    # Extrait les données temporelles pour calculer les caractéristiques spectrales
    data: np.ndarray = epochs.get_data()
    # Récupère la fréquence d'échantillonnage indispensable au calcul fréquentiel
    sfreq: float = float(epochs.info["sfreq"])
    # Construit un extracteur scikit-learn pour déléguer le calcul
    estimator = ExtractFeatures(
        sfreq=sfreq,
        feature_strategy=method,
        normalize=normalize,
        bands=band_ranges,
        strategy_config=effective_config,
    )
    # Calcule les features en déléguant à l'extracteur scikit-learn
    features = estimator.transform(data)
    # Détermine le nombre de bandes pour reconstruire les étiquettes
    n_bands = len(band_ranges)
    # Recompose un tenseur factice pour générer les étiquettes canal/bande
    stacked = features.reshape(features.shape[0], data.shape[1], n_bands)
    # Construit des étiquettes canal_bande pour interpréter les features
    labels: List[str] = _build_labels(stacked, band_ranges, channel_names)
    # Retourne les features tabulaires accompagnés de leurs étiquettes
    return features, labels


def x_extract_features__mutmut_28(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = dict(config or {})
    # Déclare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = {
        "theta": (4.0, 7.0),
        "alpha": (8.0, 12.0),
        "beta": (13.0, 30.0),
        "gamma": (31.0, 45.0),
    }
    # Fusionne les bandes personnalisées en conservant l'ordre demandé
    band_ranges: Dict[str, Tuple[float, float]] = _resolve_band_ranges(
        effective_config, default_bands
    )
    # Refuse une configuration vide pour éviter un empilement sans bandes
    if not band_ranges:
        raise ValueError("XXAt least one frequency band must be provided.XX")
    # Récupère la méthode pour aiguiller la stratégie d'extraction
    method: str = effective_config.pop("method", "welch")
    # Permet de contrôler l'activation de la normalisation via la configuration
    normalize = bool(effective_config.pop("normalize", False))
    # Supprime la configuration des bandes pour ne pas dupliquer l'information
    effective_config.pop("bands", None)
    # Capture les noms de canaux pour aligner les étiquettes de features
    channel_names: Sequence[str] = getattr(epochs.info, "ch_names", [])
    # Extrait les données temporelles pour calculer les caractéristiques spectrales
    data: np.ndarray = epochs.get_data()
    # Récupère la fréquence d'échantillonnage indispensable au calcul fréquentiel
    sfreq: float = float(epochs.info["sfreq"])
    # Construit un extracteur scikit-learn pour déléguer le calcul
    estimator = ExtractFeatures(
        sfreq=sfreq,
        feature_strategy=method,
        normalize=normalize,
        bands=band_ranges,
        strategy_config=effective_config,
    )
    # Calcule les features en déléguant à l'extracteur scikit-learn
    features = estimator.transform(data)
    # Détermine le nombre de bandes pour reconstruire les étiquettes
    n_bands = len(band_ranges)
    # Recompose un tenseur factice pour générer les étiquettes canal/bande
    stacked = features.reshape(features.shape[0], data.shape[1], n_bands)
    # Construit des étiquettes canal_bande pour interpréter les features
    labels: List[str] = _build_labels(stacked, band_ranges, channel_names)
    # Retourne les features tabulaires accompagnés de leurs étiquettes
    return features, labels


def x_extract_features__mutmut_29(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = dict(config or {})
    # Déclare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = {
        "theta": (4.0, 7.0),
        "alpha": (8.0, 12.0),
        "beta": (13.0, 30.0),
        "gamma": (31.0, 45.0),
    }
    # Fusionne les bandes personnalisées en conservant l'ordre demandé
    band_ranges: Dict[str, Tuple[float, float]] = _resolve_band_ranges(
        effective_config, default_bands
    )
    # Refuse une configuration vide pour éviter un empilement sans bandes
    if not band_ranges:
        raise ValueError("at least one frequency band must be provided.")
    # Récupère la méthode pour aiguiller la stratégie d'extraction
    method: str = effective_config.pop("method", "welch")
    # Permet de contrôler l'activation de la normalisation via la configuration
    normalize = bool(effective_config.pop("normalize", False))
    # Supprime la configuration des bandes pour ne pas dupliquer l'information
    effective_config.pop("bands", None)
    # Capture les noms de canaux pour aligner les étiquettes de features
    channel_names: Sequence[str] = getattr(epochs.info, "ch_names", [])
    # Extrait les données temporelles pour calculer les caractéristiques spectrales
    data: np.ndarray = epochs.get_data()
    # Récupère la fréquence d'échantillonnage indispensable au calcul fréquentiel
    sfreq: float = float(epochs.info["sfreq"])
    # Construit un extracteur scikit-learn pour déléguer le calcul
    estimator = ExtractFeatures(
        sfreq=sfreq,
        feature_strategy=method,
        normalize=normalize,
        bands=band_ranges,
        strategy_config=effective_config,
    )
    # Calcule les features en déléguant à l'extracteur scikit-learn
    features = estimator.transform(data)
    # Détermine le nombre de bandes pour reconstruire les étiquettes
    n_bands = len(band_ranges)
    # Recompose un tenseur factice pour générer les étiquettes canal/bande
    stacked = features.reshape(features.shape[0], data.shape[1], n_bands)
    # Construit des étiquettes canal_bande pour interpréter les features
    labels: List[str] = _build_labels(stacked, band_ranges, channel_names)
    # Retourne les features tabulaires accompagnés de leurs étiquettes
    return features, labels


def x_extract_features__mutmut_30(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = dict(config or {})
    # Déclare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = {
        "theta": (4.0, 7.0),
        "alpha": (8.0, 12.0),
        "beta": (13.0, 30.0),
        "gamma": (31.0, 45.0),
    }
    # Fusionne les bandes personnalisées en conservant l'ordre demandé
    band_ranges: Dict[str, Tuple[float, float]] = _resolve_band_ranges(
        effective_config, default_bands
    )
    # Refuse une configuration vide pour éviter un empilement sans bandes
    if not band_ranges:
        raise ValueError("AT LEAST ONE FREQUENCY BAND MUST BE PROVIDED.")
    # Récupère la méthode pour aiguiller la stratégie d'extraction
    method: str = effective_config.pop("method", "welch")
    # Permet de contrôler l'activation de la normalisation via la configuration
    normalize = bool(effective_config.pop("normalize", False))
    # Supprime la configuration des bandes pour ne pas dupliquer l'information
    effective_config.pop("bands", None)
    # Capture les noms de canaux pour aligner les étiquettes de features
    channel_names: Sequence[str] = getattr(epochs.info, "ch_names", [])
    # Extrait les données temporelles pour calculer les caractéristiques spectrales
    data: np.ndarray = epochs.get_data()
    # Récupère la fréquence d'échantillonnage indispensable au calcul fréquentiel
    sfreq: float = float(epochs.info["sfreq"])
    # Construit un extracteur scikit-learn pour déléguer le calcul
    estimator = ExtractFeatures(
        sfreq=sfreq,
        feature_strategy=method,
        normalize=normalize,
        bands=band_ranges,
        strategy_config=effective_config,
    )
    # Calcule les features en déléguant à l'extracteur scikit-learn
    features = estimator.transform(data)
    # Détermine le nombre de bandes pour reconstruire les étiquettes
    n_bands = len(band_ranges)
    # Recompose un tenseur factice pour générer les étiquettes canal/bande
    stacked = features.reshape(features.shape[0], data.shape[1], n_bands)
    # Construit des étiquettes canal_bande pour interpréter les features
    labels: List[str] = _build_labels(stacked, band_ranges, channel_names)
    # Retourne les features tabulaires accompagnés de leurs étiquettes
    return features, labels


def x_extract_features__mutmut_31(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = dict(config or {})
    # Déclare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = {
        "theta": (4.0, 7.0),
        "alpha": (8.0, 12.0),
        "beta": (13.0, 30.0),
        "gamma": (31.0, 45.0),
    }
    # Fusionne les bandes personnalisées en conservant l'ordre demandé
    band_ranges: Dict[str, Tuple[float, float]] = _resolve_band_ranges(
        effective_config, default_bands
    )
    # Refuse une configuration vide pour éviter un empilement sans bandes
    if not band_ranges:
        raise ValueError("At least one frequency band must be provided.")
    # Récupère la méthode pour aiguiller la stratégie d'extraction
    method: str = None
    # Permet de contrôler l'activation de la normalisation via la configuration
    normalize = bool(effective_config.pop("normalize", False))
    # Supprime la configuration des bandes pour ne pas dupliquer l'information
    effective_config.pop("bands", None)
    # Capture les noms de canaux pour aligner les étiquettes de features
    channel_names: Sequence[str] = getattr(epochs.info, "ch_names", [])
    # Extrait les données temporelles pour calculer les caractéristiques spectrales
    data: np.ndarray = epochs.get_data()
    # Récupère la fréquence d'échantillonnage indispensable au calcul fréquentiel
    sfreq: float = float(epochs.info["sfreq"])
    # Construit un extracteur scikit-learn pour déléguer le calcul
    estimator = ExtractFeatures(
        sfreq=sfreq,
        feature_strategy=method,
        normalize=normalize,
        bands=band_ranges,
        strategy_config=effective_config,
    )
    # Calcule les features en déléguant à l'extracteur scikit-learn
    features = estimator.transform(data)
    # Détermine le nombre de bandes pour reconstruire les étiquettes
    n_bands = len(band_ranges)
    # Recompose un tenseur factice pour générer les étiquettes canal/bande
    stacked = features.reshape(features.shape[0], data.shape[1], n_bands)
    # Construit des étiquettes canal_bande pour interpréter les features
    labels: List[str] = _build_labels(stacked, band_ranges, channel_names)
    # Retourne les features tabulaires accompagnés de leurs étiquettes
    return features, labels


def x_extract_features__mutmut_32(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = dict(config or {})
    # Déclare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = {
        "theta": (4.0, 7.0),
        "alpha": (8.0, 12.0),
        "beta": (13.0, 30.0),
        "gamma": (31.0, 45.0),
    }
    # Fusionne les bandes personnalisées en conservant l'ordre demandé
    band_ranges: Dict[str, Tuple[float, float]] = _resolve_band_ranges(
        effective_config, default_bands
    )
    # Refuse une configuration vide pour éviter un empilement sans bandes
    if not band_ranges:
        raise ValueError("At least one frequency band must be provided.")
    # Récupère la méthode pour aiguiller la stratégie d'extraction
    method: str = effective_config.pop(None, "welch")
    # Permet de contrôler l'activation de la normalisation via la configuration
    normalize = bool(effective_config.pop("normalize", False))
    # Supprime la configuration des bandes pour ne pas dupliquer l'information
    effective_config.pop("bands", None)
    # Capture les noms de canaux pour aligner les étiquettes de features
    channel_names: Sequence[str] = getattr(epochs.info, "ch_names", [])
    # Extrait les données temporelles pour calculer les caractéristiques spectrales
    data: np.ndarray = epochs.get_data()
    # Récupère la fréquence d'échantillonnage indispensable au calcul fréquentiel
    sfreq: float = float(epochs.info["sfreq"])
    # Construit un extracteur scikit-learn pour déléguer le calcul
    estimator = ExtractFeatures(
        sfreq=sfreq,
        feature_strategy=method,
        normalize=normalize,
        bands=band_ranges,
        strategy_config=effective_config,
    )
    # Calcule les features en déléguant à l'extracteur scikit-learn
    features = estimator.transform(data)
    # Détermine le nombre de bandes pour reconstruire les étiquettes
    n_bands = len(band_ranges)
    # Recompose un tenseur factice pour générer les étiquettes canal/bande
    stacked = features.reshape(features.shape[0], data.shape[1], n_bands)
    # Construit des étiquettes canal_bande pour interpréter les features
    labels: List[str] = _build_labels(stacked, band_ranges, channel_names)
    # Retourne les features tabulaires accompagnés de leurs étiquettes
    return features, labels


def x_extract_features__mutmut_33(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = dict(config or {})
    # Déclare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = {
        "theta": (4.0, 7.0),
        "alpha": (8.0, 12.0),
        "beta": (13.0, 30.0),
        "gamma": (31.0, 45.0),
    }
    # Fusionne les bandes personnalisées en conservant l'ordre demandé
    band_ranges: Dict[str, Tuple[float, float]] = _resolve_band_ranges(
        effective_config, default_bands
    )
    # Refuse une configuration vide pour éviter un empilement sans bandes
    if not band_ranges:
        raise ValueError("At least one frequency band must be provided.")
    # Récupère la méthode pour aiguiller la stratégie d'extraction
    method: str = effective_config.pop("method", None)
    # Permet de contrôler l'activation de la normalisation via la configuration
    normalize = bool(effective_config.pop("normalize", False))
    # Supprime la configuration des bandes pour ne pas dupliquer l'information
    effective_config.pop("bands", None)
    # Capture les noms de canaux pour aligner les étiquettes de features
    channel_names: Sequence[str] = getattr(epochs.info, "ch_names", [])
    # Extrait les données temporelles pour calculer les caractéristiques spectrales
    data: np.ndarray = epochs.get_data()
    # Récupère la fréquence d'échantillonnage indispensable au calcul fréquentiel
    sfreq: float = float(epochs.info["sfreq"])
    # Construit un extracteur scikit-learn pour déléguer le calcul
    estimator = ExtractFeatures(
        sfreq=sfreq,
        feature_strategy=method,
        normalize=normalize,
        bands=band_ranges,
        strategy_config=effective_config,
    )
    # Calcule les features en déléguant à l'extracteur scikit-learn
    features = estimator.transform(data)
    # Détermine le nombre de bandes pour reconstruire les étiquettes
    n_bands = len(band_ranges)
    # Recompose un tenseur factice pour générer les étiquettes canal/bande
    stacked = features.reshape(features.shape[0], data.shape[1], n_bands)
    # Construit des étiquettes canal_bande pour interpréter les features
    labels: List[str] = _build_labels(stacked, band_ranges, channel_names)
    # Retourne les features tabulaires accompagnés de leurs étiquettes
    return features, labels


def x_extract_features__mutmut_34(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = dict(config or {})
    # Déclare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = {
        "theta": (4.0, 7.0),
        "alpha": (8.0, 12.0),
        "beta": (13.0, 30.0),
        "gamma": (31.0, 45.0),
    }
    # Fusionne les bandes personnalisées en conservant l'ordre demandé
    band_ranges: Dict[str, Tuple[float, float]] = _resolve_band_ranges(
        effective_config, default_bands
    )
    # Refuse une configuration vide pour éviter un empilement sans bandes
    if not band_ranges:
        raise ValueError("At least one frequency band must be provided.")
    # Récupère la méthode pour aiguiller la stratégie d'extraction
    method: str = effective_config.pop("welch")
    # Permet de contrôler l'activation de la normalisation via la configuration
    normalize = bool(effective_config.pop("normalize", False))
    # Supprime la configuration des bandes pour ne pas dupliquer l'information
    effective_config.pop("bands", None)
    # Capture les noms de canaux pour aligner les étiquettes de features
    channel_names: Sequence[str] = getattr(epochs.info, "ch_names", [])
    # Extrait les données temporelles pour calculer les caractéristiques spectrales
    data: np.ndarray = epochs.get_data()
    # Récupère la fréquence d'échantillonnage indispensable au calcul fréquentiel
    sfreq: float = float(epochs.info["sfreq"])
    # Construit un extracteur scikit-learn pour déléguer le calcul
    estimator = ExtractFeatures(
        sfreq=sfreq,
        feature_strategy=method,
        normalize=normalize,
        bands=band_ranges,
        strategy_config=effective_config,
    )
    # Calcule les features en déléguant à l'extracteur scikit-learn
    features = estimator.transform(data)
    # Détermine le nombre de bandes pour reconstruire les étiquettes
    n_bands = len(band_ranges)
    # Recompose un tenseur factice pour générer les étiquettes canal/bande
    stacked = features.reshape(features.shape[0], data.shape[1], n_bands)
    # Construit des étiquettes canal_bande pour interpréter les features
    labels: List[str] = _build_labels(stacked, band_ranges, channel_names)
    # Retourne les features tabulaires accompagnés de leurs étiquettes
    return features, labels


def x_extract_features__mutmut_35(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = dict(config or {})
    # Déclare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = {
        "theta": (4.0, 7.0),
        "alpha": (8.0, 12.0),
        "beta": (13.0, 30.0),
        "gamma": (31.0, 45.0),
    }
    # Fusionne les bandes personnalisées en conservant l'ordre demandé
    band_ranges: Dict[str, Tuple[float, float]] = _resolve_band_ranges(
        effective_config, default_bands
    )
    # Refuse une configuration vide pour éviter un empilement sans bandes
    if not band_ranges:
        raise ValueError("At least one frequency band must be provided.")
    # Récupère la méthode pour aiguiller la stratégie d'extraction
    method: str = effective_config.pop("method", )
    # Permet de contrôler l'activation de la normalisation via la configuration
    normalize = bool(effective_config.pop("normalize", False))
    # Supprime la configuration des bandes pour ne pas dupliquer l'information
    effective_config.pop("bands", None)
    # Capture les noms de canaux pour aligner les étiquettes de features
    channel_names: Sequence[str] = getattr(epochs.info, "ch_names", [])
    # Extrait les données temporelles pour calculer les caractéristiques spectrales
    data: np.ndarray = epochs.get_data()
    # Récupère la fréquence d'échantillonnage indispensable au calcul fréquentiel
    sfreq: float = float(epochs.info["sfreq"])
    # Construit un extracteur scikit-learn pour déléguer le calcul
    estimator = ExtractFeatures(
        sfreq=sfreq,
        feature_strategy=method,
        normalize=normalize,
        bands=band_ranges,
        strategy_config=effective_config,
    )
    # Calcule les features en déléguant à l'extracteur scikit-learn
    features = estimator.transform(data)
    # Détermine le nombre de bandes pour reconstruire les étiquettes
    n_bands = len(band_ranges)
    # Recompose un tenseur factice pour générer les étiquettes canal/bande
    stacked = features.reshape(features.shape[0], data.shape[1], n_bands)
    # Construit des étiquettes canal_bande pour interpréter les features
    labels: List[str] = _build_labels(stacked, band_ranges, channel_names)
    # Retourne les features tabulaires accompagnés de leurs étiquettes
    return features, labels


def x_extract_features__mutmut_36(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = dict(config or {})
    # Déclare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = {
        "theta": (4.0, 7.0),
        "alpha": (8.0, 12.0),
        "beta": (13.0, 30.0),
        "gamma": (31.0, 45.0),
    }
    # Fusionne les bandes personnalisées en conservant l'ordre demandé
    band_ranges: Dict[str, Tuple[float, float]] = _resolve_band_ranges(
        effective_config, default_bands
    )
    # Refuse une configuration vide pour éviter un empilement sans bandes
    if not band_ranges:
        raise ValueError("At least one frequency band must be provided.")
    # Récupère la méthode pour aiguiller la stratégie d'extraction
    method: str = effective_config.pop("XXmethodXX", "welch")
    # Permet de contrôler l'activation de la normalisation via la configuration
    normalize = bool(effective_config.pop("normalize", False))
    # Supprime la configuration des bandes pour ne pas dupliquer l'information
    effective_config.pop("bands", None)
    # Capture les noms de canaux pour aligner les étiquettes de features
    channel_names: Sequence[str] = getattr(epochs.info, "ch_names", [])
    # Extrait les données temporelles pour calculer les caractéristiques spectrales
    data: np.ndarray = epochs.get_data()
    # Récupère la fréquence d'échantillonnage indispensable au calcul fréquentiel
    sfreq: float = float(epochs.info["sfreq"])
    # Construit un extracteur scikit-learn pour déléguer le calcul
    estimator = ExtractFeatures(
        sfreq=sfreq,
        feature_strategy=method,
        normalize=normalize,
        bands=band_ranges,
        strategy_config=effective_config,
    )
    # Calcule les features en déléguant à l'extracteur scikit-learn
    features = estimator.transform(data)
    # Détermine le nombre de bandes pour reconstruire les étiquettes
    n_bands = len(band_ranges)
    # Recompose un tenseur factice pour générer les étiquettes canal/bande
    stacked = features.reshape(features.shape[0], data.shape[1], n_bands)
    # Construit des étiquettes canal_bande pour interpréter les features
    labels: List[str] = _build_labels(stacked, band_ranges, channel_names)
    # Retourne les features tabulaires accompagnés de leurs étiquettes
    return features, labels


def x_extract_features__mutmut_37(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = dict(config or {})
    # Déclare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = {
        "theta": (4.0, 7.0),
        "alpha": (8.0, 12.0),
        "beta": (13.0, 30.0),
        "gamma": (31.0, 45.0),
    }
    # Fusionne les bandes personnalisées en conservant l'ordre demandé
    band_ranges: Dict[str, Tuple[float, float]] = _resolve_band_ranges(
        effective_config, default_bands
    )
    # Refuse une configuration vide pour éviter un empilement sans bandes
    if not band_ranges:
        raise ValueError("At least one frequency band must be provided.")
    # Récupère la méthode pour aiguiller la stratégie d'extraction
    method: str = effective_config.pop("METHOD", "welch")
    # Permet de contrôler l'activation de la normalisation via la configuration
    normalize = bool(effective_config.pop("normalize", False))
    # Supprime la configuration des bandes pour ne pas dupliquer l'information
    effective_config.pop("bands", None)
    # Capture les noms de canaux pour aligner les étiquettes de features
    channel_names: Sequence[str] = getattr(epochs.info, "ch_names", [])
    # Extrait les données temporelles pour calculer les caractéristiques spectrales
    data: np.ndarray = epochs.get_data()
    # Récupère la fréquence d'échantillonnage indispensable au calcul fréquentiel
    sfreq: float = float(epochs.info["sfreq"])
    # Construit un extracteur scikit-learn pour déléguer le calcul
    estimator = ExtractFeatures(
        sfreq=sfreq,
        feature_strategy=method,
        normalize=normalize,
        bands=band_ranges,
        strategy_config=effective_config,
    )
    # Calcule les features en déléguant à l'extracteur scikit-learn
    features = estimator.transform(data)
    # Détermine le nombre de bandes pour reconstruire les étiquettes
    n_bands = len(band_ranges)
    # Recompose un tenseur factice pour générer les étiquettes canal/bande
    stacked = features.reshape(features.shape[0], data.shape[1], n_bands)
    # Construit des étiquettes canal_bande pour interpréter les features
    labels: List[str] = _build_labels(stacked, band_ranges, channel_names)
    # Retourne les features tabulaires accompagnés de leurs étiquettes
    return features, labels


def x_extract_features__mutmut_38(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = dict(config or {})
    # Déclare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = {
        "theta": (4.0, 7.0),
        "alpha": (8.0, 12.0),
        "beta": (13.0, 30.0),
        "gamma": (31.0, 45.0),
    }
    # Fusionne les bandes personnalisées en conservant l'ordre demandé
    band_ranges: Dict[str, Tuple[float, float]] = _resolve_band_ranges(
        effective_config, default_bands
    )
    # Refuse une configuration vide pour éviter un empilement sans bandes
    if not band_ranges:
        raise ValueError("At least one frequency band must be provided.")
    # Récupère la méthode pour aiguiller la stratégie d'extraction
    method: str = effective_config.pop("method", "XXwelchXX")
    # Permet de contrôler l'activation de la normalisation via la configuration
    normalize = bool(effective_config.pop("normalize", False))
    # Supprime la configuration des bandes pour ne pas dupliquer l'information
    effective_config.pop("bands", None)
    # Capture les noms de canaux pour aligner les étiquettes de features
    channel_names: Sequence[str] = getattr(epochs.info, "ch_names", [])
    # Extrait les données temporelles pour calculer les caractéristiques spectrales
    data: np.ndarray = epochs.get_data()
    # Récupère la fréquence d'échantillonnage indispensable au calcul fréquentiel
    sfreq: float = float(epochs.info["sfreq"])
    # Construit un extracteur scikit-learn pour déléguer le calcul
    estimator = ExtractFeatures(
        sfreq=sfreq,
        feature_strategy=method,
        normalize=normalize,
        bands=band_ranges,
        strategy_config=effective_config,
    )
    # Calcule les features en déléguant à l'extracteur scikit-learn
    features = estimator.transform(data)
    # Détermine le nombre de bandes pour reconstruire les étiquettes
    n_bands = len(band_ranges)
    # Recompose un tenseur factice pour générer les étiquettes canal/bande
    stacked = features.reshape(features.shape[0], data.shape[1], n_bands)
    # Construit des étiquettes canal_bande pour interpréter les features
    labels: List[str] = _build_labels(stacked, band_ranges, channel_names)
    # Retourne les features tabulaires accompagnés de leurs étiquettes
    return features, labels


def x_extract_features__mutmut_39(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = dict(config or {})
    # Déclare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = {
        "theta": (4.0, 7.0),
        "alpha": (8.0, 12.0),
        "beta": (13.0, 30.0),
        "gamma": (31.0, 45.0),
    }
    # Fusionne les bandes personnalisées en conservant l'ordre demandé
    band_ranges: Dict[str, Tuple[float, float]] = _resolve_band_ranges(
        effective_config, default_bands
    )
    # Refuse une configuration vide pour éviter un empilement sans bandes
    if not band_ranges:
        raise ValueError("At least one frequency band must be provided.")
    # Récupère la méthode pour aiguiller la stratégie d'extraction
    method: str = effective_config.pop("method", "WELCH")
    # Permet de contrôler l'activation de la normalisation via la configuration
    normalize = bool(effective_config.pop("normalize", False))
    # Supprime la configuration des bandes pour ne pas dupliquer l'information
    effective_config.pop("bands", None)
    # Capture les noms de canaux pour aligner les étiquettes de features
    channel_names: Sequence[str] = getattr(epochs.info, "ch_names", [])
    # Extrait les données temporelles pour calculer les caractéristiques spectrales
    data: np.ndarray = epochs.get_data()
    # Récupère la fréquence d'échantillonnage indispensable au calcul fréquentiel
    sfreq: float = float(epochs.info["sfreq"])
    # Construit un extracteur scikit-learn pour déléguer le calcul
    estimator = ExtractFeatures(
        sfreq=sfreq,
        feature_strategy=method,
        normalize=normalize,
        bands=band_ranges,
        strategy_config=effective_config,
    )
    # Calcule les features en déléguant à l'extracteur scikit-learn
    features = estimator.transform(data)
    # Détermine le nombre de bandes pour reconstruire les étiquettes
    n_bands = len(band_ranges)
    # Recompose un tenseur factice pour générer les étiquettes canal/bande
    stacked = features.reshape(features.shape[0], data.shape[1], n_bands)
    # Construit des étiquettes canal_bande pour interpréter les features
    labels: List[str] = _build_labels(stacked, band_ranges, channel_names)
    # Retourne les features tabulaires accompagnés de leurs étiquettes
    return features, labels


def x_extract_features__mutmut_40(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = dict(config or {})
    # Déclare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = {
        "theta": (4.0, 7.0),
        "alpha": (8.0, 12.0),
        "beta": (13.0, 30.0),
        "gamma": (31.0, 45.0),
    }
    # Fusionne les bandes personnalisées en conservant l'ordre demandé
    band_ranges: Dict[str, Tuple[float, float]] = _resolve_band_ranges(
        effective_config, default_bands
    )
    # Refuse une configuration vide pour éviter un empilement sans bandes
    if not band_ranges:
        raise ValueError("At least one frequency band must be provided.")
    # Récupère la méthode pour aiguiller la stratégie d'extraction
    method: str = effective_config.pop("method", "welch")
    # Permet de contrôler l'activation de la normalisation via la configuration
    normalize = None
    # Supprime la configuration des bandes pour ne pas dupliquer l'information
    effective_config.pop("bands", None)
    # Capture les noms de canaux pour aligner les étiquettes de features
    channel_names: Sequence[str] = getattr(epochs.info, "ch_names", [])
    # Extrait les données temporelles pour calculer les caractéristiques spectrales
    data: np.ndarray = epochs.get_data()
    # Récupère la fréquence d'échantillonnage indispensable au calcul fréquentiel
    sfreq: float = float(epochs.info["sfreq"])
    # Construit un extracteur scikit-learn pour déléguer le calcul
    estimator = ExtractFeatures(
        sfreq=sfreq,
        feature_strategy=method,
        normalize=normalize,
        bands=band_ranges,
        strategy_config=effective_config,
    )
    # Calcule les features en déléguant à l'extracteur scikit-learn
    features = estimator.transform(data)
    # Détermine le nombre de bandes pour reconstruire les étiquettes
    n_bands = len(band_ranges)
    # Recompose un tenseur factice pour générer les étiquettes canal/bande
    stacked = features.reshape(features.shape[0], data.shape[1], n_bands)
    # Construit des étiquettes canal_bande pour interpréter les features
    labels: List[str] = _build_labels(stacked, band_ranges, channel_names)
    # Retourne les features tabulaires accompagnés de leurs étiquettes
    return features, labels


def x_extract_features__mutmut_41(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = dict(config or {})
    # Déclare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = {
        "theta": (4.0, 7.0),
        "alpha": (8.0, 12.0),
        "beta": (13.0, 30.0),
        "gamma": (31.0, 45.0),
    }
    # Fusionne les bandes personnalisées en conservant l'ordre demandé
    band_ranges: Dict[str, Tuple[float, float]] = _resolve_band_ranges(
        effective_config, default_bands
    )
    # Refuse une configuration vide pour éviter un empilement sans bandes
    if not band_ranges:
        raise ValueError("At least one frequency band must be provided.")
    # Récupère la méthode pour aiguiller la stratégie d'extraction
    method: str = effective_config.pop("method", "welch")
    # Permet de contrôler l'activation de la normalisation via la configuration
    normalize = bool(None)
    # Supprime la configuration des bandes pour ne pas dupliquer l'information
    effective_config.pop("bands", None)
    # Capture les noms de canaux pour aligner les étiquettes de features
    channel_names: Sequence[str] = getattr(epochs.info, "ch_names", [])
    # Extrait les données temporelles pour calculer les caractéristiques spectrales
    data: np.ndarray = epochs.get_data()
    # Récupère la fréquence d'échantillonnage indispensable au calcul fréquentiel
    sfreq: float = float(epochs.info["sfreq"])
    # Construit un extracteur scikit-learn pour déléguer le calcul
    estimator = ExtractFeatures(
        sfreq=sfreq,
        feature_strategy=method,
        normalize=normalize,
        bands=band_ranges,
        strategy_config=effective_config,
    )
    # Calcule les features en déléguant à l'extracteur scikit-learn
    features = estimator.transform(data)
    # Détermine le nombre de bandes pour reconstruire les étiquettes
    n_bands = len(band_ranges)
    # Recompose un tenseur factice pour générer les étiquettes canal/bande
    stacked = features.reshape(features.shape[0], data.shape[1], n_bands)
    # Construit des étiquettes canal_bande pour interpréter les features
    labels: List[str] = _build_labels(stacked, band_ranges, channel_names)
    # Retourne les features tabulaires accompagnés de leurs étiquettes
    return features, labels


def x_extract_features__mutmut_42(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = dict(config or {})
    # Déclare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = {
        "theta": (4.0, 7.0),
        "alpha": (8.0, 12.0),
        "beta": (13.0, 30.0),
        "gamma": (31.0, 45.0),
    }
    # Fusionne les bandes personnalisées en conservant l'ordre demandé
    band_ranges: Dict[str, Tuple[float, float]] = _resolve_band_ranges(
        effective_config, default_bands
    )
    # Refuse une configuration vide pour éviter un empilement sans bandes
    if not band_ranges:
        raise ValueError("At least one frequency band must be provided.")
    # Récupère la méthode pour aiguiller la stratégie d'extraction
    method: str = effective_config.pop("method", "welch")
    # Permet de contrôler l'activation de la normalisation via la configuration
    normalize = bool(effective_config.pop(None, False))
    # Supprime la configuration des bandes pour ne pas dupliquer l'information
    effective_config.pop("bands", None)
    # Capture les noms de canaux pour aligner les étiquettes de features
    channel_names: Sequence[str] = getattr(epochs.info, "ch_names", [])
    # Extrait les données temporelles pour calculer les caractéristiques spectrales
    data: np.ndarray = epochs.get_data()
    # Récupère la fréquence d'échantillonnage indispensable au calcul fréquentiel
    sfreq: float = float(epochs.info["sfreq"])
    # Construit un extracteur scikit-learn pour déléguer le calcul
    estimator = ExtractFeatures(
        sfreq=sfreq,
        feature_strategy=method,
        normalize=normalize,
        bands=band_ranges,
        strategy_config=effective_config,
    )
    # Calcule les features en déléguant à l'extracteur scikit-learn
    features = estimator.transform(data)
    # Détermine le nombre de bandes pour reconstruire les étiquettes
    n_bands = len(band_ranges)
    # Recompose un tenseur factice pour générer les étiquettes canal/bande
    stacked = features.reshape(features.shape[0], data.shape[1], n_bands)
    # Construit des étiquettes canal_bande pour interpréter les features
    labels: List[str] = _build_labels(stacked, band_ranges, channel_names)
    # Retourne les features tabulaires accompagnés de leurs étiquettes
    return features, labels


def x_extract_features__mutmut_43(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = dict(config or {})
    # Déclare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = {
        "theta": (4.0, 7.0),
        "alpha": (8.0, 12.0),
        "beta": (13.0, 30.0),
        "gamma": (31.0, 45.0),
    }
    # Fusionne les bandes personnalisées en conservant l'ordre demandé
    band_ranges: Dict[str, Tuple[float, float]] = _resolve_band_ranges(
        effective_config, default_bands
    )
    # Refuse une configuration vide pour éviter un empilement sans bandes
    if not band_ranges:
        raise ValueError("At least one frequency band must be provided.")
    # Récupère la méthode pour aiguiller la stratégie d'extraction
    method: str = effective_config.pop("method", "welch")
    # Permet de contrôler l'activation de la normalisation via la configuration
    normalize = bool(effective_config.pop("normalize", None))
    # Supprime la configuration des bandes pour ne pas dupliquer l'information
    effective_config.pop("bands", None)
    # Capture les noms de canaux pour aligner les étiquettes de features
    channel_names: Sequence[str] = getattr(epochs.info, "ch_names", [])
    # Extrait les données temporelles pour calculer les caractéristiques spectrales
    data: np.ndarray = epochs.get_data()
    # Récupère la fréquence d'échantillonnage indispensable au calcul fréquentiel
    sfreq: float = float(epochs.info["sfreq"])
    # Construit un extracteur scikit-learn pour déléguer le calcul
    estimator = ExtractFeatures(
        sfreq=sfreq,
        feature_strategy=method,
        normalize=normalize,
        bands=band_ranges,
        strategy_config=effective_config,
    )
    # Calcule les features en déléguant à l'extracteur scikit-learn
    features = estimator.transform(data)
    # Détermine le nombre de bandes pour reconstruire les étiquettes
    n_bands = len(band_ranges)
    # Recompose un tenseur factice pour générer les étiquettes canal/bande
    stacked = features.reshape(features.shape[0], data.shape[1], n_bands)
    # Construit des étiquettes canal_bande pour interpréter les features
    labels: List[str] = _build_labels(stacked, band_ranges, channel_names)
    # Retourne les features tabulaires accompagnés de leurs étiquettes
    return features, labels


def x_extract_features__mutmut_44(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = dict(config or {})
    # Déclare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = {
        "theta": (4.0, 7.0),
        "alpha": (8.0, 12.0),
        "beta": (13.0, 30.0),
        "gamma": (31.0, 45.0),
    }
    # Fusionne les bandes personnalisées en conservant l'ordre demandé
    band_ranges: Dict[str, Tuple[float, float]] = _resolve_band_ranges(
        effective_config, default_bands
    )
    # Refuse une configuration vide pour éviter un empilement sans bandes
    if not band_ranges:
        raise ValueError("At least one frequency band must be provided.")
    # Récupère la méthode pour aiguiller la stratégie d'extraction
    method: str = effective_config.pop("method", "welch")
    # Permet de contrôler l'activation de la normalisation via la configuration
    normalize = bool(effective_config.pop(False))
    # Supprime la configuration des bandes pour ne pas dupliquer l'information
    effective_config.pop("bands", None)
    # Capture les noms de canaux pour aligner les étiquettes de features
    channel_names: Sequence[str] = getattr(epochs.info, "ch_names", [])
    # Extrait les données temporelles pour calculer les caractéristiques spectrales
    data: np.ndarray = epochs.get_data()
    # Récupère la fréquence d'échantillonnage indispensable au calcul fréquentiel
    sfreq: float = float(epochs.info["sfreq"])
    # Construit un extracteur scikit-learn pour déléguer le calcul
    estimator = ExtractFeatures(
        sfreq=sfreq,
        feature_strategy=method,
        normalize=normalize,
        bands=band_ranges,
        strategy_config=effective_config,
    )
    # Calcule les features en déléguant à l'extracteur scikit-learn
    features = estimator.transform(data)
    # Détermine le nombre de bandes pour reconstruire les étiquettes
    n_bands = len(band_ranges)
    # Recompose un tenseur factice pour générer les étiquettes canal/bande
    stacked = features.reshape(features.shape[0], data.shape[1], n_bands)
    # Construit des étiquettes canal_bande pour interpréter les features
    labels: List[str] = _build_labels(stacked, band_ranges, channel_names)
    # Retourne les features tabulaires accompagnés de leurs étiquettes
    return features, labels


def x_extract_features__mutmut_45(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = dict(config or {})
    # Déclare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = {
        "theta": (4.0, 7.0),
        "alpha": (8.0, 12.0),
        "beta": (13.0, 30.0),
        "gamma": (31.0, 45.0),
    }
    # Fusionne les bandes personnalisées en conservant l'ordre demandé
    band_ranges: Dict[str, Tuple[float, float]] = _resolve_band_ranges(
        effective_config, default_bands
    )
    # Refuse une configuration vide pour éviter un empilement sans bandes
    if not band_ranges:
        raise ValueError("At least one frequency band must be provided.")
    # Récupère la méthode pour aiguiller la stratégie d'extraction
    method: str = effective_config.pop("method", "welch")
    # Permet de contrôler l'activation de la normalisation via la configuration
    normalize = bool(effective_config.pop("normalize", ))
    # Supprime la configuration des bandes pour ne pas dupliquer l'information
    effective_config.pop("bands", None)
    # Capture les noms de canaux pour aligner les étiquettes de features
    channel_names: Sequence[str] = getattr(epochs.info, "ch_names", [])
    # Extrait les données temporelles pour calculer les caractéristiques spectrales
    data: np.ndarray = epochs.get_data()
    # Récupère la fréquence d'échantillonnage indispensable au calcul fréquentiel
    sfreq: float = float(epochs.info["sfreq"])
    # Construit un extracteur scikit-learn pour déléguer le calcul
    estimator = ExtractFeatures(
        sfreq=sfreq,
        feature_strategy=method,
        normalize=normalize,
        bands=band_ranges,
        strategy_config=effective_config,
    )
    # Calcule les features en déléguant à l'extracteur scikit-learn
    features = estimator.transform(data)
    # Détermine le nombre de bandes pour reconstruire les étiquettes
    n_bands = len(band_ranges)
    # Recompose un tenseur factice pour générer les étiquettes canal/bande
    stacked = features.reshape(features.shape[0], data.shape[1], n_bands)
    # Construit des étiquettes canal_bande pour interpréter les features
    labels: List[str] = _build_labels(stacked, band_ranges, channel_names)
    # Retourne les features tabulaires accompagnés de leurs étiquettes
    return features, labels


def x_extract_features__mutmut_46(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = dict(config or {})
    # Déclare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = {
        "theta": (4.0, 7.0),
        "alpha": (8.0, 12.0),
        "beta": (13.0, 30.0),
        "gamma": (31.0, 45.0),
    }
    # Fusionne les bandes personnalisées en conservant l'ordre demandé
    band_ranges: Dict[str, Tuple[float, float]] = _resolve_band_ranges(
        effective_config, default_bands
    )
    # Refuse une configuration vide pour éviter un empilement sans bandes
    if not band_ranges:
        raise ValueError("At least one frequency band must be provided.")
    # Récupère la méthode pour aiguiller la stratégie d'extraction
    method: str = effective_config.pop("method", "welch")
    # Permet de contrôler l'activation de la normalisation via la configuration
    normalize = bool(effective_config.pop("XXnormalizeXX", False))
    # Supprime la configuration des bandes pour ne pas dupliquer l'information
    effective_config.pop("bands", None)
    # Capture les noms de canaux pour aligner les étiquettes de features
    channel_names: Sequence[str] = getattr(epochs.info, "ch_names", [])
    # Extrait les données temporelles pour calculer les caractéristiques spectrales
    data: np.ndarray = epochs.get_data()
    # Récupère la fréquence d'échantillonnage indispensable au calcul fréquentiel
    sfreq: float = float(epochs.info["sfreq"])
    # Construit un extracteur scikit-learn pour déléguer le calcul
    estimator = ExtractFeatures(
        sfreq=sfreq,
        feature_strategy=method,
        normalize=normalize,
        bands=band_ranges,
        strategy_config=effective_config,
    )
    # Calcule les features en déléguant à l'extracteur scikit-learn
    features = estimator.transform(data)
    # Détermine le nombre de bandes pour reconstruire les étiquettes
    n_bands = len(band_ranges)
    # Recompose un tenseur factice pour générer les étiquettes canal/bande
    stacked = features.reshape(features.shape[0], data.shape[1], n_bands)
    # Construit des étiquettes canal_bande pour interpréter les features
    labels: List[str] = _build_labels(stacked, band_ranges, channel_names)
    # Retourne les features tabulaires accompagnés de leurs étiquettes
    return features, labels


def x_extract_features__mutmut_47(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = dict(config or {})
    # Déclare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = {
        "theta": (4.0, 7.0),
        "alpha": (8.0, 12.0),
        "beta": (13.0, 30.0),
        "gamma": (31.0, 45.0),
    }
    # Fusionne les bandes personnalisées en conservant l'ordre demandé
    band_ranges: Dict[str, Tuple[float, float]] = _resolve_band_ranges(
        effective_config, default_bands
    )
    # Refuse une configuration vide pour éviter un empilement sans bandes
    if not band_ranges:
        raise ValueError("At least one frequency band must be provided.")
    # Récupère la méthode pour aiguiller la stratégie d'extraction
    method: str = effective_config.pop("method", "welch")
    # Permet de contrôler l'activation de la normalisation via la configuration
    normalize = bool(effective_config.pop("NORMALIZE", False))
    # Supprime la configuration des bandes pour ne pas dupliquer l'information
    effective_config.pop("bands", None)
    # Capture les noms de canaux pour aligner les étiquettes de features
    channel_names: Sequence[str] = getattr(epochs.info, "ch_names", [])
    # Extrait les données temporelles pour calculer les caractéristiques spectrales
    data: np.ndarray = epochs.get_data()
    # Récupère la fréquence d'échantillonnage indispensable au calcul fréquentiel
    sfreq: float = float(epochs.info["sfreq"])
    # Construit un extracteur scikit-learn pour déléguer le calcul
    estimator = ExtractFeatures(
        sfreq=sfreq,
        feature_strategy=method,
        normalize=normalize,
        bands=band_ranges,
        strategy_config=effective_config,
    )
    # Calcule les features en déléguant à l'extracteur scikit-learn
    features = estimator.transform(data)
    # Détermine le nombre de bandes pour reconstruire les étiquettes
    n_bands = len(band_ranges)
    # Recompose un tenseur factice pour générer les étiquettes canal/bande
    stacked = features.reshape(features.shape[0], data.shape[1], n_bands)
    # Construit des étiquettes canal_bande pour interpréter les features
    labels: List[str] = _build_labels(stacked, band_ranges, channel_names)
    # Retourne les features tabulaires accompagnés de leurs étiquettes
    return features, labels


def x_extract_features__mutmut_48(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = dict(config or {})
    # Déclare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = {
        "theta": (4.0, 7.0),
        "alpha": (8.0, 12.0),
        "beta": (13.0, 30.0),
        "gamma": (31.0, 45.0),
    }
    # Fusionne les bandes personnalisées en conservant l'ordre demandé
    band_ranges: Dict[str, Tuple[float, float]] = _resolve_band_ranges(
        effective_config, default_bands
    )
    # Refuse une configuration vide pour éviter un empilement sans bandes
    if not band_ranges:
        raise ValueError("At least one frequency band must be provided.")
    # Récupère la méthode pour aiguiller la stratégie d'extraction
    method: str = effective_config.pop("method", "welch")
    # Permet de contrôler l'activation de la normalisation via la configuration
    normalize = bool(effective_config.pop("normalize", True))
    # Supprime la configuration des bandes pour ne pas dupliquer l'information
    effective_config.pop("bands", None)
    # Capture les noms de canaux pour aligner les étiquettes de features
    channel_names: Sequence[str] = getattr(epochs.info, "ch_names", [])
    # Extrait les données temporelles pour calculer les caractéristiques spectrales
    data: np.ndarray = epochs.get_data()
    # Récupère la fréquence d'échantillonnage indispensable au calcul fréquentiel
    sfreq: float = float(epochs.info["sfreq"])
    # Construit un extracteur scikit-learn pour déléguer le calcul
    estimator = ExtractFeatures(
        sfreq=sfreq,
        feature_strategy=method,
        normalize=normalize,
        bands=band_ranges,
        strategy_config=effective_config,
    )
    # Calcule les features en déléguant à l'extracteur scikit-learn
    features = estimator.transform(data)
    # Détermine le nombre de bandes pour reconstruire les étiquettes
    n_bands = len(band_ranges)
    # Recompose un tenseur factice pour générer les étiquettes canal/bande
    stacked = features.reshape(features.shape[0], data.shape[1], n_bands)
    # Construit des étiquettes canal_bande pour interpréter les features
    labels: List[str] = _build_labels(stacked, band_ranges, channel_names)
    # Retourne les features tabulaires accompagnés de leurs étiquettes
    return features, labels


def x_extract_features__mutmut_49(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = dict(config or {})
    # Déclare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = {
        "theta": (4.0, 7.0),
        "alpha": (8.0, 12.0),
        "beta": (13.0, 30.0),
        "gamma": (31.0, 45.0),
    }
    # Fusionne les bandes personnalisées en conservant l'ordre demandé
    band_ranges: Dict[str, Tuple[float, float]] = _resolve_band_ranges(
        effective_config, default_bands
    )
    # Refuse une configuration vide pour éviter un empilement sans bandes
    if not band_ranges:
        raise ValueError("At least one frequency band must be provided.")
    # Récupère la méthode pour aiguiller la stratégie d'extraction
    method: str = effective_config.pop("method", "welch")
    # Permet de contrôler l'activation de la normalisation via la configuration
    normalize = bool(effective_config.pop("normalize", False))
    # Supprime la configuration des bandes pour ne pas dupliquer l'information
    effective_config.pop(None, None)
    # Capture les noms de canaux pour aligner les étiquettes de features
    channel_names: Sequence[str] = getattr(epochs.info, "ch_names", [])
    # Extrait les données temporelles pour calculer les caractéristiques spectrales
    data: np.ndarray = epochs.get_data()
    # Récupère la fréquence d'échantillonnage indispensable au calcul fréquentiel
    sfreq: float = float(epochs.info["sfreq"])
    # Construit un extracteur scikit-learn pour déléguer le calcul
    estimator = ExtractFeatures(
        sfreq=sfreq,
        feature_strategy=method,
        normalize=normalize,
        bands=band_ranges,
        strategy_config=effective_config,
    )
    # Calcule les features en déléguant à l'extracteur scikit-learn
    features = estimator.transform(data)
    # Détermine le nombre de bandes pour reconstruire les étiquettes
    n_bands = len(band_ranges)
    # Recompose un tenseur factice pour générer les étiquettes canal/bande
    stacked = features.reshape(features.shape[0], data.shape[1], n_bands)
    # Construit des étiquettes canal_bande pour interpréter les features
    labels: List[str] = _build_labels(stacked, band_ranges, channel_names)
    # Retourne les features tabulaires accompagnés de leurs étiquettes
    return features, labels


def x_extract_features__mutmut_50(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = dict(config or {})
    # Déclare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = {
        "theta": (4.0, 7.0),
        "alpha": (8.0, 12.0),
        "beta": (13.0, 30.0),
        "gamma": (31.0, 45.0),
    }
    # Fusionne les bandes personnalisées en conservant l'ordre demandé
    band_ranges: Dict[str, Tuple[float, float]] = _resolve_band_ranges(
        effective_config, default_bands
    )
    # Refuse une configuration vide pour éviter un empilement sans bandes
    if not band_ranges:
        raise ValueError("At least one frequency band must be provided.")
    # Récupère la méthode pour aiguiller la stratégie d'extraction
    method: str = effective_config.pop("method", "welch")
    # Permet de contrôler l'activation de la normalisation via la configuration
    normalize = bool(effective_config.pop("normalize", False))
    # Supprime la configuration des bandes pour ne pas dupliquer l'information
    effective_config.pop(None)
    # Capture les noms de canaux pour aligner les étiquettes de features
    channel_names: Sequence[str] = getattr(epochs.info, "ch_names", [])
    # Extrait les données temporelles pour calculer les caractéristiques spectrales
    data: np.ndarray = epochs.get_data()
    # Récupère la fréquence d'échantillonnage indispensable au calcul fréquentiel
    sfreq: float = float(epochs.info["sfreq"])
    # Construit un extracteur scikit-learn pour déléguer le calcul
    estimator = ExtractFeatures(
        sfreq=sfreq,
        feature_strategy=method,
        normalize=normalize,
        bands=band_ranges,
        strategy_config=effective_config,
    )
    # Calcule les features en déléguant à l'extracteur scikit-learn
    features = estimator.transform(data)
    # Détermine le nombre de bandes pour reconstruire les étiquettes
    n_bands = len(band_ranges)
    # Recompose un tenseur factice pour générer les étiquettes canal/bande
    stacked = features.reshape(features.shape[0], data.shape[1], n_bands)
    # Construit des étiquettes canal_bande pour interpréter les features
    labels: List[str] = _build_labels(stacked, band_ranges, channel_names)
    # Retourne les features tabulaires accompagnés de leurs étiquettes
    return features, labels


def x_extract_features__mutmut_51(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = dict(config or {})
    # Déclare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = {
        "theta": (4.0, 7.0),
        "alpha": (8.0, 12.0),
        "beta": (13.0, 30.0),
        "gamma": (31.0, 45.0),
    }
    # Fusionne les bandes personnalisées en conservant l'ordre demandé
    band_ranges: Dict[str, Tuple[float, float]] = _resolve_band_ranges(
        effective_config, default_bands
    )
    # Refuse une configuration vide pour éviter un empilement sans bandes
    if not band_ranges:
        raise ValueError("At least one frequency band must be provided.")
    # Récupère la méthode pour aiguiller la stratégie d'extraction
    method: str = effective_config.pop("method", "welch")
    # Permet de contrôler l'activation de la normalisation via la configuration
    normalize = bool(effective_config.pop("normalize", False))
    # Supprime la configuration des bandes pour ne pas dupliquer l'information
    effective_config.pop("bands", )
    # Capture les noms de canaux pour aligner les étiquettes de features
    channel_names: Sequence[str] = getattr(epochs.info, "ch_names", [])
    # Extrait les données temporelles pour calculer les caractéristiques spectrales
    data: np.ndarray = epochs.get_data()
    # Récupère la fréquence d'échantillonnage indispensable au calcul fréquentiel
    sfreq: float = float(epochs.info["sfreq"])
    # Construit un extracteur scikit-learn pour déléguer le calcul
    estimator = ExtractFeatures(
        sfreq=sfreq,
        feature_strategy=method,
        normalize=normalize,
        bands=band_ranges,
        strategy_config=effective_config,
    )
    # Calcule les features en déléguant à l'extracteur scikit-learn
    features = estimator.transform(data)
    # Détermine le nombre de bandes pour reconstruire les étiquettes
    n_bands = len(band_ranges)
    # Recompose un tenseur factice pour générer les étiquettes canal/bande
    stacked = features.reshape(features.shape[0], data.shape[1], n_bands)
    # Construit des étiquettes canal_bande pour interpréter les features
    labels: List[str] = _build_labels(stacked, band_ranges, channel_names)
    # Retourne les features tabulaires accompagnés de leurs étiquettes
    return features, labels


def x_extract_features__mutmut_52(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = dict(config or {})
    # Déclare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = {
        "theta": (4.0, 7.0),
        "alpha": (8.0, 12.0),
        "beta": (13.0, 30.0),
        "gamma": (31.0, 45.0),
    }
    # Fusionne les bandes personnalisées en conservant l'ordre demandé
    band_ranges: Dict[str, Tuple[float, float]] = _resolve_band_ranges(
        effective_config, default_bands
    )
    # Refuse une configuration vide pour éviter un empilement sans bandes
    if not band_ranges:
        raise ValueError("At least one frequency band must be provided.")
    # Récupère la méthode pour aiguiller la stratégie d'extraction
    method: str = effective_config.pop("method", "welch")
    # Permet de contrôler l'activation de la normalisation via la configuration
    normalize = bool(effective_config.pop("normalize", False))
    # Supprime la configuration des bandes pour ne pas dupliquer l'information
    effective_config.pop("XXbandsXX", None)
    # Capture les noms de canaux pour aligner les étiquettes de features
    channel_names: Sequence[str] = getattr(epochs.info, "ch_names", [])
    # Extrait les données temporelles pour calculer les caractéristiques spectrales
    data: np.ndarray = epochs.get_data()
    # Récupère la fréquence d'échantillonnage indispensable au calcul fréquentiel
    sfreq: float = float(epochs.info["sfreq"])
    # Construit un extracteur scikit-learn pour déléguer le calcul
    estimator = ExtractFeatures(
        sfreq=sfreq,
        feature_strategy=method,
        normalize=normalize,
        bands=band_ranges,
        strategy_config=effective_config,
    )
    # Calcule les features en déléguant à l'extracteur scikit-learn
    features = estimator.transform(data)
    # Détermine le nombre de bandes pour reconstruire les étiquettes
    n_bands = len(band_ranges)
    # Recompose un tenseur factice pour générer les étiquettes canal/bande
    stacked = features.reshape(features.shape[0], data.shape[1], n_bands)
    # Construit des étiquettes canal_bande pour interpréter les features
    labels: List[str] = _build_labels(stacked, band_ranges, channel_names)
    # Retourne les features tabulaires accompagnés de leurs étiquettes
    return features, labels


def x_extract_features__mutmut_53(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = dict(config or {})
    # Déclare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = {
        "theta": (4.0, 7.0),
        "alpha": (8.0, 12.0),
        "beta": (13.0, 30.0),
        "gamma": (31.0, 45.0),
    }
    # Fusionne les bandes personnalisées en conservant l'ordre demandé
    band_ranges: Dict[str, Tuple[float, float]] = _resolve_band_ranges(
        effective_config, default_bands
    )
    # Refuse une configuration vide pour éviter un empilement sans bandes
    if not band_ranges:
        raise ValueError("At least one frequency band must be provided.")
    # Récupère la méthode pour aiguiller la stratégie d'extraction
    method: str = effective_config.pop("method", "welch")
    # Permet de contrôler l'activation de la normalisation via la configuration
    normalize = bool(effective_config.pop("normalize", False))
    # Supprime la configuration des bandes pour ne pas dupliquer l'information
    effective_config.pop("BANDS", None)
    # Capture les noms de canaux pour aligner les étiquettes de features
    channel_names: Sequence[str] = getattr(epochs.info, "ch_names", [])
    # Extrait les données temporelles pour calculer les caractéristiques spectrales
    data: np.ndarray = epochs.get_data()
    # Récupère la fréquence d'échantillonnage indispensable au calcul fréquentiel
    sfreq: float = float(epochs.info["sfreq"])
    # Construit un extracteur scikit-learn pour déléguer le calcul
    estimator = ExtractFeatures(
        sfreq=sfreq,
        feature_strategy=method,
        normalize=normalize,
        bands=band_ranges,
        strategy_config=effective_config,
    )
    # Calcule les features en déléguant à l'extracteur scikit-learn
    features = estimator.transform(data)
    # Détermine le nombre de bandes pour reconstruire les étiquettes
    n_bands = len(band_ranges)
    # Recompose un tenseur factice pour générer les étiquettes canal/bande
    stacked = features.reshape(features.shape[0], data.shape[1], n_bands)
    # Construit des étiquettes canal_bande pour interpréter les features
    labels: List[str] = _build_labels(stacked, band_ranges, channel_names)
    # Retourne les features tabulaires accompagnés de leurs étiquettes
    return features, labels


def x_extract_features__mutmut_54(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = dict(config or {})
    # Déclare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = {
        "theta": (4.0, 7.0),
        "alpha": (8.0, 12.0),
        "beta": (13.0, 30.0),
        "gamma": (31.0, 45.0),
    }
    # Fusionne les bandes personnalisées en conservant l'ordre demandé
    band_ranges: Dict[str, Tuple[float, float]] = _resolve_band_ranges(
        effective_config, default_bands
    )
    # Refuse une configuration vide pour éviter un empilement sans bandes
    if not band_ranges:
        raise ValueError("At least one frequency band must be provided.")
    # Récupère la méthode pour aiguiller la stratégie d'extraction
    method: str = effective_config.pop("method", "welch")
    # Permet de contrôler l'activation de la normalisation via la configuration
    normalize = bool(effective_config.pop("normalize", False))
    # Supprime la configuration des bandes pour ne pas dupliquer l'information
    effective_config.pop("bands", None)
    # Capture les noms de canaux pour aligner les étiquettes de features
    channel_names: Sequence[str] = None
    # Extrait les données temporelles pour calculer les caractéristiques spectrales
    data: np.ndarray = epochs.get_data()
    # Récupère la fréquence d'échantillonnage indispensable au calcul fréquentiel
    sfreq: float = float(epochs.info["sfreq"])
    # Construit un extracteur scikit-learn pour déléguer le calcul
    estimator = ExtractFeatures(
        sfreq=sfreq,
        feature_strategy=method,
        normalize=normalize,
        bands=band_ranges,
        strategy_config=effective_config,
    )
    # Calcule les features en déléguant à l'extracteur scikit-learn
    features = estimator.transform(data)
    # Détermine le nombre de bandes pour reconstruire les étiquettes
    n_bands = len(band_ranges)
    # Recompose un tenseur factice pour générer les étiquettes canal/bande
    stacked = features.reshape(features.shape[0], data.shape[1], n_bands)
    # Construit des étiquettes canal_bande pour interpréter les features
    labels: List[str] = _build_labels(stacked, band_ranges, channel_names)
    # Retourne les features tabulaires accompagnés de leurs étiquettes
    return features, labels


def x_extract_features__mutmut_55(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = dict(config or {})
    # Déclare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = {
        "theta": (4.0, 7.0),
        "alpha": (8.0, 12.0),
        "beta": (13.0, 30.0),
        "gamma": (31.0, 45.0),
    }
    # Fusionne les bandes personnalisées en conservant l'ordre demandé
    band_ranges: Dict[str, Tuple[float, float]] = _resolve_band_ranges(
        effective_config, default_bands
    )
    # Refuse une configuration vide pour éviter un empilement sans bandes
    if not band_ranges:
        raise ValueError("At least one frequency band must be provided.")
    # Récupère la méthode pour aiguiller la stratégie d'extraction
    method: str = effective_config.pop("method", "welch")
    # Permet de contrôler l'activation de la normalisation via la configuration
    normalize = bool(effective_config.pop("normalize", False))
    # Supprime la configuration des bandes pour ne pas dupliquer l'information
    effective_config.pop("bands", None)
    # Capture les noms de canaux pour aligner les étiquettes de features
    channel_names: Sequence[str] = getattr(None, "ch_names", [])
    # Extrait les données temporelles pour calculer les caractéristiques spectrales
    data: np.ndarray = epochs.get_data()
    # Récupère la fréquence d'échantillonnage indispensable au calcul fréquentiel
    sfreq: float = float(epochs.info["sfreq"])
    # Construit un extracteur scikit-learn pour déléguer le calcul
    estimator = ExtractFeatures(
        sfreq=sfreq,
        feature_strategy=method,
        normalize=normalize,
        bands=band_ranges,
        strategy_config=effective_config,
    )
    # Calcule les features en déléguant à l'extracteur scikit-learn
    features = estimator.transform(data)
    # Détermine le nombre de bandes pour reconstruire les étiquettes
    n_bands = len(band_ranges)
    # Recompose un tenseur factice pour générer les étiquettes canal/bande
    stacked = features.reshape(features.shape[0], data.shape[1], n_bands)
    # Construit des étiquettes canal_bande pour interpréter les features
    labels: List[str] = _build_labels(stacked, band_ranges, channel_names)
    # Retourne les features tabulaires accompagnés de leurs étiquettes
    return features, labels


def x_extract_features__mutmut_56(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = dict(config or {})
    # Déclare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = {
        "theta": (4.0, 7.0),
        "alpha": (8.0, 12.0),
        "beta": (13.0, 30.0),
        "gamma": (31.0, 45.0),
    }
    # Fusionne les bandes personnalisées en conservant l'ordre demandé
    band_ranges: Dict[str, Tuple[float, float]] = _resolve_band_ranges(
        effective_config, default_bands
    )
    # Refuse une configuration vide pour éviter un empilement sans bandes
    if not band_ranges:
        raise ValueError("At least one frequency band must be provided.")
    # Récupère la méthode pour aiguiller la stratégie d'extraction
    method: str = effective_config.pop("method", "welch")
    # Permet de contrôler l'activation de la normalisation via la configuration
    normalize = bool(effective_config.pop("normalize", False))
    # Supprime la configuration des bandes pour ne pas dupliquer l'information
    effective_config.pop("bands", None)
    # Capture les noms de canaux pour aligner les étiquettes de features
    channel_names: Sequence[str] = getattr(epochs.info, None, [])
    # Extrait les données temporelles pour calculer les caractéristiques spectrales
    data: np.ndarray = epochs.get_data()
    # Récupère la fréquence d'échantillonnage indispensable au calcul fréquentiel
    sfreq: float = float(epochs.info["sfreq"])
    # Construit un extracteur scikit-learn pour déléguer le calcul
    estimator = ExtractFeatures(
        sfreq=sfreq,
        feature_strategy=method,
        normalize=normalize,
        bands=band_ranges,
        strategy_config=effective_config,
    )
    # Calcule les features en déléguant à l'extracteur scikit-learn
    features = estimator.transform(data)
    # Détermine le nombre de bandes pour reconstruire les étiquettes
    n_bands = len(band_ranges)
    # Recompose un tenseur factice pour générer les étiquettes canal/bande
    stacked = features.reshape(features.shape[0], data.shape[1], n_bands)
    # Construit des étiquettes canal_bande pour interpréter les features
    labels: List[str] = _build_labels(stacked, band_ranges, channel_names)
    # Retourne les features tabulaires accompagnés de leurs étiquettes
    return features, labels


def x_extract_features__mutmut_57(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = dict(config or {})
    # Déclare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = {
        "theta": (4.0, 7.0),
        "alpha": (8.0, 12.0),
        "beta": (13.0, 30.0),
        "gamma": (31.0, 45.0),
    }
    # Fusionne les bandes personnalisées en conservant l'ordre demandé
    band_ranges: Dict[str, Tuple[float, float]] = _resolve_band_ranges(
        effective_config, default_bands
    )
    # Refuse une configuration vide pour éviter un empilement sans bandes
    if not band_ranges:
        raise ValueError("At least one frequency band must be provided.")
    # Récupère la méthode pour aiguiller la stratégie d'extraction
    method: str = effective_config.pop("method", "welch")
    # Permet de contrôler l'activation de la normalisation via la configuration
    normalize = bool(effective_config.pop("normalize", False))
    # Supprime la configuration des bandes pour ne pas dupliquer l'information
    effective_config.pop("bands", None)
    # Capture les noms de canaux pour aligner les étiquettes de features
    channel_names: Sequence[str] = getattr(epochs.info, "ch_names", None)
    # Extrait les données temporelles pour calculer les caractéristiques spectrales
    data: np.ndarray = epochs.get_data()
    # Récupère la fréquence d'échantillonnage indispensable au calcul fréquentiel
    sfreq: float = float(epochs.info["sfreq"])
    # Construit un extracteur scikit-learn pour déléguer le calcul
    estimator = ExtractFeatures(
        sfreq=sfreq,
        feature_strategy=method,
        normalize=normalize,
        bands=band_ranges,
        strategy_config=effective_config,
    )
    # Calcule les features en déléguant à l'extracteur scikit-learn
    features = estimator.transform(data)
    # Détermine le nombre de bandes pour reconstruire les étiquettes
    n_bands = len(band_ranges)
    # Recompose un tenseur factice pour générer les étiquettes canal/bande
    stacked = features.reshape(features.shape[0], data.shape[1], n_bands)
    # Construit des étiquettes canal_bande pour interpréter les features
    labels: List[str] = _build_labels(stacked, band_ranges, channel_names)
    # Retourne les features tabulaires accompagnés de leurs étiquettes
    return features, labels


def x_extract_features__mutmut_58(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = dict(config or {})
    # Déclare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = {
        "theta": (4.0, 7.0),
        "alpha": (8.0, 12.0),
        "beta": (13.0, 30.0),
        "gamma": (31.0, 45.0),
    }
    # Fusionne les bandes personnalisées en conservant l'ordre demandé
    band_ranges: Dict[str, Tuple[float, float]] = _resolve_band_ranges(
        effective_config, default_bands
    )
    # Refuse une configuration vide pour éviter un empilement sans bandes
    if not band_ranges:
        raise ValueError("At least one frequency band must be provided.")
    # Récupère la méthode pour aiguiller la stratégie d'extraction
    method: str = effective_config.pop("method", "welch")
    # Permet de contrôler l'activation de la normalisation via la configuration
    normalize = bool(effective_config.pop("normalize", False))
    # Supprime la configuration des bandes pour ne pas dupliquer l'information
    effective_config.pop("bands", None)
    # Capture les noms de canaux pour aligner les étiquettes de features
    channel_names: Sequence[str] = getattr("ch_names", [])
    # Extrait les données temporelles pour calculer les caractéristiques spectrales
    data: np.ndarray = epochs.get_data()
    # Récupère la fréquence d'échantillonnage indispensable au calcul fréquentiel
    sfreq: float = float(epochs.info["sfreq"])
    # Construit un extracteur scikit-learn pour déléguer le calcul
    estimator = ExtractFeatures(
        sfreq=sfreq,
        feature_strategy=method,
        normalize=normalize,
        bands=band_ranges,
        strategy_config=effective_config,
    )
    # Calcule les features en déléguant à l'extracteur scikit-learn
    features = estimator.transform(data)
    # Détermine le nombre de bandes pour reconstruire les étiquettes
    n_bands = len(band_ranges)
    # Recompose un tenseur factice pour générer les étiquettes canal/bande
    stacked = features.reshape(features.shape[0], data.shape[1], n_bands)
    # Construit des étiquettes canal_bande pour interpréter les features
    labels: List[str] = _build_labels(stacked, band_ranges, channel_names)
    # Retourne les features tabulaires accompagnés de leurs étiquettes
    return features, labels


def x_extract_features__mutmut_59(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = dict(config or {})
    # Déclare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = {
        "theta": (4.0, 7.0),
        "alpha": (8.0, 12.0),
        "beta": (13.0, 30.0),
        "gamma": (31.0, 45.0),
    }
    # Fusionne les bandes personnalisées en conservant l'ordre demandé
    band_ranges: Dict[str, Tuple[float, float]] = _resolve_band_ranges(
        effective_config, default_bands
    )
    # Refuse une configuration vide pour éviter un empilement sans bandes
    if not band_ranges:
        raise ValueError("At least one frequency band must be provided.")
    # Récupère la méthode pour aiguiller la stratégie d'extraction
    method: str = effective_config.pop("method", "welch")
    # Permet de contrôler l'activation de la normalisation via la configuration
    normalize = bool(effective_config.pop("normalize", False))
    # Supprime la configuration des bandes pour ne pas dupliquer l'information
    effective_config.pop("bands", None)
    # Capture les noms de canaux pour aligner les étiquettes de features
    channel_names: Sequence[str] = getattr(epochs.info, [])
    # Extrait les données temporelles pour calculer les caractéristiques spectrales
    data: np.ndarray = epochs.get_data()
    # Récupère la fréquence d'échantillonnage indispensable au calcul fréquentiel
    sfreq: float = float(epochs.info["sfreq"])
    # Construit un extracteur scikit-learn pour déléguer le calcul
    estimator = ExtractFeatures(
        sfreq=sfreq,
        feature_strategy=method,
        normalize=normalize,
        bands=band_ranges,
        strategy_config=effective_config,
    )
    # Calcule les features en déléguant à l'extracteur scikit-learn
    features = estimator.transform(data)
    # Détermine le nombre de bandes pour reconstruire les étiquettes
    n_bands = len(band_ranges)
    # Recompose un tenseur factice pour générer les étiquettes canal/bande
    stacked = features.reshape(features.shape[0], data.shape[1], n_bands)
    # Construit des étiquettes canal_bande pour interpréter les features
    labels: List[str] = _build_labels(stacked, band_ranges, channel_names)
    # Retourne les features tabulaires accompagnés de leurs étiquettes
    return features, labels


def x_extract_features__mutmut_60(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = dict(config or {})
    # Déclare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = {
        "theta": (4.0, 7.0),
        "alpha": (8.0, 12.0),
        "beta": (13.0, 30.0),
        "gamma": (31.0, 45.0),
    }
    # Fusionne les bandes personnalisées en conservant l'ordre demandé
    band_ranges: Dict[str, Tuple[float, float]] = _resolve_band_ranges(
        effective_config, default_bands
    )
    # Refuse une configuration vide pour éviter un empilement sans bandes
    if not band_ranges:
        raise ValueError("At least one frequency band must be provided.")
    # Récupère la méthode pour aiguiller la stratégie d'extraction
    method: str = effective_config.pop("method", "welch")
    # Permet de contrôler l'activation de la normalisation via la configuration
    normalize = bool(effective_config.pop("normalize", False))
    # Supprime la configuration des bandes pour ne pas dupliquer l'information
    effective_config.pop("bands", None)
    # Capture les noms de canaux pour aligner les étiquettes de features
    channel_names: Sequence[str] = getattr(epochs.info, "ch_names", )
    # Extrait les données temporelles pour calculer les caractéristiques spectrales
    data: np.ndarray = epochs.get_data()
    # Récupère la fréquence d'échantillonnage indispensable au calcul fréquentiel
    sfreq: float = float(epochs.info["sfreq"])
    # Construit un extracteur scikit-learn pour déléguer le calcul
    estimator = ExtractFeatures(
        sfreq=sfreq,
        feature_strategy=method,
        normalize=normalize,
        bands=band_ranges,
        strategy_config=effective_config,
    )
    # Calcule les features en déléguant à l'extracteur scikit-learn
    features = estimator.transform(data)
    # Détermine le nombre de bandes pour reconstruire les étiquettes
    n_bands = len(band_ranges)
    # Recompose un tenseur factice pour générer les étiquettes canal/bande
    stacked = features.reshape(features.shape[0], data.shape[1], n_bands)
    # Construit des étiquettes canal_bande pour interpréter les features
    labels: List[str] = _build_labels(stacked, band_ranges, channel_names)
    # Retourne les features tabulaires accompagnés de leurs étiquettes
    return features, labels


def x_extract_features__mutmut_61(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = dict(config or {})
    # Déclare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = {
        "theta": (4.0, 7.0),
        "alpha": (8.0, 12.0),
        "beta": (13.0, 30.0),
        "gamma": (31.0, 45.0),
    }
    # Fusionne les bandes personnalisées en conservant l'ordre demandé
    band_ranges: Dict[str, Tuple[float, float]] = _resolve_band_ranges(
        effective_config, default_bands
    )
    # Refuse une configuration vide pour éviter un empilement sans bandes
    if not band_ranges:
        raise ValueError("At least one frequency band must be provided.")
    # Récupère la méthode pour aiguiller la stratégie d'extraction
    method: str = effective_config.pop("method", "welch")
    # Permet de contrôler l'activation de la normalisation via la configuration
    normalize = bool(effective_config.pop("normalize", False))
    # Supprime la configuration des bandes pour ne pas dupliquer l'information
    effective_config.pop("bands", None)
    # Capture les noms de canaux pour aligner les étiquettes de features
    channel_names: Sequence[str] = getattr(epochs.info, "XXch_namesXX", [])
    # Extrait les données temporelles pour calculer les caractéristiques spectrales
    data: np.ndarray = epochs.get_data()
    # Récupère la fréquence d'échantillonnage indispensable au calcul fréquentiel
    sfreq: float = float(epochs.info["sfreq"])
    # Construit un extracteur scikit-learn pour déléguer le calcul
    estimator = ExtractFeatures(
        sfreq=sfreq,
        feature_strategy=method,
        normalize=normalize,
        bands=band_ranges,
        strategy_config=effective_config,
    )
    # Calcule les features en déléguant à l'extracteur scikit-learn
    features = estimator.transform(data)
    # Détermine le nombre de bandes pour reconstruire les étiquettes
    n_bands = len(band_ranges)
    # Recompose un tenseur factice pour générer les étiquettes canal/bande
    stacked = features.reshape(features.shape[0], data.shape[1], n_bands)
    # Construit des étiquettes canal_bande pour interpréter les features
    labels: List[str] = _build_labels(stacked, band_ranges, channel_names)
    # Retourne les features tabulaires accompagnés de leurs étiquettes
    return features, labels


def x_extract_features__mutmut_62(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = dict(config or {})
    # Déclare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = {
        "theta": (4.0, 7.0),
        "alpha": (8.0, 12.0),
        "beta": (13.0, 30.0),
        "gamma": (31.0, 45.0),
    }
    # Fusionne les bandes personnalisées en conservant l'ordre demandé
    band_ranges: Dict[str, Tuple[float, float]] = _resolve_band_ranges(
        effective_config, default_bands
    )
    # Refuse une configuration vide pour éviter un empilement sans bandes
    if not band_ranges:
        raise ValueError("At least one frequency band must be provided.")
    # Récupère la méthode pour aiguiller la stratégie d'extraction
    method: str = effective_config.pop("method", "welch")
    # Permet de contrôler l'activation de la normalisation via la configuration
    normalize = bool(effective_config.pop("normalize", False))
    # Supprime la configuration des bandes pour ne pas dupliquer l'information
    effective_config.pop("bands", None)
    # Capture les noms de canaux pour aligner les étiquettes de features
    channel_names: Sequence[str] = getattr(epochs.info, "CH_NAMES", [])
    # Extrait les données temporelles pour calculer les caractéristiques spectrales
    data: np.ndarray = epochs.get_data()
    # Récupère la fréquence d'échantillonnage indispensable au calcul fréquentiel
    sfreq: float = float(epochs.info["sfreq"])
    # Construit un extracteur scikit-learn pour déléguer le calcul
    estimator = ExtractFeatures(
        sfreq=sfreq,
        feature_strategy=method,
        normalize=normalize,
        bands=band_ranges,
        strategy_config=effective_config,
    )
    # Calcule les features en déléguant à l'extracteur scikit-learn
    features = estimator.transform(data)
    # Détermine le nombre de bandes pour reconstruire les étiquettes
    n_bands = len(band_ranges)
    # Recompose un tenseur factice pour générer les étiquettes canal/bande
    stacked = features.reshape(features.shape[0], data.shape[1], n_bands)
    # Construit des étiquettes canal_bande pour interpréter les features
    labels: List[str] = _build_labels(stacked, band_ranges, channel_names)
    # Retourne les features tabulaires accompagnés de leurs étiquettes
    return features, labels


def x_extract_features__mutmut_63(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = dict(config or {})
    # Déclare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = {
        "theta": (4.0, 7.0),
        "alpha": (8.0, 12.0),
        "beta": (13.0, 30.0),
        "gamma": (31.0, 45.0),
    }
    # Fusionne les bandes personnalisées en conservant l'ordre demandé
    band_ranges: Dict[str, Tuple[float, float]] = _resolve_band_ranges(
        effective_config, default_bands
    )
    # Refuse une configuration vide pour éviter un empilement sans bandes
    if not band_ranges:
        raise ValueError("At least one frequency band must be provided.")
    # Récupère la méthode pour aiguiller la stratégie d'extraction
    method: str = effective_config.pop("method", "welch")
    # Permet de contrôler l'activation de la normalisation via la configuration
    normalize = bool(effective_config.pop("normalize", False))
    # Supprime la configuration des bandes pour ne pas dupliquer l'information
    effective_config.pop("bands", None)
    # Capture les noms de canaux pour aligner les étiquettes de features
    channel_names: Sequence[str] = getattr(epochs.info, "ch_names", [])
    # Extrait les données temporelles pour calculer les caractéristiques spectrales
    data: np.ndarray = None
    # Récupère la fréquence d'échantillonnage indispensable au calcul fréquentiel
    sfreq: float = float(epochs.info["sfreq"])
    # Construit un extracteur scikit-learn pour déléguer le calcul
    estimator = ExtractFeatures(
        sfreq=sfreq,
        feature_strategy=method,
        normalize=normalize,
        bands=band_ranges,
        strategy_config=effective_config,
    )
    # Calcule les features en déléguant à l'extracteur scikit-learn
    features = estimator.transform(data)
    # Détermine le nombre de bandes pour reconstruire les étiquettes
    n_bands = len(band_ranges)
    # Recompose un tenseur factice pour générer les étiquettes canal/bande
    stacked = features.reshape(features.shape[0], data.shape[1], n_bands)
    # Construit des étiquettes canal_bande pour interpréter les features
    labels: List[str] = _build_labels(stacked, band_ranges, channel_names)
    # Retourne les features tabulaires accompagnés de leurs étiquettes
    return features, labels


def x_extract_features__mutmut_64(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = dict(config or {})
    # Déclare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = {
        "theta": (4.0, 7.0),
        "alpha": (8.0, 12.0),
        "beta": (13.0, 30.0),
        "gamma": (31.0, 45.0),
    }
    # Fusionne les bandes personnalisées en conservant l'ordre demandé
    band_ranges: Dict[str, Tuple[float, float]] = _resolve_band_ranges(
        effective_config, default_bands
    )
    # Refuse une configuration vide pour éviter un empilement sans bandes
    if not band_ranges:
        raise ValueError("At least one frequency band must be provided.")
    # Récupère la méthode pour aiguiller la stratégie d'extraction
    method: str = effective_config.pop("method", "welch")
    # Permet de contrôler l'activation de la normalisation via la configuration
    normalize = bool(effective_config.pop("normalize", False))
    # Supprime la configuration des bandes pour ne pas dupliquer l'information
    effective_config.pop("bands", None)
    # Capture les noms de canaux pour aligner les étiquettes de features
    channel_names: Sequence[str] = getattr(epochs.info, "ch_names", [])
    # Extrait les données temporelles pour calculer les caractéristiques spectrales
    data: np.ndarray = epochs.get_data()
    # Récupère la fréquence d'échantillonnage indispensable au calcul fréquentiel
    sfreq: float = None
    # Construit un extracteur scikit-learn pour déléguer le calcul
    estimator = ExtractFeatures(
        sfreq=sfreq,
        feature_strategy=method,
        normalize=normalize,
        bands=band_ranges,
        strategy_config=effective_config,
    )
    # Calcule les features en déléguant à l'extracteur scikit-learn
    features = estimator.transform(data)
    # Détermine le nombre de bandes pour reconstruire les étiquettes
    n_bands = len(band_ranges)
    # Recompose un tenseur factice pour générer les étiquettes canal/bande
    stacked = features.reshape(features.shape[0], data.shape[1], n_bands)
    # Construit des étiquettes canal_bande pour interpréter les features
    labels: List[str] = _build_labels(stacked, band_ranges, channel_names)
    # Retourne les features tabulaires accompagnés de leurs étiquettes
    return features, labels


def x_extract_features__mutmut_65(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = dict(config or {})
    # Déclare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = {
        "theta": (4.0, 7.0),
        "alpha": (8.0, 12.0),
        "beta": (13.0, 30.0),
        "gamma": (31.0, 45.0),
    }
    # Fusionne les bandes personnalisées en conservant l'ordre demandé
    band_ranges: Dict[str, Tuple[float, float]] = _resolve_band_ranges(
        effective_config, default_bands
    )
    # Refuse une configuration vide pour éviter un empilement sans bandes
    if not band_ranges:
        raise ValueError("At least one frequency band must be provided.")
    # Récupère la méthode pour aiguiller la stratégie d'extraction
    method: str = effective_config.pop("method", "welch")
    # Permet de contrôler l'activation de la normalisation via la configuration
    normalize = bool(effective_config.pop("normalize", False))
    # Supprime la configuration des bandes pour ne pas dupliquer l'information
    effective_config.pop("bands", None)
    # Capture les noms de canaux pour aligner les étiquettes de features
    channel_names: Sequence[str] = getattr(epochs.info, "ch_names", [])
    # Extrait les données temporelles pour calculer les caractéristiques spectrales
    data: np.ndarray = epochs.get_data()
    # Récupère la fréquence d'échantillonnage indispensable au calcul fréquentiel
    sfreq: float = float(None)
    # Construit un extracteur scikit-learn pour déléguer le calcul
    estimator = ExtractFeatures(
        sfreq=sfreq,
        feature_strategy=method,
        normalize=normalize,
        bands=band_ranges,
        strategy_config=effective_config,
    )
    # Calcule les features en déléguant à l'extracteur scikit-learn
    features = estimator.transform(data)
    # Détermine le nombre de bandes pour reconstruire les étiquettes
    n_bands = len(band_ranges)
    # Recompose un tenseur factice pour générer les étiquettes canal/bande
    stacked = features.reshape(features.shape[0], data.shape[1], n_bands)
    # Construit des étiquettes canal_bande pour interpréter les features
    labels: List[str] = _build_labels(stacked, band_ranges, channel_names)
    # Retourne les features tabulaires accompagnés de leurs étiquettes
    return features, labels


def x_extract_features__mutmut_66(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = dict(config or {})
    # Déclare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = {
        "theta": (4.0, 7.0),
        "alpha": (8.0, 12.0),
        "beta": (13.0, 30.0),
        "gamma": (31.0, 45.0),
    }
    # Fusionne les bandes personnalisées en conservant l'ordre demandé
    band_ranges: Dict[str, Tuple[float, float]] = _resolve_band_ranges(
        effective_config, default_bands
    )
    # Refuse une configuration vide pour éviter un empilement sans bandes
    if not band_ranges:
        raise ValueError("At least one frequency band must be provided.")
    # Récupère la méthode pour aiguiller la stratégie d'extraction
    method: str = effective_config.pop("method", "welch")
    # Permet de contrôler l'activation de la normalisation via la configuration
    normalize = bool(effective_config.pop("normalize", False))
    # Supprime la configuration des bandes pour ne pas dupliquer l'information
    effective_config.pop("bands", None)
    # Capture les noms de canaux pour aligner les étiquettes de features
    channel_names: Sequence[str] = getattr(epochs.info, "ch_names", [])
    # Extrait les données temporelles pour calculer les caractéristiques spectrales
    data: np.ndarray = epochs.get_data()
    # Récupère la fréquence d'échantillonnage indispensable au calcul fréquentiel
    sfreq: float = float(epochs.info["XXsfreqXX"])
    # Construit un extracteur scikit-learn pour déléguer le calcul
    estimator = ExtractFeatures(
        sfreq=sfreq,
        feature_strategy=method,
        normalize=normalize,
        bands=band_ranges,
        strategy_config=effective_config,
    )
    # Calcule les features en déléguant à l'extracteur scikit-learn
    features = estimator.transform(data)
    # Détermine le nombre de bandes pour reconstruire les étiquettes
    n_bands = len(band_ranges)
    # Recompose un tenseur factice pour générer les étiquettes canal/bande
    stacked = features.reshape(features.shape[0], data.shape[1], n_bands)
    # Construit des étiquettes canal_bande pour interpréter les features
    labels: List[str] = _build_labels(stacked, band_ranges, channel_names)
    # Retourne les features tabulaires accompagnés de leurs étiquettes
    return features, labels


def x_extract_features__mutmut_67(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = dict(config or {})
    # Déclare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = {
        "theta": (4.0, 7.0),
        "alpha": (8.0, 12.0),
        "beta": (13.0, 30.0),
        "gamma": (31.0, 45.0),
    }
    # Fusionne les bandes personnalisées en conservant l'ordre demandé
    band_ranges: Dict[str, Tuple[float, float]] = _resolve_band_ranges(
        effective_config, default_bands
    )
    # Refuse une configuration vide pour éviter un empilement sans bandes
    if not band_ranges:
        raise ValueError("At least one frequency band must be provided.")
    # Récupère la méthode pour aiguiller la stratégie d'extraction
    method: str = effective_config.pop("method", "welch")
    # Permet de contrôler l'activation de la normalisation via la configuration
    normalize = bool(effective_config.pop("normalize", False))
    # Supprime la configuration des bandes pour ne pas dupliquer l'information
    effective_config.pop("bands", None)
    # Capture les noms de canaux pour aligner les étiquettes de features
    channel_names: Sequence[str] = getattr(epochs.info, "ch_names", [])
    # Extrait les données temporelles pour calculer les caractéristiques spectrales
    data: np.ndarray = epochs.get_data()
    # Récupère la fréquence d'échantillonnage indispensable au calcul fréquentiel
    sfreq: float = float(epochs.info["SFREQ"])
    # Construit un extracteur scikit-learn pour déléguer le calcul
    estimator = ExtractFeatures(
        sfreq=sfreq,
        feature_strategy=method,
        normalize=normalize,
        bands=band_ranges,
        strategy_config=effective_config,
    )
    # Calcule les features en déléguant à l'extracteur scikit-learn
    features = estimator.transform(data)
    # Détermine le nombre de bandes pour reconstruire les étiquettes
    n_bands = len(band_ranges)
    # Recompose un tenseur factice pour générer les étiquettes canal/bande
    stacked = features.reshape(features.shape[0], data.shape[1], n_bands)
    # Construit des étiquettes canal_bande pour interpréter les features
    labels: List[str] = _build_labels(stacked, band_ranges, channel_names)
    # Retourne les features tabulaires accompagnés de leurs étiquettes
    return features, labels


def x_extract_features__mutmut_68(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = dict(config or {})
    # Déclare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = {
        "theta": (4.0, 7.0),
        "alpha": (8.0, 12.0),
        "beta": (13.0, 30.0),
        "gamma": (31.0, 45.0),
    }
    # Fusionne les bandes personnalisées en conservant l'ordre demandé
    band_ranges: Dict[str, Tuple[float, float]] = _resolve_band_ranges(
        effective_config, default_bands
    )
    # Refuse une configuration vide pour éviter un empilement sans bandes
    if not band_ranges:
        raise ValueError("At least one frequency band must be provided.")
    # Récupère la méthode pour aiguiller la stratégie d'extraction
    method: str = effective_config.pop("method", "welch")
    # Permet de contrôler l'activation de la normalisation via la configuration
    normalize = bool(effective_config.pop("normalize", False))
    # Supprime la configuration des bandes pour ne pas dupliquer l'information
    effective_config.pop("bands", None)
    # Capture les noms de canaux pour aligner les étiquettes de features
    channel_names: Sequence[str] = getattr(epochs.info, "ch_names", [])
    # Extrait les données temporelles pour calculer les caractéristiques spectrales
    data: np.ndarray = epochs.get_data()
    # Récupère la fréquence d'échantillonnage indispensable au calcul fréquentiel
    sfreq: float = float(epochs.info["sfreq"])
    # Construit un extracteur scikit-learn pour déléguer le calcul
    estimator = None
    # Calcule les features en déléguant à l'extracteur scikit-learn
    features = estimator.transform(data)
    # Détermine le nombre de bandes pour reconstruire les étiquettes
    n_bands = len(band_ranges)
    # Recompose un tenseur factice pour générer les étiquettes canal/bande
    stacked = features.reshape(features.shape[0], data.shape[1], n_bands)
    # Construit des étiquettes canal_bande pour interpréter les features
    labels: List[str] = _build_labels(stacked, band_ranges, channel_names)
    # Retourne les features tabulaires accompagnés de leurs étiquettes
    return features, labels


def x_extract_features__mutmut_69(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = dict(config or {})
    # Déclare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = {
        "theta": (4.0, 7.0),
        "alpha": (8.0, 12.0),
        "beta": (13.0, 30.0),
        "gamma": (31.0, 45.0),
    }
    # Fusionne les bandes personnalisées en conservant l'ordre demandé
    band_ranges: Dict[str, Tuple[float, float]] = _resolve_band_ranges(
        effective_config, default_bands
    )
    # Refuse une configuration vide pour éviter un empilement sans bandes
    if not band_ranges:
        raise ValueError("At least one frequency band must be provided.")
    # Récupère la méthode pour aiguiller la stratégie d'extraction
    method: str = effective_config.pop("method", "welch")
    # Permet de contrôler l'activation de la normalisation via la configuration
    normalize = bool(effective_config.pop("normalize", False))
    # Supprime la configuration des bandes pour ne pas dupliquer l'information
    effective_config.pop("bands", None)
    # Capture les noms de canaux pour aligner les étiquettes de features
    channel_names: Sequence[str] = getattr(epochs.info, "ch_names", [])
    # Extrait les données temporelles pour calculer les caractéristiques spectrales
    data: np.ndarray = epochs.get_data()
    # Récupère la fréquence d'échantillonnage indispensable au calcul fréquentiel
    sfreq: float = float(epochs.info["sfreq"])
    # Construit un extracteur scikit-learn pour déléguer le calcul
    estimator = ExtractFeatures(
        sfreq=None,
        feature_strategy=method,
        normalize=normalize,
        bands=band_ranges,
        strategy_config=effective_config,
    )
    # Calcule les features en déléguant à l'extracteur scikit-learn
    features = estimator.transform(data)
    # Détermine le nombre de bandes pour reconstruire les étiquettes
    n_bands = len(band_ranges)
    # Recompose un tenseur factice pour générer les étiquettes canal/bande
    stacked = features.reshape(features.shape[0], data.shape[1], n_bands)
    # Construit des étiquettes canal_bande pour interpréter les features
    labels: List[str] = _build_labels(stacked, band_ranges, channel_names)
    # Retourne les features tabulaires accompagnés de leurs étiquettes
    return features, labels


def x_extract_features__mutmut_70(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = dict(config or {})
    # Déclare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = {
        "theta": (4.0, 7.0),
        "alpha": (8.0, 12.0),
        "beta": (13.0, 30.0),
        "gamma": (31.0, 45.0),
    }
    # Fusionne les bandes personnalisées en conservant l'ordre demandé
    band_ranges: Dict[str, Tuple[float, float]] = _resolve_band_ranges(
        effective_config, default_bands
    )
    # Refuse une configuration vide pour éviter un empilement sans bandes
    if not band_ranges:
        raise ValueError("At least one frequency band must be provided.")
    # Récupère la méthode pour aiguiller la stratégie d'extraction
    method: str = effective_config.pop("method", "welch")
    # Permet de contrôler l'activation de la normalisation via la configuration
    normalize = bool(effective_config.pop("normalize", False))
    # Supprime la configuration des bandes pour ne pas dupliquer l'information
    effective_config.pop("bands", None)
    # Capture les noms de canaux pour aligner les étiquettes de features
    channel_names: Sequence[str] = getattr(epochs.info, "ch_names", [])
    # Extrait les données temporelles pour calculer les caractéristiques spectrales
    data: np.ndarray = epochs.get_data()
    # Récupère la fréquence d'échantillonnage indispensable au calcul fréquentiel
    sfreq: float = float(epochs.info["sfreq"])
    # Construit un extracteur scikit-learn pour déléguer le calcul
    estimator = ExtractFeatures(
        sfreq=sfreq,
        feature_strategy=None,
        normalize=normalize,
        bands=band_ranges,
        strategy_config=effective_config,
    )
    # Calcule les features en déléguant à l'extracteur scikit-learn
    features = estimator.transform(data)
    # Détermine le nombre de bandes pour reconstruire les étiquettes
    n_bands = len(band_ranges)
    # Recompose un tenseur factice pour générer les étiquettes canal/bande
    stacked = features.reshape(features.shape[0], data.shape[1], n_bands)
    # Construit des étiquettes canal_bande pour interpréter les features
    labels: List[str] = _build_labels(stacked, band_ranges, channel_names)
    # Retourne les features tabulaires accompagnés de leurs étiquettes
    return features, labels


def x_extract_features__mutmut_71(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = dict(config or {})
    # Déclare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = {
        "theta": (4.0, 7.0),
        "alpha": (8.0, 12.0),
        "beta": (13.0, 30.0),
        "gamma": (31.0, 45.0),
    }
    # Fusionne les bandes personnalisées en conservant l'ordre demandé
    band_ranges: Dict[str, Tuple[float, float]] = _resolve_band_ranges(
        effective_config, default_bands
    )
    # Refuse une configuration vide pour éviter un empilement sans bandes
    if not band_ranges:
        raise ValueError("At least one frequency band must be provided.")
    # Récupère la méthode pour aiguiller la stratégie d'extraction
    method: str = effective_config.pop("method", "welch")
    # Permet de contrôler l'activation de la normalisation via la configuration
    normalize = bool(effective_config.pop("normalize", False))
    # Supprime la configuration des bandes pour ne pas dupliquer l'information
    effective_config.pop("bands", None)
    # Capture les noms de canaux pour aligner les étiquettes de features
    channel_names: Sequence[str] = getattr(epochs.info, "ch_names", [])
    # Extrait les données temporelles pour calculer les caractéristiques spectrales
    data: np.ndarray = epochs.get_data()
    # Récupère la fréquence d'échantillonnage indispensable au calcul fréquentiel
    sfreq: float = float(epochs.info["sfreq"])
    # Construit un extracteur scikit-learn pour déléguer le calcul
    estimator = ExtractFeatures(
        sfreq=sfreq,
        feature_strategy=method,
        normalize=None,
        bands=band_ranges,
        strategy_config=effective_config,
    )
    # Calcule les features en déléguant à l'extracteur scikit-learn
    features = estimator.transform(data)
    # Détermine le nombre de bandes pour reconstruire les étiquettes
    n_bands = len(band_ranges)
    # Recompose un tenseur factice pour générer les étiquettes canal/bande
    stacked = features.reshape(features.shape[0], data.shape[1], n_bands)
    # Construit des étiquettes canal_bande pour interpréter les features
    labels: List[str] = _build_labels(stacked, band_ranges, channel_names)
    # Retourne les features tabulaires accompagnés de leurs étiquettes
    return features, labels


def x_extract_features__mutmut_72(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = dict(config or {})
    # Déclare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = {
        "theta": (4.0, 7.0),
        "alpha": (8.0, 12.0),
        "beta": (13.0, 30.0),
        "gamma": (31.0, 45.0),
    }
    # Fusionne les bandes personnalisées en conservant l'ordre demandé
    band_ranges: Dict[str, Tuple[float, float]] = _resolve_band_ranges(
        effective_config, default_bands
    )
    # Refuse une configuration vide pour éviter un empilement sans bandes
    if not band_ranges:
        raise ValueError("At least one frequency band must be provided.")
    # Récupère la méthode pour aiguiller la stratégie d'extraction
    method: str = effective_config.pop("method", "welch")
    # Permet de contrôler l'activation de la normalisation via la configuration
    normalize = bool(effective_config.pop("normalize", False))
    # Supprime la configuration des bandes pour ne pas dupliquer l'information
    effective_config.pop("bands", None)
    # Capture les noms de canaux pour aligner les étiquettes de features
    channel_names: Sequence[str] = getattr(epochs.info, "ch_names", [])
    # Extrait les données temporelles pour calculer les caractéristiques spectrales
    data: np.ndarray = epochs.get_data()
    # Récupère la fréquence d'échantillonnage indispensable au calcul fréquentiel
    sfreq: float = float(epochs.info["sfreq"])
    # Construit un extracteur scikit-learn pour déléguer le calcul
    estimator = ExtractFeatures(
        sfreq=sfreq,
        feature_strategy=method,
        normalize=normalize,
        bands=None,
        strategy_config=effective_config,
    )
    # Calcule les features en déléguant à l'extracteur scikit-learn
    features = estimator.transform(data)
    # Détermine le nombre de bandes pour reconstruire les étiquettes
    n_bands = len(band_ranges)
    # Recompose un tenseur factice pour générer les étiquettes canal/bande
    stacked = features.reshape(features.shape[0], data.shape[1], n_bands)
    # Construit des étiquettes canal_bande pour interpréter les features
    labels: List[str] = _build_labels(stacked, band_ranges, channel_names)
    # Retourne les features tabulaires accompagnés de leurs étiquettes
    return features, labels


def x_extract_features__mutmut_73(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = dict(config or {})
    # Déclare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = {
        "theta": (4.0, 7.0),
        "alpha": (8.0, 12.0),
        "beta": (13.0, 30.0),
        "gamma": (31.0, 45.0),
    }
    # Fusionne les bandes personnalisées en conservant l'ordre demandé
    band_ranges: Dict[str, Tuple[float, float]] = _resolve_band_ranges(
        effective_config, default_bands
    )
    # Refuse une configuration vide pour éviter un empilement sans bandes
    if not band_ranges:
        raise ValueError("At least one frequency band must be provided.")
    # Récupère la méthode pour aiguiller la stratégie d'extraction
    method: str = effective_config.pop("method", "welch")
    # Permet de contrôler l'activation de la normalisation via la configuration
    normalize = bool(effective_config.pop("normalize", False))
    # Supprime la configuration des bandes pour ne pas dupliquer l'information
    effective_config.pop("bands", None)
    # Capture les noms de canaux pour aligner les étiquettes de features
    channel_names: Sequence[str] = getattr(epochs.info, "ch_names", [])
    # Extrait les données temporelles pour calculer les caractéristiques spectrales
    data: np.ndarray = epochs.get_data()
    # Récupère la fréquence d'échantillonnage indispensable au calcul fréquentiel
    sfreq: float = float(epochs.info["sfreq"])
    # Construit un extracteur scikit-learn pour déléguer le calcul
    estimator = ExtractFeatures(
        sfreq=sfreq,
        feature_strategy=method,
        normalize=normalize,
        bands=band_ranges,
        strategy_config=None,
    )
    # Calcule les features en déléguant à l'extracteur scikit-learn
    features = estimator.transform(data)
    # Détermine le nombre de bandes pour reconstruire les étiquettes
    n_bands = len(band_ranges)
    # Recompose un tenseur factice pour générer les étiquettes canal/bande
    stacked = features.reshape(features.shape[0], data.shape[1], n_bands)
    # Construit des étiquettes canal_bande pour interpréter les features
    labels: List[str] = _build_labels(stacked, band_ranges, channel_names)
    # Retourne les features tabulaires accompagnés de leurs étiquettes
    return features, labels


def x_extract_features__mutmut_74(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = dict(config or {})
    # Déclare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = {
        "theta": (4.0, 7.0),
        "alpha": (8.0, 12.0),
        "beta": (13.0, 30.0),
        "gamma": (31.0, 45.0),
    }
    # Fusionne les bandes personnalisées en conservant l'ordre demandé
    band_ranges: Dict[str, Tuple[float, float]] = _resolve_band_ranges(
        effective_config, default_bands
    )
    # Refuse une configuration vide pour éviter un empilement sans bandes
    if not band_ranges:
        raise ValueError("At least one frequency band must be provided.")
    # Récupère la méthode pour aiguiller la stratégie d'extraction
    method: str = effective_config.pop("method", "welch")
    # Permet de contrôler l'activation de la normalisation via la configuration
    normalize = bool(effective_config.pop("normalize", False))
    # Supprime la configuration des bandes pour ne pas dupliquer l'information
    effective_config.pop("bands", None)
    # Capture les noms de canaux pour aligner les étiquettes de features
    channel_names: Sequence[str] = getattr(epochs.info, "ch_names", [])
    # Extrait les données temporelles pour calculer les caractéristiques spectrales
    data: np.ndarray = epochs.get_data()
    # Récupère la fréquence d'échantillonnage indispensable au calcul fréquentiel
    sfreq: float = float(epochs.info["sfreq"])
    # Construit un extracteur scikit-learn pour déléguer le calcul
    estimator = ExtractFeatures(
        feature_strategy=method,
        normalize=normalize,
        bands=band_ranges,
        strategy_config=effective_config,
    )
    # Calcule les features en déléguant à l'extracteur scikit-learn
    features = estimator.transform(data)
    # Détermine le nombre de bandes pour reconstruire les étiquettes
    n_bands = len(band_ranges)
    # Recompose un tenseur factice pour générer les étiquettes canal/bande
    stacked = features.reshape(features.shape[0], data.shape[1], n_bands)
    # Construit des étiquettes canal_bande pour interpréter les features
    labels: List[str] = _build_labels(stacked, band_ranges, channel_names)
    # Retourne les features tabulaires accompagnés de leurs étiquettes
    return features, labels


def x_extract_features__mutmut_75(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = dict(config or {})
    # Déclare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = {
        "theta": (4.0, 7.0),
        "alpha": (8.0, 12.0),
        "beta": (13.0, 30.0),
        "gamma": (31.0, 45.0),
    }
    # Fusionne les bandes personnalisées en conservant l'ordre demandé
    band_ranges: Dict[str, Tuple[float, float]] = _resolve_band_ranges(
        effective_config, default_bands
    )
    # Refuse une configuration vide pour éviter un empilement sans bandes
    if not band_ranges:
        raise ValueError("At least one frequency band must be provided.")
    # Récupère la méthode pour aiguiller la stratégie d'extraction
    method: str = effective_config.pop("method", "welch")
    # Permet de contrôler l'activation de la normalisation via la configuration
    normalize = bool(effective_config.pop("normalize", False))
    # Supprime la configuration des bandes pour ne pas dupliquer l'information
    effective_config.pop("bands", None)
    # Capture les noms de canaux pour aligner les étiquettes de features
    channel_names: Sequence[str] = getattr(epochs.info, "ch_names", [])
    # Extrait les données temporelles pour calculer les caractéristiques spectrales
    data: np.ndarray = epochs.get_data()
    # Récupère la fréquence d'échantillonnage indispensable au calcul fréquentiel
    sfreq: float = float(epochs.info["sfreq"])
    # Construit un extracteur scikit-learn pour déléguer le calcul
    estimator = ExtractFeatures(
        sfreq=sfreq,
        normalize=normalize,
        bands=band_ranges,
        strategy_config=effective_config,
    )
    # Calcule les features en déléguant à l'extracteur scikit-learn
    features = estimator.transform(data)
    # Détermine le nombre de bandes pour reconstruire les étiquettes
    n_bands = len(band_ranges)
    # Recompose un tenseur factice pour générer les étiquettes canal/bande
    stacked = features.reshape(features.shape[0], data.shape[1], n_bands)
    # Construit des étiquettes canal_bande pour interpréter les features
    labels: List[str] = _build_labels(stacked, band_ranges, channel_names)
    # Retourne les features tabulaires accompagnés de leurs étiquettes
    return features, labels


def x_extract_features__mutmut_76(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = dict(config or {})
    # Déclare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = {
        "theta": (4.0, 7.0),
        "alpha": (8.0, 12.0),
        "beta": (13.0, 30.0),
        "gamma": (31.0, 45.0),
    }
    # Fusionne les bandes personnalisées en conservant l'ordre demandé
    band_ranges: Dict[str, Tuple[float, float]] = _resolve_band_ranges(
        effective_config, default_bands
    )
    # Refuse une configuration vide pour éviter un empilement sans bandes
    if not band_ranges:
        raise ValueError("At least one frequency band must be provided.")
    # Récupère la méthode pour aiguiller la stratégie d'extraction
    method: str = effective_config.pop("method", "welch")
    # Permet de contrôler l'activation de la normalisation via la configuration
    normalize = bool(effective_config.pop("normalize", False))
    # Supprime la configuration des bandes pour ne pas dupliquer l'information
    effective_config.pop("bands", None)
    # Capture les noms de canaux pour aligner les étiquettes de features
    channel_names: Sequence[str] = getattr(epochs.info, "ch_names", [])
    # Extrait les données temporelles pour calculer les caractéristiques spectrales
    data: np.ndarray = epochs.get_data()
    # Récupère la fréquence d'échantillonnage indispensable au calcul fréquentiel
    sfreq: float = float(epochs.info["sfreq"])
    # Construit un extracteur scikit-learn pour déléguer le calcul
    estimator = ExtractFeatures(
        sfreq=sfreq,
        feature_strategy=method,
        bands=band_ranges,
        strategy_config=effective_config,
    )
    # Calcule les features en déléguant à l'extracteur scikit-learn
    features = estimator.transform(data)
    # Détermine le nombre de bandes pour reconstruire les étiquettes
    n_bands = len(band_ranges)
    # Recompose un tenseur factice pour générer les étiquettes canal/bande
    stacked = features.reshape(features.shape[0], data.shape[1], n_bands)
    # Construit des étiquettes canal_bande pour interpréter les features
    labels: List[str] = _build_labels(stacked, band_ranges, channel_names)
    # Retourne les features tabulaires accompagnés de leurs étiquettes
    return features, labels


def x_extract_features__mutmut_77(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = dict(config or {})
    # Déclare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = {
        "theta": (4.0, 7.0),
        "alpha": (8.0, 12.0),
        "beta": (13.0, 30.0),
        "gamma": (31.0, 45.0),
    }
    # Fusionne les bandes personnalisées en conservant l'ordre demandé
    band_ranges: Dict[str, Tuple[float, float]] = _resolve_band_ranges(
        effective_config, default_bands
    )
    # Refuse une configuration vide pour éviter un empilement sans bandes
    if not band_ranges:
        raise ValueError("At least one frequency band must be provided.")
    # Récupère la méthode pour aiguiller la stratégie d'extraction
    method: str = effective_config.pop("method", "welch")
    # Permet de contrôler l'activation de la normalisation via la configuration
    normalize = bool(effective_config.pop("normalize", False))
    # Supprime la configuration des bandes pour ne pas dupliquer l'information
    effective_config.pop("bands", None)
    # Capture les noms de canaux pour aligner les étiquettes de features
    channel_names: Sequence[str] = getattr(epochs.info, "ch_names", [])
    # Extrait les données temporelles pour calculer les caractéristiques spectrales
    data: np.ndarray = epochs.get_data()
    # Récupère la fréquence d'échantillonnage indispensable au calcul fréquentiel
    sfreq: float = float(epochs.info["sfreq"])
    # Construit un extracteur scikit-learn pour déléguer le calcul
    estimator = ExtractFeatures(
        sfreq=sfreq,
        feature_strategy=method,
        normalize=normalize,
        strategy_config=effective_config,
    )
    # Calcule les features en déléguant à l'extracteur scikit-learn
    features = estimator.transform(data)
    # Détermine le nombre de bandes pour reconstruire les étiquettes
    n_bands = len(band_ranges)
    # Recompose un tenseur factice pour générer les étiquettes canal/bande
    stacked = features.reshape(features.shape[0], data.shape[1], n_bands)
    # Construit des étiquettes canal_bande pour interpréter les features
    labels: List[str] = _build_labels(stacked, band_ranges, channel_names)
    # Retourne les features tabulaires accompagnés de leurs étiquettes
    return features, labels


def x_extract_features__mutmut_78(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = dict(config or {})
    # Déclare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = {
        "theta": (4.0, 7.0),
        "alpha": (8.0, 12.0),
        "beta": (13.0, 30.0),
        "gamma": (31.0, 45.0),
    }
    # Fusionne les bandes personnalisées en conservant l'ordre demandé
    band_ranges: Dict[str, Tuple[float, float]] = _resolve_band_ranges(
        effective_config, default_bands
    )
    # Refuse une configuration vide pour éviter un empilement sans bandes
    if not band_ranges:
        raise ValueError("At least one frequency band must be provided.")
    # Récupère la méthode pour aiguiller la stratégie d'extraction
    method: str = effective_config.pop("method", "welch")
    # Permet de contrôler l'activation de la normalisation via la configuration
    normalize = bool(effective_config.pop("normalize", False))
    # Supprime la configuration des bandes pour ne pas dupliquer l'information
    effective_config.pop("bands", None)
    # Capture les noms de canaux pour aligner les étiquettes de features
    channel_names: Sequence[str] = getattr(epochs.info, "ch_names", [])
    # Extrait les données temporelles pour calculer les caractéristiques spectrales
    data: np.ndarray = epochs.get_data()
    # Récupère la fréquence d'échantillonnage indispensable au calcul fréquentiel
    sfreq: float = float(epochs.info["sfreq"])
    # Construit un extracteur scikit-learn pour déléguer le calcul
    estimator = ExtractFeatures(
        sfreq=sfreq,
        feature_strategy=method,
        normalize=normalize,
        bands=band_ranges,
        )
    # Calcule les features en déléguant à l'extracteur scikit-learn
    features = estimator.transform(data)
    # Détermine le nombre de bandes pour reconstruire les étiquettes
    n_bands = len(band_ranges)
    # Recompose un tenseur factice pour générer les étiquettes canal/bande
    stacked = features.reshape(features.shape[0], data.shape[1], n_bands)
    # Construit des étiquettes canal_bande pour interpréter les features
    labels: List[str] = _build_labels(stacked, band_ranges, channel_names)
    # Retourne les features tabulaires accompagnés de leurs étiquettes
    return features, labels


def x_extract_features__mutmut_79(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = dict(config or {})
    # Déclare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = {
        "theta": (4.0, 7.0),
        "alpha": (8.0, 12.0),
        "beta": (13.0, 30.0),
        "gamma": (31.0, 45.0),
    }
    # Fusionne les bandes personnalisées en conservant l'ordre demandé
    band_ranges: Dict[str, Tuple[float, float]] = _resolve_band_ranges(
        effective_config, default_bands
    )
    # Refuse une configuration vide pour éviter un empilement sans bandes
    if not band_ranges:
        raise ValueError("At least one frequency band must be provided.")
    # Récupère la méthode pour aiguiller la stratégie d'extraction
    method: str = effective_config.pop("method", "welch")
    # Permet de contrôler l'activation de la normalisation via la configuration
    normalize = bool(effective_config.pop("normalize", False))
    # Supprime la configuration des bandes pour ne pas dupliquer l'information
    effective_config.pop("bands", None)
    # Capture les noms de canaux pour aligner les étiquettes de features
    channel_names: Sequence[str] = getattr(epochs.info, "ch_names", [])
    # Extrait les données temporelles pour calculer les caractéristiques spectrales
    data: np.ndarray = epochs.get_data()
    # Récupère la fréquence d'échantillonnage indispensable au calcul fréquentiel
    sfreq: float = float(epochs.info["sfreq"])
    # Construit un extracteur scikit-learn pour déléguer le calcul
    estimator = ExtractFeatures(
        sfreq=sfreq,
        feature_strategy=method,
        normalize=normalize,
        bands=band_ranges,
        strategy_config=effective_config,
    )
    # Calcule les features en déléguant à l'extracteur scikit-learn
    features = None
    # Détermine le nombre de bandes pour reconstruire les étiquettes
    n_bands = len(band_ranges)
    # Recompose un tenseur factice pour générer les étiquettes canal/bande
    stacked = features.reshape(features.shape[0], data.shape[1], n_bands)
    # Construit des étiquettes canal_bande pour interpréter les features
    labels: List[str] = _build_labels(stacked, band_ranges, channel_names)
    # Retourne les features tabulaires accompagnés de leurs étiquettes
    return features, labels


def x_extract_features__mutmut_80(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = dict(config or {})
    # Déclare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = {
        "theta": (4.0, 7.0),
        "alpha": (8.0, 12.0),
        "beta": (13.0, 30.0),
        "gamma": (31.0, 45.0),
    }
    # Fusionne les bandes personnalisées en conservant l'ordre demandé
    band_ranges: Dict[str, Tuple[float, float]] = _resolve_band_ranges(
        effective_config, default_bands
    )
    # Refuse une configuration vide pour éviter un empilement sans bandes
    if not band_ranges:
        raise ValueError("At least one frequency band must be provided.")
    # Récupère la méthode pour aiguiller la stratégie d'extraction
    method: str = effective_config.pop("method", "welch")
    # Permet de contrôler l'activation de la normalisation via la configuration
    normalize = bool(effective_config.pop("normalize", False))
    # Supprime la configuration des bandes pour ne pas dupliquer l'information
    effective_config.pop("bands", None)
    # Capture les noms de canaux pour aligner les étiquettes de features
    channel_names: Sequence[str] = getattr(epochs.info, "ch_names", [])
    # Extrait les données temporelles pour calculer les caractéristiques spectrales
    data: np.ndarray = epochs.get_data()
    # Récupère la fréquence d'échantillonnage indispensable au calcul fréquentiel
    sfreq: float = float(epochs.info["sfreq"])
    # Construit un extracteur scikit-learn pour déléguer le calcul
    estimator = ExtractFeatures(
        sfreq=sfreq,
        feature_strategy=method,
        normalize=normalize,
        bands=band_ranges,
        strategy_config=effective_config,
    )
    # Calcule les features en déléguant à l'extracteur scikit-learn
    features = estimator.transform(None)
    # Détermine le nombre de bandes pour reconstruire les étiquettes
    n_bands = len(band_ranges)
    # Recompose un tenseur factice pour générer les étiquettes canal/bande
    stacked = features.reshape(features.shape[0], data.shape[1], n_bands)
    # Construit des étiquettes canal_bande pour interpréter les features
    labels: List[str] = _build_labels(stacked, band_ranges, channel_names)
    # Retourne les features tabulaires accompagnés de leurs étiquettes
    return features, labels


def x_extract_features__mutmut_81(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = dict(config or {})
    # Déclare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = {
        "theta": (4.0, 7.0),
        "alpha": (8.0, 12.0),
        "beta": (13.0, 30.0),
        "gamma": (31.0, 45.0),
    }
    # Fusionne les bandes personnalisées en conservant l'ordre demandé
    band_ranges: Dict[str, Tuple[float, float]] = _resolve_band_ranges(
        effective_config, default_bands
    )
    # Refuse une configuration vide pour éviter un empilement sans bandes
    if not band_ranges:
        raise ValueError("At least one frequency band must be provided.")
    # Récupère la méthode pour aiguiller la stratégie d'extraction
    method: str = effective_config.pop("method", "welch")
    # Permet de contrôler l'activation de la normalisation via la configuration
    normalize = bool(effective_config.pop("normalize", False))
    # Supprime la configuration des bandes pour ne pas dupliquer l'information
    effective_config.pop("bands", None)
    # Capture les noms de canaux pour aligner les étiquettes de features
    channel_names: Sequence[str] = getattr(epochs.info, "ch_names", [])
    # Extrait les données temporelles pour calculer les caractéristiques spectrales
    data: np.ndarray = epochs.get_data()
    # Récupère la fréquence d'échantillonnage indispensable au calcul fréquentiel
    sfreq: float = float(epochs.info["sfreq"])
    # Construit un extracteur scikit-learn pour déléguer le calcul
    estimator = ExtractFeatures(
        sfreq=sfreq,
        feature_strategy=method,
        normalize=normalize,
        bands=band_ranges,
        strategy_config=effective_config,
    )
    # Calcule les features en déléguant à l'extracteur scikit-learn
    features = estimator.transform(data)
    # Détermine le nombre de bandes pour reconstruire les étiquettes
    n_bands = None
    # Recompose un tenseur factice pour générer les étiquettes canal/bande
    stacked = features.reshape(features.shape[0], data.shape[1], n_bands)
    # Construit des étiquettes canal_bande pour interpréter les features
    labels: List[str] = _build_labels(stacked, band_ranges, channel_names)
    # Retourne les features tabulaires accompagnés de leurs étiquettes
    return features, labels


def x_extract_features__mutmut_82(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = dict(config or {})
    # Déclare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = {
        "theta": (4.0, 7.0),
        "alpha": (8.0, 12.0),
        "beta": (13.0, 30.0),
        "gamma": (31.0, 45.0),
    }
    # Fusionne les bandes personnalisées en conservant l'ordre demandé
    band_ranges: Dict[str, Tuple[float, float]] = _resolve_band_ranges(
        effective_config, default_bands
    )
    # Refuse une configuration vide pour éviter un empilement sans bandes
    if not band_ranges:
        raise ValueError("At least one frequency band must be provided.")
    # Récupère la méthode pour aiguiller la stratégie d'extraction
    method: str = effective_config.pop("method", "welch")
    # Permet de contrôler l'activation de la normalisation via la configuration
    normalize = bool(effective_config.pop("normalize", False))
    # Supprime la configuration des bandes pour ne pas dupliquer l'information
    effective_config.pop("bands", None)
    # Capture les noms de canaux pour aligner les étiquettes de features
    channel_names: Sequence[str] = getattr(epochs.info, "ch_names", [])
    # Extrait les données temporelles pour calculer les caractéristiques spectrales
    data: np.ndarray = epochs.get_data()
    # Récupère la fréquence d'échantillonnage indispensable au calcul fréquentiel
    sfreq: float = float(epochs.info["sfreq"])
    # Construit un extracteur scikit-learn pour déléguer le calcul
    estimator = ExtractFeatures(
        sfreq=sfreq,
        feature_strategy=method,
        normalize=normalize,
        bands=band_ranges,
        strategy_config=effective_config,
    )
    # Calcule les features en déléguant à l'extracteur scikit-learn
    features = estimator.transform(data)
    # Détermine le nombre de bandes pour reconstruire les étiquettes
    n_bands = len(band_ranges)
    # Recompose un tenseur factice pour générer les étiquettes canal/bande
    stacked = None
    # Construit des étiquettes canal_bande pour interpréter les features
    labels: List[str] = _build_labels(stacked, band_ranges, channel_names)
    # Retourne les features tabulaires accompagnés de leurs étiquettes
    return features, labels


def x_extract_features__mutmut_83(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = dict(config or {})
    # Déclare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = {
        "theta": (4.0, 7.0),
        "alpha": (8.0, 12.0),
        "beta": (13.0, 30.0),
        "gamma": (31.0, 45.0),
    }
    # Fusionne les bandes personnalisées en conservant l'ordre demandé
    band_ranges: Dict[str, Tuple[float, float]] = _resolve_band_ranges(
        effective_config, default_bands
    )
    # Refuse une configuration vide pour éviter un empilement sans bandes
    if not band_ranges:
        raise ValueError("At least one frequency band must be provided.")
    # Récupère la méthode pour aiguiller la stratégie d'extraction
    method: str = effective_config.pop("method", "welch")
    # Permet de contrôler l'activation de la normalisation via la configuration
    normalize = bool(effective_config.pop("normalize", False))
    # Supprime la configuration des bandes pour ne pas dupliquer l'information
    effective_config.pop("bands", None)
    # Capture les noms de canaux pour aligner les étiquettes de features
    channel_names: Sequence[str] = getattr(epochs.info, "ch_names", [])
    # Extrait les données temporelles pour calculer les caractéristiques spectrales
    data: np.ndarray = epochs.get_data()
    # Récupère la fréquence d'échantillonnage indispensable au calcul fréquentiel
    sfreq: float = float(epochs.info["sfreq"])
    # Construit un extracteur scikit-learn pour déléguer le calcul
    estimator = ExtractFeatures(
        sfreq=sfreq,
        feature_strategy=method,
        normalize=normalize,
        bands=band_ranges,
        strategy_config=effective_config,
    )
    # Calcule les features en déléguant à l'extracteur scikit-learn
    features = estimator.transform(data)
    # Détermine le nombre de bandes pour reconstruire les étiquettes
    n_bands = len(band_ranges)
    # Recompose un tenseur factice pour générer les étiquettes canal/bande
    stacked = features.reshape(None, data.shape[1], n_bands)
    # Construit des étiquettes canal_bande pour interpréter les features
    labels: List[str] = _build_labels(stacked, band_ranges, channel_names)
    # Retourne les features tabulaires accompagnés de leurs étiquettes
    return features, labels


def x_extract_features__mutmut_84(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = dict(config or {})
    # Déclare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = {
        "theta": (4.0, 7.0),
        "alpha": (8.0, 12.0),
        "beta": (13.0, 30.0),
        "gamma": (31.0, 45.0),
    }
    # Fusionne les bandes personnalisées en conservant l'ordre demandé
    band_ranges: Dict[str, Tuple[float, float]] = _resolve_band_ranges(
        effective_config, default_bands
    )
    # Refuse une configuration vide pour éviter un empilement sans bandes
    if not band_ranges:
        raise ValueError("At least one frequency band must be provided.")
    # Récupère la méthode pour aiguiller la stratégie d'extraction
    method: str = effective_config.pop("method", "welch")
    # Permet de contrôler l'activation de la normalisation via la configuration
    normalize = bool(effective_config.pop("normalize", False))
    # Supprime la configuration des bandes pour ne pas dupliquer l'information
    effective_config.pop("bands", None)
    # Capture les noms de canaux pour aligner les étiquettes de features
    channel_names: Sequence[str] = getattr(epochs.info, "ch_names", [])
    # Extrait les données temporelles pour calculer les caractéristiques spectrales
    data: np.ndarray = epochs.get_data()
    # Récupère la fréquence d'échantillonnage indispensable au calcul fréquentiel
    sfreq: float = float(epochs.info["sfreq"])
    # Construit un extracteur scikit-learn pour déléguer le calcul
    estimator = ExtractFeatures(
        sfreq=sfreq,
        feature_strategy=method,
        normalize=normalize,
        bands=band_ranges,
        strategy_config=effective_config,
    )
    # Calcule les features en déléguant à l'extracteur scikit-learn
    features = estimator.transform(data)
    # Détermine le nombre de bandes pour reconstruire les étiquettes
    n_bands = len(band_ranges)
    # Recompose un tenseur factice pour générer les étiquettes canal/bande
    stacked = features.reshape(features.shape[0], None, n_bands)
    # Construit des étiquettes canal_bande pour interpréter les features
    labels: List[str] = _build_labels(stacked, band_ranges, channel_names)
    # Retourne les features tabulaires accompagnés de leurs étiquettes
    return features, labels


def x_extract_features__mutmut_85(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = dict(config or {})
    # Déclare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = {
        "theta": (4.0, 7.0),
        "alpha": (8.0, 12.0),
        "beta": (13.0, 30.0),
        "gamma": (31.0, 45.0),
    }
    # Fusionne les bandes personnalisées en conservant l'ordre demandé
    band_ranges: Dict[str, Tuple[float, float]] = _resolve_band_ranges(
        effective_config, default_bands
    )
    # Refuse une configuration vide pour éviter un empilement sans bandes
    if not band_ranges:
        raise ValueError("At least one frequency band must be provided.")
    # Récupère la méthode pour aiguiller la stratégie d'extraction
    method: str = effective_config.pop("method", "welch")
    # Permet de contrôler l'activation de la normalisation via la configuration
    normalize = bool(effective_config.pop("normalize", False))
    # Supprime la configuration des bandes pour ne pas dupliquer l'information
    effective_config.pop("bands", None)
    # Capture les noms de canaux pour aligner les étiquettes de features
    channel_names: Sequence[str] = getattr(epochs.info, "ch_names", [])
    # Extrait les données temporelles pour calculer les caractéristiques spectrales
    data: np.ndarray = epochs.get_data()
    # Récupère la fréquence d'échantillonnage indispensable au calcul fréquentiel
    sfreq: float = float(epochs.info["sfreq"])
    # Construit un extracteur scikit-learn pour déléguer le calcul
    estimator = ExtractFeatures(
        sfreq=sfreq,
        feature_strategy=method,
        normalize=normalize,
        bands=band_ranges,
        strategy_config=effective_config,
    )
    # Calcule les features en déléguant à l'extracteur scikit-learn
    features = estimator.transform(data)
    # Détermine le nombre de bandes pour reconstruire les étiquettes
    n_bands = len(band_ranges)
    # Recompose un tenseur factice pour générer les étiquettes canal/bande
    stacked = features.reshape(features.shape[0], data.shape[1], None)
    # Construit des étiquettes canal_bande pour interpréter les features
    labels: List[str] = _build_labels(stacked, band_ranges, channel_names)
    # Retourne les features tabulaires accompagnés de leurs étiquettes
    return features, labels


def x_extract_features__mutmut_86(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = dict(config or {})
    # Déclare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = {
        "theta": (4.0, 7.0),
        "alpha": (8.0, 12.0),
        "beta": (13.0, 30.0),
        "gamma": (31.0, 45.0),
    }
    # Fusionne les bandes personnalisées en conservant l'ordre demandé
    band_ranges: Dict[str, Tuple[float, float]] = _resolve_band_ranges(
        effective_config, default_bands
    )
    # Refuse une configuration vide pour éviter un empilement sans bandes
    if not band_ranges:
        raise ValueError("At least one frequency band must be provided.")
    # Récupère la méthode pour aiguiller la stratégie d'extraction
    method: str = effective_config.pop("method", "welch")
    # Permet de contrôler l'activation de la normalisation via la configuration
    normalize = bool(effective_config.pop("normalize", False))
    # Supprime la configuration des bandes pour ne pas dupliquer l'information
    effective_config.pop("bands", None)
    # Capture les noms de canaux pour aligner les étiquettes de features
    channel_names: Sequence[str] = getattr(epochs.info, "ch_names", [])
    # Extrait les données temporelles pour calculer les caractéristiques spectrales
    data: np.ndarray = epochs.get_data()
    # Récupère la fréquence d'échantillonnage indispensable au calcul fréquentiel
    sfreq: float = float(epochs.info["sfreq"])
    # Construit un extracteur scikit-learn pour déléguer le calcul
    estimator = ExtractFeatures(
        sfreq=sfreq,
        feature_strategy=method,
        normalize=normalize,
        bands=band_ranges,
        strategy_config=effective_config,
    )
    # Calcule les features en déléguant à l'extracteur scikit-learn
    features = estimator.transform(data)
    # Détermine le nombre de bandes pour reconstruire les étiquettes
    n_bands = len(band_ranges)
    # Recompose un tenseur factice pour générer les étiquettes canal/bande
    stacked = features.reshape(data.shape[1], n_bands)
    # Construit des étiquettes canal_bande pour interpréter les features
    labels: List[str] = _build_labels(stacked, band_ranges, channel_names)
    # Retourne les features tabulaires accompagnés de leurs étiquettes
    return features, labels


def x_extract_features__mutmut_87(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = dict(config or {})
    # Déclare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = {
        "theta": (4.0, 7.0),
        "alpha": (8.0, 12.0),
        "beta": (13.0, 30.0),
        "gamma": (31.0, 45.0),
    }
    # Fusionne les bandes personnalisées en conservant l'ordre demandé
    band_ranges: Dict[str, Tuple[float, float]] = _resolve_band_ranges(
        effective_config, default_bands
    )
    # Refuse une configuration vide pour éviter un empilement sans bandes
    if not band_ranges:
        raise ValueError("At least one frequency band must be provided.")
    # Récupère la méthode pour aiguiller la stratégie d'extraction
    method: str = effective_config.pop("method", "welch")
    # Permet de contrôler l'activation de la normalisation via la configuration
    normalize = bool(effective_config.pop("normalize", False))
    # Supprime la configuration des bandes pour ne pas dupliquer l'information
    effective_config.pop("bands", None)
    # Capture les noms de canaux pour aligner les étiquettes de features
    channel_names: Sequence[str] = getattr(epochs.info, "ch_names", [])
    # Extrait les données temporelles pour calculer les caractéristiques spectrales
    data: np.ndarray = epochs.get_data()
    # Récupère la fréquence d'échantillonnage indispensable au calcul fréquentiel
    sfreq: float = float(epochs.info["sfreq"])
    # Construit un extracteur scikit-learn pour déléguer le calcul
    estimator = ExtractFeatures(
        sfreq=sfreq,
        feature_strategy=method,
        normalize=normalize,
        bands=band_ranges,
        strategy_config=effective_config,
    )
    # Calcule les features en déléguant à l'extracteur scikit-learn
    features = estimator.transform(data)
    # Détermine le nombre de bandes pour reconstruire les étiquettes
    n_bands = len(band_ranges)
    # Recompose un tenseur factice pour générer les étiquettes canal/bande
    stacked = features.reshape(features.shape[0], n_bands)
    # Construit des étiquettes canal_bande pour interpréter les features
    labels: List[str] = _build_labels(stacked, band_ranges, channel_names)
    # Retourne les features tabulaires accompagnés de leurs étiquettes
    return features, labels


def x_extract_features__mutmut_88(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = dict(config or {})
    # Déclare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = {
        "theta": (4.0, 7.0),
        "alpha": (8.0, 12.0),
        "beta": (13.0, 30.0),
        "gamma": (31.0, 45.0),
    }
    # Fusionne les bandes personnalisées en conservant l'ordre demandé
    band_ranges: Dict[str, Tuple[float, float]] = _resolve_band_ranges(
        effective_config, default_bands
    )
    # Refuse une configuration vide pour éviter un empilement sans bandes
    if not band_ranges:
        raise ValueError("At least one frequency band must be provided.")
    # Récupère la méthode pour aiguiller la stratégie d'extraction
    method: str = effective_config.pop("method", "welch")
    # Permet de contrôler l'activation de la normalisation via la configuration
    normalize = bool(effective_config.pop("normalize", False))
    # Supprime la configuration des bandes pour ne pas dupliquer l'information
    effective_config.pop("bands", None)
    # Capture les noms de canaux pour aligner les étiquettes de features
    channel_names: Sequence[str] = getattr(epochs.info, "ch_names", [])
    # Extrait les données temporelles pour calculer les caractéristiques spectrales
    data: np.ndarray = epochs.get_data()
    # Récupère la fréquence d'échantillonnage indispensable au calcul fréquentiel
    sfreq: float = float(epochs.info["sfreq"])
    # Construit un extracteur scikit-learn pour déléguer le calcul
    estimator = ExtractFeatures(
        sfreq=sfreq,
        feature_strategy=method,
        normalize=normalize,
        bands=band_ranges,
        strategy_config=effective_config,
    )
    # Calcule les features en déléguant à l'extracteur scikit-learn
    features = estimator.transform(data)
    # Détermine le nombre de bandes pour reconstruire les étiquettes
    n_bands = len(band_ranges)
    # Recompose un tenseur factice pour générer les étiquettes canal/bande
    stacked = features.reshape(features.shape[0], data.shape[1], )
    # Construit des étiquettes canal_bande pour interpréter les features
    labels: List[str] = _build_labels(stacked, band_ranges, channel_names)
    # Retourne les features tabulaires accompagnés de leurs étiquettes
    return features, labels


def x_extract_features__mutmut_89(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = dict(config or {})
    # Déclare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = {
        "theta": (4.0, 7.0),
        "alpha": (8.0, 12.0),
        "beta": (13.0, 30.0),
        "gamma": (31.0, 45.0),
    }
    # Fusionne les bandes personnalisées en conservant l'ordre demandé
    band_ranges: Dict[str, Tuple[float, float]] = _resolve_band_ranges(
        effective_config, default_bands
    )
    # Refuse une configuration vide pour éviter un empilement sans bandes
    if not band_ranges:
        raise ValueError("At least one frequency band must be provided.")
    # Récupère la méthode pour aiguiller la stratégie d'extraction
    method: str = effective_config.pop("method", "welch")
    # Permet de contrôler l'activation de la normalisation via la configuration
    normalize = bool(effective_config.pop("normalize", False))
    # Supprime la configuration des bandes pour ne pas dupliquer l'information
    effective_config.pop("bands", None)
    # Capture les noms de canaux pour aligner les étiquettes de features
    channel_names: Sequence[str] = getattr(epochs.info, "ch_names", [])
    # Extrait les données temporelles pour calculer les caractéristiques spectrales
    data: np.ndarray = epochs.get_data()
    # Récupère la fréquence d'échantillonnage indispensable au calcul fréquentiel
    sfreq: float = float(epochs.info["sfreq"])
    # Construit un extracteur scikit-learn pour déléguer le calcul
    estimator = ExtractFeatures(
        sfreq=sfreq,
        feature_strategy=method,
        normalize=normalize,
        bands=band_ranges,
        strategy_config=effective_config,
    )
    # Calcule les features en déléguant à l'extracteur scikit-learn
    features = estimator.transform(data)
    # Détermine le nombre de bandes pour reconstruire les étiquettes
    n_bands = len(band_ranges)
    # Recompose un tenseur factice pour générer les étiquettes canal/bande
    stacked = features.reshape(features.shape[1], data.shape[1], n_bands)
    # Construit des étiquettes canal_bande pour interpréter les features
    labels: List[str] = _build_labels(stacked, band_ranges, channel_names)
    # Retourne les features tabulaires accompagnés de leurs étiquettes
    return features, labels


def x_extract_features__mutmut_90(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = dict(config or {})
    # Déclare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = {
        "theta": (4.0, 7.0),
        "alpha": (8.0, 12.0),
        "beta": (13.0, 30.0),
        "gamma": (31.0, 45.0),
    }
    # Fusionne les bandes personnalisées en conservant l'ordre demandé
    band_ranges: Dict[str, Tuple[float, float]] = _resolve_band_ranges(
        effective_config, default_bands
    )
    # Refuse une configuration vide pour éviter un empilement sans bandes
    if not band_ranges:
        raise ValueError("At least one frequency band must be provided.")
    # Récupère la méthode pour aiguiller la stratégie d'extraction
    method: str = effective_config.pop("method", "welch")
    # Permet de contrôler l'activation de la normalisation via la configuration
    normalize = bool(effective_config.pop("normalize", False))
    # Supprime la configuration des bandes pour ne pas dupliquer l'information
    effective_config.pop("bands", None)
    # Capture les noms de canaux pour aligner les étiquettes de features
    channel_names: Sequence[str] = getattr(epochs.info, "ch_names", [])
    # Extrait les données temporelles pour calculer les caractéristiques spectrales
    data: np.ndarray = epochs.get_data()
    # Récupère la fréquence d'échantillonnage indispensable au calcul fréquentiel
    sfreq: float = float(epochs.info["sfreq"])
    # Construit un extracteur scikit-learn pour déléguer le calcul
    estimator = ExtractFeatures(
        sfreq=sfreq,
        feature_strategy=method,
        normalize=normalize,
        bands=band_ranges,
        strategy_config=effective_config,
    )
    # Calcule les features en déléguant à l'extracteur scikit-learn
    features = estimator.transform(data)
    # Détermine le nombre de bandes pour reconstruire les étiquettes
    n_bands = len(band_ranges)
    # Recompose un tenseur factice pour générer les étiquettes canal/bande
    stacked = features.reshape(features.shape[0], data.shape[2], n_bands)
    # Construit des étiquettes canal_bande pour interpréter les features
    labels: List[str] = _build_labels(stacked, band_ranges, channel_names)
    # Retourne les features tabulaires accompagnés de leurs étiquettes
    return features, labels


def x_extract_features__mutmut_91(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = dict(config or {})
    # Déclare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = {
        "theta": (4.0, 7.0),
        "alpha": (8.0, 12.0),
        "beta": (13.0, 30.0),
        "gamma": (31.0, 45.0),
    }
    # Fusionne les bandes personnalisées en conservant l'ordre demandé
    band_ranges: Dict[str, Tuple[float, float]] = _resolve_band_ranges(
        effective_config, default_bands
    )
    # Refuse une configuration vide pour éviter un empilement sans bandes
    if not band_ranges:
        raise ValueError("At least one frequency band must be provided.")
    # Récupère la méthode pour aiguiller la stratégie d'extraction
    method: str = effective_config.pop("method", "welch")
    # Permet de contrôler l'activation de la normalisation via la configuration
    normalize = bool(effective_config.pop("normalize", False))
    # Supprime la configuration des bandes pour ne pas dupliquer l'information
    effective_config.pop("bands", None)
    # Capture les noms de canaux pour aligner les étiquettes de features
    channel_names: Sequence[str] = getattr(epochs.info, "ch_names", [])
    # Extrait les données temporelles pour calculer les caractéristiques spectrales
    data: np.ndarray = epochs.get_data()
    # Récupère la fréquence d'échantillonnage indispensable au calcul fréquentiel
    sfreq: float = float(epochs.info["sfreq"])
    # Construit un extracteur scikit-learn pour déléguer le calcul
    estimator = ExtractFeatures(
        sfreq=sfreq,
        feature_strategy=method,
        normalize=normalize,
        bands=band_ranges,
        strategy_config=effective_config,
    )
    # Calcule les features en déléguant à l'extracteur scikit-learn
    features = estimator.transform(data)
    # Détermine le nombre de bandes pour reconstruire les étiquettes
    n_bands = len(band_ranges)
    # Recompose un tenseur factice pour générer les étiquettes canal/bande
    stacked = features.reshape(features.shape[0], data.shape[1], n_bands)
    # Construit des étiquettes canal_bande pour interpréter les features
    labels: List[str] = None
    # Retourne les features tabulaires accompagnés de leurs étiquettes
    return features, labels


def x_extract_features__mutmut_92(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = dict(config or {})
    # Déclare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = {
        "theta": (4.0, 7.0),
        "alpha": (8.0, 12.0),
        "beta": (13.0, 30.0),
        "gamma": (31.0, 45.0),
    }
    # Fusionne les bandes personnalisées en conservant l'ordre demandé
    band_ranges: Dict[str, Tuple[float, float]] = _resolve_band_ranges(
        effective_config, default_bands
    )
    # Refuse une configuration vide pour éviter un empilement sans bandes
    if not band_ranges:
        raise ValueError("At least one frequency band must be provided.")
    # Récupère la méthode pour aiguiller la stratégie d'extraction
    method: str = effective_config.pop("method", "welch")
    # Permet de contrôler l'activation de la normalisation via la configuration
    normalize = bool(effective_config.pop("normalize", False))
    # Supprime la configuration des bandes pour ne pas dupliquer l'information
    effective_config.pop("bands", None)
    # Capture les noms de canaux pour aligner les étiquettes de features
    channel_names: Sequence[str] = getattr(epochs.info, "ch_names", [])
    # Extrait les données temporelles pour calculer les caractéristiques spectrales
    data: np.ndarray = epochs.get_data()
    # Récupère la fréquence d'échantillonnage indispensable au calcul fréquentiel
    sfreq: float = float(epochs.info["sfreq"])
    # Construit un extracteur scikit-learn pour déléguer le calcul
    estimator = ExtractFeatures(
        sfreq=sfreq,
        feature_strategy=method,
        normalize=normalize,
        bands=band_ranges,
        strategy_config=effective_config,
    )
    # Calcule les features en déléguant à l'extracteur scikit-learn
    features = estimator.transform(data)
    # Détermine le nombre de bandes pour reconstruire les étiquettes
    n_bands = len(band_ranges)
    # Recompose un tenseur factice pour générer les étiquettes canal/bande
    stacked = features.reshape(features.shape[0], data.shape[1], n_bands)
    # Construit des étiquettes canal_bande pour interpréter les features
    labels: List[str] = _build_labels(None, band_ranges, channel_names)
    # Retourne les features tabulaires accompagnés de leurs étiquettes
    return features, labels


def x_extract_features__mutmut_93(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = dict(config or {})
    # Déclare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = {
        "theta": (4.0, 7.0),
        "alpha": (8.0, 12.0),
        "beta": (13.0, 30.0),
        "gamma": (31.0, 45.0),
    }
    # Fusionne les bandes personnalisées en conservant l'ordre demandé
    band_ranges: Dict[str, Tuple[float, float]] = _resolve_band_ranges(
        effective_config, default_bands
    )
    # Refuse une configuration vide pour éviter un empilement sans bandes
    if not band_ranges:
        raise ValueError("At least one frequency band must be provided.")
    # Récupère la méthode pour aiguiller la stratégie d'extraction
    method: str = effective_config.pop("method", "welch")
    # Permet de contrôler l'activation de la normalisation via la configuration
    normalize = bool(effective_config.pop("normalize", False))
    # Supprime la configuration des bandes pour ne pas dupliquer l'information
    effective_config.pop("bands", None)
    # Capture les noms de canaux pour aligner les étiquettes de features
    channel_names: Sequence[str] = getattr(epochs.info, "ch_names", [])
    # Extrait les données temporelles pour calculer les caractéristiques spectrales
    data: np.ndarray = epochs.get_data()
    # Récupère la fréquence d'échantillonnage indispensable au calcul fréquentiel
    sfreq: float = float(epochs.info["sfreq"])
    # Construit un extracteur scikit-learn pour déléguer le calcul
    estimator = ExtractFeatures(
        sfreq=sfreq,
        feature_strategy=method,
        normalize=normalize,
        bands=band_ranges,
        strategy_config=effective_config,
    )
    # Calcule les features en déléguant à l'extracteur scikit-learn
    features = estimator.transform(data)
    # Détermine le nombre de bandes pour reconstruire les étiquettes
    n_bands = len(band_ranges)
    # Recompose un tenseur factice pour générer les étiquettes canal/bande
    stacked = features.reshape(features.shape[0], data.shape[1], n_bands)
    # Construit des étiquettes canal_bande pour interpréter les features
    labels: List[str] = _build_labels(stacked, None, channel_names)
    # Retourne les features tabulaires accompagnés de leurs étiquettes
    return features, labels


def x_extract_features__mutmut_94(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = dict(config or {})
    # Déclare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = {
        "theta": (4.0, 7.0),
        "alpha": (8.0, 12.0),
        "beta": (13.0, 30.0),
        "gamma": (31.0, 45.0),
    }
    # Fusionne les bandes personnalisées en conservant l'ordre demandé
    band_ranges: Dict[str, Tuple[float, float]] = _resolve_band_ranges(
        effective_config, default_bands
    )
    # Refuse une configuration vide pour éviter un empilement sans bandes
    if not band_ranges:
        raise ValueError("At least one frequency band must be provided.")
    # Récupère la méthode pour aiguiller la stratégie d'extraction
    method: str = effective_config.pop("method", "welch")
    # Permet de contrôler l'activation de la normalisation via la configuration
    normalize = bool(effective_config.pop("normalize", False))
    # Supprime la configuration des bandes pour ne pas dupliquer l'information
    effective_config.pop("bands", None)
    # Capture les noms de canaux pour aligner les étiquettes de features
    channel_names: Sequence[str] = getattr(epochs.info, "ch_names", [])
    # Extrait les données temporelles pour calculer les caractéristiques spectrales
    data: np.ndarray = epochs.get_data()
    # Récupère la fréquence d'échantillonnage indispensable au calcul fréquentiel
    sfreq: float = float(epochs.info["sfreq"])
    # Construit un extracteur scikit-learn pour déléguer le calcul
    estimator = ExtractFeatures(
        sfreq=sfreq,
        feature_strategy=method,
        normalize=normalize,
        bands=band_ranges,
        strategy_config=effective_config,
    )
    # Calcule les features en déléguant à l'extracteur scikit-learn
    features = estimator.transform(data)
    # Détermine le nombre de bandes pour reconstruire les étiquettes
    n_bands = len(band_ranges)
    # Recompose un tenseur factice pour générer les étiquettes canal/bande
    stacked = features.reshape(features.shape[0], data.shape[1], n_bands)
    # Construit des étiquettes canal_bande pour interpréter les features
    labels: List[str] = _build_labels(stacked, band_ranges, None)
    # Retourne les features tabulaires accompagnés de leurs étiquettes
    return features, labels


def x_extract_features__mutmut_95(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = dict(config or {})
    # Déclare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = {
        "theta": (4.0, 7.0),
        "alpha": (8.0, 12.0),
        "beta": (13.0, 30.0),
        "gamma": (31.0, 45.0),
    }
    # Fusionne les bandes personnalisées en conservant l'ordre demandé
    band_ranges: Dict[str, Tuple[float, float]] = _resolve_band_ranges(
        effective_config, default_bands
    )
    # Refuse une configuration vide pour éviter un empilement sans bandes
    if not band_ranges:
        raise ValueError("At least one frequency band must be provided.")
    # Récupère la méthode pour aiguiller la stratégie d'extraction
    method: str = effective_config.pop("method", "welch")
    # Permet de contrôler l'activation de la normalisation via la configuration
    normalize = bool(effective_config.pop("normalize", False))
    # Supprime la configuration des bandes pour ne pas dupliquer l'information
    effective_config.pop("bands", None)
    # Capture les noms de canaux pour aligner les étiquettes de features
    channel_names: Sequence[str] = getattr(epochs.info, "ch_names", [])
    # Extrait les données temporelles pour calculer les caractéristiques spectrales
    data: np.ndarray = epochs.get_data()
    # Récupère la fréquence d'échantillonnage indispensable au calcul fréquentiel
    sfreq: float = float(epochs.info["sfreq"])
    # Construit un extracteur scikit-learn pour déléguer le calcul
    estimator = ExtractFeatures(
        sfreq=sfreq,
        feature_strategy=method,
        normalize=normalize,
        bands=band_ranges,
        strategy_config=effective_config,
    )
    # Calcule les features en déléguant à l'extracteur scikit-learn
    features = estimator.transform(data)
    # Détermine le nombre de bandes pour reconstruire les étiquettes
    n_bands = len(band_ranges)
    # Recompose un tenseur factice pour générer les étiquettes canal/bande
    stacked = features.reshape(features.shape[0], data.shape[1], n_bands)
    # Construit des étiquettes canal_bande pour interpréter les features
    labels: List[str] = _build_labels(band_ranges, channel_names)
    # Retourne les features tabulaires accompagnés de leurs étiquettes
    return features, labels


def x_extract_features__mutmut_96(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = dict(config or {})
    # Déclare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = {
        "theta": (4.0, 7.0),
        "alpha": (8.0, 12.0),
        "beta": (13.0, 30.0),
        "gamma": (31.0, 45.0),
    }
    # Fusionne les bandes personnalisées en conservant l'ordre demandé
    band_ranges: Dict[str, Tuple[float, float]] = _resolve_band_ranges(
        effective_config, default_bands
    )
    # Refuse une configuration vide pour éviter un empilement sans bandes
    if not band_ranges:
        raise ValueError("At least one frequency band must be provided.")
    # Récupère la méthode pour aiguiller la stratégie d'extraction
    method: str = effective_config.pop("method", "welch")
    # Permet de contrôler l'activation de la normalisation via la configuration
    normalize = bool(effective_config.pop("normalize", False))
    # Supprime la configuration des bandes pour ne pas dupliquer l'information
    effective_config.pop("bands", None)
    # Capture les noms de canaux pour aligner les étiquettes de features
    channel_names: Sequence[str] = getattr(epochs.info, "ch_names", [])
    # Extrait les données temporelles pour calculer les caractéristiques spectrales
    data: np.ndarray = epochs.get_data()
    # Récupère la fréquence d'échantillonnage indispensable au calcul fréquentiel
    sfreq: float = float(epochs.info["sfreq"])
    # Construit un extracteur scikit-learn pour déléguer le calcul
    estimator = ExtractFeatures(
        sfreq=sfreq,
        feature_strategy=method,
        normalize=normalize,
        bands=band_ranges,
        strategy_config=effective_config,
    )
    # Calcule les features en déléguant à l'extracteur scikit-learn
    features = estimator.transform(data)
    # Détermine le nombre de bandes pour reconstruire les étiquettes
    n_bands = len(band_ranges)
    # Recompose un tenseur factice pour générer les étiquettes canal/bande
    stacked = features.reshape(features.shape[0], data.shape[1], n_bands)
    # Construit des étiquettes canal_bande pour interpréter les features
    labels: List[str] = _build_labels(stacked, channel_names)
    # Retourne les features tabulaires accompagnés de leurs étiquettes
    return features, labels


def x_extract_features__mutmut_97(
    epochs: Any,
    config: Mapping[str, Any] | None = None,
) -> Tuple[np.ndarray, List[str]]:
    """Compute band power features from epochs with configurable PSD options."""

    # Stocke une configuration vide lorsque l'appelant ne fournit rien
    effective_config: Dict[str, Any] = dict(config or {})
    # Déclare les bandes EEG usuelles pour guider l'extraction
    default_bands: Dict[str, Tuple[float, float]] = {
        "theta": (4.0, 7.0),
        "alpha": (8.0, 12.0),
        "beta": (13.0, 30.0),
        "gamma": (31.0, 45.0),
    }
    # Fusionne les bandes personnalisées en conservant l'ordre demandé
    band_ranges: Dict[str, Tuple[float, float]] = _resolve_band_ranges(
        effective_config, default_bands
    )
    # Refuse une configuration vide pour éviter un empilement sans bandes
    if not band_ranges:
        raise ValueError("At least one frequency band must be provided.")
    # Récupère la méthode pour aiguiller la stratégie d'extraction
    method: str = effective_config.pop("method", "welch")
    # Permet de contrôler l'activation de la normalisation via la configuration
    normalize = bool(effective_config.pop("normalize", False))
    # Supprime la configuration des bandes pour ne pas dupliquer l'information
    effective_config.pop("bands", None)
    # Capture les noms de canaux pour aligner les étiquettes de features
    channel_names: Sequence[str] = getattr(epochs.info, "ch_names", [])
    # Extrait les données temporelles pour calculer les caractéristiques spectrales
    data: np.ndarray = epochs.get_data()
    # Récupère la fréquence d'échantillonnage indispensable au calcul fréquentiel
    sfreq: float = float(epochs.info["sfreq"])
    # Construit un extracteur scikit-learn pour déléguer le calcul
    estimator = ExtractFeatures(
        sfreq=sfreq,
        feature_strategy=method,
        normalize=normalize,
        bands=band_ranges,
        strategy_config=effective_config,
    )
    # Calcule les features en déléguant à l'extracteur scikit-learn
    features = estimator.transform(data)
    # Détermine le nombre de bandes pour reconstruire les étiquettes
    n_bands = len(band_ranges)
    # Recompose un tenseur factice pour générer les étiquettes canal/bande
    stacked = features.reshape(features.shape[0], data.shape[1], n_bands)
    # Construit des étiquettes canal_bande pour interpréter les features
    labels: List[str] = _build_labels(stacked, band_ranges, )
    # Retourne les features tabulaires accompagnés de leurs étiquettes
    return features, labels

x_extract_features__mutmut_mutants : ClassVar[MutantDict] = {
'x_extract_features__mutmut_1': x_extract_features__mutmut_1, 
    'x_extract_features__mutmut_2': x_extract_features__mutmut_2, 
    'x_extract_features__mutmut_3': x_extract_features__mutmut_3, 
    'x_extract_features__mutmut_4': x_extract_features__mutmut_4, 
    'x_extract_features__mutmut_5': x_extract_features__mutmut_5, 
    'x_extract_features__mutmut_6': x_extract_features__mutmut_6, 
    'x_extract_features__mutmut_7': x_extract_features__mutmut_7, 
    'x_extract_features__mutmut_8': x_extract_features__mutmut_8, 
    'x_extract_features__mutmut_9': x_extract_features__mutmut_9, 
    'x_extract_features__mutmut_10': x_extract_features__mutmut_10, 
    'x_extract_features__mutmut_11': x_extract_features__mutmut_11, 
    'x_extract_features__mutmut_12': x_extract_features__mutmut_12, 
    'x_extract_features__mutmut_13': x_extract_features__mutmut_13, 
    'x_extract_features__mutmut_14': x_extract_features__mutmut_14, 
    'x_extract_features__mutmut_15': x_extract_features__mutmut_15, 
    'x_extract_features__mutmut_16': x_extract_features__mutmut_16, 
    'x_extract_features__mutmut_17': x_extract_features__mutmut_17, 
    'x_extract_features__mutmut_18': x_extract_features__mutmut_18, 
    'x_extract_features__mutmut_19': x_extract_features__mutmut_19, 
    'x_extract_features__mutmut_20': x_extract_features__mutmut_20, 
    'x_extract_features__mutmut_21': x_extract_features__mutmut_21, 
    'x_extract_features__mutmut_22': x_extract_features__mutmut_22, 
    'x_extract_features__mutmut_23': x_extract_features__mutmut_23, 
    'x_extract_features__mutmut_24': x_extract_features__mutmut_24, 
    'x_extract_features__mutmut_25': x_extract_features__mutmut_25, 
    'x_extract_features__mutmut_26': x_extract_features__mutmut_26, 
    'x_extract_features__mutmut_27': x_extract_features__mutmut_27, 
    'x_extract_features__mutmut_28': x_extract_features__mutmut_28, 
    'x_extract_features__mutmut_29': x_extract_features__mutmut_29, 
    'x_extract_features__mutmut_30': x_extract_features__mutmut_30, 
    'x_extract_features__mutmut_31': x_extract_features__mutmut_31, 
    'x_extract_features__mutmut_32': x_extract_features__mutmut_32, 
    'x_extract_features__mutmut_33': x_extract_features__mutmut_33, 
    'x_extract_features__mutmut_34': x_extract_features__mutmut_34, 
    'x_extract_features__mutmut_35': x_extract_features__mutmut_35, 
    'x_extract_features__mutmut_36': x_extract_features__mutmut_36, 
    'x_extract_features__mutmut_37': x_extract_features__mutmut_37, 
    'x_extract_features__mutmut_38': x_extract_features__mutmut_38, 
    'x_extract_features__mutmut_39': x_extract_features__mutmut_39, 
    'x_extract_features__mutmut_40': x_extract_features__mutmut_40, 
    'x_extract_features__mutmut_41': x_extract_features__mutmut_41, 
    'x_extract_features__mutmut_42': x_extract_features__mutmut_42, 
    'x_extract_features__mutmut_43': x_extract_features__mutmut_43, 
    'x_extract_features__mutmut_44': x_extract_features__mutmut_44, 
    'x_extract_features__mutmut_45': x_extract_features__mutmut_45, 
    'x_extract_features__mutmut_46': x_extract_features__mutmut_46, 
    'x_extract_features__mutmut_47': x_extract_features__mutmut_47, 
    'x_extract_features__mutmut_48': x_extract_features__mutmut_48, 
    'x_extract_features__mutmut_49': x_extract_features__mutmut_49, 
    'x_extract_features__mutmut_50': x_extract_features__mutmut_50, 
    'x_extract_features__mutmut_51': x_extract_features__mutmut_51, 
    'x_extract_features__mutmut_52': x_extract_features__mutmut_52, 
    'x_extract_features__mutmut_53': x_extract_features__mutmut_53, 
    'x_extract_features__mutmut_54': x_extract_features__mutmut_54, 
    'x_extract_features__mutmut_55': x_extract_features__mutmut_55, 
    'x_extract_features__mutmut_56': x_extract_features__mutmut_56, 
    'x_extract_features__mutmut_57': x_extract_features__mutmut_57, 
    'x_extract_features__mutmut_58': x_extract_features__mutmut_58, 
    'x_extract_features__mutmut_59': x_extract_features__mutmut_59, 
    'x_extract_features__mutmut_60': x_extract_features__mutmut_60, 
    'x_extract_features__mutmut_61': x_extract_features__mutmut_61, 
    'x_extract_features__mutmut_62': x_extract_features__mutmut_62, 
    'x_extract_features__mutmut_63': x_extract_features__mutmut_63, 
    'x_extract_features__mutmut_64': x_extract_features__mutmut_64, 
    'x_extract_features__mutmut_65': x_extract_features__mutmut_65, 
    'x_extract_features__mutmut_66': x_extract_features__mutmut_66, 
    'x_extract_features__mutmut_67': x_extract_features__mutmut_67, 
    'x_extract_features__mutmut_68': x_extract_features__mutmut_68, 
    'x_extract_features__mutmut_69': x_extract_features__mutmut_69, 
    'x_extract_features__mutmut_70': x_extract_features__mutmut_70, 
    'x_extract_features__mutmut_71': x_extract_features__mutmut_71, 
    'x_extract_features__mutmut_72': x_extract_features__mutmut_72, 
    'x_extract_features__mutmut_73': x_extract_features__mutmut_73, 
    'x_extract_features__mutmut_74': x_extract_features__mutmut_74, 
    'x_extract_features__mutmut_75': x_extract_features__mutmut_75, 
    'x_extract_features__mutmut_76': x_extract_features__mutmut_76, 
    'x_extract_features__mutmut_77': x_extract_features__mutmut_77, 
    'x_extract_features__mutmut_78': x_extract_features__mutmut_78, 
    'x_extract_features__mutmut_79': x_extract_features__mutmut_79, 
    'x_extract_features__mutmut_80': x_extract_features__mutmut_80, 
    'x_extract_features__mutmut_81': x_extract_features__mutmut_81, 
    'x_extract_features__mutmut_82': x_extract_features__mutmut_82, 
    'x_extract_features__mutmut_83': x_extract_features__mutmut_83, 
    'x_extract_features__mutmut_84': x_extract_features__mutmut_84, 
    'x_extract_features__mutmut_85': x_extract_features__mutmut_85, 
    'x_extract_features__mutmut_86': x_extract_features__mutmut_86, 
    'x_extract_features__mutmut_87': x_extract_features__mutmut_87, 
    'x_extract_features__mutmut_88': x_extract_features__mutmut_88, 
    'x_extract_features__mutmut_89': x_extract_features__mutmut_89, 
    'x_extract_features__mutmut_90': x_extract_features__mutmut_90, 
    'x_extract_features__mutmut_91': x_extract_features__mutmut_91, 
    'x_extract_features__mutmut_92': x_extract_features__mutmut_92, 
    'x_extract_features__mutmut_93': x_extract_features__mutmut_93, 
    'x_extract_features__mutmut_94': x_extract_features__mutmut_94, 
    'x_extract_features__mutmut_95': x_extract_features__mutmut_95, 
    'x_extract_features__mutmut_96': x_extract_features__mutmut_96, 
    'x_extract_features__mutmut_97': x_extract_features__mutmut_97
}

def extract_features(*args, **kwargs):
    result = _mutmut_trampoline(x_extract_features__mutmut_orig, x_extract_features__mutmut_mutants, args, kwargs)
    return result 

extract_features.__signature__ = _mutmut_signature(x_extract_features__mutmut_orig)
x_extract_features__mutmut_orig.__name__ = 'x_extract_features'
